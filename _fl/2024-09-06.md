---
title: 連合学習 (2024-09-06 ~ 2024-09-12)
date: 2024-09-06
---

連合学習に関する論文まとめ (2024-09-06 ~ 2024-09-12)


- - -

### [Advancing Hybrid Defense for Byzantine Attacks in Federated Learning](http://arxiv.org/abs/2409.06474)

**連合学習におけるビザンチン攻撃へのハイブリッド防御の進展**

Kai Yue, Richeng Jin, Chau-Wai Wong, Huaiyu Dai

- 連合学習は複数のクライアントがデータを共有せずに共同でグローバルモデルを訓練
- 攻撃者戦略や悪意のあるクライアント数を事前に知らないFLシナリオでの攻撃耐性を調査
- 状況に応じた防御選択により、大量の毒性更新があってもサーバーの頑強性を立証
- 新しいTrapsetter攻撃は既存のFL防御をすり抜け、モデル精度をさらに8-10%低下

新しい防御メカニズムがくしゃみしないで強力ってすごいよね！まだまだ課題はいろいろあるけど、この研究を基にもっと安全な連合学習ができるようになるかもね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-09-10 13:04


- - -

### [Compute-Update Federated Learning: A Lattice Coding Approach](http://arxiv.org/abs/2409.06343)

**計算更新連合学習：格子符号化アプローチ**

Seyed Mohammad Azimi-Abarghouyi, Lav R. Varshney

- 無線通信を介した計算を可能にする新たな連合学習フレームワークを提案
- 格子符号を使い、モデルパラメータを量子化してデバイス間の干渉を活用
- サーバー上で量子化モデルパラメータの整数の組み合わせを格子点として集約する受信構造を提案
- 提案手法がさまざまなパラメータで一貫した学習精度を提供し、他の無線通信手法を上回ることを実証

格子符号化を使ってエラー訂正しながら連合学習するなんて、面白そう！通信状態が変わっても一貫して精度がいいってすごいね！

**Comment:** Extended version of the preprint available at arXiv:2403.01023

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.IT, cs.AI, cs.LG, math.IT, **投稿日時:** 2024-09-10 08:52


- - -

### [Rate-Constrained Quantization for Communication-Efficient Federated Learning](http://arxiv.org/abs/2409.06319)

**通信効率の高い連合学習のためのレート制約付き量子化**

Shayan Mohajer Hamidi, Ali Bereyhi

- 連合学習の通信コストを軽減するために量子化を使用する
- 量子化されたローカルパラメータはヒュフマン符号などのエントロピー符号化技術でさらに圧縮
- 新たな量子化FLフレームワーク「RC-FED」を提案し、信号忠実度とデータレートの両方を制約
- RC-FEDは、最適化を通じて量子化歪みを最小化しつつ通信コスト目標を下回ることを実現

量子化フレームワークであるRC-FEDの提案とか、通信コストを最適化しつつ精度も保つのめっちゃ面白そう！他の手法と比較してもパフォーマンスが良いなら期待できるよね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, eess.SP, **投稿日時:** 2024-09-10 08:22


- - -

### [On Applying Bandit Algorithm to Fault Localization Techniques](http://arxiv.org/abs/2409.06268)

**バンディットアルゴリズムの故障位置特定技術への適用について**

Masato Nakao, Kensei Hamamoto, Masateru Tsunoda, Amjed Tahir, Koji Toda, Akito Monden, Keitaro Nakasai, Kenichi Matsumoto

- 開発者は高性能な故障位置特定（FL）技術を選ぶ必要がある
- 伝統的な方法はデバッグ前に一つのFL技術を選ぶこと
- 本研究はデバッグ中に動的により良いFL技術を選択する新しい方法を提案
- 新しいアプローチは動的選択により性能向上が期待される

バンディットアルゴリズム使うのってなんかゲームみたいで面白そうじゃない？この新しいアプローチでデバッグがもっと楽になるといいね！

**Comment:** 2 pages, 2 figures, 1 table

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.SE, **投稿日時:** 2024-09-10 07:15


- - -

### [Contrastive Federated Learning with Tabular Data Silos](http://arxiv.org/abs/2409.06123)

**タブラー形式データサイロを用いた対照的連合学習**

Achmad Ginanjar, Xue Li, Wen Hua

- データサイロからの学習は、ラベル無し、独立非同分布(NIID)、垂直分割等の課題がある
- プライバシー保護が課題を複雑化し、協力的な作業の意欲を阻害
- 対照学習を用いてラベルコスト問題に対処するが、タブラー形式には適用困難
- 半教師付き対照的連合学習(CFL)を提案し、精度面での改善を実証

対照的連合学習がこれまでの方法より効果的だなんて、未来のデータ解析がもっと楽しみになるね！クライアント環境の複雑さも克服できるところがポイント高いね。

**Comment:** 18 Pages. Was submitted on Artificial Intelligence Journal, Jan 29,   2024, ARTINT-D-24-00098

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, 68A00, I.1.1, **投稿日時:** 2024-09-10 00:24


- - -

### [MLLM-FL: Multimodal Large Language Model Assisted Federated Learning on Heterogeneous and Long-tailed Data](http://arxiv.org/abs/2409.06067)

**MLLM-FL: 異質で長尾分布データにおけるマルチモーダル大規模言語モデルを活用した連合学習**

Jianyi Zhang, Hao Frank Yang, Ang Li, Xin Guo, Pu Wang, Haiming Wang, Yiran Chen, Hai Li

- 異なるクライアント間のデータの異質性により発生するパフォーマンス低下に焦点
- MLLMをサーバー側に導入し、異質性や長尾分布の課題に対応
- オープンソースデータと強力なサーバー計算資源を活用し、プライバシー漏洩や端末負担増加を回避
- 実験評価により、データの異質性や長尾分布下でのパフォーマンス向上を確認

MLLM使うとかめっちゃ面白そう！データ多様でもちゃんと学習できるってすごいなぁ。実際のアプリケーションでどう活かせるんだろうね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.AI, **投稿日時:** 2024-09-09 21:04


- - -

### [FLoRA: Federated Fine-Tuning Large Language Models with Heterogeneous Low-Rank Adaptations](http://arxiv.org/abs/2409.05976)

**FLoRA: 異質な低ランク適応による連合型大規模言語モデルの微調整**

Ziyao Wang, Zheyu Shen, Yexiao He, Guoheng Sun, Hongyi Wang, Lingjuan Lyu, Ang Li

- LLMの急速な発展がAIの進歩を促進し、連合学習によりプライバシーを保護しながら微調整を可能に
- クライアントのリソースに制約があるため、既存の低ランク適応手法は効果が低下
- FLORAという新しいアプローチを提案、スタッキングベースの集約方法で異質なLoRAアダプタ対応を実現
- 実験により、同質および異質の設定の両方で既存手法を上回る性能を示す

FLORAって、何だか未来的でワクワクするよね！プライバシーと効率性を両立できるなんて素敵✨



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-09-09 18:21


- - -

### [pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning](http://arxiv.org/abs/2409.05701)

**個別連合学習のための拡散ベース生成パラメータ集約：pFedGPA**

Jiahao Lai, Jiaqi Li, Jian Xu, Yanru Wu, Boshi Tang, Siqi Chen, Yongfeng Huang, Wenbo Ding, Yang Li

- 連合学習 (FL) は、データをローカルに保持しモデルパラメータのみを共有する分散アプローチ。
- 従来の線形集約方法（FedAvgなど）は、異質なデータ分布でのパラメータ空間の複雑さを見落とす可能性がある。
- 拡散モデルを使用し、サーバー上で多様なパラメータ分布を統合し、個別のパラメータ生成を提案。
- 提案手法（pFedGPA）は高次元拡散モデルを使用し、各クライアントのデータ分布依存を効果的に解消、実験で優れた性能を実証。

これはめっちゃ面白そう！これからの個別対応の連合学習の常識を変えるかもね。実績あるって心強いなー。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-09-09 15:13


- - -

### [HMAFlow: Learning More Accurate Optical Flow via Hierarchical Motion Field Alignment](http://arxiv.org/abs/2409.05531)

**HMAFlow: 階層的動きフィールド整合によるより正確なオプティカルフローの学習**

Dianbo Ma, Kousuke Imamura, Ziyan Gao, Xiangjie Wang, Satoshi Yamane

- オプティカルフロー推定を改良する新しい手法HMAFlowを提案
- 階層的動きフィールド整合モジュールと相関セルフアテンションモジュールを導入
- Multi-Scale Correlation Search層で4Dコストボリュームを再構築し精度向上
- RAFTと比較してSintelおよびKITTIベンチマークで誤差を大幅に削減

新しい手法でオプティカルフロー推定がずっと精度高くなるなんてすごいよね！コード公開も嬉しいし、これからの研究がさらに進展しそうで楽しみ～。

**Comment:** 11 pages, 6 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.AI, **投稿日時:** 2024-09-09 11:43


- - -

### [FedBrain-Distill: Communication-Efficient Federated Brain Tumor Classification Using Ensemble Knowledge Distillation on Non-IID Data](http://arxiv.org/abs/2409.05359)

**FedBrain-Distill: 非識別データに対するアンサンブル知識蒸留を用いた通信効率の良い連合型脳腫瘍分類**

Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour

- 頭部の複雑さにより、脳腫瘍の分類は依然として大きな課題である
- 連合学習（FL）がプライバシー保護を図るが、通信コストやモデルの依存性が問題
- 提案のFedBrain-Distillはアンサンブル知識蒸留でモデルの独立性とプライバシーを維持
- 実験結果は、現実世界のデータセットで高精度と低通信コストの両方を実証

脳腫瘍の分類ってめっちゃ難しいんだって。FedBrain-Distillなら通信コストもかからないし、色んなモデルを使えるってところが面白いね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-09-09 06:42


- - -

### [TriplePlay: Enhancing Federated Learning with CLIP for Non-IID Data and Resource Efficiency](http://arxiv.org/abs/2409.05347)

**TriplePlay: 非独立同一分布データとリソース効率のためのCLIPを用いた連合学習の強化**

Ahmed Imteaj, Md Zarif Hossain, Saika Zaman, Abdur R. Shahid

- 連合学習でCLIPのような大規模基盤モデルを統合して、プライバシー、効率性、適応性を向上
- 非IIDデータ分布、計算・通信の負荷、データセット内のクラスの偏りに焦点を当てている
- TriplePlayフレームワークを提案し、CLIPをアダプタとして統合し公平性とリソース要求を軽減
- シミュレーション結果はGPU使用コストの大幅削減と学習過程の高速化、通信オーバーヘッドの削減を示す

連合学習にCLIPを統合するなんて、すごく未来的でワクワクするね！効率性の課題も解決しそうだし、これからの研究が楽しみだな～。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-09-09 06:04


- - -

### [Towards Practical Overlay Networks for Decentralized Federated Learning](http://arxiv.org/abs/2409.05331)

**実用的な分散型連合学習のためのオーバーレイネットワークへの挑戦**

Yifan Hua, Jinlong Pang, Xiaoxue Zhang, Yi Liu, Xiaofeng Shi, Bao Wang, Yang Liu, Chen Qian

- 分散型連合学習（DFL）はピアツーピア通信を使用し、単一点故障問題を回避
- DFLのオーバーレイネットワークにおける高速トレーニングと低通信、分散型構築と保守の課題解決
- FedLayというネットワークを提案し、分散型で近似ランダムなレギュラートポロジーの構築とノード参加・故障時の維持を実現
- 実験ではFedLayが他のDFLソリューションと比較して最速のモデル収束、高精度、低通信コスト、ノードへの耐性を示した

分散型連合学習でオーバーレイネットワークの欠点を解決するFedLay、頼もしいよね！みんなのデバイスでの機械学習がもっとスムーズになる未来が楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.NI, **投稿日時:** 2024-09-09 05:20


- - -

### [FedFT: Improving Communication Performance for Federated Learning with Frequency Space Transformation](http://arxiv.org/abs/2409.05242)

**FedFT：周波数空間変換による連合学習の通信性能の向上**

Chamath Palihawadana, Nirmalie Wiratunga, Anjana Wijekoon, Harsha Kalutarage

- 連合学習における通信効率問題に対応するためのFedFTを提案
- モデルパラメータを離散コサイン変換（DCT）で周波数空間に変換し効率的に圧縮
- FedFTは既存の連合学習手法やニューラルアーキテクチャと互換性があり、線形特性を持つ
- 通信オーバーヘッドの削減とモデル精度の維持、時には向上が見られ、削減率はデータセットにより5%から30%ほど

周波数変換を使うことで効率的に通信コストを減らしてるのが面白そう！これで連合学習がもっと広がる可能性があるね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.AI, **投稿日時:** 2024-09-08 23:05


- - -

### [Some Results on Neural Network Stability, Consistency, and Convergence: Insights into Non-IID Data, High-Dimensional Settings, and Physics-Informed Neural Networks](http://arxiv.org/abs/2409.05030)

**ニューラルネットワークの安定性、一貫性、収束性に関するいくつかの結果：非IIDデータ、高次元設定、および物理情報ニューラルネットワークへの洞察**

Ronald Katende, Henry Kasumba, Godwin Kakuba, John M. Mango

- 非凸設定における動的学習率でのニューラルネットワークの一様安定性について新しい理論的結果を提供
- 分散シフトと曲率効果を考慮し、非ユークリッド空間での連合学習モデルの一貫性境界を確立
- 物理情報ニューラルネットワーク（PINNs）において、ノイズ環境下での偏微分方程式（PDE）の解法に対する安定性、一貫性、および収束性を保証
- 複雑で非理想的な条件下でのモデル挙動の理解における重要なギャップを埋め、より堅牢で信頼性の高い機械学習応用を実現するための道を開く

物理情報ニューラルネットワーク（PINNs）がノイズの中でもきちんと動くなんて未来が広がりそう！データの揺らぎが多いリアルな世界でも、深層学習モデルが信頼できるなんて素敵だね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.NA, math.NA, **投稿日時:** 2024-09-08 08:48


- - -

### [DynamicFL: Federated Learning with Dynamic Communication Resource Allocation](http://arxiv.org/abs/2409.04986)

**DynamicFL: ダイナミックな通信資源配分による連合学習**

Qi Le, Enmao Diao, Xinran Wang, Vahid Tarokh, Jie Ding, Ali Anwar

- 連合学習（FL）は、複数のユーザーがローカルデータを利用して分散的にモデルを訓練する枠組み
- ローカルデータの統計的不均一性がモデル性能を低下させる原因
- DynamicFLは、FedSGDとFedAvgの通信資源配分を動的に調整し、パフォーマンス向上を図る手法を提案
- 実験結果でモデルの精度が現行手法を最大10％上回ることを示し、DynamicFLの有効性を確認

通信リソースをうまく使いながら、性能も良くするなんてすごいと思う！どんな実験や条件でその結果になったのか、詳しく知りたいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-08 05:53


- - -

### [Balancing Security and Accuracy: A Novel Federated Learning Approach for Cyberattack Detection in Blockchain Networks](http://arxiv.org/abs/2409.04972)

**セキュリティと精度のバランス調整: ブロックチェーンネットワークにおけるサイバー攻撃検出のための新しい連合学習アプローチ**

Tran Viet Khoa, Mohammad Abu Alsheikh, Yibeltal Alem, Dinh Thai Hoang

- 新しいCollaborative Cyberattack Detection (CCD)システムを提案し、ブロックチェーンベースのデータ共有ネットワークのセキュリティを強化
- 差分プライバシーの理論を活用し、訓練済みのサブモデルにノイズを追加後、グローバルモデルを再構築
- ガウス、ラプラス、モーメントアカウンタなどのノイズの種類が性能指標に与える影響を体系的に調査
- データ保護とシステムの効率性の最適なバランスを達成するための実用的な推奨事項を提供

ブロックチェーンと連合学習が合わさると最強になりそう！データを守りながらも高い精度を維持するなんて未来が楽しみ！

**Comment:** 13 pages

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-09-08 04:38


- - -

### [Fair Allocation of Bandwidth At Edge Servers For Concurrent Hierarchical Federated Learning](http://arxiv.org/abs/2409.04921)

**エッジサーバでの同時階層連合学習のための公正な帯域幅割り当て**

Md Anwar Hossen, Fatema Siddika, Wensheng Zhang

- 三層システム内で同時連合学習プロセスを探る
- エッジデバイスからエッジサーバへの帯域幅が限られていることが課題
- ゲーム理論的アプローチで帯域幅割り当て問題をモデル化
- 分散型と集中型のヒューリスティックスキームが基準スキームを上回る

帯域幅割り当て問題を解決するこのゲーム理論的アプローチ、ちょっとかっこいいよね。集中型と分散型で競技力を持つって、実用性が高まりそうでワクワクする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.GT, **投稿日時:** 2024-09-07 22:03


- - -

### [Unlocking the Potential of Model Calibration in Federated Learning](http://arxiv.org/abs/2409.04901)

**連合学習におけるモデルキャリブレーションの可能性を解き放つ**

Yun-Wei Chu, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher Brinton

- 連合学習（FL）はモデル精度の向上を目的とするが、予測の信頼性が重要
- NUCFLというフレームワークでモデルキャリブレーションを統合
- データの異質性に対応するため、クライアントのローカルモデルとグローバルモデルの統計的関係を利用
- 実験でNUCFLがFLアルゴリズムで精度とモデルキャリブレーションの両方を向上させることを確認

モデルの信頼性も考慮するってすごく大事だよね！これで連合学習がもっと実用的になるかも。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-07 20:11


- - -

### [FedModule: A Modular Federated Learning Framework](http://arxiv.org/abs/2409.04849)

**FedModule: モジュラーフェデレーテッドラーニングフレームワーク**

Chuyi Chen, Zhe Zhang, Yanchao Zhao

- 連合学習がヘルスケアや金融、スマートシティなどで広く採用されている
- FedModuleは多様な連合学習パラダイムをサポートし、包括的なベンチマークを提供する
- モジュラー設計により、異なる連合学習パラダイムの統合が容易である
- 公開データセットでの実験により、FedModuleの柔軟性と拡張性が立証された

FedModuleの紹介を読んでみると、新しい実験がたくさんできそうでワクワクするね！他の連合学習ツールキットより優れているみたいだし、今後も注目しちゃお！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-09-07 15:03


- - -

### [Enhancing Quantum Security over Federated Learning via Post-Quantum Cryptography](http://arxiv.org/abs/2409.04637)

**連合学習における量子セキュリティ強化のためのポスト量子暗号の活用**

Pingzhi Li, Tianlong Chen, Junyu Liu

- 連合学習はエッジデバイス上で機械学習モデルを展開する標準的なアプローチ
- 伝達されるモデル更新が悪意ある改ざんに対して脆弱で、グローバルモデルの整合性にリスク
- ポスト量子暗号のNIST標準化アルゴリズム（Dilithium、FALCON、SPHINCS+）がこの脆弱性に対処
- デジタル署名においてDilithiumが最も効率的なポスト量子暗号アルゴリズムであることを実証

ポスト量子暗号に興味ある！これからの連合学習はもっと安心になるかもね。未来が楽しみ～！

**Comment:** Submission for IEEE 2024 IEEE Workshop on Quantum IntelLigence,   Learning & Security (QUILLS), https://sites.google.com/pitt.edu/quills/home

**トピック:** [連合学習](../../fl), **カテゴリ:** quant-ph, cs.AI, cs.CR, cs.LG, **投稿日時:** 2024-09-06 22:02


- - -

### [Active-Passive Federated Learning for Vertically Partitioned Multi-view Data](http://arxiv.org/abs/2409.04111)

**アクティブ-パッシブ連合学習による垂直分割されたマルチビューデータの処理**

Jiyuan Liu, Xinwang Liu, Siqi Wang, Xingchen Hu, Qing Liao, Xinhang Wan, Yi Zhang, Xin Lv, Kunlun He

- 垂直連合学習は、デバイス間で垂直分割されたマルチビューデータを統合し、プライバシーを保護しながら利用するアプローチ
- 既存の方法では、モデル推論においてすべてのクライアントの協力が必要であり、現実世界のシナリオでは困難が生じる可能性がある
- アクティブクライアントが学習タスクを開始し、完全なモデルを構築し、受動クライアントは補助役として機能する
- 再構築損失およびコントラスト損失を用いた2つの分類方法を実験でテストして望ましい結果を達成

垂直連合学習の新しい方法だね！クライアント間の協力が減るのはすごく便利だし、実践的だよね。なんか、これから色んな応用が考えられそうでワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-06 08:28


- - -

### [Heterogeneity-Aware Cooperative Federated Edge Learning with Adaptive Computation and Communication Compression](http://arxiv.org/abs/2409.04022)

**異質性対応型協調連合エッジ学習：適応計算および通信圧縮を用いたアプローチ**

Zhenxiao Zhang, Zhidong Gao, Yuanxiong Guo, Yanmin Gong

- クラウドベースの連合学習の欠点を改良するため、協調連合エッジ学習（CFEL）を提案
- CFELは動的かつ異質なデバイス特性による収束速度低下とリソース消費の増加に直面
- 適応計算と通信圧縮を用いてモデル精度を最大化しつつ、トレーニング時間とエネルギー消費を最小化
- HCEFはローカル更新頻度と圧縮率を動的に調整し、高いモデル精度を維持しつつトレーニング遅延とエネルギー効率を改善

協調するエッジサーバーがいっぱいあれば、もっと早く正確なモデルが作れるようになるんだね！こんな技術が普及したら、私たちの日常に役立つサービスももっとたくさん出てくるかも。

**Comment:** 20 pages, 7 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, **投稿日時:** 2024-09-06 04:26
