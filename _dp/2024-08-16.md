---
title: 差分プライバシー (2024-08-16 ~ 2024-08-22)
date: 2024-08-16
---

差分プライバシーに関する論文まとめ (2024-08-16 ~ 2024-08-22)


- - -

### [Calibrating Noise for Group Privacy in Subsampled Mechanisms](http://arxiv.org/abs/2408.09943)

**サブサンプリングメカニズムにおけるグループプライバシーのためのノイズ校正**

Yangfan Jiang, Xinjian Luo, Yin Yang, Xiaokui Xiao

- グループプライバシー(GP)は個々ではなくm人のグループの集約情報を保護する
- 従来の方法はディファレンシャルプライバシー(DP)からの変換だが、最適ではない
- 提案する新しい分析フレームワークは、サブサンプリングメカニズムのランダム性を活用
- 現実データを用いた実験で、ノイズ削減効果は従来法の一桁以上向上

グループ単位でのプライバシー保護って面白そうだね！これ、もっと多くのアプリケーションで応用できるかも！

**Comment:** accepted for publication in Proceedings of VLDB Endowment (PVLDB)   2025

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-08-19 12:32


- - -

### [Differential Private Stochastic Optimization with Heavy-tailed Data: Towards Optimal Rates](http://arxiv.org/abs/2408.09891)

**差分プライバシーを用いた重尾データの確率的最適化: 最適レートへの到達**

Puning Zhao, Jiafei Wu, Zhe Liu, Chong Wang, Rongfei Fan, Qingming Li

- 差分プライバシー下での凸最適化問題を研究し、既存のサブオプティマルレートを改善
- クリッピングアプローチにより、データの重尾勾配に対し最適レートを達成
- 反復的な更新方法が提案され、すべてのプライバシーパラメータ$\epsilon$に対して最適レートを実現
- 結果は理論的な下限を満たし、既存手法に比べ大幅な改善を示す

差分プライバシーで重尾データの問題がここまで改善されるなんてすごいね！このアプローチでさらに多くの課題がクリアされるといいな～。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DS, **投稿日時:** 2024-08-19 11:07


- - -

### [A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs](http://arxiv.org/abs/2408.08868)

**実践でのプライベート学習のための手間のかからないアルゴリズム: ツリー集約を使わずにBLTを使おう**

H. Brendan McMahan, Zheng Xu, Yanxiang Zhang

- ツリー集約はプライバシーと有用性のトレードオフが最適ではない
- 行列分解は事前に推定が難しい定数による高額な最適化と高い実行時メモリコストを要求
- 緩衝されたリニアトープリッツ(BLT)メカニズムを用い、マルチ参加シナリオでDP-FTRLを拡張
- BLT-DP-FTRLはツリー集約の使いやすさを保持しつつ、行列分解並みの有用性とプライバシーを実現

BLTメカニズム、なんだか効率良さそうで現実のアプリでもかなり使えそうだわ！スマホのキーボードでこれが使われたら入力がもっとプライベートで快適に!?



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-16 17:52


- - -

### [A Multivocal Literature Review on Privacy and Fairness in Federated Learning](http://arxiv.org/abs/2408.08666)

**連合学習におけるプライバシーと公平性に関する多面的文献レビュー**

Beatrice Balbierer, Lukas Heinlein, Domenique Zipperling, Niklas Kühl

- 連合学習はデータ共有なしでAI応用を革新するが、学習中に情報が抽出される可能性が示された
- 差分プライバシーなどの追加のプライバシー保護措置が必要である
- 高リスクな応用（例：医療）では過去の差別的なエラーを繰り返さないことが重要
- プライバシーと公平性の関係性が無視され、現実世界のアプリケーションに重大なリスクをもたらしている

プライバシーと公平性のバランスを取るって超難しそうだけど、やりがいがありそう。実際のアプリにも早く使われたらいいな！

**Comment:** Accepted for publication at the Internationale Tagung   Wirtschaftsinformatik 2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-16 11:15


- - -

### [Models Matter: Setting Accurate Privacy Expectations for Local and Central Differential Privacy](http://arxiv.org/abs/2408.08475)

**モデルは重要: ローカルおよび中央差分プライバシーのための正確なプライバシー期待の設定**

Mary Anne Smart, Priyanka Nanayakkara, Rachel Cummings, Gabriel Kaptchuk, Elissa Redmiles

- 差分プライバシーは人気のあるプライバシー技術で、業界や政府で導入されている
- 現行の差分プライバシーの説明は、データ提供者が期待するプライバシーを正確に設定できていない
- ローカルモデルと中央モデルのための新しい差分プライバシーの説明を設計し評価
- プライバシー影響を明示した説明が、正確なプライバシー期待を設定する上で有望であることを発見

この論文、正確なプライバシー期待を設定するための新しい説明方法について研究してて、めっちゃ興味深い！プライバシーを守ることがもっと確実になりそうだよね。



**トピック:** [差分プライバシー](../../dp), [PETs](../../pets), **カテゴリ:** cs.CR, cs.HC, **投稿日時:** 2024-08-16 01:21


- - -

### [Fairness Issues and Mitigations in (Differentially Private) Socio-demographic Data Processes](http://arxiv.org/abs/2408.08471)

**（差分プライバシー付き）社会人口統計データ処理における公平性の問題と対策**

Joonhyuk Ko, Juba Ziani, Saswat Das, Matt Williams, Ferdinando Fioretto

- 重要な社会調査はサンプリング誤差を導入し、グループレベルの推定に不公平が生じる
- 最適化手法を導入し、サンプリングコストを最適化しつつ誤差を許容範囲内に抑える
- サンプリング率を決定するプライバシー保護手法が公平性問題に影響を与える
- 差分プライバシーによるノイズが不公平を軽減し、小規模データに正の影響を与える

大規模なデータセット分析で実証されたみたい！差分プライバシーが不公平を減らすって驚きだよね、もっと詳しく知りたいな。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.CY, **投稿日時:** 2024-08-16 01:13
