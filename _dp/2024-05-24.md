---
title: 差分プライバシー (2024-05-24 ~ 2024-05-30)
date: 2024-05-24
---

差分プライバシーに関する論文まとめ (2024-05-24 ~ 2024-05-30)


- - -

### [Robust Kernel Hypothesis Testing under Data Corruption](http://arxiv.org/abs/2405.19912)

**データ破損下でのロバストなカーネル仮説検定**

Antonin Schrab, Ilmun Kim

- 2つの一般的なロバストな置換検定の構築方法を提案
- 最小条件下での一型誤差制御と検出力の一致性を証明
- 差分プライバシーを保証し、プライベートデータ分析にも適用可能
- 提案手法がカーネルMMDとHSICメトリクスでミニマックス最適であることを示す

差分プライバシーを自然に含む検定方法とか、未来のデータ分析に超使えそうじゃない？実装も公開されてるし、試してみたいな！

**Comment:** 26 pages, 2 figures, 2 algorithms

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ML, cs.LG, **投稿日時:** 2024-05-30 10:23


- - -

### [Just Rewrite It Again: A Post-Processing Method for Enhanced Semantic Similarity and Privacy Preservation of Differentially Private Rewritten Text](http://arxiv.org/abs/2405.19831)

**もう一度書き直そう：差分プライバシーによる再書き換え法の意味的類似性とプライバシー保護の強化**

Stephen Meisenbacher, Florian Matthes

- 差分プライバシー（DP）でテキストをプライバタイズするタスクは、再書き換えタスクと見なされる
- 敏感な情報を隠すために、再書き換えテキストと元のテキストの整合性を高める後処理法を提案
- 提案手法により、意味的にオリジナルに近い出力と、高いプライバシー評価が達成できる
- DPの再書き換え手法の評価基準を引き上げ、悪意のある攻撃者に対する追加の保護を提供する

新しい後処理法ってのがどうやって元のテキストとの整合性を高めるのか気になるね！DPの質も上がるなら、色んな応用が考えられそう！

**Comment:** 10 pages, 2 figures, 2 tables. Accepted to ARES 2024 (IWAPS)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CL, **投稿日時:** 2024-05-30 08:41


- - -

### [Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering](http://arxiv.org/abs/2405.19272)

**連合学習における差分プライバシーの不均等影響をロバストクラスタリングで軽減する方法**

Saber Malekmohammadi, Afaf Taik, Golnoosh Farnadi

- 連合学習はデータを局所化し、差分プライバシーを組み合わせるが、少数派グループに対する性能格差が生じる
- 既存のクラスタリング手法はDPノイズの影響で誤差が生じやすく、その改善が必要
- 提案手法はモデル更新とトレーニング損失に基づくクラスタリングで高精度を維持
- 提案手法はGMMと大きなバッチサイズを活用し、ノイズやクラスタリングエラーの影響を緩和する

クラスタリングと連合学習の組み合わせ、すごく期待できそう！ノイズが問題になりやすいDPでも、こういう工夫で公平さを保てるのは最新技術の進歩って感じだね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-05-29 17:03


- - -

### [Algorithmic Transparency and Participation through the Handoff Lens: Lessons Learned from the U.S. Census Bureau's Adoption of Differential Privacy](http://arxiv.org/abs/2405.19187)

**ハンドオフレンズから見たアルゴリズムの透明性と参加：米国国勢調査局の差分プライバシー採用から得た教訓**

Amina A. Abdu, Lauren M. Chambers, Deirdre K. Mulligan, Abigail Z. Jacobs

- 差分プライバシー採用で社会的、組織的、政治的文脈が変化
- 透明性と参加への努力は、技術設計だけでなく価値と政策に焦点を当てるべき
- ハンドオフモデルは、技術的決定に隠れた価値を明らかにする有用なツール
- 境界オブジェクト単独では不十分で、信頼される専門家が必要

DPを探る技術と価値のバランスが面白そう！どんな専門家が課題を解決するかも知りたいな。

**Comment:** 21 pages, FAccT '24

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CY, **投稿日時:** 2024-05-29 15:29


- - -

### [LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models](http://arxiv.org/abs/2405.18776)

**LMO-DP: 微調整のための差分プライバシーランダム化メカニズムの最適化（大規模）言語モデル**

Qin Yang, Meisam Mohammad, Han Wang, Ali Payani, Ashish Kundu, Kai Shu, Yan Yan, Yuan Hong

- DP-SGDは大規模な言語モデルの微調整におけるプライバシーを保証するが、ガウス機構に依存しすぎて精度を低下させる
- LMO-DPは、強いプライバシー条件下でも、正確な微調整を可能にする新しい差分プライバシーメカニズムを提案
- オフライン最適ノイズ探索法により、ノイズの大きさを効率的に削減し、精度を向上させる
- RoBERTa-largeやGPT-2のタスクで精度を大幅に向上させ、Llama-2にも対応

ガウス機構よりも性能がいいって、かなり画期的じゃない？プライバシーに配慮しつつ精度を追求できる未来が待ってるかも！

**Comment:** 18 pages, 15 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.CL, cs.LG, **投稿日時:** 2024-05-29 05:32


- - -

### [Differentially-Private Distributed Model Predictive Control of Linear Discrete-Time Systems with Global Constraints](http://arxiv.org/abs/2405.18690)

**差分プライバシーを用いた線形離散時間システムの分散モデル予測制御におけるグローバル制約**

Kaixiang Zhang, Yongqiang Wang, Ziyou Song, Zhaojian Li

- 分散モデル予測制御(DMPC)は、システム制約を明示的に扱い、分散的に最適制御を達成するが、データ共有がプライバシーを侵害する。
- 従来の分散デュアル勾配アルゴリズムはDMPC問題を解決するが、強力なプライバシー保護はできない。
- 盗聴者に対するプライバシー保護のため、DMPCフレームワークに差分プライバシーのノイズ注入機構を組み込み、収束と$\epsilon$-差分プライバシーを両立。
- 閉ループシステムの再帰的な実現可能性と安定性を保証するDMPCの実装戦略を設計し、数値シミュレーションでその有効性を確認。

システムの制約を守りながらプライバシーも保護する仕組みってすごくない？これ、現場で使えるなら未来の制御システムに革命が起きちゃいそう！📈💡

**Comment:** 11 pages, 3 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** eess.SY, cs.SY, **投稿日時:** 2024-05-29 01:58


- - -

### [Universal Exact Compression of Differentially Private Mechanisms](http://arxiv.org/abs/2405.20782)

**差分プライバシー機構のためのユニバーサルな正確な圧縮**

Yanxiao Liu, Wei-Ning Chen, Ayfer Özgür, Cheuk Ting Li

- 差分プライバシー手法の通信コストを削減するため、Poisson private representation (PPR)を提案
- PPRは、元のランダム化機構のデータと出力の結合分布を正確に保存
- 元のプライバシー機構と同じ統計特性を保持し、理論的な下限に近い圧縮サイズを達成
- 実験結果で、通信、精度、中央とローカル差分プライバシーの間のトレードオフが改善

新しい圧縮手法で差分プライバシーの効率をめっちゃ向上できそう！データの分布をしっかり守りつつ省エネになるって、ホントすごいと思う！

**Comment:** 30 pages, 3 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.IT, math.IT, stat.ML, **投稿日時:** 2024-05-28 23:54


- - -

### [Delving into Differentially Private Transformer](http://arxiv.org/abs/2405.18194)

**差分プライバシーを備えたTransformerの探求**

Youlong Ding, Xueyang Wu, Yining Meng, Yonggang Luo, Hao Wang, Weike Pan

- 差分プライバシーを用いた深層学習は、モデルの精度とトレーニング効率を向上する多くの方法が開発されてきた
- 本論文はTransformerモデルでの差分プライバシー学習の問題に取り組む
- DP Transformer特有の問題として、Attention分散現象と効率的な勾配クリッピング技術との非互換性を指摘
- Re-Attention MechanismとPhantom Clippingを提案し、これらの問題に対応する方法を示す

どんな新しいアイディアがもっと研究を進めるのか、すごく気になる！連合学習や秘密計算にも応用できたらいいな！

**Comment:** ICML 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-05-28 14:04


- - -

### [P4: Towards private, personalized, and Peer-to-Peer learning](http://arxiv.org/abs/2405.17697)

**P4：プライベートでパーソナライズされたピア・ツー・ピア学習に向けて**

Mohammad Mahdi Maheri, Sandra Siby, Ali Shahin Shamsabadi, Sina Abdollahi, Anastasia Borovykh, Hamed Haddadi

- 個々のクライアントがデータのプライバシーを保ちながらパーソナライズされたモデルを受け取る方法を開発
- クライアントをプライベートなピア・ツー・ピア(P2P)方式でグループ化する軽量なアルゴリズムを設計
- 差分プライバシーを保ちながら知識蒸留を用いて協同訓練、精度の影響を最小限に抑える
- 3つのベンチマークデータセットで評価し、最新の差分プライバシーP2P学習よりも最大40%精度が向上

パーソナライズされた学習がデータのプライバシーを守りつつP2Pで行われるなんて、すっごく未来的で期待できない？どんなデバイスでも実装できるところもかなり実用的だよね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-05-27 23:04


- - -

### [Alistair: Efficient On-device Budgeting for Differentially-Private Ad-Measurement Systems](http://arxiv.org/abs/2405.16719)

**Alistair：差分プライバシー広告測定システムの効率的なデバイス予算管理**

Pierre Tholoniat, Kelly Kostopoulou, Peter McNeely, Prabhpreet Singh Sodhi, Anirudh Varanasi, Benjamin Case, Asaf Cidon, Roxana Geambasu, Mathias Lécuyer

- サードパーティのクッキーが主要ブラウザから削除されるため、新しいプライバシー保護広告APIの導入が進む
- Google、Apple、Meta、Mozillaの既存のプライバシー保護広告測定APIを強化
- Alistairというアプローチで、差分プライバシーの予算管理をより効率的にし、個別のDP保証を提供
- ChromeにAlistairを組み込み、ミクロベンチマークと広告データセットで評価し、基準よりも多くの広告測定を可能に

今の広告のプライバシー問題を解決できたら、新しいビジネスが生まれそう！こういう革新があると、未来のテクノロジーはもっと安全で面白くなりそうだね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-05-26 23:27


- - -

### [Data Reconstruction: When You See It and When You Don't](http://arxiv.org/abs/2405.15753)

**データ再構築：見える時と見えない時**

Edith Cohen, Haim Kaplan, Yishay Mansour, Shay Moran, Kobbi Nissim, Uri Stemmer, Eliad Tsfadia

- 再構築攻撃の定義は文脈によるが、包括的な定義は困難である
- 再構築攻撃に対する保護を「ナルシス・レジリエンシー」と定義
- ナルシス・レジリエンシーは差分プライバシーなど多くの概念を特別ケースとして含む
- 再構築攻撃とコルモゴロフ複雑性の関連を形成し、成功基準を提案

ナルシス・レジリエンシーなんて新しい概念が出てきたの、めっちゃおもしろそう！コルモゴロフ複雑性との関連も、攻撃の理解が深まるなぁ。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-05-24 17:49


- - -

### [Enhancing Learning with Label Differential Privacy by Vector Approximation](http://arxiv.org/abs/2405.15150)

**ベクトル近似によるラベル差分プライバシーを強化する手法**

Puning Zhao, Rongfei Fan, Huiwen Wu, Qingming Li, Jiafei Wu, Zhe Liu

- ラベル差分プライバシーはトレーニングデータセットのラベルのプライバシーを保護するフレームワークである
- 従来の方法はラベルをランダムに切り替え、その後モデルをトレーニングしてプライバシー化したラベルに近似させる
- 提案するベクトル近似法は、各ラベルをK成分のランダムベクトルに変換し、クラス条件付き確率を反映する
- 理論解析と実験によると、提案手法の性能はKが大きくなってもわずかにしか低下しない

新しいベクトル近似法、すごい面白そう！これでプライバシーを守りながらも精度が向上しそうだから、実用的な応用が増えるといいな。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-05-24 02:08
