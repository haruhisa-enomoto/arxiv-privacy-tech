---
title: 差分プライバシー (2024-10-04 ~ 2024-10-10)
date: 2024-10-04
---

差分プライバシーに関する論文まとめ (2024-10-04 ~ 2024-10-10)


- - -

### [Private and Communication-Efficient Federated Learning based on Differentially Private Sketches](http://arxiv.org/abs/2410.05733)

**差分プライベートスケッチに基づくプライバシーと通信効率の良い連合学習**

Meifan Zhang, Zhanhong Xie, Lihua Yin

- 連合学習ではプライバシーの漏洩リスクと通信の非効率が課題
- DPSFLは差分プライバシースケッチを使用し通信効率とプライバシーを向上
- 勾配クリッピングはノイズの影響を抑えるがバイアスを生むため性能に悪影響
- DPSFL-ACは適応クリッピングによりバイアスを軽減し優れた性能を実証

連合学習って、ただ共有すればいいってもんじゃないのが面白いね！DPSFLでプライバシーも通信も改善できちゃうなんて、実用化されたらすごく便利そうだし、頼もしいなって思っちゃう！💡



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-08 06:50


- - -

### [KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server](http://arxiv.org/abs/2410.05725)

**KnowledgeSG: サーバからの知識蒸留によるプライバシー保護付き合成テキスト生成**

Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang

- 大規模言語モデルの記憶化でプライバシー懸念が生じる
- 合成データ利用は性能向上とプライバシー保護の両立が難しい
- KnowledgeSGは、差分プライバシーと知識蒸留で品質と性能を向上
- 連合学習に着想を得て、モデルをクライアント・サーバ間で共有しプライバシーを保護

この方法は、プライバシーも守りつつ性能も上げるなんてすごくおもしろそう！医療や金融みたいなデータが重要でセンシティブな分野でもうまくいくなら、めっちゃ役立ちそうだね。どんな時代が来るんだろう、ワクワクする～！

**Comment:** EMNLP 2024 Main

**トピック:** [連合学習](../../fl), [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-10-08 06:42


- - -

### [A Blockchain-Enhanced Framework for Privacy and Data Integrity in Crowdsourced Drone Services](http://arxiv.org/abs/2410.05653)

**ブロックチェーン強化型フレームワークによる群衆からのドローンサービスのプライバシーとデータ完全性**

Junaid Akram, Ali Anaissi

- 消費者向けドローンをブッシュファイア管理に統合し、サービス改善とデータプライバシーに対処
- ブッシュファイア当局がデータを利用し、ドローン運営者が提供する市場を形成
- データ提供者のプライバシーを局所的差分プライバシーで保護し、プライバシー基準に準拠
- ブロックチェーンで公正なデータと料金交換を促進し、不変の記録で責任を強化

災害管理にドローンを使うってすごく活用されてるよね！このシステムでなら、みんなにとって安全で信頼できる情報が飛び交う未来が見えてきそうだよ。大規模への適応もばっちりだから、実際の現場でも活躍してくれるかも！

**Comment:** 8 pages, 5 figures, accepted and to be published in the proceedings   of 22nd International Conference on Service-Oriented Computing (ICSOC 2024)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-08 03:08


- - -

### [Privacy Vulnerabilities in Marginals-based Synthetic Data](http://arxiv.org/abs/2410.05506)

**周辺確率に基づく合成データのプライバシー脆弱性**

Steven Golob, Sikha Pentyala, Anuar Maratkhan, Martine De Cock

- 合成データ生成（SDG）は実データと似つつ個人情報を排除することを目指している
- 数多くのSDGアルゴリズムは強力な差分プライバシー保証を提供している
- 周辺確率を保持するSDGアルゴリズムには個人情報が漏洩する危険があると判明
- 新たなメンバーシップ推論攻撃MAMA-MIAを使い、脆弱性が効率的に暴かれる

個人情報の安全性って、どんな技術でも100%確保するのは難しいんだね。それでも続々と新しい手法が開発されててすごいと思う！どんな対策がこれから登場するのかすっごく楽しみ〜！



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), [PETs](../../pets), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-10-07 21:24


- - -

### [Testing Credibility of Public and Private Surveys through the Lens of Regression](http://arxiv.org/abs/2410.05458)

**回帰の視点から見る公共およびプライベート調査の信頼性**

Debabrota Basu, Sourav Chakraborty, Debarshi Chanda, Buddha Dev Das, Arijit Ghosh, Arnab Ray

- サンプル調査が母集団の信頼できる表現かどうかを回帰分析でテストするアルゴリズムを設計
- Gaussian Differential Privacyを用いて、信頼性の検証を差分プライバシー下の調査にも拡張
- 提案したアルゴリズムで、ノイズがあるデータから線形回帰モデルを学習することが可能
- リアルデータと合成データでアルゴリズムの性能を数値的に実証し、理論的な正しさを証明

サンプル調査とプライバシー技術って、ずっと複雑だと思ってたから、こうやってアルゴリズムで検証できるってすごいよね！しかも、ノイズのあるデータからも学習できるなんて、もっと幅広く応用が効きそう～！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ME, stat.ML, **投稿日時:** 2024-10-07 19:44


- - -

### [DiSK: Differentially Private Optimizer with Simplified Kalman Filter for Noise Reduction](http://arxiv.org/abs/2410.03883)

**DiSK: ノイズ低減のためのカマンフィルターを用いた差分プライベート最適化技術**

Xinwei Zhang, Zhiqi Bu, Borja Balle, Mingyi Hong, Meisam Razaviyayn, Vahab Mirrokni

- 差分プライバシーは個人データを保護する枠組みであり、差分プライベート最適化技術が注目されている
- 既存の技術は大規模なトレーニングで性能が低下する問題があり、それが大量のノイズ注入に起因
- DiSKという新しいフレームワークを提案し、カマンフィルターを用いてプライベート化された勾配をデノイズ
- 広範な実験でDiSKが標準のDP最適化手法を超える性能を示し、複数のベンチマークで差をつけた

わー、このDiSKって技術すごいね！大規模データでもプライバシーを保ちつつ性能アップできるなんて、今後のAIの発展に大きな影響を与えそう♪



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ML, **投稿日時:** 2024-10-04 19:30


- - -

### [Camel: Communication-Efficient and Maliciously Secure Federated Learning in the Shuffle Model of Differential Privacy](http://arxiv.org/abs/2410.03407)

**Camel: 差分プライバシーのシャッフルモデルにおける通信効率の高い悪意あるセキュア連合学習**

Shuangqing Xu, Yifeng Zheng, Zhongyun Hua

- 連合学習はクライアントのプライベートデータを公開せずにモデルを学習するパラダイム
- LDPメカニズムでプライバシー保証を提供するが、ノイズが多くモデルの有用性が低下
- シャッフルモデルを用いてプライバシー増幅し、より良いプライバシー-ユーティリティのトレードオフを実現
- Camelは通信効率とセキュリティを最適化し、RDPを用いてプライバシー損失を厳しく評価

連合学習って面白そうだよね。大人数で協力して賢いモデルを育てるなんて、未来の学校みたいでワクワクする！Camelの方法で、もっと安全で効率的になっていくのかなぁ。

**Comment:** Accepted by CCS'2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-04 13:13
