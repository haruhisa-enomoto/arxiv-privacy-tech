---
title: 差分プライバシー (2024-11-08 ~ 2024-11-14)
date: 2024-11-08
---

差分プライバシーに関する論文まとめ (2024-11-08 ~ 2024-11-14)


- - -

### [SAFES: Sequential Privacy and Fairness Enhancing Data Synthesis for Responsible AI](http://arxiv.org/abs/2411.09178)

**SAFES: 責任あるAIのための逐次的プライバシーと公正性を高めるデータ合成**

Spencer Giddens, Fang Liu

- データ駆動の意思決定で情報のプライバシーと公正性を確保することが重要である
- 差分プライバシーと公正性は個別に扱われがちで、その統合には課題がある
- SAFESは差分プライバシーに基づきデータ合成と公正性向上を組み合わせた手法である
- 実証実験により、SAFESの出力データは、プライバシーを保ちながら公正性を向上することを示した

プライバシーって本当に大切だよね！SAFESのように、同時に公正性も考えてくれる技術は未来のAIにぴったり。彼らのアプローチが、他の分野でも応用されていくといいな！



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-11-14 04:36


- - -

### [Laplace Transform Interpretation of Differential Privacy](http://arxiv.org/abs/2411.09142)

**差分プライバシーのラプラス変換解釈**

Rishav Chourasia, Uzair Javaid, Biplap Sikdar

- 差分プライバシーの概念をプライバシー損失分布のラプラス変換で表現
- 時間と周波数領域の二重性を利用し、DPの特性について新たな考察を提供
- R\'enyi DP曲線と$(\epsilon, \delta(\epsilon))$-DP曲線がラプラス・逆ラプラス変換であることを示す
- すべての$\epsilon$の値に対して正確な$(\epsilon, \delta)$-DPの適応合成定理を証明

この研究は、差分プライバシーをもっと視覚的に理解するための新しいアプローチを示していて面白そう！ラプラス変換を使って、複雑な概念をより直感的に説明できるかもしれないね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-11-14 02:52


- - -

### [Minimax Optimal Two-Sample Testing under Local Differential Privacy](http://arxiv.org/abs/2411.09064)

**局所差分プライバシーにおけるミニマックス最適な2標本検定**

Jongmin Mun, Seungwoo Kwak, Ilmun Kim

- 局所差分プライバシーに基づく多項分布と連続データの2標本検定で、プライバシーと統計的有用性のトレードオフを探求
- ラプラスやGoogleのRAPPORなどのメカニズムを用いた多項分布向けのプライベートな置換検定を提案
- ヒルダーとベゾフの滑らかさクラスについて、LDPにおける一様分離率を調査し、連続データ検定に拡張
- 非適応的なスムーズネスパラメータを持つ密度検定向けに、ボンフェローニアプローチを基にした適応型検定を提案

この論文、プライバシーを保持しつつしっかりとした検定ができるの面白そう！特にGoogleのRAPPORみたいな実用的な手法を活かせるってところがいいね。やっぱりプライバシーと便利さは天秤にかけたくなるけど、そこをうまくバランス取ってる感じがする！

**Comment:** 59 pages, 5 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ML, cs.CR, cs.LG, 62G10, **投稿日時:** 2024-11-13 22:44


- - -

### [Locally Private Sampling with Public Data](http://arxiv.org/abs/2411.08791)

**公開データを用いた局所的なプライバシーサンプリング**

Behnoosh Zamanlooy, Mario Diaz, Shahab Asoodeh

- ローカル差分プライバシーは、ユーザーデータを保護する機械学習で使用されるが、データ記録が単一であるという制約がある。
- ユーザーのプライベートデータセットとパブリックデータセットの両方を活用する、局所的なプライバシーサンプリングの枠組みを提案。
- プライベートなサンプルを生成しつつ、パブリックデータセットを保持するメカニズムを設計することを目的とする。
- 一般的な$f$-分岐を用いた最小最大最適メカニズムを具体化し、実験で最先端のサンプラーと比較して効果を確認。

ユーザーのデータを守りながらも、今あるデータをうまく活用しようってアイデアがめっちゃ新しい！これが広まったら、もっと安全にオープンデータを活用できる世の中になりそうでワクワクするね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-13 17:17


- - -

### [A Stochastic Optimization Framework for Private and Fair Learning From Decentralized Data](http://arxiv.org/abs/2411.07889)

**プライバシーと公正さを両立した分散データからの学習のための確率的最適化フレームワーク**

Devansh Gupta, A. S. Poornash, Andrew Lowy, Meisam Razaviyayn

- 連合学習モデルのプライバシーと公正性の課題に対抗するアルゴリズムを開発
- 各シロデータの記録レベル差分プライバシー（ISRL-DP）を満たす
- 公正性として、人口平等や均等的成果を促進できる
- 以前は必要だった強凸性なしに、緩やかな滑らかさでの収束を保証

データのプライバシーも守りつつ、公正な結果を導くなんてすごくない？これ、社会にめちゃ貢献できそうな技術だよね！新しい方法でシロデータを守るなんて、聞くだけでワクワクしちゃう！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-12 15:51


- - -

### [Federated Low-Rank Adaptation with Differential Privacy over Wireless Networks](http://arxiv.org/abs/2411.07806)

**差分プライバシーを用いた無線ネットワーク上の連合低ランク適応**

Tianqu Kang, Zixin Wang, Hengtao He, Jun Zhang, Shenghui Song, Khaled B. Letaief

- 大規模モデルの連合学習はプライバシー保護の問題を軽減する。
- LoRAの利用で計算負荷を減らし効率的にモデル微調整が可能。
- 分割されたFMがデバイス間で共有されプライバシー攻撃の懸念。
- 無線チャンネルノイズを利用し差分プライバシーを実現。

差分プライバシーの工夫が面白いね！通信の「ノイズ」を役立てちゃうなんて発想がユニークだし、これは革新的な無線通信のプライバシー保護の手法になる予感！

**Comment:** 6 pages, 3 figures, submitted to IEEE ICC 2025

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, eess.SP, **投稿日時:** 2024-11-12 14:01


- - -

### [Differentially-Private Collaborative Online Personalized Mean Estimation](http://arxiv.org/abs/2411.07094)

**差分プライバシーを用いた協調型オンラインパーソナライズ平均推定**

Yauhen Yakimenka, Chung-Wei Weng, Hsuan-Yin Lin, Eirik Rosnes, Jörg Kliewer

- プライバシー制約下での協調型平均推定問題に取り組み、差分プライバシーによる手法を提案
- 仮説検定とデータ分散推定を組み合わせ、2つのプライバシー機構と分散推定手法を提案
- 提案手法は各エージェントのデータが未知でも、理論的に局所手法より高速な収束を示す
- 理想的な性能に近い収束速度を達成し、プライベートコラボレーションのメリットを確認

データが未知でも、協力することで素早く収束できるのってすごいよね。プライバシーを守りながらもスムーズに情報を共有できる仕組みが、これからのデータ社会にとって重要になりそう！

**Comment:** Presented in part at the 2023 IEEE International Symposium on   Information Theory (ISIT)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.IT, math.IT, **投稿日時:** 2024-11-11 16:14


- - -

### [Federated Split Learning for Human Activity Recognition with Differential Privacy](http://arxiv.org/abs/2411.06263)

**連合スプリット学習による差分プライバシーを活用した人の行動認識**

Josue Ndeko, Shaba Shaon, Aubrey Beal, Avimanyu Sahoo, Dinh C. Nguyen

- 新たなFSL-DPフレームワークにより、人の行動認識精度が向上
- 従来の連合学習に比べ、FSLフレームワークが精度と損失面で優れている
- プライバシー保証とモデル精度のバランスを探るため、DPメカニズムのデータ設定を調査
- FSLフレームワークは通信時間が短く、効率性と効果的な性能を示す

この技術が進化すれば、私たちのデバイスはもっと賢くなるかもね！実生活のデータでテストされたっていうのも頼もしいな。連合スプリット学習…響きからしてなにかすごそう！

**Comment:** Accepted to IEEE Consumer Communications and Networking Conference   (CCNC), 6 pages

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-11-09 19:32


- - -

### [Differential Privacy Under Class Imbalance: Methods and Empirical Insights](http://arxiv.org/abs/2411.05733)

**クラス不均衡下における差分プライバシー: 方法と実証的洞察**

Lucas Rosenblatt, Yuliia Lut, Eitan Turok, Marco Avella-Medina, Rachel Cummings

- クラス不均衡は、疾病予測や詐欺検出でよく見られる課題である
- プライバシー保護技術を適用すると、クラス不均衡がさらに深刻化する
- 差分プライバシー版の前処理技術で不均衡を削減する手法を提案
- プライベート合成データが前処理として効果的、高次元設定ではクラス重みづけERMが有効

差分プライバシーでクラス不均衡を分析するのって面白い挑戦だね！特に疾病予測や詐欺検出でプライバシーを守りつつ効果的な結果を得るのは難しそうだけど、解決策が紹介されててワクワクするね。これからもこういったプライバシー課題に取り組む研究が進むのが楽しみ！

**Comment:** 14 pages

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, 68P27, I.2.0; F.0; G.3; J.0, **投稿日時:** 2024-11-08 17:46


- - -

### [The Limits of Differential Privacy in Online Learning](http://arxiv.org/abs/2411.05483)

**オンライン学習における差分プライバシーの限界**

Bo Li, Wei Wang, Peng Ye

- 差分プライバシーは、プライバシー漏洩とユーティリティのトレードオフを伴う問題である
- オンライン学習における差分プライバシーの限界を明らかにし、三つの制約を分離した
- 近似差分プライバシーで学習可能なクラスが純粋差分プライバシーでは不可能な状況がある
- 任意のプライベートなオンライン学習者は無限のミスをする必要があり、非プライベートと強く分かれる

差分プライバシーってすごくのるけど、オンライン学習では限界があるんだね。いろいろ試して突破口を見つけるのが、一緒に研究領域を広げる楽しさになりそうだね！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-08 11:21
