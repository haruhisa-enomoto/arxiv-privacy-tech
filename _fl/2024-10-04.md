---
title: 連合学習 (2024-10-04 ~ 2024-10-10)
date: 2024-10-04
---

連合学習に関する論文まとめ (2024-10-04 ~ 2024-10-10)


- - -

### [FRIDA: Free-Rider Detection using Privacy Attacks](http://arxiv.org/abs/2410.05020)

**FRIDA: プライバシー攻撃を用いたフリーライダー検出**

Pol G. Recasens, Ádám Horváth, Alberto Gutierrez-Torre, Jordi Torres, Josep Ll. Berral, Balázs Pejó

- 連合学習は複数の参加者でモデルを共同訓練するが、フリーライダーの存在が問題
- フリーライダーは学習プロセスの妥当性を損ない、モデルの収束を遅らせ、コスト増加を招く
- FRIDAはプライバシー攻撃を使い、参加者のデータセットからフリーライダーを直接検出
- FRIDAは最新の手法より効果的で、特にデータが非独立同分布（非IID）の場合に優位性を示す

これって、なんかすごくない？プライバシー攻撃を逆手に取って、みんなで守る側の発想を変えるんだって！技術的に新しいチャレンジをしてるから、これからも注目したいな！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-07 13:20


- - -

### [FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models](http://arxiv.org/abs/2410.04810)

**FedBiP: 個別化潜象拡散モデルを用いた異質ワンショット連合学習**

Haokun Chen, Hang Li, Yao Zhang, Gengyuan Zhang, Jinhe Bi, Philip Torr, Jindong Gu, Denis Krompass, Volker Tresp

- ワンショット連合学習（OSFL）は通信費を削減しプライバシーを保護する手法
- 従来のOSFLはクライアントデータの異質性と少量のデータが課題
- プレトレーニングされた潜象拡散モデル（LDM）は高品質画像生成に優れるが、OSFLには最適でない
- FedBiPはLDMを個別化し、データ分布を考慮した画像を合成して性能を向上

おもしろそうな論文だね！医療画像とか珍しいデータでもしっかり対応できるのってすごいな〜。プライバシーも守りつつ効果的に連合学習を実現するなんて、未来の技術って感じでワクワクする〜！



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.CV, cs.DC, cs.MM, **投稿日時:** 2024-10-07 07:45


- - -

### [Federated Learning Nodes Can Reconstruct Peers' Image Data](http://arxiv.org/abs/2410.04661)

**連合学習ノードが他のノードの画像データを再構築できる**

Ethan Wilson, Kai Yue, Chau-Wai Wong, Huaiyu Dai

- 連合学習はプライバシーを保ちつつノード間でモデルを訓練する技術だが、データのプライバシーは保証されない
- 誠実だが好奇心旺盛なノードが、他のノードの画像データを再構築できることを示す
- 単一のクライアントが連続した更新情報を利用し、他のクライアントの画像を密かに再構築できる
- 拡散モデルを使って再構築画像の質を高め、セマンティックな情報漏洩のリスクを強調

連合学習って便利そうだったけど、ちゃんと考えないと他人のデータを覗かれちゃうんだね！もっと安全な仕組みができたら、いろんな分野で活用できそうでワクワク！

**Comment:** 12 pages including references, 12 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-07 00:18


- - -

### [Implicit to Explicit Entropy Regularization: Benchmarking ViT Fine-tuning under Noisy Labels](http://arxiv.org/abs/2410.04256)

**暗黙から明示的なエントロピーレギュラリゼーションへの移行: ノイズラベル下におけるViTファインチューニングのベンチマーク**

Maria Marrium, Arif Mahmood, Mohammed Bennamoun

- 大規模データセットの自動アノテーションはノイズラベルを導入し、DNNの学習に悪影響を与える
- ViTのファインチューニングはノイズラベルに脆弱で、CNNと比較した頑健性を評価した
- CNN向けに開発されたNLL手法がViTにも同様に効果的かどうかを調査
- エントロピー正則化が既存の損失関数やNLL手法の頑健性を向上させることが判明

ノイズラベルによる悪影響を軽減するために、エントロピーの役割が重要ってことなんだね！データサイエンスの未来に貢献できる研究だし、ViTが普及してきた今、私たちも頑張らなきゃって思った！✨



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.AI, **投稿日時:** 2024-10-05 18:24


- - -

### [ConDa: Fast Federated Unlearning with Contribution Dampening](http://arxiv.org/abs/2410.04144)

**ConDa: 貢献抑制による高速連合アンラーニング**

Vikram S Chundawat, Pushkar Niroula, Prasanna Dhungana, Stefan Schoepf, Murari Mandal, Alexandra Brintrup

- 連合学習では参加者の追加は簡単だが、参加者の削除は難題である
- ConDaは、不要な情報の寄与を弱体化することで効率的にデータを消去
- クライアントのデータ再学習や計算負荷なく、プライバシーの確保を実現
- 非IID環境で、他の方法より100倍以上の速さでアンラーニングが可能

すごい！データの消去ってずっと難しかったけど、こんなに早くて簡単にできちゃうなんて驚きだよね！プライバシーが守られる世界がさらに近づいてるのかもって思うとワクワクするな！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-05 12:45


- - -

### [pFedGame -- Decentralized Federated Learning using Game Theory in Dynamic Topology](http://arxiv.org/abs/2410.04058)

** pFedGame -- 動的トポロジーにおけるゲーム理論を用いた分散型連合学習 **

Monik Raj Behera, Suchetana Chakraborty

- 連合学習の課題として、中央集約サーバへの負荷やデータバイアスが存在
- pFedGameは中央サーバ不要のゲーム理論ベースの手法を提案
- 動的ネットワークでの消失する勾配と収束の問題を対応
- pFedGameは異種データで精度70%以上を達成し有望な結果

面白そう！分散型で部分連合学習ができるなんて、なんだか未来を感じるね。この技術が新しい協力関係を生むかもって思ったよ。



**トピック:** [連合学習](../../fl), **カテゴリ:** stat.ML, cs.CR, cs.GT, cs.LG, **投稿日時:** 2024-10-05 06:39


- - -

### [A Survey on Group Fairness in Federated Learning: Challenges, Taxonomy of Solutions and Directions for Future Research](http://arxiv.org/abs/2410.03855)

**連合学習におけるグループ公正性の調査：課題、解決策の分類と今後の研究の方向性**

Teresa Salazar, Helder Araújo, Alberto Cano, Pedro Henriques Abreu

- 機械学習におけるグループ公正性は重要で、連合学習が異なるデータの偏りを増幅させる可能性がある。
- 連合学習とグループ公正性の交差点に関する47の研究があるが、包括的な調査はなかった。
- 本研究は新しい分類法を用いて関連するアプローチを整理し、データ分割、位置、戦略による評価を行う。
- 将来の研究に必要な領域を強調し、連合システムにおけるグループ公正性の達成の複雑さに対応する方法を提案する。

この研究面白そうだよね！連合学習でのグループ公正性の課題をバッチリ解決できたら、多様なデータを持つサービスにとって革命的になりそう。これからの研究で、もっと公正な未来が開けるといいな！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CY, 68T01, I.2.6; I.5.1; K.4.1, **投稿日時:** 2024-10-04 18:39


- - -

### [FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein Estimator](http://arxiv.org/abs/2410.03499)

**FedStein: ジェームズ・スタイン推定器を用いたマルチドメイン連合学習の向上**

Sunny Gupta, Nikita Jangid, Amit Sethi

- 連合学習は、非独立同分布データの扱いで性能と収束性の課題がある
- 本研究は、異なる特徴分布を持つ複数ドメインの連合学習というあまり探索されていない問題に焦点を当てた
- 提案手法FedSteinは、クライアント間でバッチ正規化統計のジェームズ・スタイン推定値のみを共有する
- FedSteinは既存手法を超え、特定ドメインで14%以上の精度向上を達成

FedSteinって面白そう！新しい連合学習の方向性を切り開くかな？データの特徴が違ってもバッチ正規化だけ共有するアイデアが新鮮だし、精度も上がってるなんてすごい！私たちも試してみたいね。

**Comment:** 12 pages, 2 figures. Accepted at International Workshop on Federated   Foundation Models In Conjunction with NeurIPS 2024 (FL@FM-NeurIPS'24)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, cs.DC, I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;
  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10, **投稿日時:** 2024-10-04 15:13


- - -

### [Collaborative and Efficient Personalization with Mixtures of Adaptors](http://arxiv.org/abs/2410.03497)

**協力的かつ効率的なパーソナライズとアダプタの組み合わせ**

Abdulla Jasem Almansoori, Samuel Horváth, Martin Takáč

- 非独立同分布データは現実世界の連合学習でよく見られる問題である
- 提案するフレームワーク「FLoRAL」は各クライアントがパラメータを効率的に学習しタスクに適応
- アダプタのフェデレーションによりメモリ効率が向上し、効率的な協力学習が可能
- 実験でフルモデルのクラスタリングを超える性能を発揮し、有用性と堅牢性を実証

この研究って、みんなで協力してデータをシェアしながらも、それぞれに合った学び方ができるってのが面白いな！未来のアプリとかで個人にぴったりなサービスとか提供できたら楽しそうじゃない？

**Comment:** 36 pages, 10 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-04 15:11


- - -

### [Camel: Communication-Efficient and Maliciously Secure Federated Learning in the Shuffle Model of Differential Privacy](http://arxiv.org/abs/2410.03407)

**Camel: 差分プライバシーのシャッフルモデルにおける通信効率の高い悪意あるセキュア連合学習**

Shuangqing Xu, Yifeng Zheng, Zhongyun Hua

- 連合学習はクライアントのプライベートデータを公開せずにモデルを学習するパラダイム
- LDPメカニズムでプライバシー保証を提供するが、ノイズが多くモデルの有用性が低下
- シャッフルモデルを用いてプライバシー増幅し、より良いプライバシー-ユーティリティのトレードオフを実現
- Camelは通信効率とセキュリティを最適化し、RDPを用いてプライバシー損失を厳しく評価

連合学習って面白そうだよね。大人数で協力して賢いモデルを育てるなんて、未来の学校みたいでワクワクする！Camelの方法で、もっと安全で効率的になっていくのかなぁ。

**Comment:** Accepted by CCS'2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-04 13:13


- - -

### [Influence-oriented Personalized Federated Learning](http://arxiv.org/abs/2410.03315)

**影響指向の個別連合学習**

Yue Tan, Guodong Long, Jing Jiang, Chengqi Zhang

- 従来の連合学習は固定加重に頼り、データの不均一性に対応できない
- 提案するFedC^2Iは、クライアントとクラスの影響を定量化し適応的なパラメータ集約を実現
- 影響ベクトルと影響マトリクスを用いてクライアント間の影響をモデル化
- 非IID設定下で実験し、FedC^2Iが従来手法よりも優れていると評価

この論文、データのバラバラな状態での連合学習をもっと効果的にする方法なんだね！個々に合わせた学習を実現してくれるって、なんか未来の勉強スタイルみたいでワクワクする～！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-10-04 11:00


- - -

### [BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated Learning](http://arxiv.org/abs/2410.03281)

**BN-SCAFFOLD: 連合学習におけるバッチ正規化統計のドリフト制御**

Gonzalo Iñaki Quintana, Laurence Vancamberg, Vincent Jugnon, Mathilde Mougeot, Agnès Desolneux

- 連合学習は分散型で機械学習モデルを訓練する新しいパラダイム
- バッチ正規化は深層ニューラルネットワークで普及しているが、バラつきが問題に
- FedTANはバッチ正規化の統計を集約して対応するが通信コストが高い
- 新アルゴリズムBN-SCAFFOLDは通信効率を上げつつ性能でFedTANと同等

BN-SCAFFOLDって、通信コストを下げつつ性能を上げるなんてかっこいい！深層学習の訓練がもっと効率的になって、色んな新しい技術がでてきそうでワクワクしちゃう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-04 09:53


- - -

### [FedMAC: Tackling Partial-Modality Missing in Federated Learning with Cross-Modal Aggregation and Contrastive Regularization](http://arxiv.org/abs/2410.03070)

**FedMAC: 連合学習における部分モダリティ欠損へのクロスモーダル集約とコントラスト正則化による対処**

Manh Duong Nguyen, Trung Thanh Nguyen, Huy Hieu Pham, Trong Nghia Hoang, Phi Le Nguyen, Thanh Trung Huynh

- 連合学習は分散データで機械学習モデルを訓練し、クライアントのデータプライバシーを守る技術
- クライアント間でデータのモダリティが欠損する場合があり、データ分布の不均一さが課題となる
- 既存研究は完全なモダリティ欠損に対処するが、部分的なモダリティ欠損には効果的でない
- 提案手法FedMACは、統計的に不均一なクライアント構成でも26%の性能向上を達成

FedMAC、すごくイケてる名前だね！部分的にデータが欠けてても、ちゃんと結果が出る技術って便利そう！次のデジタル時代を支える技術になりそうだね。

**Comment:** The 22nd International Symposium on Network Computing and   Applications (NCA 2024)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.MM, **投稿日時:** 2024-10-04 01:24


- - -

### [FedCert: Federated Accuracy Certification](http://arxiv.org/abs/2410.03067)

**FedCert: 連合学習の精度認証**

Minh Hieu Nguyen, Huu Tien Nguyen, Trung Thanh Nguyen, Manh Duong Nguyen, Trong Nghia Hoang, Truong Thao Nguyen, Phi Le Nguyen

- 連合学習はデータをクライアントに保持することでプライバシーを守るが、データの改変に対するロバスト性評価が課題
- FedCertは各クライアントの認定精度とクラス分布を基にグローバルモデルの認定精度を近似する新手法を提案
- 非独立同分布なデータに対し、認定精度を安定させるためのクライアントグループ化アルゴリズムを導入
- CIFAR-10とCIFAR-100データセットでの実験で、FedCertが従来手法よりも一貫して推定誤差を減少させることを確認

FedCert、面白そう！連合学習の新しい可能性を探ってるって感じでワクワクするね。実際のデータで有効性が確認されたってすごく重要だし、これからの研究でどんな進展があるのか楽しみ！

**Comment:** The 22nd International Symposium on Network Computing and   Applications (NCA 2024)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-10-04 01:19
