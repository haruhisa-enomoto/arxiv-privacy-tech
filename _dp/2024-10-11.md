---
title: 差分プライバシー (2024-10-11 ~ 2024-10-17)
date: 2024-10-11
---

差分プライバシーに関する論文まとめ (2024-10-11 ~ 2024-10-17)


- - -

### [Model-Based Differentially Private Knowledge Transfer for Large Language Models](http://arxiv.org/abs/2410.10481)

**大規模言語モデルのためのモデルベース差分プライバシー知識転送**

Zhaomin Wu, Jizhou Guo, Junyi Hou, Bingsheng He, Lixin Fan, Qiang Yang

- 大規模言語モデルの普及により、プライバシーを守りつつドメイン知識を活用する必要が増加。
- 既存手法はドメイン知識の有用性かデータのプライバシーを犠牲にする場合が多い。
- 新たに提案したLlamdexは、プライバシーを保ちながらドメイン特化モデルを統合。
- この手法により、ディファレンシャルプライバシー制約の下で最大26%の精度向上を実現。

これってすごいね！プライバシー守りながら精度も上げられるなんて、未来の技術って感じ！Llamdexがどんな風に現実世界で使われるか楽しみだね。



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-14 13:18


- - -

### [Tighter Risk Bounds for Mixtures of Experts](http://arxiv.org/abs/2410.10397)

**専門家の混合に対するリスク境界の強化**

Wissam Akretche, Frédéric LeBlanc, Mario Marchand

- 専門家の混合のリスクに対し、局所的差分プライバシー（LDP）を用いて上限を提供
- 従来の$n$-out-of-$n$ではなく、one-out-of-$n$ゲーティング機構に特化した理論的保証
- リスク境界が専門家の数に対して対数依存し、LDPパラメータによりかなり緊密
- 実験結果は理論を支持し、一般化能力の向上とゲーティングへのLDP適用の実現可能性を示す

理論的に新しい境界を導出しながら、実験でその効果を確認しているのが特に面白いと思った！これで、専門家の混合がもっと効率的になるかもね！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ML, **投稿日時:** 2024-10-14 11:37


- - -

### [Differentially Private Selection using Smooth Sensitivity](http://arxiv.org/abs/2410.10187)

**スムースセンシティビティを用いたDifferentially Private Selection**

Akito Yamamoto, Tetsuo Shibuya

- データ解析におけるプライバシー保護は差分プライバシーで重要情報を取得する選択タスクで強調される
- 既存の手法はグローバルセンシティビティを使用し、必要以上の摂動を加える可能性がある
- スムースセンシティビティを用いた新しい手法を提案し、厳密なプライバシー保証の理論的証明を示す
- 新しい定理で効率的なノイズ生成を提案し、実験で既存手法より高精度を示す

プライバシーを守るためにスムースセンシティビティを使った方法、とても面白そうだよね！これが使えると、もっと正確にプライバシーを保ちながらデータ分析ができるようになりそうで、ワクワクしちゃう。Python実装が公開されてるから、自分でも試してみたいなぁ！

**Comment:** Preprint of an article accepted at IEEE IPCCC 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, **投稿日時:** 2024-10-14 06:14


- - -

### [Efficient Federated Unlearning under Plausible Deniability](http://arxiv.org/abs/2410.09947)

**もっともらしい否認の下での効率的な連合学習の忘却**

Ayush K. Varshney, Vicenç Torra

- 欧州のGDPRや米国のCCPAは、ユーザーにデータ削除の権利を与える
- 従来の機械学習では、モデルのパラメータを変えずにデータ削除と偽る事が可能
- 提案手法は、サーバーがクライアントの参加を否認できるプライバシーモデルを活用
- 新手法は学習後でも差分プライバシーを満たしつつ、メモリと再訓練時間を大幅に削減

効率的な連合学習の忘却を実現するってちょっとワクワクするよね！30倍もメモリ節約ってすごくない？しかも再訓練時間まで大幅減少！この研究でプライバシー保護がもっと進むといいな。

**Comment:** This paper has been accepted for publication in the journal track   (Springer Machine Learning) of ACML 2024. Published version will be available   after the conference. The source code is available at   https://github.com/Ayush-Umu/Federated-Unlearning-under-Plausible-Deniability

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-10-13 18:08


- - -

### ["I inherently just trust that it works": Investigating Mental Models of Open-Source Libraries for Differential Privacy](http://arxiv.org/abs/2410.09721)

**「うまくいくと信じているだけ」：差分プライバシーのオープンソースライブラリに関するメンタルモデルの調査**

Patrick Song, Jayshree Sarathy, Michael Shoemate, Salil Vadhan

- 差分プライバシー（DP）はプライバシー保護の有望な手法だが、実践への移行は難しい
- オープンソースライブラリはDPの理解と信頼の構築において重要な役割を果たすが課題が多い
- 開発者とユーザー間のメンタルモデルのギャップを埋めることが重要であると示唆
- DPライブラリの発展には、厳密な実装とユーザーの相互作用を両立させる工夫が必要

オープンソースのライブラリ開発って、プライバシーを守るだけじゃなくて、ユーザーとのコミュニケーションも大切なんだね！差分プライバシーの理解を深める新しいデザインが試みられてどんな進化を遂げるのか、ワクワクする！

**Comment:** 39 Pages, 12 Figures. To be published in CSCW 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.HC, **投稿日時:** 2024-10-13 04:24


- - -

### [Distribution-Aware Mean Estimation under User-level Local Differential Privacy](http://arxiv.org/abs/2410.09506)

**ユーザーレベルの局所的差分プライバシーにおける分布認識型平均推定**

Corentin Pla, Hugo Richard, Maxime Vono

- ユーザーごとに均一でないデータ量を持つ平均推定の問題に取り組む
- 統計者が知らないユーザーデータ量が既知の分布から得られる状況を考慮
- 分布に基づいた平均推定アルゴリズムで最悪のリスクに対する上界を示す
- 上界と下界が対数因子を除いて漸近的に一致し、一様な場合の既知の境界を含む

この論文、ユーザーごとに異なるデータ量を考慮しつつ平均を正確に推定する手法を提案してて面白そう！新しいアプローチがどんな実用的なインパクトをもたらすか気になるね。これからの研究の発展が楽しみ～！

**Comment:** 25 pages, 1 figure

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ME, cs.AI, cs.CR, cs.LG, stat.ML, **投稿日時:** 2024-10-12 11:57


- - -

### [The 2020 United States Decennial Census Is More Private Than You (Might) Think](http://arxiv.org/abs/2410.09296)

**2020年アメリカ合衆国10年ごとの国勢調査は思ったよりプライバシーが保護されている**

Buxin Su, Weijie J. Su, Chendi Wang

- 2020年の国勢調査は差分プライバシーを採用して個人データを保護
- プライバシー予算を完全に活用せず8.50%から13.76%が未使用
- 不要なノイズ追加により、精度改善の余地があることを発見
- ノイズを減らすことで統計データの歪みを緩和し精度向上を示した

この論文、めっちゃ興味深いね！プライバシーとデータの精度を両立しようとしてるところがすごくクールで、未来の政策決定に役立ちそう！テクノロジーが社会にどう影響するか考えるいい機会だね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DS, stat.AP, stat.ML, **投稿日時:** 2024-10-11 23:06


- - -

### [Federated Learning in Practice: Reflections and Projections](http://arxiv.org/abs/2410.08892)

**実践における連合学習: 振り返りと展望**

Katharine Daly, Hubert Eichner, Peter Kairouz, H. Brendan McMahan, Daniel Ramage, Zheng Xu

- 連合学習は複数のエンティティがデータを交換せずに共同でモデルを学習する技術
- GoogleやApple、Metaのシステムは、連合学習の実際の適用例を示している
- 課題はサーバー側の差分プライバシー保証の検証や異種デバイス間の調整
- 新たな連合学習フレームワークはプライバシー原則を優先し、未来の課題に対応

連合学習ってすごいね！みんなでデータをシェアせずに、匿名で一緒に学習できるなんて、まるで未来の技術みたい。これからさらに進化していくと、もっと便利なことができそうでワクワクするね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-11 15:10


- - -

### [Privacy-Preserving Optimal State Estimation with Low Complexity via Cramér-Rao Lower Bound Approach](http://arxiv.org/abs/2410.08756)

**低複雑度でプライバシーを保護する最適状態推定：クレーマー・ラオ下界アプローチによる解法**

Liping Guo, Jimin Wang, Yanlong Zhao, Ji-Feng Zhang

- 動的システムの最適状態推定問題をプライバシー保護しつつ解決する方法を検討
- クレーマー・ラオ下界を用い、平均二乗誤差でプライバシーレベルを評価
- 制約付き最適化問題として定式化し、プライバシーと有用性のトレードオフを実現
- 提案手法は低複雑度で微分プライバシーを達成し、実例でその有効性を示す

この研究、プライバシー保護しながら精度も妥協しないっていうのがすごいね！しかもオンラインで計算できるなんて、今後の応用も楽しみだね～。いろんな分野で役に立ちそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** eess.SY, cs.SY, **投稿日時:** 2024-10-11 12:15


- - -

### [Balancing Innovation and Privacy: Data Security Strategies in Natural Language Processing Applications](http://arxiv.org/abs/2410.08553)

**革新とプライバシーのバランス：自然言語処理アプリケーションにおけるデータセキュリティ戦略**

Shaobo Liu, Guiran Liu, Binrong Zhu, Yuanshuai Luo, Linxiao Wu, Rui Wang

- 差分プライバシーに基づく新しいアルゴリズムを提案し、チャットボットや感情分析などでユーザーデータを保護する
- 差分プライバシー機構によりランダムノイズを追加し、情報漏洩リスクを削減しつつデータ処理を効果的に実現
- 従来のデータ匿名化や準同型暗号と比較して、計算効率とスケーラビリティにおいて優位性がある
- 各種性能指標で他の手法を上回り、プライバシーと有用性のバランスを効果的に実現

差分プライバシーを使ってるのがすごく面白いって思った！これからのNLPアプリは、安全に楽しめる時代になりそうだね。ユーザーのプライバシーを守りつつ、どんどん進化していく未来が楽しみ！



**トピック:** [差分プライバシー](../../dp), [準同型暗号](../../he), **カテゴリ:** cs.CR, cs.AI, cs.CL, **投稿日時:** 2024-10-11 06:05
