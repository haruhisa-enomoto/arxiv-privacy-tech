---
title: 全て (2024-08-16 ~ 2024-08-22)
date: 2024-08-16
---

全てに関する論文まとめ (2024-08-16 ~ 2024-08-22)


- - -

### [A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs](http://arxiv.org/abs/2408.08868)

**実践でのプライベート学習のための手間のかからないアルゴリズム: ツリー集約を使わずにBLTを使おう**

H. Brendan McMahan, Zheng Xu, Yanxiang Zhang

- ツリー集約はプライバシーと有用性のトレードオフが最適ではない
- 行列分解は事前に推定が難しい定数による高額な最適化と高い実行時メモリコストを要求
- 緩衝されたリニアトープリッツ(BLT)メカニズムを用い、マルチ参加シナリオでDP-FTRLを拡張
- BLT-DP-FTRLはツリー集約の使いやすさを保持しつつ、行列分解並みの有用性とプライバシーを実現

BLTメカニズム、なんだか効率良さそうで現実のアプリでもかなり使えそうだわ！スマホのキーボードでこれが使われたら入力がもっとプライベートで快適に!?



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-16 17:52


- - -

### [A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT](http://arxiv.org/abs/2408.08722)

**プライバシー重視のIIoT異常検知のための新しいバッファ付き連合学習フレームワーク**

Samira Kamali Poorazad, Chafika Benzaid, Tarik Taleb

- IIoTはデータプライバシーとサイバーセキュリティの脅威に敏感
- FLはプライバシーを保護しつつ、ローカルデータでモデルを共同訓練
- 垂直同期と非同期のFLには限界があり、データ異質性とリソース制約が影響
- 新提案のBFLは、準同型暗号とバッファベースサーバーで限界を克服

バッファ技術を使ってプライバシーと効率性を両立させちゃうとか、めっちゃおもしろそう！さらに、データ保護も強化されるから、もっと安心してIIoTが使える未来が広がりそうだね。



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-08-16 13:01


- - -

### [Beyond the Hype: A dispassionate look at vision-language models in medical scenario](http://arxiv.org/abs/2408.08704)

**誇張を超えて：医療シナリオにおける視覚言語モデルの冷静な評価**

Yang Nan, Huichi Zhou, Xiaodan Xing, Guang Yang

- 最近のLarge Vision-Language Models (LVLMs)は多様なタスクで卓越した能力を示しており、特にAIコミュニティで注目されている
- 医療分野でのパフォーマンスと信頼性は十分に評価されておらず、多くの評価が視覚質問応答(VQA)に集中している
- RadVUQA（新たな放射線視覚理解と質問応答ベンチマーク）を導入し、既存のLVLMsを包括的に評価する
- 結果として、LVLMsには重大な欠陥があり、多モーダル理解と定量的推論能力が弱いことが判明した

医療で使われる視覚言語モデルにもっと頑張って欲しいな！この研究がレベルアップに貢献してくれるといいね。

**Comment:** 10 pages

**トピック:** [合成データ](../../sd), **カテゴリ:** cs.CV, cs.AI, **投稿日時:** 2024-08-16 12:32


- - -

### [RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS](http://arxiv.org/abs/2408.08699)

**RBLA: 連合学習サービスにおける異種モデルの微調整のためのランクベースLoRAアグリゲーション**

Shuaijun Chen, Omid Tavallaie, Niousha Nazemi, Albert Y. Zomaya

- 連合学習（FL）はモバイルやデスクトップなどの多様なデバイスでプライバシーを保護しながら学習を分散させる枠組み
- LoRAはモデルのパラメータの低次元部分に焦点を当てて効率的に微調整を行う方法で、計算およびメモリコストを削減
- FL環境でのLoRAは、ローカルモデルのランクを調整することで異なるハードウェアに柔軟かつ効率的に展開可能
- 異なるランクのモデルの集約にRBLAを提案し、現行のパディング手法が性能を低下させる問題を解決

Rank-Based LoRA Aggregation (RBLA)の提案で、これまでのモデル集約の課題が改善されるみたい。特に異なるデバイスの特徴を活かせるところが新しくて良いね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-08-16 12:26


- - -

### [A Multivocal Literature Review on Privacy and Fairness in Federated Learning](http://arxiv.org/abs/2408.08666)

**連合学習におけるプライバシーと公平性に関する多面的文献レビュー**

Beatrice Balbierer, Lukas Heinlein, Domenique Zipperling, Niklas Kühl

- 連合学習はデータ共有なしでAI応用を革新するが、学習中に情報が抽出される可能性が示された
- 差分プライバシーなどの追加のプライバシー保護措置が必要である
- 高リスクな応用（例：医療）では過去の差別的なエラーを繰り返さないことが重要
- プライバシーと公平性の関係性が無視され、現実世界のアプリケーションに重大なリスクをもたらしている

プライバシーと公平性のバランスを取るって超難しそうだけど、やりがいがありそう。実際のアプリにも早く使われたらいいな！

**Comment:** Accepted for publication at the Internationale Tagung   Wirtschaftsinformatik 2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-16 11:15


- - -

### [Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons](http://arxiv.org/abs/2408.08655)

**連合学習におけるバックドア攻撃の軽減：低活性入力ニューロンの重み更新を反転させる手法**

Binbin Ding, Penghui Yang, Zeqing Ge, Shengjun Huang

- 連合学習はサーバの管理下で複数のクライアントが協力し、プライバシー要件を遵守しながら機械学習モデルを訓練する技術である
- バックドア攻撃は、妥協されたモデル中の特定のニューロンを活性化させ、クリーンデータではこれらのニューロンは休止状態にある
- FLAINと呼ばれる新しい手法を提案し、低活性入力ニューロンの重み更新を反転させることでバックドア攻撃を防ぐ
- 広範な実験により、非独立同分布（non-IID）データや高MCRシナリオでもバックドア攻撃の成功率を低く抑え、クリーンデータの性能劣化も最小限に抑えることが確認された

FLAINって名前がかわいい(笑) どんな攻撃にもピンポイントに対抗できるなんて、まるでデジタル世界の防犯カメラみたい。未来のセキュリティ技術に繋がるかもって思うとワクワクするよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-16 10:44


- - -

### [The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy](http://arxiv.org/abs/2408.08642)

**バイアスの力：異質な差分プライバシーを考慮した連合学習のクライアント選択の最適化**

Jiating Ma, Yipeng Zhou, Qi Li, Quan Z. Sheng, Laizhong Cui, Jiangchuan Liu

- クライアントはモデル勾配を公開するが、元のデータは公開しない連合学習のプライバシー保護
- 差分プライバシーを導入したDPFLは勾配にノイズを加えて保護を強化
- クライアント選択の問題として、異質なプライバシー要件とデータ品質、ノイズの影響を考慮
- DPFL-BCSアルゴリズムを提案し、実験結果から既存手法に比べモデル性能向上を確認

このアルゴリズム、めちゃおもしろそう！差分プライバシーのノイズまで考慮して最適化してるのって新しいから、実際にどう使えるのかもっと知りたいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-16 10:19


- - -

### [Linear combinations of latents in diffusion models: interpolation and beyond](http://arxiv.org/abs/2408.08558)

**拡散モデルにおける潜在変数の線形結合：補間とその先**

Erik Bodin, Henry Moss, Carl Henrik Ek

- 生成モデルはデータ合成や拡張に重要で、ガウス潜在変数を使用して生成する
- 現在の標準手法では、中間体が期待される分布に従わないことがある
- 新しい補間手法COGは、標準手法を上回るか匹敵し、実装が簡単
- COGは線形結合に対応し、高次元オブジェクトの表現を簡単に生成可能

この論文、生成モデルの操作方法をより自由にできるってところが面白そう！ガウス潜在変数の新しい使い方、いろいろな可能性が広がりそうだなって思う。



**トピック:** [合成データ](../../sd), **カテゴリ:** stat.ML, cs.LG, **投稿日時:** 2024-08-16 06:43


- - -

### [SeeWasm: An Efficient and Fully-Functional Symbolic Execution Engine for WebAssembly Binaries](http://arxiv.org/abs/2408.08537)

**SeeWasm: WebAssemblyバイナリのための効率的かつ完全機能のシンボリック実行エンジン**

Ningyu He, Zhehao Zhao, Hanqin Guan, Jikai Wang, Shuo Peng, Ding Li, Haoyu Wang, Xiangqun Chen, Yao Guo

- WebAssemblyは40以上の高級プログラミング言語からコンパイル可能なコンパクトで高速なバイナリフォーマット
- Wasmバイナリの脆弱性は機密データ漏洩やホスティング環境の脅威になる可能性がある
- SeeWasmは全機能のWasmバイナリをサポートしつつ手動介入を不要にし、既存ツールに比べて解析速度を2〜6倍向上
- SeeWasmを使用して30以上のゼロデイ脆弱性やセキュリティ問題を特定した実績がある

SeeWasmを使えば、もっとスムーズに脆弱性が見つかりそうだね！WebAssemblyの解析が効率化されたら、セキュリティ強化に大活躍するに違いないよ！

**Comment:** Accepted by ISSTA'24 Demo Track, the tool can be accessed at   https://github.com/PKU-ASAL/SeeWasm

**トピック:** [TEE](../../tee), **カテゴリ:** cs.CR, cs.SE, **投稿日時:** 2024-08-16 05:42


- - -

### [Models Matter: Setting Accurate Privacy Expectations for Local and Central Differential Privacy](http://arxiv.org/abs/2408.08475)

**モデルは重要: ローカルおよび中央差分プライバシーのための正確なプライバシー期待の設定**

Mary Anne Smart, Priyanka Nanayakkara, Rachel Cummings, Gabriel Kaptchuk, Elissa Redmiles

- 差分プライバシーは人気のあるプライバシー技術で、業界や政府で導入されている
- 現行の差分プライバシーの説明は、データ提供者が期待するプライバシーを正確に設定できていない
- ローカルモデルと中央モデルのための新しい差分プライバシーの説明を設計し評価
- プライバシー影響を明示した説明が、正確なプライバシー期待を設定する上で有望であることを発見

この論文、正確なプライバシー期待を設定するための新しい説明方法について研究してて、めっちゃ興味深い！プライバシーを守ることがもっと確実になりそうだよね。



**トピック:** [差分プライバシー](../../dp), [PETs](../../pets), **カテゴリ:** cs.CR, cs.HC, **投稿日時:** 2024-08-16 01:21


- - -

### [Fairness Issues and Mitigations in (Differentially Private) Socio-demographic Data Processes](http://arxiv.org/abs/2408.08471)

**（差分プライバシー付き）社会人口統計データ処理における公平性の問題と対策**

Joonhyuk Ko, Juba Ziani, Saswat Das, Matt Williams, Ferdinando Fioretto

- 重要な社会調査はサンプリング誤差を導入し、グループレベルの推定に不公平が生じる
- 最適化手法を導入し、サンプリングコストを最適化しつつ誤差を許容範囲内に抑える
- サンプリング率を決定するプライバシー保護手法が公平性問題に影響を与える
- 差分プライバシーによるノイズが不公平を軽減し、小規模データに正の影響を与える

大規模なデータセット分析で実証されたみたい！差分プライバシーが不公平を減らすって驚きだよね、もっと詳しく知りたいな。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.CY, **投稿日時:** 2024-08-16 01:13
