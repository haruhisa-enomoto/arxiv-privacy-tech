---
title: 連合学習 (2024-10-04 ~ 2024-10-10)
date: 2024-10-04
---

連合学習に関する論文まとめ (2024-10-04 ~ 2024-10-10)


- - -

### [Distributionally Robust Clustered Federated Learning: A Case Study in Healthcare](http://arxiv.org/abs/2410.07039)

**分布的にロバストなクラスタ化連合学習: ヘルスケアにおけるケーススタディ**

Xenia Konti, Hans Riess, Manos Giannopoulos, Yi Shen, Michael J. Pencina, Nicoleta J. Economou-Zavlanos, Michael M. Zavlanos

- ヘテロなデータ分布の課題に対し、新アルゴリズムCS-RCFLを提案
- Wasserstein距離を用いて各クライアントのデータ分布の曖昧さを測定
- 最適な分布的にロバストなクラスタリングでローカルモデルの偏りを回避
- プライバシーを保持しつつの連合学習プロトコルを提案し、評価を行う

この研究って、ヘルスケアのデータをうまく活用しつつ個人情報も守れるってすごく重要だよね。クライアント間の偏りを避けるための新しいアプローチも面白そう！

**Comment:** 8 pages, 3 figures, Accepted to IEEE CDC 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-09 16:25


- - -

### [Diagnosis of Malignant Lymphoma Cancer Using Hybrid Optimized Techniques Based on Dense Neural Networks](http://arxiv.org/abs/2410.06974)

**密集ニューラルネットワークに基づくハイブリッド最適化技術を用いた悪性リンパ腫癌の診断**

Salah A. Aly, Ali Bakhiet, Mazen Balat

- リンパ腫の診断は形態の微細な違いで難易度が高い
- DenseNet201とDNNを組み合わせたハイブリッド学習フレームワークを提案
- Harris Hawks Optimizationアルゴリズムで最適化し、99.33%の精度を達成
- 精度、再現率、F1スコア、ROC-AUCでモデルの頑健性を評価

ハイブリッド学習と呼ばれる技術の進化で、医療分野でもますます効率的に精度が向上しそうだね！実際の臨床現場で、早く助かる患者さんが増えるといいなって思う。

**Comment:** 6 pages, 5 figures, 4 tables, IEEE ICCA

**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.CV, cs.LG, **投稿日時:** 2024-10-09 15:12


- - -

### [Forgetting Through Transforming: Enabling Federated Unlearning via Class-Aware Representation Transformation](http://arxiv.org/abs/2410.06848)

**変換による忘却: クラス認識表現変換による連合消去の実現**

Qi Guo, Zhen Tian, Minghao Yao, Yong Qi, Saiyu Qi, Yun Li, Jin Song Dong

- 連合消去（FU）は、プライバシーと規制を考慮し、特定データの影響を排除する技術。
- 従来のFU法はデータ削除とモデル性能の維持のバランスが難しい課題がある。
- 提案手法（FUCRT）は、クラス認識表現の変換を用いて消去を実現。
- 実験結果でFUCRTは100%のクラス消去と性能維持を達成し、従来手法を上回る。

新しい技術でプライバシーがもっと守られる未来が近づいてる感じ！データ削除しつつモデルの性能を保つとか、すごく役立ちそうだよね。ますますAIの可能性が広がりそうでワクワクする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-09 13:08


- - -

### [PFAttack: Stealthy Attack Bypassing Group Fairness in Federated Learning](http://arxiv.org/abs/2410.06509)

**PFAttack: 連合学習におけるグループフェアネスを回避するステルス攻撃**

Jiashi Gao, Ziwei Wang, Xiangyu Zhao, Xin Yao, Xuetao Wei

- 連合学習は複数のクライアントが共同で公平な決定を行うためのものである
- 攻撃者はフェアネス機構を回避しバイアスを持つグローバルモデルを作ることが可能である
- PFATTACKはグローバルモデルの精度を損なわずにフェアネス機構を回避する攻撃である
- PFATTACKは目立たず発見されにくい攻撃で、モデルのパラメータ変化が微細である

うわー、PFATTACKがやばそう！みんなが気づかないうちにモデルが偏っちゃうかも。連合学習の未来には、新しい対策が必要になるね。楽しみだなぁ、どんな展開になるか。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-09 03:23


- - -

### [FedL2G: Learning to Guide Local Training in Heterogeneous Federated Learning](http://arxiv.org/abs/2410.06490)

**FedL2G: 異種連合学習におけるローカルトレーニングのガイドを学習する方法**

Jianqing Zhang, Yang Liu, Yang Hua, Jian Cao, Qiang Yang

- 異種連合学習ではデータとモデルの異種性が課題で、モデルパラメータの集約が難しい
- グローバルなプロトタイプに合わせると、クライアントの目的と指導目標にミスマッチが生じる
- FedL2Gは、クライアントの目的に有益な形でローカルトレーニングをガイドする方法を提案
- 実験で6モデル異種性と2データ異種性において優れた性能を示した

これ、色んな異種モデルを扱えるんだね！ローカルトレーニングを賢くガイドするって、まるでデジタルの先生みたい。連合学習でもっと効率的な解決策がどんどん生まれるといいね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-09 02:31


- - -

### [OledFL: Unleashing the Potential of Decentralized Federated Learning via Opposite Lookahead Enhancement](http://arxiv.org/abs/2410.06482)

**OledFL: 逆見通し強化による非中央集権型連合学習の可能性の解放**

Qinglun Li, Miao Zhang, Mengzhu Wang, Quanjun Yin, Li Shen

- 非中央集権型連合学習（DFL）は中央集権型よりも高速なトレーニングとプライバシー保護を実現
- しかし、DFLは一般化能力で中央集権型に劣り、理論理解や実証性能が不十分
- 逆見通し強化技術（Ole）を活用して、DFLの一貫性を向上させることで一般化力と収束速度を改善
- CIFAR10とCIFAR100のデータセットで、最大5%性能向上と8倍の高速化を達成

最近の連合学習の話、面白そう！逆見通しとか新しいアプローチでどんな可能性が開けるのかワクワクするよね。いろんな実験で結果がしっかり出るのも期待できて嬉しいな！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-09 02:16


- - -

### [Communication-Efficient Federated Group Distributionally Robust Optimization](http://arxiv.org/abs/2410.06369)

**通信効率の良い連合グループ分布ロバスト最適化**

Zhishuai Guo, Tianbao Yang

- 連合学習はクライアント間のデータ量と分布の異質性により一般化能力が低下する課題がある
- 既存のグループ分布ロバスト最適化(GDRO)は通信とサンプルの複雑性が高い
- 提案するFGDRO-CVaRは平均の上位-K損失を最適化し通信複雑性を低減
- FGDRO-KLとFGDRO-KL-Adamにより、KL正則化を通じてさらに通信コストを削減

この論文、連合学習の通信コストをどんどん減らせるっていうのがすごくイケてる！特にFGDRO-KL-Adamが実用的に活躍しそうで、データ不足の問題を解決する未来が見える✨

**Comment:** Accepted to NeurIPS 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, stat.ML, **投稿日時:** 2024-10-08 21:07


- - -

### [De-VertiFL: A Solution for Decentralized Vertical Federated Learning](http://arxiv.org/abs/2410.06127)

**分散型垂直連合学習のためのDe-VertiFL**

Alberto Huertas Celdrán, Chao Feng, Sabyasachi Banik, Gerome Bovet, Gregorio Martinez Perez, Burkhard Stiller

- 水平連合学習と異なり、垂直連合学習は同一エンティティの異なるデータを扱うため未開拓
- De-VertiFLは新しいネットワークアーキテクチャや知識交換方式を導入した
- 各クライアント間で隠れ層の出力を共有し、中間計算の利益を享受しつつ効率的に学習
- 評価結果は高性能でプライバシーも守りつつF1スコアで最新手法を上回る

新しい仕組みを使って色々工夫してるから、どんなデータでも上手くできちゃうってことなのかな？分散型でプライバシーを守りつつ性能が良いのは、なんだか安心して使える未来が待ってる感じ♪



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-08 15:31


- - -

### [Private and Communication-Efficient Federated Learning based on Differentially Private Sketches](http://arxiv.org/abs/2410.05733)

**差分プライベートスケッチに基づくプライバシーと通信効率の良い連合学習**

Meifan Zhang, Zhanhong Xie, Lihua Yin

- 連合学習ではプライバシーの漏洩リスクと通信の非効率が課題
- DPSFLは差分プライバシースケッチを使用し通信効率とプライバシーを向上
- 勾配クリッピングはノイズの影響を抑えるがバイアスを生むため性能に悪影響
- DPSFL-ACは適応クリッピングによりバイアスを軽減し優れた性能を実証

連合学習って、ただ共有すればいいってもんじゃないのが面白いね！DPSFLでプライバシーも通信も改善できちゃうなんて、実用化されたらすごく便利そうだし、頼もしいなって思っちゃう！💡



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-08 06:50


- - -

### [KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server](http://arxiv.org/abs/2410.05725)

**KnowledgeSG: サーバからの知識蒸留によるプライバシー保護付き合成テキスト生成**

Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang

- 大規模言語モデルの記憶化でプライバシー懸念が生じる
- 合成データ利用は性能向上とプライバシー保護の両立が難しい
- KnowledgeSGは、差分プライバシーと知識蒸留で品質と性能を向上
- 連合学習に着想を得て、モデルをクライアント・サーバ間で共有しプライバシーを保護

この方法は、プライバシーも守りつつ性能も上げるなんてすごくおもしろそう！医療や金融みたいなデータが重要でセンシティブな分野でもうまくいくなら、めっちゃ役立ちそうだね。どんな時代が来るんだろう、ワクワクする～！

**Comment:** EMNLP 2024 Main

**トピック:** [連合学習](../../fl), [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-10-08 06:42


- - -

### [Federated Learning with Dynamic Client Arrival and Departure: Convergence and Rapid Adaptation via Initial Model Construction](http://arxiv.org/abs/2410.05662)

**動的クライアント到着と離脱を伴う連合学習: 収束と初期モデル構築による迅速な適応**

Zhan-Lun Chang, Dong-Jun Han, Rohit Parasnis, Seyyedali Hosseinalipour, Christopher G. Brinton

- 従来の連合学習は固定されたクライアントを想定するが、実際にはクライアントは動的に参加や離脱を行う。
- クライアントの変動によって、最適化目標が動的に変化するため、適応が遅れる可能性がある。
- 最適モデルを動的に調整するための初期モデル構築戦略を提案し、クライアントのデータ特性に基づくモデルを使用。
- 様々なデータセットとアルゴリズムで検証を行い、多様なクライアント変化において強力な性能を示した。

動的なクライアントの参加と離脱を考慮した連合学習なんて、なんかめっちゃ面白そう！これからはもっと柔軟で適応力のあるAIが求められるから、この研究が実現したら、いろんなアプリに応用できそうでワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-08 03:22


- - -

### [Aiding Global Convergence in Federated Learning via Local Perturbation and Mutual Similarity Information](http://arxiv.org/abs/2410.05545)

**ローカル摂動と相互類似情報による連合学習のグローバル収束支援**

Emanuel Buttaci, Giuseppe Carlo Calafiore

- 連合学習は、携帯端末の増加による分散最適化パラダイムとして注目される技術
- 類似性グラフを用い、クライアント間の統計的類似性を活かす新たなフレームワークを提案
- 提案手法は、FedAvgやFedProxに比べて強凸な場合の収束速度を理論的に向上
- 実験ではCIFAR10とFEMNISTを用い、最大30ラウンドの収束高速化と一般化の改善を確認

連合学習の収束を加速するために、クライアントの類似性を活用しているんだね！技術的には難しそうだけど、実験結果が30ラウンド早くなるなんてすごくおもしろいよね！実際の活用が楽しみだな〜！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, math.OC, **投稿日時:** 2024-10-07 23:14


- - -

### [Over-the-Air Federated Learning in Cell-Free MIMO with Long-term Power Constraint](http://arxiv.org/abs/2410.05354)

**セルフリーMIMOにおける長期的な電力制約を考慮した無線連合学習**

Yifan Wang, Cheng Zhang, Yuanndong Zhuang, Yongming Huang

- 無線ネットワークでのAI対応が注目され、無線連合学習が重要な応用として浮上
- セルフリーMIMOシステムでの無線連合学習の誤差境界を導出し、最適化問題を設定
- MOP-LOFPCアルゴリズムを提案し、長期制約をラウンドごとに切り離しつつ、随時のチャネル状態情報を利用
- 実験結果で、MOP-LOFPCが既存のベースラインに比べて、モデルの訓練損失と長期電力制約のバランスを改善

この技術を使えば、無線ネットワーク上でのAI応用がさらにスムーズに！MOP-LOFPCの適応性もキーポイントで、新たな可能性が広がりそうだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-07 13:44


- - -

### [FRIDA: Free-Rider Detection using Privacy Attacks](http://arxiv.org/abs/2410.05020)

**FRIDA: プライバシー攻撃を用いたフリーライダー検出**

Pol G. Recasens, Ádám Horváth, Alberto Gutierrez-Torre, Jordi Torres, Josep Ll. Berral, Balázs Pejó

- 連合学習は複数の参加者でモデルを共同訓練するが、フリーライダーの存在が問題
- フリーライダーは学習プロセスの妥当性を損ない、モデルの収束を遅らせ、コスト増加を招く
- FRIDAはプライバシー攻撃を使い、参加者のデータセットからフリーライダーを直接検出
- FRIDAは最新の手法より効果的で、特にデータが非独立同分布（非IID）の場合に優位性を示す

これって、なんかすごくない？プライバシー攻撃を逆手に取って、みんなで守る側の発想を変えるんだって！技術的に新しいチャレンジをしてるから、これからも注目したいな！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-07 13:20


- - -

### [FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models](http://arxiv.org/abs/2410.04810)

**FedBiP: 個別化潜象拡散モデルを用いた異質ワンショット連合学習**

Haokun Chen, Hang Li, Yao Zhang, Gengyuan Zhang, Jinhe Bi, Philip Torr, Jindong Gu, Denis Krompass, Volker Tresp

- ワンショット連合学習（OSFL）は通信費を削減しプライバシーを保護する手法
- 従来のOSFLはクライアントデータの異質性と少量のデータが課題
- プレトレーニングされた潜象拡散モデル（LDM）は高品質画像生成に優れるが、OSFLには最適でない
- FedBiPはLDMを個別化し、データ分布を考慮した画像を合成して性能を向上

おもしろそうな論文だね！医療画像とか珍しいデータでもしっかり対応できるのってすごいな〜。プライバシーも守りつつ効果的に連合学習を実現するなんて、未来の技術って感じでワクワクする〜！



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.CV, cs.DC, cs.MM, **投稿日時:** 2024-10-07 07:45


- - -

### [Federated Learning Nodes Can Reconstruct Peers' Image Data](http://arxiv.org/abs/2410.04661)

**連合学習ノードが他のノードの画像データを再構築できる**

Ethan Wilson, Kai Yue, Chau-Wai Wong, Huaiyu Dai

- 連合学習はプライバシーを保ちつつノード間でモデルを訓練する技術だが、データのプライバシーは保証されない
- 誠実だが好奇心旺盛なノードが、他のノードの画像データを再構築できることを示す
- 単一のクライアントが連続した更新情報を利用し、他のクライアントの画像を密かに再構築できる
- 拡散モデルを使って再構築画像の質を高め、セマンティックな情報漏洩のリスクを強調

連合学習って便利そうだったけど、ちゃんと考えないと他人のデータを覗かれちゃうんだね！もっと安全な仕組みができたら、いろんな分野で活用できそうでワクワク！

**Comment:** 12 pages including references, 12 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-07 00:18


- - -

### [Implicit to Explicit Entropy Regularization: Benchmarking ViT Fine-tuning under Noisy Labels](http://arxiv.org/abs/2410.04256)

**暗黙から明示的なエントロピーレギュラリゼーションへの移行: ノイズラベル下におけるViTファインチューニングのベンチマーク**

Maria Marrium, Arif Mahmood, Mohammed Bennamoun

- 大規模データセットの自動アノテーションはノイズラベルを導入し、DNNの学習に悪影響を与える
- ViTのファインチューニングはノイズラベルに脆弱で、CNNと比較した頑健性を評価した
- CNN向けに開発されたNLL手法がViTにも同様に効果的かどうかを調査
- エントロピー正則化が既存の損失関数やNLL手法の頑健性を向上させることが判明

ノイズラベルによる悪影響を軽減するために、エントロピーの役割が重要ってことなんだね！データサイエンスの未来に貢献できる研究だし、ViTが普及してきた今、私たちも頑張らなきゃって思った！✨



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.AI, **投稿日時:** 2024-10-05 18:24


- - -

### [ConDa: Fast Federated Unlearning with Contribution Dampening](http://arxiv.org/abs/2410.04144)

**ConDa: 貢献抑制による高速連合アンラーニング**

Vikram S Chundawat, Pushkar Niroula, Prasanna Dhungana, Stefan Schoepf, Murari Mandal, Alexandra Brintrup

- 連合学習では参加者の追加は簡単だが、参加者の削除は難題である
- ConDaは、不要な情報の寄与を弱体化することで効率的にデータを消去
- クライアントのデータ再学習や計算負荷なく、プライバシーの確保を実現
- 非IID環境で、他の方法より100倍以上の速さでアンラーニングが可能

すごい！データの消去ってずっと難しかったけど、こんなに早くて簡単にできちゃうなんて驚きだよね！プライバシーが守られる世界がさらに近づいてるのかもって思うとワクワクするな！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-05 12:45


- - -

### [pFedGame -- Decentralized Federated Learning using Game Theory in Dynamic Topology](http://arxiv.org/abs/2410.04058)

** pFedGame -- 動的トポロジーにおけるゲーム理論を用いた分散型連合学習 **

Monik Raj Behera, Suchetana Chakraborty

- 連合学習の課題として、中央集約サーバへの負荷やデータバイアスが存在
- pFedGameは中央サーバ不要のゲーム理論ベースの手法を提案
- 動的ネットワークでの消失する勾配と収束の問題を対応
- pFedGameは異種データで精度70%以上を達成し有望な結果

面白そう！分散型で部分連合学習ができるなんて、なんだか未来を感じるね。この技術が新しい協力関係を生むかもって思ったよ。



**トピック:** [連合学習](../../fl), **カテゴリ:** stat.ML, cs.CR, cs.GT, cs.LG, **投稿日時:** 2024-10-05 06:39


- - -

### [An Intelligent Native Network Slicing Security Architecture Empowered by Federated Learning](http://arxiv.org/abs/2410.05312)

**連合学習によって強化されたインテリジェントなネイティブネットワークスライシングセキュリティアーキテクチャ**

Rodrigo Moreira, Rodolfo S. Villaca, Moises R. N. Ribeiro, Joberto S. B. Martins, Joao Henrique Correa, Tereza C. Carvalho, Flavio de Oliveira Silva

- ネットワークスライシングは、5G/6Gネットワークなどでのリソース共有を変革
- 既存のアーキテクチャは、インテリジェントなセキュリティ機能が不足
- 提案するアーキテクチャは、機械学習ベースの連合エージェントを活用
- 提案手法により、DDoSと侵入攻撃を高精度で検出、約95.60%の平均精度を達成

新しいセキュリティアーキテクチャが連合学習で賢くなるなんてすごいよね！通信技術がもっと安全で便利になっちゃう未来が楽しみ。みんなも早くこの技術を体験できるといいなーって思ったよ。

**Comment:** 18 pages, 12 figures, Future Generation Computer Systems (FGCS)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, cs.ET, cs.LG, cs.NI, I.2; I.6; F.2.2, **投稿日時:** 2024-10-04 21:12


- - -

### [A Survey on Group Fairness in Federated Learning: Challenges, Taxonomy of Solutions and Directions for Future Research](http://arxiv.org/abs/2410.03855)

**連合学習におけるグループ公正性の調査：課題、解決策の分類と今後の研究の方向性**

Teresa Salazar, Helder Araújo, Alberto Cano, Pedro Henriques Abreu

- 機械学習におけるグループ公正性は重要で、連合学習が異なるデータの偏りを増幅させる可能性がある。
- 連合学習とグループ公正性の交差点に関する47の研究があるが、包括的な調査はなかった。
- 本研究は新しい分類法を用いて関連するアプローチを整理し、データ分割、位置、戦略による評価を行う。
- 将来の研究に必要な領域を強調し、連合システムにおけるグループ公正性の達成の複雑さに対応する方法を提案する。

この研究面白そうだよね！連合学習でのグループ公正性の課題をバッチリ解決できたら、多様なデータを持つサービスにとって革命的になりそう。これからの研究で、もっと公正な未来が開けるといいな！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CY, 68T01, I.2.6; I.5.1; K.4.1, **投稿日時:** 2024-10-04 18:39


- - -

### [FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein Estimator](http://arxiv.org/abs/2410.03499)

**FedStein: ジェームズ・スタイン推定器を用いたマルチドメイン連合学習の向上**

Sunny Gupta, Nikita Jangid, Amit Sethi

- 連合学習は、非独立同分布データの扱いで性能と収束性の課題がある
- 本研究は、異なる特徴分布を持つ複数ドメインの連合学習というあまり探索されていない問題に焦点を当てた
- 提案手法FedSteinは、クライアント間でバッチ正規化統計のジェームズ・スタイン推定値のみを共有する
- FedSteinは既存手法を超え、特定ドメインで14%以上の精度向上を達成

FedSteinって面白そう！新しい連合学習の方向性を切り開くかな？データの特徴が違ってもバッチ正規化だけ共有するアイデアが新鮮だし、精度も上がってるなんてすごい！私たちも試してみたいね。

**Comment:** 12 pages, 2 figures. Accepted at International Workshop on Federated   Foundation Models In Conjunction with NeurIPS 2024 (FL@FM-NeurIPS'24)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, cs.DC, I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;
  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10, **投稿日時:** 2024-10-04 15:13


- - -

### [Collaborative and Efficient Personalization with Mixtures of Adaptors](http://arxiv.org/abs/2410.03497)

**協力的かつ効率的なパーソナライズとアダプタの組み合わせ**

Abdulla Jasem Almansoori, Samuel Horváth, Martin Takáč

- 非独立同分布データは現実世界の連合学習でよく見られる問題である
- 提案するフレームワーク「FLoRAL」は各クライアントがパラメータを効率的に学習しタスクに適応
- アダプタのフェデレーションによりメモリ効率が向上し、効率的な協力学習が可能
- 実験でフルモデルのクラスタリングを超える性能を発揮し、有用性と堅牢性を実証

この研究って、みんなで協力してデータをシェアしながらも、それぞれに合った学び方ができるってのが面白いな！未来のアプリとかで個人にぴったりなサービスとか提供できたら楽しそうじゃない？

**Comment:** 36 pages, 10 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-04 15:11


- - -

### [Camel: Communication-Efficient and Maliciously Secure Federated Learning in the Shuffle Model of Differential Privacy](http://arxiv.org/abs/2410.03407)

**Camel: 差分プライバシーのシャッフルモデルにおける通信効率の高い悪意あるセキュア連合学習**

Shuangqing Xu, Yifeng Zheng, Zhongyun Hua

- 連合学習はクライアントのプライベートデータを公開せずにモデルを学習するパラダイム
- LDPメカニズムでプライバシー保証を提供するが、ノイズが多くモデルの有用性が低下
- シャッフルモデルを用いてプライバシー増幅し、より良いプライバシー-ユーティリティのトレードオフを実現
- Camelは通信効率とセキュリティを最適化し、RDPを用いてプライバシー損失を厳しく評価

連合学習って面白そうだよね。大人数で協力して賢いモデルを育てるなんて、未来の学校みたいでワクワクする！Camelの方法で、もっと安全で効率的になっていくのかなぁ。

**Comment:** Accepted by CCS'2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-04 13:13


- - -

### [Influence-oriented Personalized Federated Learning](http://arxiv.org/abs/2410.03315)

**影響指向の個別連合学習**

Yue Tan, Guodong Long, Jing Jiang, Chengqi Zhang

- 従来の連合学習は固定加重に頼り、データの不均一性に対応できない
- 提案するFedC^2Iは、クライアントとクラスの影響を定量化し適応的なパラメータ集約を実現
- 影響ベクトルと影響マトリクスを用いてクライアント間の影響をモデル化
- 非IID設定下で実験し、FedC^2Iが従来手法よりも優れていると評価

この論文、データのバラバラな状態での連合学習をもっと効果的にする方法なんだね！個々に合わせた学習を実現してくれるって、なんか未来の勉強スタイルみたいでワクワクする～！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-10-04 11:00


- - -

### [BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated Learning](http://arxiv.org/abs/2410.03281)

**BN-SCAFFOLD: 連合学習におけるバッチ正規化統計のドリフト制御**

Gonzalo Iñaki Quintana, Laurence Vancamberg, Vincent Jugnon, Mathilde Mougeot, Agnès Desolneux

- 連合学習は分散型で機械学習モデルを訓練する新しいパラダイム
- バッチ正規化は深層ニューラルネットワークで普及しているが、バラつきが問題に
- FedTANはバッチ正規化の統計を集約して対応するが通信コストが高い
- 新アルゴリズムBN-SCAFFOLDは通信効率を上げつつ性能でFedTANと同等

BN-SCAFFOLDって、通信コストを下げつつ性能を上げるなんてかっこいい！深層学習の訓練がもっと効率的になって、色んな新しい技術がでてきそうでワクワクしちゃう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-04 09:53


- - -

### [FedMAC: Tackling Partial-Modality Missing in Federated Learning with Cross-Modal Aggregation and Contrastive Regularization](http://arxiv.org/abs/2410.03070)

**FedMAC: 連合学習における部分モダリティ欠損へのクロスモーダル集約とコントラスト正則化による対処**

Manh Duong Nguyen, Trung Thanh Nguyen, Huy Hieu Pham, Trong Nghia Hoang, Phi Le Nguyen, Thanh Trung Huynh

- 連合学習は分散データで機械学習モデルを訓練し、クライアントのデータプライバシーを守る技術
- クライアント間でデータのモダリティが欠損する場合があり、データ分布の不均一さが課題となる
- 既存研究は完全なモダリティ欠損に対処するが、部分的なモダリティ欠損には効果的でない
- 提案手法FedMACは、統計的に不均一なクライアント構成でも26%の性能向上を達成

FedMAC、すごくイケてる名前だね！部分的にデータが欠けてても、ちゃんと結果が出る技術って便利そう！次のデジタル時代を支える技術になりそうだね。

**Comment:** The 22nd International Symposium on Network Computing and   Applications (NCA 2024)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.MM, **投稿日時:** 2024-10-04 01:24


- - -

### [FedCert: Federated Accuracy Certification](http://arxiv.org/abs/2410.03067)

**FedCert: 連合学習の精度認証**

Minh Hieu Nguyen, Huu Tien Nguyen, Trung Thanh Nguyen, Manh Duong Nguyen, Trong Nghia Hoang, Truong Thao Nguyen, Phi Le Nguyen

- 連合学習はデータをクライアントに保持することでプライバシーを守るが、データの改変に対するロバスト性評価が課題
- FedCertは各クライアントの認定精度とクラス分布を基にグローバルモデルの認定精度を近似する新手法を提案
- 非独立同分布なデータに対し、認定精度を安定させるためのクライアントグループ化アルゴリズムを導入
- CIFAR-10とCIFAR-100データセットでの実験で、FedCertが従来手法よりも一貫して推定誤差を減少させることを確認

FedCert、面白そう！連合学習の新しい可能性を探ってるって感じでワクワクするね。実際のデータで有効性が確認されたってすごく重要だし、これからの研究でどんな進展があるのか楽しみ！

**Comment:** The 22nd International Symposium on Network Computing and   Applications (NCA 2024)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-10-04 01:19
