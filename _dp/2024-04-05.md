---
title: 差分プライバシー (2024-04-05 ~ 2024-04-11)
date: 2024-04-05
---

差分プライバシーに関する論文まとめ (2024-04-05 ~ 2024-04-11)

### [Differentially Private Reinforcement Learning with Self-Play](http://arxiv.org/abs/2404.07559)
**差分プライバシーを用いた自己対戦型強化学習**

Dan Qiao, Yu-Xiang Wang

- 複数エージェント強化学習における差分プライバシー制約の問題を研究
- 双方向ゼロサムエピソード型マルコフゲームにJoint DPとLocal DPの定義を拡張し、軌道ごとのプライバシー保護を実現
- 楽観的ナッシュ値反復とBernstein型ボーナスのプライベート化に基づく効率的なアルゴリズムを設計
- 提案アルゴリズムは、適切なプライバシーメカニズムを用いてJoint DPとLocal DPの要件を満たす

**Comment:** 32 pages

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-11

---
### [Differentially Private GANs for Generating Synthetic Indoor Location Data](http://arxiv.org/abs/2404.07366)
**差分プライバシーを用いた合成室内位置データ生成のためのGAN**

Vahideh Moghtadaiee, Mina Alishahi, Milad Rabiei

- 室内位置情報システムの普及に伴い、建物内の個人の位置追跡が可能となるが、プライバシー侵害の懸念も生じる
- 差分プライバシー（DP）を用いることで、個々のデータポイントのプライバシーを保護しながら現実的な合成データを生成する差分プライバシー生成敵対ネットワーク（DPGAN）が注目されている
- 本研究では、DPGANを活用した室内位置情報フレームワークを導入し、プライバシー保護型室内位置データを生成
- 実際の室内位置情報データセットを使用してフレームワークの性能を評価し、プライバシー保護と位置情報システムの精度維持の効果を実証

**Comment:** Submitted to International Journal of Information Security

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **投稿日:** 2024-04-10

---
### [Indoor Location Fingerprinting Privacy: A Comprehensive Survey](http://arxiv.org/abs/2404.07345)
**屋内位置指紋プライバシーに関する包括的な調査**

Amir Fathalizadeh, Vahideh Moghtadaiee, Mina Alishahi

- 屋内位置情報サービスでは、利用者のデバイスからの信号指紋を用いて位置を正確に特定するが、これによりプライバシーのリスクが生じる
- 位置情報サービスプロバイダや潜在的な攻撃者が、このデータを閲覧できるため、利用者のプライバシーが侵害される可能性がある
- 暗号化、匿名化、差分プライバシー、連合学習などの手法を基に、屋内位置指紋におけるプライバシー保護メカニズムを包括的にレビュー
- 新たなプライバシーの脆弱性の分類、敵モデル、攻撃モデル、評価指標を提案し、今後の研究の課題と可能性に光を当てる

**Comment:** Submitted to ACM Computing Surveys

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **投稿日:** 2024-04-10

---
### [Private Wasserstein Distance with Random Noises](http://arxiv.org/abs/2404.06787)
**プライベートワッサースタイン距離におけるランダムノイズの利用**

Wenqian Li, Haozhi Wang, Zhe Huang, Yan Pang

- ワッサースタイン距離は、分布の観点からデータの発散を測る主要な尺度だが、データプライバシーの文脈では適用が困難
- 従来の差分プライバシーや連合学習によるワッサースタイン距離の近似は精度とロバスト性が不足していた
- 本研究で提案されたTriangleWadは、ワッサースタイン空間内の三角形の特性を利用して高速かつ正確に距離を計算
- TriangleWadは攻撃に対する耐性を高めつつ、画像とテキストデータを含む様々なタスクでの優れた性能と一般化を実証

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-10

---
### [Poisoning Prevention in Federated Learning and Differential Privacy via Stateful Proofs of Execution](http://arxiv.org/abs/2404.06721)
**連合学習と差分プライバシーにおけるポイズニング防止のための状態証明に基づく手法**

Norrathep Rattanavipanon, Ivan De Oliveira Nunes

- IoT駆動型の分散データ分析の増加とプライバシー懸念の高まりが、プライバシーを保護する効果的なデータ収集・モデル訓練の機構として連合学習（FL）および局所差分プライバシー（LDP）の需要を生んだ
- FLおよびLDPは偽造データ（poisoned data）によるポイズニング攻撃のリスクにさらされており、エッジデバイスのデータ整合性を損なわれる可能性がある
- 本研究は、Provable of Stateful Execution（PoSX）という新しいセキュリティ概念を用いて、ポイズニング攻撃から保護するシステムレベルのアプローチSLAPPを提案
- SLAPPは、ARM TrustZoneMセキュリティ拡張を利用して、FL/LDPのエッジデバイスのプロセスにおいて正確なデータ使用を保証し、セキュリティと低オーバーヘッドの双方を実現している

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **投稿日:** 2024-04-10

---
### [Atlas-X Equity Financing: Unlocking New Methods to Securely Obfuscate Axe Inventory Data Based on Differential Privacy](http://arxiv.org/abs/2404.06686)
**Atlas-X エクイティファイナンス：差分プライバシーを用いた斧インヴェントリーデータの安全な難読化方法の解放**

Antigoni Polychroniadou, Gabriele Cipriani, Richard Hua, Tucker Balch

- 銀行はロング（購入）およびショート（売却）取引の効果的な位置付けを支援するため、選択したクライアントに毎日利用可能な証券/資産（斧リスト）のリストを公開している
- しかし、これにより銀行の在庫や大きな取引を行うクライアントの取引が他のクライアントに漏れる問題が生じる
- 差分プライバシーを活用した新しい方法「Atlas-X Axe Obfuscation」によって、銀行は日々公開する斧リストを曖昧化し、トレーディングの利益と損失（P&L）コストを維持しながらクライアントの取引活動の漏洩を減らすことができる
- この差分プライバシーのソリューションは金融セクターで初めて実用化され、J.P. Morganで過去2年間に渡りUSA、ヨーロッパ、アジアの主要三地域で利用されている

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **投稿日:** 2024-04-10

---
### [Privacy-preserving Scanpath Comparison for Pervasive Eye Tracking](http://arxiv.org/abs/2404.06216)
**画面ベースデバイス及びヘッドマウントディスプレイにおけるプライバシー保護型視線追跡スキャンパス比較**

Suleyman Ozdel, Efe Bozkir, Enkelejda Kasneci

- スキャンパスに対するプライバシー保護方法に焦点を当て、新しい視線追跡用プロトコルを提案
- Needleman-Wunschアルゴリズムを利用したプライバシー保護方法に、準同型暗号スキーム（Paillier法）を組み込む
- ランダム処理戦略と多層マスキング法を導入し、暗号化された編集操作コストの順序を保持しながら値を難読化
- 計算性能の詳細な分析を公開し、ソースコードを公開しており、効率と適用性を示す

**Comment:** Proc. ACM Hum.-Comput. Interact. 8, ETRA (May 2024)

**トピック:** [差分プライバシー](../../dp), [準同型暗号](../../he), **投稿日:** 2024-04-09

---
### [Differential Privacy for Anomaly Detection: Analyzing the Trade-off Between Privacy and Explainability](http://arxiv.org/abs/2404.06144)
**差分プライバシーを用いた異常検出: プライバシーと説明可能性のトレードオフの分析**

Fatima Ezzeddine, Mirna Saad, Omran Ayoub, Davide Andreoletti, Martin Gjoreski, Ihab Sbeity, Marc Langheinrich, Silvia Giordano

- 異常検出は、データセット内の期待されるパターンから大幅に逸脱する観測値を特定する統計的プロセスで、金融や医療など幅広い分野で応用されている
- 本研究では説明可能AI（XAI）技術の一種であるSHapley Additive exPlanations（SHAP）と差分プライバシーを適用して、プライバシー保護のコストを検出精度と説明可能性の低下という観点から評価した
- 差分プライバシーの適用によるプライバシー保護は、検出精度と説明可能性に顕著な影響を与え、その影響はデータセットと異常検出モデルの選択に依存する
- 異常検出アルゴリズムの選択は説明の視覚的解釈にも影響を与える

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-09

---
### [Advances in Differential Privacy and Differentially Private Machine Learning](http://arxiv.org/abs/2404.04706)
**差分プライバシーと差分プライバシー機械学習の進展**

Saswat Das, Subhankar Mishra

- 差分プライバシーとその様々な応用についての研究が急増している
- 差分プライバシーの新しい形式や計算技術、差分プライバシー機械学習の分野が拡張を続けている
- レニープライバシーや集中差分プライバシーなどの新しい差分プライバシーの変種や理論的発展に焦点を当てている
- 実際の差分プライバシーの実装例や、プライバシー保護のための機械学習への応用についても議論している

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-06

---
### [Prompt Public Large Language Models to Synthesize Data for Private On-device Applications](http://arxiv.org/abs/2404.04360)
**大規模言語モデルを用いたプライベートデバイス用合成データの生成**

Shanshan Wu, Zheng Xu, Yanxiang Zhang, Yuanbo Zhang, Daniel Ramage

- 大規模言語モデル（LLM）が公開データを用いて、差分プライバシーと連合学習を活用したオンデバイス言語モデルの事前学習データ品質を向上させる可能性を探る
- 公開データをフィルタリングし変換する促進プロンプトを設計し、実際のユーザーデータの分布に似た新しいデータを生成
- 生成された合成データセットを用いたモデルが、標準の公開データセットで事前学習された基準モデルに比べて、次の単語の予測精度で19.0%および22.8%の相対的な改善を達成
- 合成データを使用し、差分プライバシーと連合学習の微調整後に実ユーザーデータで評価した結果、基準モデルと同等またはそれ以上の精度を実現し、製品のA/Bテストで基準モデルを上回る性能を示す

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **投稿日:** 2024-04-05

---
### [You Can Use But Cannot Recognize: Preserving Visual Privacy in Deep Neural Networks](http://arxiv.org/abs/2404.04098)
**ディープニューラルネットワークにおける視覚プライバシーの保護: 利用は可能だが認識は不可**

Qiushi Li, Yan Zhang, Ju Ren, Qi Li, Yaoxue Zhang

- ディープニューラルネットワーク（DNN）の訓練データで視覚的プライバシーを保護する新しいフレームワーク「VisualMixer」を提案
- VisualMixerは画像の特定の領域をシャッフルすることで視覚的特徴を難読化し、ノイズを加えずにプライバシーを守る
- 新たなプライバシーメトリック「視覚特徴エントロピー（VFE）」を使用して、生物学的および機械視覚の観点から画像の特徴を定量化
- 実世界のデータセットでの広範な実験により、平均的にモデル精度の低下は2.35パーセントポイントに留まり、モデルのトレーニングにほとんど影響を与えないことを示す

**Comment:** 18 pages, 11 figures

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-05

---
### [From Theory to Comprehension: A Comparative Study of Differential Privacy and $k$-Anonymity](http://arxiv.org/abs/2404.04006)
**理論から理解へ：差分プライバシーと$k$-匿名化の比較研究**

Saskia Nuñez von Voigt, Luise Mehner, Florian Tschorsch

- 差分プライバシーの$\varepsilon$は個々のプライバシーを定量化する広範囲に使用される概念である
- 本研究は差分プライバシー機構によるプライバシー保護のユーザーの理解度を焦点とする
- 差分プライバシーの説明を三種類で行う: (1) 元の数学的定義、(2) 特定のプライバシーリスクへの$\varepsilon$の変換、(3) ランダム化応答技術を使用した説明
- 参加者による差分プライバシー保護の理解度は、プライバシーリスクモデルとランダム化応答ベースのモデルにより向上し、$k$-匿名化のプライバシー保護が最も理解しやすかったことを確認

**Comment:** Accepted to ACM CODASPY'24, 19-21 June 2024, Porto, Portugal

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-05

---
### [PrivShape: Extracting Shapes in Time Series under User-Level Local Differential Privacy](http://arxiv.org/abs/2404.03873)
**PrivShape: ユーザーレベルの局所差分プライバシーの下で時系列の形状を抽出する**

Yulian Mao, Qingqing Ye, Haibo Hu, Qi Wang, Kai Huang

- 時系列データに含まれる個人情報のプライバシー保護には、差分プライバシーが利用されるが、既存の手法では形状保存が難しい
- PatternLDPは時系列データの特定のグループのプライバシーを保護する試みだが、有限な要素しか保護できない
- PrivShapeはユーザーレベルでの局所差分プライバシーを実現し、時系列を短縮し、trie展開と二段階の精錬を採用して全要素を保護
- 実世界のデータセットによる広範囲な実験で、PrivShapeはオフラインでの使用時にPatternLDPを上回り、頻繁な形状を効果的に抽出することを示した

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-05

---