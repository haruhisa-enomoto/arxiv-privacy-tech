---
title: 連合学習 (2024-12-20 ~ 2024-12-26)
date: 2024-12-20
---

連合学習に関する論文まとめ (2024-12-20 ~ 2024-12-26)


- - -

### [Differentially Private Federated Learning of Diffusion Models for Synthetic Tabular Data Generation](http://arxiv.org/abs/2412.16083)

**差分プライバシーを備えた拡散モデルの連合学習による合成表データ生成**

Timur Sattarov, Marco Schreyer, Damian Borth

- 財務分野でのプライバシー保護データ分析の需要が増えている
- DP-Fed-FinDiffフレームワークは差分プライバシーと連合学習を組み合わせたもの
- 厳しいプライバシー規制を遵守しつつ高品質な合成表データを生成する
- 実証評価でプライバシーとデータ品質のバランスを最適化 

差分プライバシーと拡散モデルの組み合わせが面白そうで、しっかりデータ品質を保っているのが魅力的！金融業界でも安全にデータをシェアする未来がすぐそこに感じるね。

**Comment:** 9 pages, 9 figures, preprint version, currently under review

**トピック:** [連合学習](../../fl), [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, q-fin.ST, **投稿日時:** 2024-12-20 17:30


- - -

### [fluke: Federated Learning Utility frameworK for Experimentation and research](http://arxiv.org/abs/2412.15728)

**fluke: 実験と研究のための連合学習ユーティリティフレームワーク**

Mirko Polato

- 連合学習は2016年から人気が高まり、さまざまなフレームワークが提案されている
- 既存フレームワークは柔軟性が不足しており、学習曲線が急であるため独自実装が多い
- flukeはPythonで構築された新アルゴリズム開発を簡素化するためのオープンソースのパッケージ
- デフォルトで使用可能で、少ない手間で新アルゴリズムを拡張できる

flukeってめっちゃ便利そう！新しいアルゴリズムがどんどん生まれちゃうかもね。Pythonで使いやすいし、研究者にぴったりかも。

**Comment:** Accepted at FLUID workshop (AAAI 2025) [4 pages (+2 references), 2   figures, 1 algorithm]

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-12-20 09:51


- - -

### [Code Review Automation Via Multi-task Federated LLM -- An Empirical Study](http://arxiv.org/abs/2412.15676)

**連合学習によるマルチタスク型大規模言語モデルを用いたコードレビュー自動化の実証研究**

Jahnavi Kumar, Sridhar Chimalakonda

- コードレビュー自動化は重要だが、通常の手法は3つの独立したサブタスクとして扱われている
- 研究は、サブタスクの関係を利用しマルチタスクモデルで統合的に解決することを目指す
- 連合学習を用いることで、プロプライエタリコードの秘密保持と未知データへのモデルの頑健性を向上させる
- 累積的ファインチューニングが個別タスクモデルより効果的であることが示された

この研究、なんか新しい視点で興味深い感じ！連合学習活用で、セキュリティも保てて効率的に進化できるとか、もっと別の分野にも応用できそうだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.SE, **投稿日時:** 2024-12-20 08:46


- - -

### [AutoRank: MCDA Based Rank Personalization for LoRA-Enabled Distributed Learning](http://arxiv.org/abs/2412.15553)

**AutoRank: LoRA対応分散学習のためのMCDAベースのランク個別化**

Shuaijun Chen, Omid Tavallaie, Niousha Nazemi, Xin Chen, Albert Y. Zomaya

- 分散学習は非独立同分布(Non-IID)データでのモデル学習が難しい問題に直面
- LoRAは低ランクの更新を個別化し計算を最小化するが初期ランク設定が難題
- AutoRankはデータの複雑性に基づいて動的にローカルランクを割り当てるアルゴリズム
- AutoRankにより計算負担を削減し、モデル性能を向上させ、収束を加速させることに成功

データの複雑さに応じて適応するAutoRankは、分散学習における重要な進化だね。ランクを自動設定するって、たくさんの参加者がいる場合にも効率的で嬉しい！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-12-20 04:27


- - -

### [The Impact of Cut Layer Selection in Split Federated Learning](http://arxiv.org/abs/2412.15536)

**スプリット連合学習におけるカット層選択の影響**

Justin Dachille, Chao Huang, Xin Liu

- スプリット連合学習（SFL）は連合学習とスプリット学習を組み合わせた分散学習パラダイムである
- カット層選択がモデル性能に与える影響の定量分析が重要だとわかった
- SFL-V1はカット層の選択に対して性能が比較的一定である
- SFL-V2はカット層選択により性能が大きく変わり、適切な選択でFedAvgより高性能

カット層の選び方で性能が変わるなんて面白いよね。SFLは複雑なデータセットに強そうなので、もっと研究が進むといいな。

**Comment:** 16 pages, 1 figure, AAAI FLUID Workshop 2025

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, **投稿日時:** 2024-12-20 03:52


- - -

### [DualGFL: Federated Learning with a Dual-Level Coalition-Auction Game](http://arxiv.org/abs/2412.15492)

**DualGFL: 二重レベル連合学習フレームワークによる連合学習**

Xiaobing Chen, Xiangwei Zhou, Songyang Zhang, Mingxuan Sun

- 従来の連合学習では単一レベルのゲーム理論を使い、複雑な参加者間の動態を捉えるのが難しかった
- DualGFLは、協力と競争を兼ね備えた二重レベルのゲームを用いて、これを改善する新しいフレームワーク
- 下位レベルでは、クライアントの意思による最適な分割を見つけるため、オークションを意識した効用関数とパレート最適な分割アルゴリズムを提案
- 上位レベルでは、資源制約付きの多属性オークションゲームを設計し、クライアントとサーバー双方の利得を最大化する

DualGFLって、連合学習の協力と競争のバランスをうまく取ってて面白そうだね！これでどんな成果が上がるのか、早く知りたいなぁ。結果が出次第、最新のアプローチとして注目集めそう！

**Comment:** 12 pages, 6 figures. Accepted by AAAI25

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.GT, cs.LG, I.2.6; I.2.11, **投稿日時:** 2024-12-20 02:13
