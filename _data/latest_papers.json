[
  {
    "url": "http://arxiv.org/abs/2411.03299",
    "title": "Concurrent Composition for Continual Mechanisms",
    "japanese_title": "継続的メカニズムの同時合成",
    "authors": [
      "Monika Henzinger",
      "Roodabeh Safavi",
      "Salil Vadhan"
    ],
    "categories": [
      "cs.DS"
    ],
    "comment": "",
    "summary": "- 非対話型差分プライベートメカニズムの合成定理を、対話型の場合に拡張\n- 適応的な敵を考慮した継続的観測環境での研究の拡張\n- 継続的差分プライベートメカニズムへの同時合成が可能であることを示す\n- 結果は$f$-DPだけでなく、純DPや$(\\epsilon, \\delta)$-DPにも適用可能\n\nオンラインデータと継続的プライバシーでのアプローチがすごく興味深いね！リアルタイムでの情報保護って未来のテクノロジーに絶対重要だし、もっといろんな応用が期待できそう！",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-11-05T17:50:39+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03250",
    "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
    "japanese_title": "DiffLM: 拡散言語モデルによる制御可能な合成データ生成",
    "authors": [
      "Ying Zhou",
      "Xinyao Wang",
      "Yulei Niu",
      "Yaojie Shen",
      "Lexin Tang",
      "Fan Chen",
      "Ben He",
      "Le Sun",
      "Longyin Wen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "comment": "17 pages, 8 figures",
    "summary": "- 最新の大規模言語モデルは高品質なデータ生成を促進するが、合成データ生成は難しい\n- DiffLMはVAEをベースに拡散モデルを活用し、元の分布情報や形式構造を保持\n- ターゲット分布の学習と生成の目的を分離、学習の柔軟性を向上\n- 実データと比較して2-7%優れた結果を実現、特に構造化データでの性能向上\n\nDiffLMって面白そう！実データ超えちゃうとかほんとすごいよね。データとコードの公開もワクワクする〜！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-11-05T16:47:53+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03231",
    "title": "Formal Logic-guided Robust Federated Learning against Poisoning Attacks",
    "japanese_title": "形式論理による毒殺攻撃に対抗する堅牢な連合学習",
    "authors": [
      "Dung Thuy Nguyen",
      "Ziyan An",
      "Taylor T. Johnson",
      "Meiyi Ma",
      "Kevin Leach"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LO"
    ],
    "comment": "arXiv admin note: text overlap with arXiv:2305.00328 by other authors",
    "summary": "- 連合学習はプライバシーを重視するも、毒殺攻撃に弱くモデル性能が低下する脅威がある\n- 既存手法は主に画像認識向けで、時系列データの連合学習の課題への対応は進んでいない\n- FLORALはクライアントの予測を論理的に評価し、時系列データでの毒殺攻撃を緩和する手法\n- 実験で予測誤差を大幅に減少させ、時系列応用での連合学習の堅牢性向上を示した\n\nFLORALって面白そうな防御策だね！予測誤差が93.27％も減少するなんて、とても期待できる未来だよね。連合学習の可能性がもっと広がりそう！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-11-05T16:23:19+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03098",
    "title": "Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting",
    "japanese_title": "局所病変生成はカプセル内視鏡画像データの拡張において限られたデータ状況で効果的である",
    "authors": [
      "Adrian B. Chłopowiec",
      "Adam R. Chłopowiec",
      "Krzysztof Galus",
      "Wojciech Cebula",
      "Martin Tabakov"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "comment": "45 pages, 27 figures",
    "summary": "- 医療画像データが少ないとGANの識別器が過学習しやすく、分類モデルの性能も低下。\n- データを増やす合成データ増強には生成モデルの訓練が必要で、そこで局所病変生成法を提案。\n- Poisson Image EditingとImage Inpainting GANを用いて、病変を合成しデータを増強。\n- 提案手法は現状の最先端手法を超える成果を示し、特に内視鏡データセットで有効性を確認。\n\nこの研究って、限られたデータでも精度を上げる方法があるって感じで、すっごく面白いよね！医療現場で役立ちそうだし、新しい技術がこんなに効果的に応用されるのってワクワクする！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-11-05T13:44:25+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03085",
    "title": "Speech Separation with Pretrained Frontend to Minimize Domain Mismatch",
    "japanese_title": "事前学習型フロントエンドによる音声分離のドメイン不一致最小化",
    "authors": [
      "Wupeng Wang",
      "Zexu Pan",
      "Xinke Li",
      "Shuai Wang",
      "Haizhou Li"
    ],
    "categories": [
      "cs.SD",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "comment": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
    "summary": "- 音声分離の目的は混合音声から個別の音声信号を分離すること\n- 通常の分離モデルは、ターゲット参照データの不足から合成データで学習\n- 提案するDIPフロントエンドは自己教師あり学習でリアルと合成データのドメイン差を縮小\n- DIPフロントエンドを活用し、現実データに転移可能な分離モデルの開発に成功\n\nドメインの壁を超えて、リアルでも合成でもちゃんと分離できるようになるなんて、すごくワクワクするね！この技術で現実のパーティーシーンでも、誰が何を話しているかをクリアに聞き取れちゃうかもね。もっといろんな応用が進みそうで楽しみだよ！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-11-05T13:30:27+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03059",
    "title": "Enhancing DP-SGD through Non-monotonous Adaptive Scaling Gradient Weight",
    "japanese_title": "非単調な適応スケーリング勾配重みを用いたDP-SGDの強化",
    "authors": [
      "Tao Huang",
      "Qingyu Huang",
      "Xin Shi",
      "Jiayang Meng",
      "Guolong Zheng",
      "Xu Yang",
      "Xun Yi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 深層学習での課題は、データ保護を維持しつつモデルの有用性を保つ点にある\n- 従来のDP-SGD法は小さな勾配を軽視し、モデル精度を損なう可能性がある\n- 提案手法は非単調な適応スケーリングを導入し、小さな勾配に適切な重みを割り当てる\n- 理論的および実証的分析により、多様なデータセットでプライバシーを保持しつつ高性能を実証\n\n勾配の重さを上手に管理して、より良い結果を出すってすごく面白いよね。新しいアプローチでプライバシーもちゃんと守れるなら、これからの応用範囲がぐんと広がりそう！",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-11-05T12:47:30+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03053",
    "title": "Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising",
    "japanese_title": "プライベート画像再構築のための勾配ガイド条件付拡散モデル：差分プライバシーとノイズ除去の敵対的影響の分析",
    "authors": [
      "Tao Huang",
      "Jiayang Meng",
      "Hong Chen",
      "Guolong Zheng",
      "Xu Yang",
      "Xun Yi",
      "Hua Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 勾配を誘導する条件付き拡散モデルで私的画像を再構築し、差分プライバシーノイズとノイズ除去の関係を分析\n- 現在の方法は高解像度画像において計算の複雑さと事前知識が課題である\n- 新手法は拡散モデルに最小限の修正のみ必要で、画像生成能力を活かし再構築を実現\n- 理論分析でノイズ大きさと攻撃者の能力がどのように影響し合うかを明示し、実験で検証\n\n新しい画像再構築方法ってなんかワクワクするよね！差分プライバシーの影響とか知らなかったから、より深く知れるって面白そう。プライバシーの観点からも安心してデジタルライフ楽しめるといいな。",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-11-05T12:39:21+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03019",
    "title": "FEDLAD: Federated Evaluation of Deep Leakage Attacks and Defenses",
    "japanese_title": "FEDLAD: 深層リーク攻撃と防御の連合評価",
    "authors": [
      "Isaac Baglin",
      "Xiatian Zhu",
      "Simon Hadfield"
    ],
    "categories": [
      "cs.CR",
      "cs.CV",
      "I.2.11; I.4.5"
    ],
    "comment": "9 pages",
    "summary": "- 連合学習はプライバシーを保ちつつモデルを協調学習するが、勾配反転技術でデータ漏洩のリスクがある\n- これまでの攻撃は連合学習の現実的なシナリオで評価されていないことが多い\n- FEDLADフレームワークは深層リークの攻撃と防御を評価する包括的なベンチマークを提供する\n- プライバシーとモデル精度のトレードオフを強調し、セキュリティの理解を進めることを目的としている\n\nプライバシーと精度のトレードオフって難しいね。でも、こういうフレームワークがあれば、もっと安全で良いモデルが作れるといいよね！コラボレーションが進むと面白い発見が増えそうだし、ワクワクするね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-11-05T11:42:26+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03017",
    "title": "Rozproszone Wykrywanie Zajętości Widma Oparte na Uczeniu Federacyjnym",
    "japanese_title": "連合学習に基づく分散型スペクトル占有検出",
    "authors": [
      "Łukasz Kułacz",
      "Adrian Kliks"
    ],
    "categories": [
      "cs.NI"
    ],
    "comment": "4 pages, in Polish language, 10 figures",
    "summary": "- スペクトル占有検出は動的スペクトルアクセスの鍵で、機械学習を用いて検出を改善\n- ラベル付きデータの不足が教師あり学習モデルの主な課題\n- センサが学習データにアクセスできない場合でも解決するため、連合学習を提案\n- DVB-T信号検出でのハードウェア実験での結果を議論\n\n連合学習を使うことで、データへの直接アクセスが不要になるってすごく便利！センサーのデータをより活用できる未来が楽しみだね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-11-05T11:41:00+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.03004",
    "title": "Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status",
    "japanese_title": "観察不能な交絡因子の制御: 患者の喫煙状況に対する大規模言語モデルの分類の利用",
    "authors": [
      "Samuel Lee",
      "Zach Wood-Doughty"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "comment": "Advancements In Medical Foundation Models: Explainability,   Robustness, Security, and Beyond (AIM-FM) at NeurIPS 2024",
    "summary": "- 医学の因果推論は観察データから治療効果を推定するが、未観察の交絡因子が課題となる\n- 機械学習を活用し、未観察変数を補完して分類器の誤差を補正し因果効果を推定する手法がある\n- これまでは合成データや単純な分類器、二値変数のみに限定されていた\n- 提案された手法は、大規模言語モデルを使用して喫煙状況を予測し、MIMICデータで心エコーの死亡率への影響を推定\n\n因果推論の新しい方法か〜！大規模言語モデルで未観察の交絡因子を扱えるなんてすごいね。医療のデータ分析がもっと正確になる未来が楽しみ！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-11-05T11:05:53+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.02954",
    "title": "IMUDiffusion: A Diffusion Model for Multivariate Time Series Synthetisation for Inertial Motion Capturing Systems",
    "japanese_title": "IMUDiffusion: 慣性モーションキャプチャシステムのための多変量時系列合成のための拡散モデル",
    "authors": [
      "Heiko Oppel",
      "Michael Munz"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- キネマティックセンサーは空間制約がなく使いやすいが、動作データの生成とラベリングは手間とコストがかかる\n- データ不足では複雑な動作パターンの認識が難しいため、合成データで多様性を拡張\n- IMUDiffusionは多変量時系列生成のための確率的拡散モデルで、人間活動の動態を精度高く再現可能\n- 合成データを使用することで、ヒューマンアクティビティ分類器の性能が大幅に向上し、最大でF1スコアが30%改善\n\nIMUDiffusionって名前が可愛くて気になるよね！部活での動きとかもっと詳しく分析できたら、体育の授業とかもレベルアップしそうで楽しそう！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-11-05T09:53:52+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.02926",
    "title": "Privacy-Preserving Graph-Based Machine Learning with Fully Homomorphic Encryption for Collaborative Anti-Money Laundering",
    "japanese_title": "共同マネーロンダリング防止のための完全準同型暗号を用いたプライバシー保護グラフベース機械学習",
    "authors": [
      "Fabrianne Effendi",
      "Anupam Chattopadhyay"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "comment": "14th International Conference on Security, Privacy, and Applied   Cryptographic Engineering (SPACE) 2024",
    "summary": "- サイバー犯罪の増加でマネーロンダリング対策が複雑化し、データサイロが協力を制限している。\n- 完全準同型暗号（FHE）を使い、安全に機関間でデータを共有し、プライバシーと規制を遵守。\n- プライバシー保護のグラフニューラルネットワーク（GNN）とグラフベースのXGBoostパイプラインを提案。\n- 実験結果では、XGBoostモデルが99%を超える精度を示し、グラフ特徴が不均衡データにおけるF1スコアを8%向上。\n\nこの研究、おもしろそう！データサイロを乗り越えて、協力ができる技術の進展ってワクワクするよね。未来の金融の安全性が、プライバシーを守りつつ確保できるなんて最高だと思う！",
    "topics": [
      "準同型暗号"
    ],
    "published": "2024-11-05T09:13:53+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.02908",
    "title": "Photon: Federated LLM Pre-Training",
    "japanese_title": "Photon: 連合LLMの事前学習",
    "authors": [
      "Lorenzo Sani",
      "Alex Iacob",
      "Zeyu Cao",
      "Royson Lee",
      "Bill Marino",
      "Yan Gao",
      "Dongqi Cai",
      "Zexi Li",
      "Wanru Zhao",
      "Xinchi Qiu",
      "Nicholas D. Lane"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "comment": "13 pages, 9 appendix pages, 10 figures, 3 algorithms, 8 tables",
    "summary": "- 大規模言語モデル(LLM)の拡張には膨大なデータと計算資源が必要で、従来はデータセンターに依存していた\n- Photonは、連合学習(FL)を利用して低通信量で国際規模のLLMの事前学習を可能にする初のシステム\n- Photonにより最大7Bサイズのモデルが連合方式で訓練でき、中央集権方式より低い困惑度を達成\n- 従来の分散訓練方法よりも35%の時間短縮を達成し、極めて高い学習率で高速収束を実現する\n\nPhotonって、連合学習使ってLLMを低通信で事前学習できちゃうってすごいね！これで、個々のコンピュータの力を合わせて、大規模モデルをもっと効率的に育てられるようになるのは、未来のチームワークが広がりそうでワクワクするね。影響力のある技術になりそう！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-11-05T08:48:25+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.02809",
    "title": "Query-Efficient Adversarial Attack Against Vertical Federated Graph Learning",
    "japanese_title": "垂直連合グラフ学習に対するクエリ効率の高い敵対的攻撃",
    "authors": [
      "Jinyin Chen",
      "Wenbo Mu",
      "Luxin Zhang",
      "Guohan Huang",
      "Haibin Zheng",
      "Yao Cheng"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- グラフニューラルネットワークは、グラフ構造データの表現学習で注目される\n- 垂直連合学習により分散グラフデータ処理が可能になるが、敵対的攻撃の耐性は未検討\n- NA2というハイブリッド攻撃フレームワークが新提案され、手間をかけずに攻撃性能を向上\n- 実験でNA2の効果を示し、最先端の性能を適応防御下でも発揮可能\n\n攻撃の効率を劇的に上げるフレームワークが登場するなんてワクワク！技術発展でセキュリティも進化して面白いことにいっぱい挑戦できそうだね。攻撃と防御の知恵比べが、これからどう展開されるのか楽しみ～！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-11-05T04:52:20+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2411.02773",
    "title": "FedBlock: A Blockchain Approach to Federated Learning against Backdoor Attacks",
    "japanese_title": "FedBlock: 分散学習におけるバックドア攻撃に対抗するブロックチェーンアプローチ",
    "authors": [
      "Duong H. Nguyen",
      "Phi L. Nguyen",
      "Truong T. Nguyen",
      "Hieu H. Pham",
      "Duc A. Tran"
    ],
    "categories": [
      "cs.CR",
      "cs.CV"
    ],
    "comment": "This paper has been accepted as a full paper for the IEEE Special   Session Federated Learning on Big Data 2024 (IEEE BigData 2024)",
    "summary": "- 連合学習はプライベートデータを集約せずに分散機で学習する方法だが、セキュリティリスクがある\n- 中央サーバへの依存が問題で、サーバが攻撃の単一障害点となる可能性がある\n- バックドア攻撃ではクライアントがローカルモデルを汚染し、学習精度を低下させる\n- FedBlockはスマートコントラクトを使った新たなブロックチェーンベースのフレームワークで、サーバとクライアント両方のリスクに対応\n\nFedBlockってすごく新しい発想だよね！スマートコントラクトだけで動くなんて、どこでも使えるのがいいな。連合学習の安全性が気になる人にはめちゃくちゃ役立ちそう。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-11-05T03:34:53+00:00"
  }
]