---
title: 差分プライバシー (2024-03-29 ~ 2024-04-04)
date: 2024-03-29
---

差分プライバシーに関する論文まとめ (2024-03-29 ~ 2024-04-04)

### [Knowledge Distillation-Based Model Extraction Attack using Private Counterfactual Explanations](http://arxiv.org/abs/2404.03348)
**知識蒸留を用いたプライベートな反事実説明を使ったモデル抽出攻撃**

Fatima Ezzeddine, Omran Ayoub, Silvia Giordano

- MLaaS（機械学習サービス）の利用拡大と並行して、XAI（説明可能なAI）が進化しMLモデルの透明性と信頼性を提供する技術向上を図っている
- この研究は、GANベースの反事実説明が、MLaaSプラットフォーム内でモデル抽出攻撃（MEA）を行う際にどのように悪用され得るかを調査
- 知識蒸留（KD）を基にした新しいMEA方法を提案し、反事実説明を利用して目標モデルの代替モデルを効率的に抽出
- 差分プライバシー（DP）を導入した反事実ジェネレータの訓練を通じて、プライバシーを保守しつつ、高品質の代替モデルを抽出可能であることを実証

**Comment:** 15 pages

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-04

---
### [A Comparative Analysis of Word-Level Metric Differential Privacy: Benchmarking The Privacy-Utility Trade-off](http://arxiv.org/abs/2404.03324)
**自然言語処理における単語レベルの差分プライバシーの比較分析: プライバシー・ユーティリティのトレードオフのベンチマーク**

Stephen Meisenbacher, Nihildev Nandakumar, Alexandra Klymenko, Florian Matthes

- 自然言語処理(NLP)での差分プライバシーの適用が高まっており、特に単語レベルでのプライバシー対策として、単語の埋め込みベクトルに雑音を加える手法が注目されている
- これまでに複数の単語レベル差分プライバシー実装が提案されているが、それらの相対的な性能を比較する研究は実施されていなかった
- 本研究では7つの異なるアルゴリズムを2つのNLPタスクに適用し、プライバシーバジェットを変数として性能を比較し、プライバシーとユーティリティのトレードオフについて詳細に分析
- 分析結果として、単語レベルの差分プライバシーのメリットと課題を明らかにし、研究分野の発展のための具体的な提案を行っている

**Comment:** Accepted to LREC-COLING 2024

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-04

---
### [Differentially Private Verification of Survey-Weighted Estimates](http://arxiv.org/abs/2404.02519)
**差分プライバシーを満たす調査加重推定の検証**

Tong Lin, Jerome P. Reiter

- 公的統計機関は合成データを一般利用のマイクロデータファイルとして公開している
- 合成データはすべての分析で正確な結果を出すわけではないため、検証サーバーを利用して推定値の類似度をユーザーに提供する方法がある
- この類似度の測定は機密データに関する情報を漏洩する可能性があるため、開示管理手法が必要である
- 提案する検証方法は差分プライバシーを満たし、複雑な調査設計で収集された機密データに使用できる

**Comment:** 21 pages including references, 5 figures

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **投稿日:** 2024-04-03

---
### [A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability](http://arxiv.org/abs/2404.02462)
**視覚自己指導エンコーダのための統一されたメンバーシップ推論方法に関する研究**

Jie Zhu, Jirong Zha, Ding Li, Leye Wang

- 視覚自己指導型モデルへの攻撃は、通常ブラックボックスシステム下で行われるため、新しい推論方法PartCropを提案
- PartCropはオブジェクトの一部を切り取り、画像の表現空間での反応を問い合わせることに基づいている
- 三つの広く使用される画像データセットを使用して様々な訓練プロトコルと構造で自己指導モデルに対する攻撃を実施し、PartCropの有効性と汎用性を検証
- PartCropを防御するために、早期停止と差分プライバシーの一般的なアプローチを評価し、専用の方法として切り取り範囲の縮小を提案

**Comment:** Membership Inference, Self-supervised learning

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-03

---
### [Robust Constrained Consensus and Inequality-constrained Distributed Optimization with Guaranteed Differential Privacy and Accurate Convergence](http://arxiv.org/abs/2404.02327)
**分散最適化問題における強固な制約型コンセンサスと不等式制約の確実な差分プライバシーと正確な収束保証**

Yongqiang Wang, Angelia Nedic

- 分散最適化メカニズムと差分プライバシーのノイズ注入機構を共同設計することで、グローバルな最適解への証明可能な収束と厳格なε-差分プライバシーの両方を保証できる初の分散制約最適化アルゴリズムを提案
- このアプローチはラグランジュ関数が厳密に凸/凹である必要がなく、全体の目的関数が非分割可能である場合にも適用可能
- 共同設計の副産物として、厳格なε-差分プライバシーを達成しながら正確な収束を維持する新しい制約付きコンセンサスアルゴリズムを提案
- スマートグリッドの需要応答制御問題に関する数値シミュレーションの結果、提案方法の効果が確認された

**Comment:** Accepted as a full paper to IEEE Transactions on Automatic Control

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-02

---
### [Incentives in Private Collaborative Machine Learning](http://arxiv.org/abs/2404.01676)
**プライベート共同機械学習におけるインセンティブ**

Rachael Hwee Ling Sim, Yehong Zhang, Trong Nghia Hoang, Xinyi Xu, Bryan Kian Hsiang Low, Patrick Jaillet

- 共同機械学習は複数の当事者からのデータを用いてモデルを訓練するが、参加を促進するためのインセンティブが必要
- 既存のデータ評価方法はデータまたはモデルパラメータの共有に基づいて当事者に公平に報酬を提供するが、プライバシーリスクを無視
- 差分プライバシーをインセンティブとして導入し、各当事者が必要なDP保証を選択し、それに応じて十分統計量を摂動
- 中間者は摂動した十分統計量に基づき、モデルパラメータについてのベイジアンサプライズを評価し、それによってプライバシーと評価のトレードオフが強化され、最終的には各当事者にモデルパラメータの異なる事後サンプルによる報酬を提供

**Comment:** Accepted to NeurIPS 2023

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-02

---
### [AAA: an Adaptive Mechanism for Locally Differential Private Mean Estimation](http://arxiv.org/abs/2404.01625)
**AAA: 局所差分プライバシーにおける適応型平均推定メカニズム**

Fei Wei, Ergute Bao, Xiaokui Xiao, Yin Yang, Bolin Ding

- 局所差分プライバシー（LDP）は個人が自身のデータをローカルに乱し、乱されたデータのみをデータアグリゲーターに提出するという強力なプライバシー標準である
- 従来の研究では最悪のケースの保証の改善に焦点が当てられたが、実データの分布を考慮しないため、平均的なパフォーマンスの改善にはつながらない
- 本論文では、分布認識型アプローチである進展的適応加算（AAA）メカニズムを提案し、平均効用を向上させるとともに、古典的な平均推定問題に対処する
- AAAメカニズムは、広範なプライバシー制約と実世界および合成データセットにおいて、既存のソリューションよりも結果の効用で一貫して優れたパフォーマンスを示した

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-02

---
### [Decentralized Collaborative Learning Framework with External Privacy Leakage Analysis](http://arxiv.org/abs/2404.01270)
**分散型協調学習フレームワークと外部プライバシー漏洩分析**

Tsuyoshi Idé, Dzung T. Phan, Rudy Raymond

- 分散型の多タスク学習の進展を目指し、連合学習フレームワーク(CollabDict)に深層変分オートエンコーダー（VAE）を導入し、特に異常検出に焦点を当てた
- VAEに基づく異常スコア機能が非深層モデルと同じ数学構造を共有し、その質的な比較を提供
- 事前訓練されたモデルの広範な使用を考慮して、CollabDictで訓練されたモデルの外部共有時のデータプライバシー漏れに対する数学的分析を行い、レニー差分プライバシー基準を満たすことを示した
- 学習プロセスの内部プライバシー違反をモニタリングする実用的な指標を提案

**Comment:** To appear in Proceeding of 2023 International workshop Blockchain   Kaigi (BCK 23), JPS Conference Proceedings, 2024

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-01

---
### [SoK: A Review of Differentially Private Linear Models For High-Dimensional Data](http://arxiv.org/abs/2404.01141)
**SoK: 高次元データの差分プライバシー線形モデルに関するレビュー**

Amol Khanna, Edward Raff, Nathan Inkawhich

- 線形モデルはデータ科学において広く用いられているが、高次元データでは過学習とデータ記憶に特に弱い
- 高次元の差分プライバシー線形モデルに対して多くの最適化手法が提案されているにもかかわらず、これらの方法間の体系的な比較は存在しない
- 全ての手法についての包括的なレビューを提供し、実証実験が行われた結果、ロバストで座標最適化されたアルゴリズムが最も性能が良いことが示された
- すべての方法を実装するコードがオンラインで公開されている

**Comment:** 21 pages, 7 figures. To be published at the 2nd IEEE Conference on   Secure and Trustworthy Machine Learning (SaTML)

**トピック:** [差分プライバシー](../../dp), **投稿日:** 2024-04-01

---