---
title: 連合学習 (2024-08-16 ~ 2024-08-22)
date: 2024-08-16
---

連合学習に関する論文まとめ (2024-08-16 ~ 2024-08-22)


- - -

### [NeuLite: Memory-Efficient Federated Learning via Elastic Progressive Training](http://arxiv.org/abs/2408.10826)

**NeuLite：エラスティック進行トレーニングによるメモリ効率の高い連合学習**

Yebo Wu, Li Li, Chunlin Tian, Dubing Chen, Chengzhong Xu

- 連合学習はデータプライバシーを保ちながら複数のデバイスが共同でモデルを訓練する新たな学習パラダイムである
- リソースが限られたデバイスにおいて、トレーニング中の大きなメモリ使用量が実装のボトルネックである
- NeuLiteはモデルをブロックに分割し、進行的にトレーニングを行うことでメモリ使用量を削減するフレームワークを提案している
- 実験では、NeuLiteが最大50.4%のメモリ使用量削減、最大84.2%のモデル性能向上、最大1.9倍のトレーニング速度向上を示した

NeuLiteって、メモリ使うときもすごくエコな感じだね！これでスマホとかももっと賢くなるといいなー。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-08-20 13:21


- - -

### [Security Assessment of Hierarchical Federated Deep Learning](http://arxiv.org/abs/2408.10752)

**階層型連合深層学習のセキュリティ評価**

D Alqattan, R Sun, H Liang, G Nicosia, V Snasel, R Ranjan, V Ojha

- 階層型連合学習（HFL）は有望な分散型深層学習モデルであるが、敵対的攻撃に対して重要なセキュリティ問題がある
- HFLは階層構造のおかげで、ターゲティングされていない訓練時の攻撃に対する堅牢性を持つ
- 特にバックドア攻撃では、悪意のあるクライアントが辺縁サーバーの重複領域に配置されるとHFLのアーキテクチャを悪用する
- 階層的アグリゲーションにより、HFLは推論時の攻撃に対する耐性を強化し、敵対的訓練に適している

HFLのセキュリティについての研究、めっちゃおもしろそう！攻撃自体にも対策が必要なんだし、こんな感じでより安全な連合学習が実現できるのかもしれないね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-08-20 11:34


- - -

### [Federated Clustering: An Unsupervised Cluster-Wise Training for Decentralized Data Distributions](http://arxiv.org/abs/2408.10664)

**連合クラスタリング：分散データのための教師なしクラスターワイズトレーニング**

Mirko Nardi, Lorenzo Valerio, Andrea Passarella

- 連合学習はデータプライバシーが重要な場面で中心的なアプローチだが、教師なし学習の可能性は未探索
- FedCRefは異なるクライアント間で協調してクラスタデータをトレーニングし、再構成誤差分析で比較
- クライアントはデータ分布のセット内で共同トレーニングを行い、ローカルクラスタを継続的に精緻化
- EMNISTとKMNISTデータセットでの実験により、FedCRefが実際のデータ分布にクラスタモデルを整合させる能力を示した

なんかおもしろそうだよね、FedCRefっていかにも最新技術って感じだし、どんなふうに役立つのかもっと知りたくなっちゃうね。実験結果もすっごく興味深い！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-20 09:05


- - -

### [Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement](http://arxiv.org/abs/2408.10456)

**差分プライバシー付き確率的勾配降下法における固定サイズミニバッチ: 置き換え有無に関係なく緊密なRDP保証**

Jeremiah Birrell, Reza Ebrahimi, Rouzbeh Behnia, Jason Pacheco

- 差分プライバシー付きSGDがプライバシー保護の下で深層学習モデルを訓練
- 固定サイズサブサンプリングは一定のメモリ使用量で魅力的
- 提案するRDPアカウンタントが現行の境界を4倍改善
- 固定サイズサンプリングが実践でメモリ使用と低い分散を実現

学習中のプライバシー損失がしっかり管理できるってすごく安心だよね！固定サイズの方が実用的で結果も良かったら、ますます取り入れられそう！

**Comment:** 39 pages, 10 figures

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-08-19 23:57


- - -

### [Federated Learning of Large ASR Models in the Real World](http://arxiv.org/abs/2408.10443)

**現実の世界における大規模なASRモデルの連合学習**

Yonghui Xiao, Yuxin Ding, Changwan Ryu, Petr Zadrazil, Francoise Beaufays

- 連合学習（FL）はプライバシー保護の機械学習に有望な結果を見せている
- 1億以上のパラメータを持つ大規模モデルのトレーニングは、リソース要件が障害に
- ConformerベースのASRの全サイズモデル130MパラメータをFLでトレーニングする体系的な解決策を提示
- 提案された方法でクライアントのデータとラベルの品質を精査し、モデルの品質向上を実現

大規模なモデルにも連合学習が使えるって、すごく現実的になってきたね！改善されたトレーニング方法で、これからもっと高品質なモデルができるかも～！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, cs.SD, eess.AS, **投稿日時:** 2024-08-19 22:44


- - -

### [Federated Frank-Wolfe Algorithm](http://arxiv.org/abs/2408.10090)

**連合フランク-ウルフアルゴリズム**

Ali Dadras, Sourasekhar Banerjee, Karthik Prakhya, Alp Yurtsever

- 連合学習はプライバシー保護型の協調学習システムとして注目
- 提案するFedFWはデータのプライバシーを確保しつつ、低コストで疎信号の通信を実現
- 決定論的設定で、滑らかかつ凸な目的には$O(\varepsilon^{-2})$、滑らかで非凸な目的には$O(\varepsilon^{-3})$の反復で$\varepsilon$-準最適解を達成
- 確率的バリアントも提案し、凸な設定で$O(\varepsilon^{-3})$の反復で解を得る

新しい連合学習の手法面白そう！特に低コストで疎信号を扱えるところが今後の応用に期待だね。試してみたらどんな成果が出るのか気になるな〜。

**Comment:** European Conference on Machine Learning and Principles and Practice   of Knowledge Discovery in Databases

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-08-19 15:31


- - -

### [Towards Robust Federated Image Classification: An Empirical Study of Weight Selection Strategies in Manufacturing](http://arxiv.org/abs/2408.10024)

**ロバストな連合画像分類に向けて: 製造業における重み選択戦略の実証研究**

Vinit Hegiste, Tatjana Legler, Martin Ruskowski

- 製造業の連合学習でのサーバー集約におけるクライアント重み選択戦略がモデル性能に影響
- 最終エポック重み選択（FEWS）と最適エポック重み選択（OEWS）の2つの戦略が比較対象
- EfficientNet、ResNet、VGGなどのニューラルネットワークアーキテクチャを使用して影響を評価
- 実証分析と実験を通じて、限られたクライアント数で連合学習の最適化の洞察を提供

製造業での連合学習を使ったコラボレーションって面白そう！クライアントの数が少なくてもモデルの精度を上げる方法がわかると、効率がすごくアップしそうだね！

**Comment:** Submitted to The 2nd IEEE International Conference on Federated   Learning Technologies and Applications (FLTA24)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-08-19 14:18


- - -

### [Sequential Federated Learning in Hierarchical Architecture on Non-IID Datasets](http://arxiv.org/abs/2408.09762)

**階層的アーキテクチャにおける非IIDデータセットでの逐次連合学習**

Xingrun Yan, Shiyuan Zuo, Rongfei Fan, Han Hu, Li Shen, Puning Zhao, Yong Luo

- 連合学習(FL)システムでは、クライアントとパラメータサーバー(PS)間の通信オーバーヘッドがボトルネック
- 階層的連合学習(HFL)はクライアントとPS間に複数のエッジサーバー(ESs)を配置し通信圧力を部分的に緩和
- 初めて逐次連合学習(SFL)をHFLに導入し、中央PSを排除し隣接するESs間でグローバルモデルを渡すことで学習を完結
- 提案したFed-CHSアルゴリズムは通信オーバーヘッドを削減し、テスト精度で優れた性能を示す

通信オーバーヘッドを削減しながら精度を保つなんて、めっちゃおもしろそう！これからの分散学習に革命が起こりそうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-19 07:43


- - -

### [Impact of Large Language Models of Code on Fault Localization](http://arxiv.org/abs/2408.09657)

**大規模言語モデルによるコードのフォルトローカリゼーションへの影響**

Suhwan Ji, Sanghwa Lee, Changsup Lee, Hyeonseung Im, Yo-Sub Han

- 従来のフォルトローカリゼーション技術はコードカバレッジマトリクスとテストケース結果に依存
- 新手法は大規模言語モデルの事前学習済みのコード理解を利用するシーケンス生成アプローチを提案
- 提案アプローチは、従来手法に比べコンパイル不要で構文エラーのあるコードも分析可能
- 実験結果では、提案手法が誤り位置を高精度に特定し、従来の学習ベース技術を大幅に上回る

大規模言語モデルのポテンシャルを活かした新手法、すごく興味深いね！未来のデバッグがもっと簡単になりそうでワクワクするね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.SE, **投稿日時:** 2024-08-19 02:36


- - -

### [Addressing Heterogeneity in Federated Learning: Challenges and Solutions for a Shared Production Environment](http://arxiv.org/abs/2408.09556)

**連合学習における異質性への対処：共有生産環境における課題と解決策**

Tatjana Legler, Vinit Hegiste, Ahmed Anwar, Martin Ruskowski

- 連合学習は、データプライバシーを保護しながら分散データソースでモデルを訓練する手法である
- 異なるクライアントや生産現場でのデータ分布や質、量の違いが連合学習の効果と効率に影響
- 個別化モデルや堅牢な集約技術、クライアント選択技術などで異質性の悪影響を軽減
- 産業4.0における連合学習の改善へ向け、適応性とスケーラビリティのある解決策の研究が必要

異質なデータの統一的な活用方法が見えてくるのが面白そう！未来の生産環境がもっと効率的になるんじゃないかな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-18 17:49


- - -

### [Seamless Integration: Sampling Strategies in Federated Learning Systems](http://arxiv.org/abs/2408.09545)

**シームレスな統合：連合学習システムにおけるサンプリング戦略**

Tatjana Legler, Vinit Hegiste, Martin Ruskowski

- 連合学習はローカルデータのプライバシーを維持しつつ、分散トレーニングを可能にする新たな機械学習アプローチを提供
- 新しいクライアントの多様なデータ分布と計算能力がFLシステムの安定性と効率性に挑戦をもたらす
- データ多様性と計算力の分散を活用して学習パフォーマンスを改善できる
- クライアント選択戦略やシステムのスケーラビリティと安定性を確保するための解決策を提示

クライアントの多様性をシームレスに統合することで、連合学習がより実用的になりそうだね。これって、まるで全員の意見をうまく取り入れるディベートみたいでワクワクする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-18 17:16


- - -

### [Byzantine-resilient Federated Learning Employing Normalized Gradients on Non-IID Datasets](http://arxiv.org/abs/2408.09539)

**非IIDデータセットにおける正規化勾配を用いるビザンチン耐性の連合学習**

Shiyuan Zuo, Xingrun Yan, Rongfei Fan, Li Shen, Puning Zhao, Jie Xu, Han Hu

- 連合学習では、ビザンチン攻撃やデータの異質性が学習プロセスにバイアスを引き起こす
- 既存の方法は、損失関数のタイプへの適応性とデータの異質性に対する耐性の間でトレードオフ
- Fed-NGAは単純な正規化によって、計算複雑性を最良の水準に達成し、適応性と最適性の問題を解消
- 実験結果は、Fed-NGAが時間複雑性と収束性能で従来の方法より優れていることを示す

ビザンチン問題を扱いつつ効率も上げちゃうなんて、めっちゃスゴイない？データの異質性にもうまく対応してるし、実用化に期待が高まるよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-08-18 16:50


- - -

### [Orchestrating Federated Learning in Space-Air-Ground Integrated Networks: Adaptive Data Offloading and Seamless Handover](http://arxiv.org/abs/2408.09522)

**宇宙・空・地上統合ネットワークにおける連合学習の実現：適応的データオフローディングとシームレスハンドオーバー**

Dong-Jun Han, Wenzhi Fang, Seyyedali Hosseinalipour, Mung Chiang, Christopher G. Brinton

- 僻地では地上通信インフラが乏しく、高品質な通信サービスや機械学習サービスが提供されにくい
- 提案手法は宇宙・空・地上統合ネットワーク（SAGIN）を利用し、連合学習の課題を解決する
- 宇宙・空層のノードをエッジ計算ユニットとモデル集約機として活用し、適応的データオフローディングとハンドオーバーを行う
- 提案アルゴリズムの理論収束境界を特徴付け、実験結果によりトレーニング時間とテスト精度で基準手法より優れていることを確認

この連合学習のやり方、すごく未来的でワクワクするよね！実験結果でちゃんと成果も出てるから、これからどんどん実用化されそうだね。

**Comment:** This paper is accepted for publication in IEEE Journal on Selected   Areas in Communications (JSAC)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-08-18 16:09


- - -

### [Mitigating Noise Detriment in Differentially Private Federated Learning with Model Pre-training](http://arxiv.org/abs/2408.09478)

**事前学習を活用した差分プライバシー連合学習におけるノイズ影響の軽減**

Huitong Jin, Yipeng Zhou, Laizhong Cui, Quan Z. Sheng

- 事前学習は公開データセットを利用し、高性能な機械学習モデルを事前に訓練する手法
- 機械学習において差分プライバシーノイズがモデルの精度を著しく低下させる課題を解決へ
- 事前学習を用いたヘッド微調整(HT)、全面微調整(FT)がノイズの影響を軽減することを実証
- HTはプライバシーバジェットが少ない場合やモデルサイズが大きい場合に特に有効である

事前学習でノイズの影響を軽減するとか面白いね！プライバシー守りつつ高精度なモデルが実現できそう🎉



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-08-18 13:48


- - -

### [Federated Graph Learning with Structure Proxy Alignment](http://arxiv.org/abs/2408.09393)

**構造プロキシ整列による連合グラフ学習**

Xingbo Fu, Zihan Chen, Binchi Zhang, Chen Chen, Jundong Li

- 連合グラフ学習（FGL）は、複数のデータオーナー間で分散されるグラフデータに基づくモデル構築を目指している
- FGLは、クライアントごとにラベル分布が大きく異なるデータの異質性という課題を抱えている
- ノード分類のタスクでは、少数クラスのノードがバイアスのかかった近隣情報を持つため、表現力のあるノード埋め込みが学習しにくい
- 提案するFedSprayフレームワークは、クライアントごとに局所的なクラス単位の構造プロキシを学習・整列して、グローバルな構造プロキシを取得することで、安定したノード分類を実現する

FedSpray、なかなか面白そうじゃない？色んなデータの違いとかバイアスを解消して、もっと正確な結果を目指すってすごいよね！何か新しい発見がありそうでワクワクする！

**Comment:** Accepted by KDD 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-08-18 07:32


- - -

### [FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models](http://arxiv.org/abs/2408.10276)

**FEDKIM: 医療基盤モデルへの適応的な連合知識注入**

Xiaochen Wang, Jiaqi Wang, Houping Xiao, Jinghui Chen, Fenglong Ma

- 基盤モデルは多様なモダリティに対応し、従来のAI手法を上回る
- 医療分野では多様なモダリティと厳しいプライバシー規制が課題
- 本研究は連合学習フレームワークでの知識注入法FedKIMを提案
- FedKIMはプライバシーを保ちながら多様な医療タスクの処理能力向上を実現

医療分野でのプライバシー保護をしながら性能を上げる手法ってすごく未来感あるね！FedKIMのおかげで、もっと安全に医療AIが進化しそうで楽しみだな。

**Comment:** Submitted to EMNLP'24

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-17 15:42


- - -

### [FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection](http://arxiv.org/abs/2408.09227)

**FEDMEKI：連合知識注入を活用した医療基盤モデルのスケーリングに関するベンチマーク**

Jiaqi Wang, Xiaochen Wang, Lingjuan Lyu, Jinghui Chen, Fenglong Ma

- FEDMEKIは医療知識をプライバシー制約下でモデルに統合するための新たなベンチマークを導入。
- 中央集権的なデータ収集を回避するため、クロスサイロ連合学習アプローチを活用している。
- 7つの医療モダリティと8つの医療タスクで、16のベンチマークアプローチ下での分散トレーニングを実現。
- プライバシーを保ちながら広範な医療知識を学習し、医療基盤モデルの能力向上を目指す。

医療データをこんな風に安全に使える方法が増えると、未来の医療が本当に楽しみだよね！どんな風に進化するのかワクワクしちゃう～。

**Comment:** Submitted to Neurips 2024 DB Track

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.AI, **投稿日時:** 2024-08-17 15:18


- - -

### [FedKBP: Federated dose prediction framework for knowledge-based planning in radiation therapy](http://arxiv.org/abs/2408.10275)

**FedKBP: 連合学習による放射線治療の知識ベース計画における線量予測フレームワーク**

Jingyun Chen, Martin King, Yading Yuan

- 線量予測は、患者ごとの線量分布を自動生成する知識ベース計画で重要
- 連合学習（FL）は、患者データのプライバシーを保ちながら深層学習モデルを共同訓練
- IIDデータ分割では、FLの性能は中央集約型の訓練に匹敵
- 非IIDデータ分割では、データ分布の偏りが性能に影響を与える

連合学習って、特にデータが偏っているサイト間でどうやって改善していくかが面白そうだね！デザイン次第で、みんなで協力すれば最高の結果を出せるかもって感じがする。

**Comment:** Under review by SPIE Medical Imaging 2025 Conference

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-17 14:57


- - -

### [DRL-Based Resource Allocation for Motion Blur Resistant Federated Self-Supervised Learning in IoV](http://arxiv.org/abs/2408.09194)

**IoVにおける動体ぼけ耐性を持つ連合自己教師あり学習のためのDRLベースリソース割り当て**

Xueying Gu, Qiong Wu, Pingyi Fan, Qiang Fan, Nan Cheng, Wen Chen, Khaled B. Letaief

- 連合自己教師あり学習 (FSSL) は、データ共有せずにプライバシー保護しながらローカルモデルを集約
- Momentum Contrast (MoCo) は計算資源とストレージ需要を削減するが、辞書のアップロードでプライバシー漏洩リスク
- Simplified Contrast (SimCo) は辞書を使わずにサンプル分布を制御し、MoCoのプライバシー漏洩問題を解決
- 深層強化学習 (DRL) ベースのリソース割り当てでエネルギー消費と遅延を最小化し、動体ぼけレベルに基づくモデル集約を実現

動体ぼけに強い連合学習なんてすごい！次世代の車載ネットワークでどんな未来が待ってるのか楽しみだね。

**Comment:** This paper has been submitted to IEEE Journal. The source code has   been released at: https://github.com/qiongwu86/DRL-BFSSL

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.LG, cs.NI, **投稿日時:** 2024-08-17 13:12


- - -

### [Twin Sorting Dynamic Programming Assisted User Association and Wireless Bandwidth Allocation for Hierarchical Federated Learning](http://arxiv.org/abs/2408.09076)

**双子ソーティング動的計画法による階層型連合学習システムのユーザー割り当てと無線帯域幅割り当て**

Rung-Hung Gau, Ting-Yu Wang, Chun-Hung Liu

- ユーザー割り当てと無線帯域幅割り当ての最適化は階層型連合学習における重要な課題
- 二つのエッジサーバがある場合、双子ソーティング動的計画法(TSDP)で多項式時間で最適解を得る
- 三つ以上のエッジサーバがある場合、TSDPを応用したユーザー割り当てアルゴリズムを提案
- 提案手法はシミュレーション結果で他の手法を上回る性能を示す

エッジサーバを増やしても最適化できるのはめっちゃすごい！これからはもっと効率的な学習ができるかもね。

**Comment:** 14 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.NI, **投稿日時:** 2024-08-17 02:29


- - -

### [FedFQ: Federated Learning with Fine-Grained Quantization](http://arxiv.org/abs/2408.08977)

**FedFQ:細粒度量子化を用いた連合学習**

Haowei Li, Weiying Xie, Hangyu Ye, Jitao Ma, Shuran Ma, Yunsong Li

- 連合学習はデータプライバシーを守りつつ複数の参加者が協力してモデルを訓練する手法
- 通信のボトルネックを解消するために量子化が有効であり、細粒度の適応量子化戦略を提案
- Constraint-Guided Simulated Annealingアルゴリズムを使用して特定の量子化スキームを決定
- 幅広い実験でFedFQが既存のフレームワークよりも優れた収束性能と27倍から63倍の圧縮率を実現

通信のボトルネックをスマートに解決するアプローチって面白いね。しかも、圧縮率が高いのに性能を損なわないなんて、次世代の連合学習に期待が高まるね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-08-16 19:00


- - -

### [Enhancing Object Detection with Hybrid dataset in Manufacturing Environments: Comparing Federated Learning to Conventional Techniques](http://arxiv.org/abs/2408.08974)

**製造環境におけるハイブリッドデータセットを用いた物体検出の強化：連合学習と従来技術の比較**

Vinit Hegiste, Snehal Walunj, Jibinraj Antony, Tatjana Legler, Martin Ruskowski

- 連合学習（FL）は製造分野での耐久性あるモデル開発とプライバシー保護能力で注目を集めている
- 小さな物体検出において、ハイブリッドデータセットを使用したFLが従来の技術よりも優れていると判明
- 異なる環境でのテストでは、視点、照明、背景の違いを超えFLが中央集権的トレーニングモデルよりも優れていた
- 製造環境で堅牢な物体検出モデルの展開において、FLの有効性が示唆される貴重な見解を提供

連合学習がどれだけ異なる環境に対応できるか興味深いね！実際の製造現場に応用したらどんな変化が起きるか想像するとワクワクするよ。

**Comment:** Submitted and Presented at the IEEE International Conference on   Innovative Engineering Sciences and Technological Research (ICIESTR-2024)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.LG, **投稿日時:** 2024-08-16 18:50


- - -

### [A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs](http://arxiv.org/abs/2408.08868)

**実践でのプライベート学習のための手間のかからないアルゴリズム: ツリー集約を使わずにBLTを使おう**

H. Brendan McMahan, Zheng Xu, Yanxiang Zhang

- ツリー集約はプライバシーと有用性のトレードオフが最適ではない
- 行列分解は事前に推定が難しい定数による高額な最適化と高い実行時メモリコストを要求
- 緩衝されたリニアトープリッツ(BLT)メカニズムを用い、マルチ参加シナリオでDP-FTRLを拡張
- BLT-DP-FTRLはツリー集約の使いやすさを保持しつつ、行列分解並みの有用性とプライバシーを実現

BLTメカニズム、なんだか効率良さそうで現実のアプリでもかなり使えそうだわ！スマホのキーボードでこれが使われたら入力がもっとプライベートで快適に!?



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-16 17:52


- - -

### [A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT](http://arxiv.org/abs/2408.08722)

**プライバシー重視のIIoT異常検知のための新しいバッファ付き連合学習フレームワーク**

Samira Kamali Poorazad, Chafika Benzaid, Tarik Taleb

- IIoTはデータプライバシーとサイバーセキュリティの脅威に敏感
- FLはプライバシーを保護しつつ、ローカルデータでモデルを共同訓練
- 垂直同期と非同期のFLには限界があり、データ異質性とリソース制約が影響
- 新提案のBFLは、準同型暗号とバッファベースサーバーで限界を克服

バッファ技術を使ってプライバシーと効率性を両立させちゃうとか、めっちゃおもしろそう！さらに、データ保護も強化されるから、もっと安心してIIoTが使える未来が広がりそうだね。



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-08-16 13:01


- - -

### [RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS](http://arxiv.org/abs/2408.08699)

**RBLA: 連合学習サービスにおける異種モデルの微調整のためのランクベースLoRAアグリゲーション**

Shuaijun Chen, Omid Tavallaie, Niousha Nazemi, Albert Y. Zomaya

- 連合学習（FL）はモバイルやデスクトップなどの多様なデバイスでプライバシーを保護しながら学習を分散させる枠組み
- LoRAはモデルのパラメータの低次元部分に焦点を当てて効率的に微調整を行う方法で、計算およびメモリコストを削減
- FL環境でのLoRAは、ローカルモデルのランクを調整することで異なるハードウェアに柔軟かつ効率的に展開可能
- 異なるランクのモデルの集約にRBLAを提案し、現行のパディング手法が性能を低下させる問題を解決

Rank-Based LoRA Aggregation (RBLA)の提案で、これまでのモデル集約の課題が改善されるみたい。特に異なるデバイスの特徴を活かせるところが新しくて良いね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-08-16 12:26


- - -

### [A Multivocal Literature Review on Privacy and Fairness in Federated Learning](http://arxiv.org/abs/2408.08666)

**連合学習におけるプライバシーと公平性に関する多面的文献レビュー**

Beatrice Balbierer, Lukas Heinlein, Domenique Zipperling, Niklas Kühl

- 連合学習はデータ共有なしでAI応用を革新するが、学習中に情報が抽出される可能性が示された
- 差分プライバシーなどの追加のプライバシー保護措置が必要である
- 高リスクな応用（例：医療）では過去の差別的なエラーを繰り返さないことが重要
- プライバシーと公平性の関係性が無視され、現実世界のアプリケーションに重大なリスクをもたらしている

プライバシーと公平性のバランスを取るって超難しそうだけど、やりがいがありそう。実際のアプリにも早く使われたらいいな！

**Comment:** Accepted for publication at the Internationale Tagung   Wirtschaftsinformatik 2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-16 11:15


- - -

### [Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons](http://arxiv.org/abs/2408.08655)

**連合学習におけるバックドア攻撃の軽減：低活性入力ニューロンの重み更新を反転させる手法**

Binbin Ding, Penghui Yang, Zeqing Ge, Shengjun Huang

- 連合学習はサーバの管理下で複数のクライアントが協力し、プライバシー要件を遵守しながら機械学習モデルを訓練する技術である
- バックドア攻撃は、妥協されたモデル中の特定のニューロンを活性化させ、クリーンデータではこれらのニューロンは休止状態にある
- FLAINと呼ばれる新しい手法を提案し、低活性入力ニューロンの重み更新を反転させることでバックドア攻撃を防ぐ
- 広範な実験により、非独立同分布（non-IID）データや高MCRシナリオでもバックドア攻撃の成功率を低く抑え、クリーンデータの性能劣化も最小限に抑えることが確認された

FLAINって名前がかわいい(笑) どんな攻撃にもピンポイントに対抗できるなんて、まるでデジタル世界の防犯カメラみたい。未来のセキュリティ技術に繋がるかもって思うとワクワクするよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-16 10:44


- - -

### [The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy](http://arxiv.org/abs/2408.08642)

**バイアスの力：異質な差分プライバシーを考慮した連合学習のクライアント選択の最適化**

Jiating Ma, Yipeng Zhou, Qi Li, Quan Z. Sheng, Laizhong Cui, Jiangchuan Liu

- クライアントはモデル勾配を公開するが、元のデータは公開しない連合学習のプライバシー保護
- 差分プライバシーを導入したDPFLは勾配にノイズを加えて保護を強化
- クライアント選択の問題として、異質なプライバシー要件とデータ品質、ノイズの影響を考慮
- DPFL-BCSアルゴリズムを提案し、実験結果から既存手法に比べモデル性能向上を確認

このアルゴリズム、めちゃおもしろそう！差分プライバシーのノイズまで考慮して最適化してるのって新しいから、実際にどう使えるのかもっと知りたいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-16 10:19
