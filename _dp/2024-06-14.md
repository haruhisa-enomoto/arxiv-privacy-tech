---
title: 差分プライバシー (2024-06-14 ~ 2024-06-20)
date: 2024-06-14
---

差分プライバシーに関する論文まとめ (2024-06-14 ~ 2024-06-20)


- - -

### [Consistent community detection in multi-layer networks with heterogeneous differential privacy](http://arxiv.org/abs/2406.14772)

**異種差分プライバシーを用いた多層ネットワークにおける一貫したコミュニティ検出**

Yaoming Zhen, Shirong Xu, Junhui Wang

- トポロジー構造を保ちながら敏感情報を保護することが課題
- 個々のノードのプライバシー好みに基づくパーソナライズドエッジフリッピング機構を提案
- 適切なデバイアスでコミュニティ構造を保持しつつ差分プライバシー達成可能
- 提案手法の有効性を様々な合成ネットワークや実際の多層ネットワークで数値的に確認

この論文、ネットワークの個々のノード毎に対応するプライバシー対策を導入しているっていうところが超おもしろそう！どんな風に使われるか想像するとワクワクするよね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ME, cs.CR, cs.SI, **投稿日時:** 2024-06-20 22:49


- - -

### [Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning](http://arxiv.org/abs/2406.14322)

**プライバシーユニットを考慮せよ！言語モデルのファインチューニングにおけるユーザーレベル差分プライバシー**

Lynn Chua, Badih Ghazi, Yangsibo Huang, Pritish Kamath, Daogao Liu, Pasin Manurangsi, Amer Sinha, Chiyuan Zhang

- 大規模言語モデル（LLM）のファインチューニングにはプライバシーリスクがあり、特定のユーザーのデータを覚える可能性がある
- 現在のLLM評価は各テキストレコードをプライバシーユニットと見なしているが、これはユーザーごとのプライバシー保証が不均一になる
- 本研究では、ユーザーごとの貢献が均等でない場合に均一なプライバシー保護を確保するため、ユーザー単位の差分プライバシー（DP）を評価
- ユーザーレベルのDPを実現するために、Group Privacyとユーザー単位のDP-SGDの2つのメカニズムを検討し、データ選択戦略やパラメータ調整を探求

従来の方法じゃ個別のレコードばかりだと不安定だよね。でもユーザーレベルでプライバシーを均一に保護するって新しいし、みんなに公平で素敵かも。期待しちゃうね！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CL, cs.CR, cs.LG, **投稿日時:** 2024-06-20 13:54


- - -

### [Privacy-Preserving ECG Data Analysis with Differential Privacy: A Literature Review and A Case Study](http://arxiv.org/abs/2406.13880)

**差分プライバシーを用いたECGデータ解析: 文献レビューとケーススタディ**

Arin Ghazarian, Jianwei Zheng, Cyril Rakovski

- 差分プライバシーは、データベース内の個人のプライバシーを保護しつつ、有用なデータ解析結果を共有する技術である。
- 実際の適用には重要なパラメータの推定が必要であり、明確な解決策やガイドラインが不足している。
- 論文前半では差分プライバシーの主要概念とECG解析への応用に関する文献レビューを行う。
- 後半では、不整脈データベースに対する差分プライバシー付きクエリリリースの実装方法と課題、ガイドラインに言及。

差分プライバシーって安全だけど実装が難しそうな技術だね。でも、それをECG解析に応用するなんて未来のヘルスケアが楽しみだなって思ったよ。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-19 23:17


- - -

### [Bayes' capacity as a measure for reconstruction attacks in federated learning](http://arxiv.org/abs/2406.13569)

**連合学習における再構築攻撃の測定としてのベイズ容量**

Sayan Biswas, Mark Dras, Pedro Faustini, Natasha Fernandes, Annabelle McIver, Catuscia Palamidessi, Parastoo Sadeghi

- 連合学習でも再構築攻撃が懸念されており、攻撃者は重み更新情報を基に訓練データを推測可能
- プライバシーコミュニティは差分プライバシーを用いたDP-SGDを推奨するが、効果は未確立
- 情報理論的枠組みを用いて再構築脅威モデルを形式化し、ベイズ容量を上限として設定
- 実証結果により、再構築脅威に対するメカニズムの効果を比較するための有効な測定法を提示

プライバシー保護しながら連合学習の安全性を向上させるなんて面白い！新しいアプローチが多くの分野で役立つといいね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, cs.IT, math.IT, **投稿日時:** 2024-06-19 13:58


- - -

### [Certificates of Differential Privacy and Unlearning for Gradient-Based Training](http://arxiv.org/abs/2406.13433)

**差分プライバシーと勾配ベース訓練のためのアンラーン証明書**

Matthew Wicker, Philip Sosnin, Adrianna Janik, Mark N. Müller, Adrian Weller, Calvin Tsay

- モデル所有者が訓練時に個人データのプライバシーを守る必要がある
- 差分プライバシーやアンラーンの技術は性能に悪影響を与える場合がある
- 具体的な予測の公開が$\epsilon=0$のプライバシー保証を満たすことを証明する新しいフレームワークを提案
- 金融サービス、医療画像診断、自然言語処理のタスクでフレームワークの有効性を検証

差分プライバシーだけでなく、アンラーンの証明も視野に入れててすごい！これで、ユーザーのデータ保護がより安心できるね。

**Comment:** 15 pages, 14 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-19 10:47


- - -

### [Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data](http://arxiv.org/abs/2406.13130)

**小売データサイエンスの進展：合成データの包括的評価**

Yu Xia, Chi-Hua Wang, Joshua Mabry, Guang Cheng

- 合成データ評価は、小売部門でのデータの正確性が重要
- フレームワークは合成小売データを忠実度、実用性、プライバシーの観点から評価
- 忠実度は安定性と汎用性で測定され、安定性は既知のデータ分布を正確に再現
- 差分プライバシーを使用して、訓練データと保留データセットの間でプライバシーを保障

評価のフレームワークめっちゃ必要かもね！将来の小売業界の合成データ技術がもっと進むといいな。



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, stat.ML, **投稿日時:** 2024-06-19 00:47


- - -

### [Centering Policy and Practice: Research Gaps around Usable Differential Privacy](http://arxiv.org/abs/2406.12103)

**政策と実践の中心化：使いやすい差分プライバシーに関する研究のギャップ**

Rachel Cummings, Jayshree Sarathy

- 差分プライバシーは理論的に非常に強力だが、実践には大きな課題がある
- 実世界での利用可能性を向上させるためには、研究者と実務家の協力が必要
- ユーザーのニーズに合わせたリスクフレームワークの開発が提案されている
- ユーザーインターフェースの投資やアルゴリズム監査が重要な改善点である

理論だけじゃなくて実践も大事って視点が新鮮！みんなのための差分プライバシーが早く実現するといいな。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.CY, cs.HC, **投稿日時:** 2024-06-17 21:32


- - -

### [Making Old Things New: A Unified Algorithm for Differentially Private Clustering](http://arxiv.org/abs/2406.11649)

**古いものを新しくする：差分プライバシー・クラスタリングのための統一アルゴリズム**

Max Dupré la Tour, Monika Henzinger, David Saulpic

- プライベートクラスタリング問題は様々なプライバシーモデルで広く研究されている
- 20年前のアルゴリズムを少し修正することで、すべてのモデルに対応可能にした
- 既存の多くの結果と一致しつつ、一部の結果を改善し新しいプライバシーモデルにも拡張
- 継続的観察設定という入力が時間と共に変化する新しいプライバシーモデルに対応

20年前のアルゴリズムを使って、最新の問題にも対応できるなんてすごくない？これでプライバシー保護のクラスタリングも、もっと広く使えるようになりそうだね！

**Comment:** Oral presentation at ICML 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, cs.CR, cs.LG, **投稿日時:** 2024-06-17 15:31


- - -

### [Private Approximate Query over Horizontal Data Federation](http://arxiv.org/abs/2406.11421)

**水平データ連合におけるプライベート近似クエリ**

Ala Eddine Laouir, Abdessamad Imine

- 複数のデータ提供者がプライベートデータの共同分析を行う課題が存在
- 暗号技術はプライバシーを向上させるが、クエリ応答時間が増加
- 近似クエリ処理と差分プライバシーを組み合わせた新手法を提案
- 計算時間を最大8倍高速化しつつ、学習ベース攻撃への耐性を維持

既存の方法が遅いのを改善できるっぽい！学習攻撃にも強いから安心だね。pliant response time with robust protectionってすごくいいかも☆

**Comment:** To appear in EDBT 2025

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DB, cs.CR, H.2.8, **投稿日時:** 2024-06-17 11:19


- - -

### [Transparency, Privacy, and Fairness in Recommender Systems](http://arxiv.org/abs/2406.11323)

**推薦システムにおける透明性、プライバシー、公正性**

Dominik Kowald

- 推薦システムに心理学的理論を導入し、透明な設計プロセスを実現
- 差分プライバシーを用いて精度とプライバシーのトレードオフを調整し、ユーザー保護を効率化
- セッションベースおよびコールドスタート推薦におけるユーザーの好み情報の不足に対処
- 人気バイアスが推薦の頻度と人気の相関を示し、公正性に影響を与えることを確認

心理学の理論がどんな風に使われるのか気になるね！また、人気バイアスが推薦システムに与える影響がどう解決されるかも注目したいよ～！

**Comment:** Habilitation (post-doctoral thesis) at Graz University of Technology   for the scientific subject Applied Computer Science

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.IR, **投稿日時:** 2024-06-17 08:37


- - -

### [Retraining with Predicted Hard Labels Provably Increases Model Accuracy](http://arxiv.org/abs/2406.11206)

**予測されたハードラベルによる再訓練はモデル精度を証明的に向上させる**

Rudrajit Das, Inderjit S. Dhillon, Alessandro Epasto, Adel Javanmard, Jieming Mao, Vahab Mirrokni, Sujay Sanghavi, Peilin Zhong

- ノイズの多いラベルで訓練したモデルの性能は、自身の予測ハードラベルで再訓練することで向上する
- 本研究では、ランダムに破損したラベルを用いた線形分離設定での再訓練を理論的に分析
- 最初のノイズラベルで得た精度を再訓練で向上できることを証明した初の理論的結果
- ラベル差分プライバシー(DP)訓練において、予測ラベルと与えられたラベルが一致するサンプルの再訓練が有効

この研究、本当面白そう！予測ラベルと与えられたラベルに基づく再訓練でプライバシーを損ねずに精度が向上するだなんて、未来に向けてもっと探求したくなるね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ML, **投稿日時:** 2024-06-17 04:53


- - -

### [MemDPT: Differential Privacy for Memory Efficient Language Models](http://arxiv.org/abs/2406.11087)

**MemDPT: メモリ効率型言語モデルのための差分プライバシー**

Yanming Liu, Xinyue Peng, Jiannan Cao, Yuwei Zhang, Chen Ma, Songhang Deng, Mengchen Fu, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du

- 大規模言語モデルは優れた性能を発揮するが、ユーザープライバシーのリスクがある
- トレーニング時のメモリ消費が大きく、資源消耗の課題がある
- 提案するMemDPTはメモリコストを2~3倍最適化し、データプライバシーを強化
- MemDPTはさまざまなタスクシナリオで差分プライバシー効率のファインチューニングを実現

MemDPTって、メモリも節約しながらプライバシーも守るなんて最強じゃない？色んな応用ができそうでめちゃくちゃワクワクするね！

**Comment:** 12 pages first version

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.CL, cs.LG, **投稿日時:** 2024-06-16 22:11


- - -

### [Privacy-Preserving Heterogeneous Federated Learning for Sensitive Healthcare Data](http://arxiv.org/abs/2406.10563)

**センシティブな医療データに対するプライバシー保護を図る異なる連合学習**

Yukai Xu, Jingfeng Zhang, Yujie Gu

- 医療データの集中化によるプライバシー漏洩の課題
- 知的財産保護のため、異なるローカルモデルの機密性を保ちながら共同訓練が必要
- 新たなAAFVフレームワークを提案。差分プライバシー機構と棄権認識投票を組み合わせる
- 糖尿病と院内患者死亡率の予測において有効性と機密性を実証

新しい仕組みでデータのプライバシーを守りつつ、正確な医療予測ができるなんてすごいよね。これからモデル同士も秘密を守りながら仲良く協力する時代になるのかも！

**Comment:** Accepted to the 2024 IEEE Conference on Artificial Intelligence (IEEE   CAI 2024)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-06-15 08:43
