[
  {
    "url": "http://arxiv.org/abs/2406.02502",
    "title": "Singular Subspace Perturbation Bounds via Rectangular Random Matrix Diffusions",
    "japanese_title": "直交行列の摂動境界: 長方形ランダム行列の拡散によるアプローチ",
    "authors": [
      "Peiyao Lai",
      "Oren Mangoubi"
    ],
    "categories": [
      "math.ST",
      "cs.DS",
      "cs.NA",
      "math.NA",
      "math.PR",
      "stat.TH"
    ],
    "comment": "",
    "summary": "- 行列$A$に対する上位$k$の特異ベクトルがランダム行列$G$を加えた$A+G$による変動を分析\n- 特異値の間のギャップが$\\Omega(\\sigma_k-\\sigma_{k+1})$のとき、期待されるフロベニウス距離は$\\tilde{O}(\\sqrt{d}/(\\sigma_k-\\sigma_{k+1}) \\times \\sqrt{T})$\n- 提案手法で以前の境界より$\\sqrt{m}/\\sqrt{d} \\sqrt{k}$の改善を実現\n- 摂動をダイソン‐ベッセル過程として捉え、確率計算を使用して特異ベクトルの進化を追跡\n\n行列の特異ベクトルがどう変わるかって、統計とかプライバシー保護にも関係あって面白いよね！ランダム性がどう影響するかも要チェックだよ。",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-06-04T17:20:42+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02470",
    "title": "Meta-Designing Quantum Experiments with Language Models",
    "japanese_title": "言語モデルを用いた量子実験のメタデザイン",
    "authors": [
      "Sören Arlt",
      "Haonan Duan",
      "Felix Li",
      "Sang Michael Xie",
      "Yuhuai Wu",
      "Mario Krenn"
    ],
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "comment": "10+3 pages, 5 figures",
    "summary": "- AIは人間の能力を超える解決策を見出すが、その理解には多大な努力が必要\n- 合成データで訓練されたコード生成言語モデルが特定問題の解決だけでなく、メタソリューションも創出\n- 新たな量子物理実験の設計において、シークエンス・トゥ・シークエンス変換器が実験の設計原理を生成\n- 無限に広がる量子状態クラスの設計ルールを発見し、読みやすいPythonコードで一般化されたパターンを自動生成\n\nAIが未知の設計ルールを発見してプログラムコード化するなんて、未来のサイエンティストのアシスタントが形になった感じだね。新しい量子実験がもっと楽しくなりそう！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-04T16:40:55+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02463",
    "title": "Click Without Compromise: Online Advertising Measurement via Per User Differential Privacy",
    "japanese_title": "妥協のないクリック: ユーザーごとの差分プライバシーによるオンライン広告測定",
    "authors": [
      "Yingtai Xiao",
      "Jian Du",
      "Shikun Zhang",
      "Qiang Yan",
      "Danfeng Zhang",
      "Daniel Kifer"
    ],
    "categories": [
      "cs.CR"
    ],
    "comment": "",
    "summary": "- オンライン広告の測定は効率化に重要であり、ユーザーの活動データを収集する必要がある\n- 高まるプライバシー懸念により対策が求められており、ユーザープライバシー保護が不可欠\n- Ads-BPCという新たなユーザー差分プライバシー保護スキームを導入\n- 実験で既存の方法と比較し25%から50%の精度向上を達成し、形式的プライバシー保証も提供\n\nこの方法、プライバシーを守りつつ精度を上げちゃうってすごくない？広告業界の未来が変わる予感！",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-06-04T16:31:19+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02447",
    "title": "Reducing Bias in Federated Class-Incremental Learning with Hierarchical Generative Prototypes",
    "japanese_title": "階層的生成プロトタイプによる連合増分学習におけるバイアスの低減",
    "authors": [
      "Riccardo Salami",
      "Pietro Buzzega",
      "Matteo Mosconi",
      "Mattia Verasani",
      "Simone Calderara"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合継続学習（FCL）は、時間と共に進化するデータ分布に対処\n- 増分バイアスとローカル分布へのバイアスが生じる問題を指摘\n- 学習可能なプロンプトを使用して事前学習済みのバックボーンを微調整しバイアスを抑制\n- 生成プロトタイプを活用し、グローバルモデルの予測バランスを改善し、精度が平均+7.9%向上\n\n生成プロトタイプなんて斬新なアイデア！未来のデータ分析がもっと公平になるかもね、ワクワクするよね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-04T16:12:27+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02424",
    "title": "Contextual Dynamic Pricing: Algorithms, Optimality, and Local Differential Privacy Constraints",
    "japanese_title": "コンテクストを考慮した動的価格設定: アルゴリズム、最適性、およびローカル差分プライバシー制約",
    "authors": [
      "Zifeng Zhao",
      "Feiyu Jiang",
      "Yi Yu"
    ],
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "comment": "",
    "summary": "- 需要モデルが不明な状態で製品販売を行う企業が、収益最大化を目指す問題を研究\n- 最適後悔上限が$\\sqrt{dT}$オーダーであり、既存上限を$\\sqrt{d}$で改善\n- 信頼境界型(supCB)アルゴリズムと探索-コミット(ETC)アルゴリズムが鍵\n- ローカル差分プライバシー(LDP)制約下でも最適後悔上限を確立し、プライバシーコストを評価\n\n動的価格設定がこんなに複雑で面白いなんて思わなかった。プライバシーを守りつつも、最適な価格設定を見つけるなんて科学ってすごいね！",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-06-04T15:44:10+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02416",
    "title": "Improved Modelling of Federated Datasets using Mixtures-of-Dirichlet-Multinomials",
    "japanese_title": "ディリクレ多項分布混合モデルを用いた連合データセットの改善モデリング",
    "authors": [
      "Jonathan Scott",
      "Áine Cahill"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "comment": "",
    "summary": "- 連合学習のトレーニングは中央集権型に比べると非常に遅く、実験やチューニングが困難\n- サーバ側のプロキシデータでシミュレーションを行い、ハイパーパラメータチューニングを高速化\n- 中央集権データセットをクライアントに分割する際、不適切な分割は実際の連合学習を正確に反映しない\n- 提案するアルゴリズムは、真のクライアントの分布を学習し、シミュレーションクライアントを効率的に作成\n\n複雑な連合学習の課題に挑戦してて面白いよね。データの分割方法が改善されると、いろんなデータ活用の可能性が広がりそう！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-04T15:27:53+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02355",
    "title": "FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning",
    "japanese_title": "FedDr+: グローバル特徴抽出の蒸留を用いた連合学習におけるドット回帰の安定化",
    "authors": [
      "Seongyoon Kim",
      "Minchan Jeong",
      "Sungnyun Kim",
      "Sungwoo Cho",
      "Sumyeong Ahn",
      "Se-Young Yun"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合学習 (FL) は、クライアント間の異種非独立同分布データで効果的なグローバルモデルやパーソナライズモデルを開発\n- クライアントドリフトがFLの課題で、データの異質性が知識の集約を妨げる\n- 新しいアルゴリズムFedDr+は、未観測クラスの表現を保持しつつドット回帰損失を使用してローカルモデルの整合性を強化\n- frozen classifierと特徴蒸留メカニズムを併用することで寄与されたグローバルモデルを改善、既存手法を超える性能を実証\n\nFedDr+って難しそうだけど、未観測クラスについての情報保持しながらローカルな整合性を取るって画期的！連合学習の未来がまた開けそうだね！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-04T14:34:13+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02209",
    "title": "Automatic nonstationary anisotropic Tikhonov regularization through bilevel optimization",
    "japanese_title": "バイレベル最適化による非定常異方性ティホノフ正則化の自動化",
    "authors": [
      "Silvia Gazzola",
      "Ali Gholami"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "65F22, 65K10, 65R32"
    ],
    "comment": "",
    "summary": "- 離散逆問題の解決には正則化手法が必要である\n- 共通の2ノルムティホノフ正則化法は大きな勾配成分を抑制するが一様である\n- 異方性正則化を用いることで重要な構造やテクスチャ、非連続性を保存できる\n- 提案手法はバイレベル最適化で正則化解と局所方向を同時に復元し有効性を示す\n\nバイレベル最適化で異方性を扱うなんてすごいね！実際の画像処理に応用してみたいなぁ。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-04T11:07:11+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02177",
    "title": "One-Shot Federated Learning with Bayesian Pseudocoresets",
    "japanese_title": "ベイズ・ピソードコアセットを用いたワンショット連合学習",
    "authors": [
      "Tim d'Hondt",
      "Mykola Pechenizkiy",
      "Robert Peharz"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "stat.ML"
    ],
    "comment": "10 pages",
    "summary": "- 連合学習は通信コストが高く、サーバとクライアント間で高次元モデルパラメータを繰り返し通信する必要がある\n- 提案手法はベイズアプローチを用い、ローカルクライアントの事後分布の積としてグローバル推論問題を解決し、ワンショット通信を実現\n- ニューラルネット等の多峰性尤度を持つモデルに対して、クライアントが異なる事後モードを捉えるため、素朴なアプローチでは後部が崩壊する\n- 分散型関数空間推論とベイズ・ピソードコアセット学習の関連性を示し、通信コストを最大二桁減少させ、予測性能も最新技術と競合することを実証\n\nワンショットで連合学習を実現するなんて、革新的だね！通信コストが二桁も減るのは未来のネットワーク負荷軽減に繋がるね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-04T10:14:39+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02140",
    "title": "Optimality of Matrix Mechanism on -metric",
    "japanese_title": "行列メカニズムの$\\ell_p^p$-メトリック最適性",
    "authors": [
      "Jingcheng Liu",
      "Jalaj Upadhyay",
      "Zongrui Zou"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- $\\ell_p^p$-誤差メトリックを導入し、線形クエリへの差分プライバシー制約下での回答を評価\n- $(\\epsilon,\\delta)$-差分プライバシー下での誤差を特徴付け\n- $\\ell_2^2$や$\\ell_p^2$-誤差メトリックに基づく以前の研究を一般化\n- すべての定数$p$に対して$\\ell_p^p$-誤差に基づくプレフィックス和およびパリティクエリの厳密な境界を提供\n\n行列メカニズムって色々応用できそうで面白いよね！あと、こういう具体的な境界を提供するのって解決策のヒントになりそうで良いなと思った。",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-06-04T09:27:35+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02131",
    "title": "CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting",
    "japanese_title": "CondTSF: 時系列予測のためのデータセット凝縮のワンライン・プラグイン",
    "authors": [
      "Jianrong Ding",
      "Zhanyu Liu",
      "Guanjie Zheng",
      "Haiming Jin",
      "Linghe Kong"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "comment": "23 pages, 13 figures",
    "summary": "- データセット凝縮技術は、訓練コストを低減するために小さなデータセットを生成する\n- 既存の手法は分類タスクに焦点を当てており、時系列予測への適用が困難\n- 時系列予測では、モデル予測の距離が評価基準であり、分類よりも厳格\n- CondTSFを提案し、予測距離を縮めることで性能を向上させる\n\n時系列予測の他の応用も気になるね！データセットの凝縮がどれだけ他の分野でも使えるのか、今後もチェックしてみたいな。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-04T09:18:20+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02100",
    "title": "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data",
    "japanese_title": "合成データを用いた大規模言語モデルの数学的外挿の探求",
    "authors": [
      "Haolong Li",
      "Yu Ma",
      "Yinqi Zhang",
      "Chen Ye",
      "Jie Chen"
    ],
    "categories": [
      "cs.CL"
    ],
    "comment": "Accept by Findings of ACL 2024",
    "summary": "- LLMは言語理解、テキスト生成、コード生成で優れているが、多段階の数学的推論に苦労している\n- 新しい算術パズル問題を通じ、質の高い合成データでファインチューニングすることで、モデルは多段階推論が可能\n- open-llama-3Bモデルの実験結果は、in-domainデータセットでゼロショットの正解率@1が0.44に達し、アウト・オブ・ドメインデータセットでも一般化能力を示した\n- 数値範囲と構成要素を拡張した2つのアウト・オブ・ドメインデータセットで、ゼロショットの正解率@1がそれぞれ0.33と0.35を記録\n\nこの研究、合成データで数学難問を解決しようとしてるんだね！モデルが未知の問題でも自己解決する未来が見えそう！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-04T08:30:37+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.02015",
    "title": "Parameterizing Federated Continual Learning for Reproducible Research",
    "japanese_title": "再現可能な研究のための連合継続学習のパラメータ化",
    "authors": [
      "Bart Cox",
      "Jeroen Galjaard",
      "Aditya Shankar",
      "Jérémie Decouchant",
      "Lydia Y. Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "I.2.11"
    ],
    "comment": "Preprint: Accepted at the 1st WAFL (Workshop on Advancements in   Federated Learning) workshop, ECML-PKDD 2023",
    "summary": "- 連合学習システムは異質で常に変化する環境で進化し、性能に挑戦がある\n- クライアントの学習タスクも時間と共に進化し、継続学習の統合が必要\n- 複雑な学習シナリオを正確にキャプチャしエミュレートする実験ベストプラクティスを提案\n- Freddieは完全に構成可能な連合継続学習フレームワークで、大規模なマシン上での展開が可能\n\n連合学習と継続学習を組み合わせて、現場ですぐ活用できるってスゴイね！将来的には、もっと多くの分野での応用が期待できそう。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-04T06:54:53+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01964",
    "title": "Measure-Observe-Remeasure: An Interactive Paradigm for Differentially-Private Exploratory Analysis",
    "japanese_title": "測定・観察・再測定：差分プライバシーによる探索的分析のためのインタラクティブパラダイム",
    "authors": [
      "Priyanka Nanayakkara",
      "Hyeok Kim",
      "Yifan Wu",
      "Ali Sarvghad",
      "Narges Mahyar",
      "Gerome Miklau",
      "Jessica Hullman"
    ],
    "categories": [
      "cs.CR",
      "cs.DB",
      "cs.HC"
    ],
    "comment": "Published in IEEE Symposium on Security and Privacy (SP) 2024",
    "summary": "- 差分プライバシーはプライバシー保護分析を可能にするが、専門知識を要し探索的分析には難しい\n- 新しいインタラクティブな分析パラダイム「測定・観察・再測定」を提案\n- インタラクティブな可視化インターフェースを使用し、限られた予算内で$\\epsilon$を効果的に使える\n- ユーザースタディで、参加者が効率的な$\\epsilon$配分戦略を用いて成功を収めることを示す\n\n差分プライバシーの分析がこんなふうにインタラクティブになるなんて面白そう！実際のデータ分析の効率改善が期待できるよね。",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-06-04T04:48:40+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01950",
    "title": "A Comparative Study of Sampling Methods with Cross-Validation in the FedHome Framework",
    "japanese_title": "FedHomeフレームワークにおけるクロスバリデーションを活用したサンプリング手法の比較研究",
    "authors": [
      "Arash Ahmadi",
      "Sarah S. Sharif",
      "Yaser M. Banad"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "comment": "11 Figures",
    "summary": "- FedHomeは連合学習と生成畳み込みオートエンコーダを使用し、個人の自宅での健康モニタリングをプライバシー保護しながら向上させる\n- 健康データのクラス不均衡が課題であり、転倒などの重大なイベントが過小評価されモデル性能に悪影響\n- 6つのオーバーサンプリング技術（SMOTE、Borderline-SMOTE、Random OverSampler、SMOTE-Tomek、SVM-SMOTE、SMOTE-ENN）を評価\n- SMOTE-ENNが最も安定した試験精度を示し、他のサンプラーに比べて信頼性と精度の向上が期待できる\n\nSMOTE-ENNがハズレなさそうなのが安心！他の手法と比べてどれだけ実際に差がでるのか、自分でも試してみたくなるね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-04T04:03:07+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01872",
    "title": "A Survey of Unikernel Security: Insights and Trends from a Quantitative Analysis",
    "japanese_title": "A Survey of Unikernel Security: Insights and Trends from a Quantitative Analysisの和訳",
    "authors": [
      "Alex Wollman",
      "John Hastings"
    ],
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.OS",
      "C.2.4; K.6.5; D.4.6"
    ],
    "comment": "8 pages, 3 figures, 7 tables",
    "summary": "- UnikernelはLibOSの進化形で、クラウドプロバイダに利用される仮想化技術に対抗しつつある\n- ユーザーとカーネルスペースを統一し、不要な機能を省略することでリソースを削減\n- 省略される機能には、ASLRやDEP、NXビットなどの一般的なセキュリティ技術も含まれる\n- TF-IDFを用いたセキュリティディスカッションの分析により、SGXが最も頻繁に言及されていることが判明\n\nUnikernelってクラウドでも使えるとか凄くない？！特に、リソースを削減しながら安全性をどう保つのか興味津々！",
    "topics": [
      "TEE"
    ],
    "published": "2024-06-04T00:51:12+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01811",
    "title": "A Game-Theoretic Approach to Privacy-Utility Tradeoff in Sharing Genomic Summary Statistics",
    "japanese_title": "ゲノム要約統計の共有におけるプライバシーと有用性のトレードオフに対するゲーム理論的アプローチ",
    "authors": [
      "Tao Zhang",
      "Rajagopal Venkatesaramani",
      "Rajat K. De",
      "Bradley A. Malin",
      "Yevgeniy Vorobeychik"
    ],
    "categories": [
      "cs.CR"
    ],
    "comment": "",
    "summary": "- ゲノム情報の要約統計を共有することで、意図せずプライバシーリスクが増大する\n- 提案されたベイズゲーム理論フレームワークが従来のLRTモデルより強力であることを証明\n- Gaussianメカニズム下でのベイズ攻撃とLRT攻撃を比較する解析的アプローチを提案\n- 深層学習を用いてBayes-Nash均衡の近似を実現し、防御戦略を強化\n\nゲーム理論でプライバシーと有用性のバランスを最適化するなんて面白そう！あと、この手法が今後どんなふうに現実で使われるのか気になるなー。",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-06-03T22:09:47+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01774",
    "title": "Efficient Data Distribution Estimation for Accelerated Federated Learning",
    "japanese_title": "加速連合学習のための効率的なデータ分布推定",
    "authors": [
      "Yuanli Wang",
      "Lei Huang"
    ],
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合学習は、多数の分散エッジデバイス上でプライバシーを守る機械学習パラダイムである\n- デバイスはリソースと訓練データが異質で、それによりデバイス選択が難しい\n- 新たに効率的なデータ分布要約計算アルゴリズムを提案、その結果オーバーヘッドを削減\n- 提案された解決策はデータ要約時間を最大30倍、クラスタリング時間を最大360倍削減した\n\nフェデレーテッドラーニングっていっぱい聞くけど、こうやって具体的な改善方法を提案していくのが面白いよね。大規模な環境でどれくらい効率化できるか、未来が楽しみ！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-03T20:33:17+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01727",
    "title": "Federated Learning-based Collaborative Wideband Spectrum Sensing and Scheduling for UAVs in UTM Systems",
    "japanese_title": "連合学習に基づくUAVのための協調的ワイドバンドスペクトラムセンシングおよびスケジューリング",
    "authors": [
      "Sravan Reddy Chintareddy",
      "Keenan Roach",
      "Kenny Cheung",
      "Morteza Hashemi"
    ],
    "categories": [
      "cs.LG",
      "cs.MA",
      "eess.SP"
    ],
    "comment": "This is a preprint version submitted to IEEE Transactions on Machine   learning in Communications and Networking. arXiv admin note: text overlap   with arXiv:2308.05036",
    "summary": "- UAVを二次利用者として、検出された「スペクトラムホール」を利用するデータ駆動型フレームワークを提案\n- 学習データセット生成と連合学習アーキテクチャを統合し、空中信号からI/Qサンプルを取得\n- 協調スペクトラム推論のための戦略を提案し、UTMエコシステムと互換性を持たせた\n- 検出されたスペクトラムホールを動的に割り当てるために強化学習手法を活用\n\nこのフレームワークでUAVが効率的にスペクトラムを利用する未来にワクワクするね。現実に近いデータセット生成がすごくキーポイントになりそう！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-03T18:39:27+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01457",
    "title": "Differentially Private Tabular Data Synthesis using Large Language Models",
    "japanese_title": "差分プライバシーを利用した大規模言語モデルによるタブularデータの合成",
    "authors": [
      "Toan V. Tran",
      "Li Xiong"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 差分プライバシーを持つ合成タブularデータ生成は、データ共有において重要であるが困難である\n- DP-LLMTGenは、大規模言語モデル（LLM）を活用してタブularデータを合成する新しいフレームワークを提案\n- DP-LLMTGenは2段階のファインチューニング手法と、タブularデータに特化した新しい損失関数を使用\n- 実証評価では、DP-LLMTGenが複数のデータセットとプライバシー設定で既存手法より優れていることを示している\n\nDP-LLMTGenは、大規模言語モデルを使って新しいアプローチを取っているみたい。どんな本番環境で使われるか気になるなー。",
    "topics": [
      "合成データ",
      "差分プライバシー"
    ],
    "published": "2024-06-03T15:43:57+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01439",
    "title": "Asynchronous Multi-Server Federated Learning for Geo-Distributed Clients",
    "japanese_title": "地理分散クライアント向けの非同期マルチサーバ連合学習",
    "authors": [
      "Yuncong Zuo",
      "Bart Cox",
      "Jérémie Decouchant",
      "Lydia Y. Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "I.2.11"
    ],
    "comment": "",
    "summary": "- 既存の連合学習システムは単一サーバ使用で同期通信により効率が低下することがある\n- 新提案の非同期マルチサーバFLアーキテクチャは、サーバとクライアントを常にアクティブに保つ\n- 提案手法では、クライアントは最も近いサーバとだけ対話し、サーバ間も非同期で更新\n- より高い精度を達成しつつ従来手法より61%少ない時間で収束する結果を示す\n\n地理的に分散した環境での効率的な連合学習って、未来のIoTとかにぴったりじゃない？ぜんぶのデバイスがスムーズにつながるなんて、楽しみだね！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-03T15:29:46+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01438",
    "title": "Asynchronous Byzantine Federated Learning",
    "japanese_title": "非同期ビザンチン連合学習",
    "authors": [
      "Bart Cox",
      "Abele Mălan",
      "Jérémie Decouchant",
      "Lydia Y. Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "I.2.11"
    ],
    "comment": "",
    "summary": "- 地理的に分散したクライアントが、サーバを通じてモデルを共同訓練する\n- 非同期学習により、遅いクライアントや異種ネットワークでも速度維持可能\n- 補助サーバデータセットを使わず、過去の問題点を解決する新アルゴリズムを提案\n- 画像とテキストのデータセットで、高速かつ高精度の学習が可能であることを確認\n\n非同期ビザンチン連合学習なんて面白そう！ぶっちゃけ遅いクライアントに妨げられないのがすごく魅力的だよね。これからもっと多様なネットワークでも連合学習が活用できそう！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-03T15:29:38+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01355",
    "title": "Differentially Private Fine-Tuning of Diffusion Models",
    "japanese_title": "差分プライバシーによる拡散モデルの微調整",
    "authors": [
      "Yu-Lin Tsai",
      "Yizhe Li",
      "Zekai Chen",
      "Po-Yu Chen",
      "Chia-Mu Yu",
      "Xuebin Ren",
      "Francois Buet-Golfouse"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "comment": "16 pages, 5 figures, 11 tables",
    "summary": "- 拡散モデルの高い暗記能力がプライバシーリスクを生む\n- 差分プライバシーSGDを使い、データポイントを保護\n- 拡散モデルの構造に合わせた、パラメータ効率の高い微調整戦略を提案\n- CelebA-64データセットで35%以上の性能向上を達成\n\n差分プライバシーと拡散モデルの組み合わせって本当に面白そう！プライバシーとパフォーマンスのバランスとる新しい方法、試してみたいな。",
    "topics": [
      "合成データ",
      "差分プライバシー"
    ],
    "published": "2024-06-03T14:18:04+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01284",
    "title": "Extraction of Weak Surface Diaphragmatic Electromyogram Using Modified Progressive FastICA Peel-Off",
    "japanese_title": "修正されたプログレッシブFastICAを用いた弱い表面横隔膜筋電図の抽出",
    "authors": [
      "Yao Li",
      "Dongsheng Zhao",
      "Haowen Zhao",
      "Xu Zhang",
      "Min Shao"
    ],
    "categories": [
      "physics.med-ph",
      "cs.HC"
    ],
    "comment": "",
    "summary": "- 表面横隔膜筋電図（sEMGdi）は非侵襲的に記録可能だが、ノイズからの抽出が課題\n- 提案手法はFastICA、制約付きFastICA、そしてピールオフ戦略を組み合わせている\n- 合成データと臨床データで検証し、ノイズレベルに関係なく高いSIRとCORRを達成\n- 吸息識別の精度は95.06%、F2スコアは96.73%で、呼吸リハビリに有用である\n\nこれって凄くない？最新技術を駆使していて、呼吸リハビリへの貢献が感じられるんだよね。医療現場での可能性が広がりそうだね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-03T12:53:29+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01281",
    "title": "Extraction of Maternal and fetal ECG in a non-invasive way from abdominal ECG recordings using modified Progressive FastICA Peel-off",
    "japanese_title": "修正されたProgressive FastICA Peel-offを使用した腹部心電図記録からの非侵襲的な母体および胎児心電図の抽出",
    "authors": [
      "Yao Li",
      "Xuanyu Luo",
      "Haowen Zhao",
      "Jiawen Cui",
      "Yangfan She",
      "Dongfang Li",
      "Lai Jiang",
      "Xu Zhang"
    ],
    "categories": [
      "physics.med-ph",
      "cs.HC"
    ],
    "comment": "",
    "summary": "- 非侵襲的な腹部心電図(AECG)は妊娠中の胎児の健康状態を監視する手段である\n- 母体心電図(MECG)との重なりおよび他のノイズが弱い胎児心電図(FECG)の抽出を困難にしている\n- FastICAとその改良版、およびSVD法を組み合わせた新たなFECG抽出フレームワークを提案\n- 公開データセット、合成データ、臨床データで優れたF1スコアを達成し、他の手法を上回る結果を示す\n\n胎児と母体の安全を高めるための技術がどんどん進んでる！これで妊娠中のモニタリングがもっと安心になるね。未来が楽しみ！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-03T12:49:54+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01186",
    "title": "SNPGuard: Remote Attestation of SEV-SNP VMs Using Open Source Tools",
    "japanese_title": "SNPGuard: オープンソースツールを用いたSEV-SNP VMのリモート認証",
    "authors": [
      "Luca Wilke",
      "Gianluca Scopelliti"
    ],
    "categories": [
      "cs.CR"
    ],
    "comment": "to appear at SysTEX'24",
    "summary": "- クラウドプロバイダがデータやコードに完全アクセスできるため、プライバシー問題が重要\n- VMベースのTrusted Execution Environments (TEEs)は強力な隔離保証と認証機能を提供\n- VM全体のブートチェーン認証には多くのソフトウェア変更が必要で複雑\n- 2つの一般的なブートワークフローに対応するツールの提供により低労力で実現\n\nクラウドのプライバシー問題を解決するための技術って感じで、ちょっと未来感あるよね。オープンソースでみんなが使いやすいのも素敵！",
    "topics": [
      "TEE"
    ],
    "published": "2024-06-03T10:48:30+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01116",
    "title": "Accelerating Heterogeneous Federated Learning with Closed-form Classifiers",
    "japanese_title": "閉形式分類器を用いた異種連合学習の加速",
    "authors": [
      "Eros Fanì",
      "Raffaello Camoriano",
      "Barbara Caputo",
      "Marco Ciccone"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "comment": "Accepted at ICML 2024 - https://fed-3r.github.io/",
    "summary": "- 非IIDデータ分布に起因するクライアントドリフトとローカル解の偏りが、収束速度と精度に悪影響を及ぼす\n- Federated Recursive Ridge Regression (Fed3R)を導入し、事前学習済みの特徴を利用してリッジ回帰分類器を閉形式で計算する\n- Fed3Rは統計的異質性やクライアントのサンプリング順序に影響されず、通信と計算コストも競合技術に比べて大幅に低い\n- Fed3Rのパラメータをソフトマックス分類器の初期化に利用し、さらにFed3R+FTとして任意のFLアルゴリズムで微調整する方法を提案\n\nこれ、異質なデータでも学習が効率的にできるのがポイントね。特に、通信や計算リソースを大幅に節約できるのはすごい！未来のデバイス間連携がもっとスムーズになるかもってワクワクしちゃう。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-03T08:52:06+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01115",
    "title": "Cohort Squeeze: Beyond a Single Communication Round per Cohort in Cross-Device Federated Learning",
    "japanese_title": "コホートスクイーズ：クロスデバイス連合学習における単一通信ラウンドを越えて",
    "authors": [
      "Kai Yi",
      "Timur Kharisov",
      "Igor Sokolov",
      "Peter Richtárik"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合学習の従来手法は、サーバとクライアントの単一通信ラウンドに依存\n- 新手法が各コホートからより多くの情報を引き出す可能性を検討\n- 提案手法は通信コストを最大74%削減する効果を確認\n- SPPM-ASを用い、新たなクライアントサンプリング手法で従来手法よりも向上\n\nこれ、すごい興味深いね！通信コストが大幅に削減されたら、実用化も早まりそうだよね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-03T08:48:49+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01085",
    "title": "FedAdOb: Privacy-Preserving Federated Deep Learning with Adaptive Obfuscation",
    "japanese_title": "FedAdOb: 適応的難読化によるプライバシー保護型連合深層学習",
    "authors": [
      "Hanlin Gu",
      "Jiahuan Luo",
      "Yan Kang",
      "Yuan Yao",
      "Gongxi Zhu",
      "Bowen Li",
      "Lixin Fan",
      "Qiang Yang"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 連合学習は、プライベートデータを共有せずに機械学習モデルを共同学習\n- 従来のプライバシー保護方法はモデル性能を低下させる問題がある\n- FedAdObはパスポートベースの適応的難読化でデータプライバシーを保護\n- 実験でFedAdObは既存方法を超えたプライバシーと性能のトレードオフを示した\n\n最強の連合学習って感じかな💡 プライバシーとモデル性能のバランスがすごくいいみたい！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-03T08:12:09+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01080",
    "title": "No Vandalism: Privacy-Preserving and Byzantine-Robust Federated Learning",
    "japanese_title": "バンダリズムなし: プライバシー保護とビザンチン耐性の連合学習",
    "authors": [
      "Zhibo Xing",
      "Zijian Zhang",
      "Zi'ang Zhang",
      "Jiamou Liu",
      "Liehuang Zhu",
      "Giovanni Russello"
    ],
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合学習は複数のクライアントがプライベートデータを共有せずにモデルを共同学習可能\n- ただし、従来の連合学習はデータやモデルへの破壊攻撃に弱く、パフォーマンス低下やバックドアのリスクがある\n- 新提案のモデルフィルターが毒性のあるローカルモデルを検出し、ゼロ知識証明でプライバシーを強化\n- 秘密分散を採用し、安全な集約を実現しつつ、悪意あるクライアントを排除\n\n毒性攻撃とか、ゼロ知識証明の使い方が興味深いなぁ。ついでに、従来の方法よりパフォーマンスが良くなるのもすごいかもね！",
    "topics": [
      "連合学習",
      "ゼロ知識証明"
    ],
    "published": "2024-06-03T07:59:10+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01078",
    "title": "CUT: A Controllable, Universal, and Training-Free Visual Anomaly Generation Framework",
    "japanese_title": "CUT: 制御可能で汎用的かつトレーニング不要な視覚異常生成フレームワーク",
    "authors": [
      "Han Sun",
      "Yunkang Cao",
      "Olga Fink"
    ],
    "categories": [
      "cs.CV"
    ],
    "comment": "9 pages excluding appendix",
    "summary": "- 視覚異常検出は異常データの不足のため大きな課題に直面する\n- 既存の生成手法ではサンプルが現実味に欠けたり、訓練データの分布に制限される\n- CUTはStable Diffusionの画像生成能力を活用し、多様でリアルな異常を生成\n- 提案したVLADモデルは生成された異常サンプルを用いて異常検出タスクで最先端の性能を達成\n\n視覚異常検出でこんなに汎用性のあるフレームワークがあるなんてすごいね！トレーニング不要ってところも画期的で、もっといろんな場面で使いたくなっちゃう。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-03T07:58:09+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01071",
    "title": "Visual Car Brand Classification by Implementing a Synthetic Image Dataset Creation Pipeline",
    "japanese_title": "画像データセット作成パイプラインを用いた合成画像による自動車ブランド分類",
    "authors": [
      "Jan Lippemeier",
      "Stefanie Hittmeyer",
      "Oliver Niehörster",
      "Markus Lange-Hegermann"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "comment": "10 pages, 6 figures",
    "summary": "- 深層学習と物体検出により画像分類と合成が向上\n- 特定用途に対応したラベル付きデータ収集の課題\n- 高精細な合成画像生成のためStable Diffusionを使用\n- 合成データのみで75%の分類精度を実現\n\n合成データで75%の精度ってすごい！これ、本物のデータを使えばもっとすごい成果が出そうだよね。興味津々！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-03T07:44:08+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01063",
    "title": "DANCE: Dual-View Distribution Alignment for Dataset Condensation",
    "japanese_title": "DANCE: デュアルビュー分布整合によるデータセット凝縮",
    "authors": [
      "Hansong Zhang",
      "Shikun Li",
      "Fanzhao Lin",
      "Weiping Wang",
      "Zhenxing Qian",
      "Shiming Ge"
    ],
    "categories": [
      "cs.CV"
    ],
    "comment": "This work has been accepted by IJCAI-24",
    "summary": "- データセットの凝縮は、大規模な実データセットから重要な知識を保持しつつ小さな合成トレーニングセットを学習する技術\n- 最先端の最適化指向の方法は高い成果を上げるが、効率が低い\n- 分布整合法は効率的だが、最適化指向の方法と比べると性能が劣る\n- 提案手法DANCEは、同クラス内と異クラス間の分布整合性を向上し、複数の事前に訓練されたモデルを利用\n\nデータ圧縮と性能維持が両立してるなんてすごいよね！簡単に使えるようになったら、色んな分野で役立ちそう！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-03T07:22:17+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01040",
    "title": "Synthetic Data Generation for 3D Myocardium Deformation Analysis",
    "japanese_title": "3D心筋変形解析のための合成データ生成",
    "authors": [
      "Shahar Zuler",
      "Dan Raviv"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 高解像度CTデータセットの不足が、堅牢な心筋変形解析モデルの開発に課題となっている\n- 新たな合成データ生成法を提案し、重要なGT 3Dオプティカルフロー注釈を強化\n- 心臓4D CTスキャンデータからのデータ準備やパラメータ選定、異なる3D心臓CTデータからの合成データ生成を詳細に説明\n- この研究により、高精度な注釈を持つCTデータセットの不足を補い、臨床応用と診断のための信頼性の高いアルゴリズムの開発を促進\n\n合成データで心臓解析が進むなんて超すごい！今までのデータ不足の壁をぶち壊せるかも。これで解析精度もグンと上がりそうじゃない？",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-03T06:40:53+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00999",
    "title": "Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients",
    "japanese_title": "木を見て森を見る: 部分的なトランスフォーマー勾配からのデータ漏洩",
    "authors": [
      "Weijun Li",
      "Qiongkai Xu",
      "Mark Dras"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CR",
      "I.2.7; I.2.11"
    ],
    "comment": "12 pages, 7 figures",
    "summary": "- 分散機械学習は勾配逆転攻撃に脆弱で、プライベートな訓練データが勾配解析で再構築される\n- 以前の攻撃では全パラメータの勾配を使用してデータ再構築が可能と立証\n- 中間層の一部モジュールやサブモジュールもデータ漏洩リスクがあると仮定し検証\n- 単一のトランスフォーマー層や0.54%パラメータの線形コンポーネントも漏洩の危険があると実験で明示\n\n分散機械学習の勾配解析からデータ漏洩しちゃうんだね。でも、勾配逆転攻撃の防御策とかを未来に研究するのが楽しそうだよね！",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-06-03T05:15:04+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00966",
    "title": "Guaranteeing Data Privacy in Federated Unlearning with Dynamic User Participation",
    "japanese_title": "動的ユーザ参加を伴う連合学習におけるデータプライバシーの保証",
    "authors": [
      "Ziyao Liu",
      "Yu Jiang",
      "Weifeng Jiang",
      "Jiale Guo",
      "Jun Zhao",
      "Kwok-Yan Lam"
    ],
    "categories": [
      "cs.CR"
    ],
    "comment": "",
    "summary": "- 伝統的な方法では削除されたユーザの影響を除去し、全ユーザで再訓練するが大きな負担が発生する\n- クラスタリングを使用してFLユーザをクラスターに分け、それぞれのモデルで投票を集計することで効率を向上\n- クラスター内でのSecAggスキーム統合がユーザの勾配からの情報漏洩を防ぎ、プライバシーを保護\n- 理論的評価と実験結果により、提案手法が動的なユーザ参加に対応しつつプライバシーと効果を両立することが示される\n\n動的なユーザ参加にも強いクラスタリングとプライバシー保護の組み合わせ、気になるー！これで本当に効果が上がるなら、今後の連合学習がもっと安全・効率的になりそうだね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-03T03:39:07+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00846",
    "title": "Local Methods with Adaptivity via Scaling",
    "japanese_title": "適応性を持つローカルメソッドによるスケーリング",
    "authors": [
      "Savelii Chezhegov",
      "Sergey Skorik",
      "Nikolas Khachaturov",
      "Danil Shalagin",
      "Aram Avetisyan",
      "Aleksandr Beznosikov",
      "Martin Takáč",
      "Yaroslav Kholodov",
      "Alexander Gasnikov"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "math.OC"
    ],
    "comment": "42 pages, 2 algorithms, 6 figures, 1 table",
    "summary": "- 機械学習や深層学習の進展に伴い、最適化の課題が複雑化\n- 分散環境での訓練が必須であり、連合学習にも重要\n- 通信ボトルネックを軽減するためにローカルトレーニングを利用\n- Adamのような適応手法とローカルトレーニングの統合を提案\n\n適応手法とローカルトレーニングの組み合わせがどう実際の訓練効率を上げるか、気になるね。どんなコツがあるのか、追って実験結果も見てみたい！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-02T19:50:05+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00752",
    "title": "Blockchain-aided wireless federated learning: Resource allocation and client scheduling",
    "japanese_title": "ブロックチェーン支援型無線連合学習：リソース割り当てとクライアントスケジューリング",
    "authors": [
      "Jun Li",
      "Weiwei Zhang",
      "Kang Wei",
      "Guangji Chen",
      "Feng Shu",
      "Wen Chen",
      "Shi Jin"
    ],
    "categories": [
      "cs.DC"
    ],
    "comment": "14 pages, 4 figures",
    "summary": "- 集中型設計の連合学習（FL）は信頼問題と単一障害点の課題がある\n- ブロックチェーン支援型連合学習（BDFL）はこれらを解決し、分散型ネットワークで効果的に中央集権型の欠点を克服\n- 無線ネットワークでのBDFL導入は帯域幅、計算能力、エネルギー消費の制約に直面する\n- DRC-BDFLアルゴリズムは、Lyapunov最適化を使用して動的にリソース割り当てとクライアントスケジューリングを最適化し、トレーニング遅延を約12％削減\n\n無線環境での学習遅延が解決できたとしたら、これすっごく便利じゃない？新しい技術が色々な制約を克服できるの楽しみだよね！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-02T14:10:29+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00748",
    "title": "Augmenting the FedProx Algorithm by Minimizing Convergence",
    "japanese_title": "FedProxアルゴリズムを収束最小化によって拡張する",
    "authors": [
      "Anomitra Sarkar",
      "Lavanya Vajpayee"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "F.2.2; I.2.7"
    ],
    "comment": "",
    "summary": "- IoTの急成長と多様な産業における重要性\n- FedProx技術を基に効率と効果を高める新手法G Federated Proximityを提案\n- 正規化技術を用いてトレーニング後のモデル精度を向上させ、実時間デバイスと異種ネットワークでの性能を最適化\n- 既存モデルに比べて約90％の収束改善を達成\n\nIoTの効率化がすごく進みそうで、FedProxの新しい応用方法が楽しみだな！IoTデバイスの普及がもっと進んで、日常生活がさらに便利になりそうだよね。",
    "topics": [
      "連合転移学習"
    ],
    "published": "2024-06-02T14:01:55+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00738",
    "title": "Global Rewards in Restless Multi-Armed Bandits",
    "japanese_title": "レストレスマルチアームバンディットにおけるグローバル報酬",
    "authors": [
      "Naveen Raman",
      "Ryan Shi",
      "Fei Fang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "comment": "27 pages",
    "summary": "- レストレスマルチアームバンディット（RMAB）は、アームを引くことが未来の状態に影響する\n- 報酬をアームごとの合計として分離するという制約があることが限界であった\n- グローバル非分離報酬を持つ新しいモデルRMAB-Gを提案\n- リニアとシャープリー-ウィットル指標、適応ポリシーを用いて性能向上を示した\n\n非線形報酬関数の扱いが難しいけれど、それを工夫するのがおもしろそう。リアルデータとの比較が未来の応用に役立ちそうだね！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-02T13:13:46+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00605",
    "title": "LongSkywork: A Training Recipe for Efficiently Extending Context Length in Large Language Models",
    "japanese_title": "LongSkywork: 大規模言語モデルのコンテキスト長を効率的に延長するためのトレーニングレシピ",
    "authors": [
      "Liang Zhao",
      "Tianwen Wei",
      "Liang Zeng",
      "Cheng Cheng",
      "Liu Yang",
      "Peng Cheng",
      "Lijie Wang",
      "Chenxia Li",
      "Xuejie Wu",
      "Bo Zhu",
      "Yimeng Gan",
      "Rui Hu",
      "Shuicheng Yan",
      "Han Fang",
      "Yahui Zhou"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- LongSkyworkは最大200,000トークンを処理できる長文コンテキスト大規模言語モデルである\n- 長文コンテキスト処理能力を高めるためには、標準的なSFTステージに続く長文コンテキストSFTステージを組み込むことが重要\n- 合成データを生成する2つの新しい方法を開発し、連続的プレトレーニングフェーズとSFTフェーズに適用することでトレーニング効率を大幅に向上\n- LongSkyworkはNeedleテストなどの長文コンテキストベンチマークで完璧な精度を達成し、実際のアプリケーションシナリオでも優れた性能を示す\n\n長文コンテキストを扱えるモデルってすごいね！これからの自然言語処理の可能性が広がるね💡",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-02T03:34:41+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00569",
    "title": "Redefining Contributions: Shapley-Driven Federated Learning",
    "japanese_title": "貢献の再定義: Shapley駆動の連合学習",
    "authors": [
      "Nurbek Tastan",
      "Samar Fares",
      "Toluwani Aremu",
      "Samuel Horvath",
      "Karthik Nandakumar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "comment": "Accepted by IJCAI 2024",
    "summary": "- 連合学習（FL）は、生データを共有せずに複数の参加者が共同でグローバルモデルを訓練できるが、参加者の貢献度が均等でない場合や誠実でない場合、モデル収束が困難となることがある。\n- 従来の貢献度評価は全体的な精度評価に依存しており、クラス固有の影響を捉えることに失敗することが多い。\n- 本論文では、協力ゲーム理論のShapley値を利用して、連合学習における参加者の細かい貢献度評価を行う新たな方法ShapFedを提案する。\n- ShapFedに基づく重み付け集約方法ShapFed-WAは、特にクラス不均衡シナリオにおいて従来の連合平均法よりも優れており、効用、効率、公平性の改善が実証された。\n\nこの研究、本当に面白そう！特にクラス不均衡にどう対応するかの部分、すごく参考になりそうだよね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-01T22:40:31+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00519",
    "title": "Learning Discrete Concepts in Latent Hierarchical Models",
    "japanese_title": "潜在階層モデルで離散的概念を学習する",
    "authors": [
      "Lingjing Kong",
      "Guangyi Chen",
      "Biwei Huang",
      "Eric P. Xing",
      "Yuejie Chi",
      "Kun Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "comment": "",
    "summary": "- 概念を高次元データから学ぶことで、解釈可能な機械学習モデルを構築できる\n- 隠れた因果関係が階層的モデルで表され、様々な抽象レベルを組み込む\n- 複雑な構造を持つ因果階層構造を識別する条件を定式化し、無監督データから概念学習の可能性を示す\n- その理論の有効性を合成データ実験で実証し、潜在拡散モデルの理解における理論的洞察の実証を行う\n\n概念を高次元データからどうやって引っ張り出すのかって面白そうだよね！無監督データでできるなんてすごいし、潜在拡散モデルにも応用できるなら未来のAIがどう進化するのかワクワクしちゃう！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-01T18:01:03+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00488",
    "title": "Federated Model Heterogeneous Matryoshka Representation Learning",
    "japanese_title": "連合モデル異質マトリョーシカ表現学習",
    "authors": [
      "Liping Yi",
      "Han Yu",
      "Chao Ren",
      "Gang Wang",
      "Xiaoguang Liu",
      "Xiaoxiao Li"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "comment": "",
    "summary": "- 異質な構造を持つ連合学習クライアントが協調訓練できるが、既存手法は知識交換が制限されている\n- 補助的な小規模の均質モデルを追加し、クライアント間の知識の融合を実現するFedMRLを提案\n- 個別の軽量な表現プロジェクタで表現を融合し、ローカルデータ分布に適応させる\n- FedMRLは非凸収束率$O(1/T)$を達成し、最新手法と比較して最大8.48%および24.94%の精度向上\n\n連合学習って、ほんとに未来感じちゃう。知識の融合とかマトリョーシカみたいで面白そう！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-01T16:37:08+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00431",
    "title": "SpaFL: Communication-Efficient Federated Learning with Sparse Models and Low computational Overhead",
    "japanese_title": "SpaFL: スパースモデルと低計算オーバーヘッドを用いた通信効率の高い連合学習",
    "authors": [
      "Minsu Kim",
      "Walid Saad",
      "Merouane Debbah",
      "Choong Seon Hong"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "comment": "",
    "summary": "- 連合学習(FL)の大きな通信および計算負荷がリソース制約のあるクライアントとシステムでの実用化の課題\n- SpaFLはスパースモデル構造を最適化し低計算オーバーヘッドで通信効率を向上させるFLフレームワーク\n- フィルタ/ニューロンごとに訓練可能な閾値を定義し、接続パラメータをプルーニングすることで構造的スパース性を実現\n- 閾値のみをサーバとクライアント間で通信し、プルーニング方法を学習、グローバル閾値でモデルパラメータを更新\n\nスパースモデルを使うことで、通信と計算コストをぐっと下げながら精度を保てるとか、すごくない？これ、本当に実用化されたら、もっと多くのシステムでFLが使えるようになるかもね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-01T13:10:35+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00302",
    "title": "FedAST: Federated Asynchronous Simultaneous Training",
    "japanese_title": "FedAST: 連合非同期同時トレーニング",
    "authors": [
      "Baris Askin",
      "Pranay Sharma",
      "Carlee Joe-Wong",
      "Gauri Joshi"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "comment": "Accepted to UAI 2024",
    "summary": "- 連合学習（FL）は、プライベートデータを共有せずにエッジデバイスが共同で機械学習モデルをトレーニングする技術である\n- 多くの既存のFL研究は単一タスクの効率的なモデル学習に焦点を当てている\n- FedASTは、複数タスクのモデルをエッジデバイスで同時にトレーニングするためのバッファ非同期アルゴリズムを提案\n- 実世界のデータセットを用いた実験で、FedASTは既存の同時FL手法に比べ、最大46.0%のトレーニング時間短縮を達成\n\nこの研究、めっちゃ面白そう！複数のタスクを同時に処理できるなんて、効率アップ間違いなしだね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-01T05:14:20+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00287",
    "title": "GenPalm: Contactless Palmprint Generation with Diffusion Models",
    "japanese_title": "GenPalm: 拡散モデルを用いた非接触手掌紋生成",
    "authors": [
      "Steven A. Grosz",
      "Anil K. Jain"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 大規模な手掌紋データベースの不足が非接触手掌紋認識の進展を阻んでいる\n- 合成データ生成に向けて拡散確率モデルが提案され、安定した訓練と優れた分布カバレッジを提供\n- この論文は、拡散確率モデルを用いた新しい手掌紋生成方法と複数の手掌IDを合成するエンドツーエンドのフレームワークを開発\n- 実験結果は、さまざまなテストデータベースで接触なしの手掌紋認識性能を向上させる有効性を示している\n\n手掌紋画像を拡散モデルで生成するなんて、しゅごい！！認識性能が向上するなんて未来が楽しみだね～！🌟📷",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-01T03:33:25+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00181",
    "title": "Wait or Not to Wait: Evaluating Trade-Offs between Speed and Precision in Blockchain-based Federated Aggregation",
    "japanese_title": "待つべきか待たざるべきか：ブロックチェーンを用いた連合集約における速度と精度のトレードオフ評価",
    "authors": [
      "Huong Nguyen",
      "Tri Nguyen",
      "Lauri Lovén",
      "Susanna Pirttikangas"
    ],
    "categories": [
      "cs.DC"
    ],
    "comment": "Accepted at Workshop on Engineering techniques for Distributed   Computing Continuum Systems 2024",
    "summary": "- ブロックチェーンを用いた連合学習アーキテクチャを提案し、訓練と集約を分散化することで単一障害点を排除\n- 共有モデルの選択とカスタマイズ可能な集約により、システム性能と正確な推論結果を最適化\n- プライベートなイーサリアムプラットフォームでの実験結果は、中央集約と分散集約で推論精度が比較可能であることを示す\n- 非同期集約は単純な学習モデルには適しているが、複雑なモデルには集約関与が必要で、精度と非同期集約のバランスが重要\n\nブロックチェーンで連合学習がもっと便利になるなんてびっくり！複雑なモデルだと工夫が必要だけど、それがまた面白そうだよね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-31T20:16:04+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.00150",
    "title": "Non-Federated Multi-Task Split Learning for Heterogeneous Sources",
    "japanese_title": "非連合型マルチタスク分割学習による異質データ源の処理",
    "authors": [
      "Yilin Zheng",
      "Atilla Eryilmaz"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "comment": "",
    "summary": "- エッジネットワークとモバイルコンピューティングの発展で異質なデータ源を処理する新たな分散機械学習メカニズムが必要\n- 連合学習（FL）は収束性とデータプライバシー保証があるが、データの不均質性や計算の不均質性に対応できない\n- 代替として、分割学習（SL）と分散ネットワークアーキテクチャの柔軟性を組み合わせたマルチタスク分割学習（MTSL）を提案\n- 理論的分析でMTSLが迅速な収束を達成できることを示し、画像分類データセット上でFLに比べてトレーニング速度、通信コスト、不均質データへの耐性で優位性を示す\n\n新たな学習パラダイムを提案するってかなり期待できそう！私たちのプロジェクトにも応用できるかもね！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-31T19:27:03+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.01611",
    "title": "System-2 Recommenders: Disentangling Utility and Engagement in Recommendation Systems via Temporal Point-Processes",
    "japanese_title": "システム-2推薦者: 時間的ポイントプロセスを用いた推薦システムにおける効用とエンゲージメントの分離",
    "authors": [
      "Arpit Agarwal",
      "Nicolas Usunier",
      "Alessandro Lazaric",
      "Maximilian Nickel"
    ],
    "categories": [
      "cs.IR",
      "cs.LG",
      "stat.ML"
    ],
    "comment": "Accepted at FAccT'24",
    "summary": "- 現在の推薦システムは、エンゲージメント信号（例：いいね、シェア、視聴時間）を最適化の主な指標としている\n- ユーザーの行動は、効用駆動の意思決定（システム-2）と衝動的な意思決定（システム-1）に影響される\n- 提案手法は、エンゲージメント信号ではなくユーザーの再来可能性に基づきユーザー効用を推測する\n- システム-1とシステム-2の行動を分離し、ユーザー効用に基づくコンテンツ最適化を実現する生成モデルを提案\n\nユーザーが長期的にプラットフォームに戻ってくるかどうかで効用を評価するアイディア、新しい視点って感じでワクワクするね。実験も合成データ使ってるから、安全な環境で試せるのがいいよね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-05-29T18:19:37+00:00"
  }
]