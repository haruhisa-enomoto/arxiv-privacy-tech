---
title: 連合学習 (2024-06-14 ~ 2024-06-20)
date: 2024-06-14
---

連合学習に関する論文まとめ (2024-06-14 ~ 2024-06-20)


- - -

### [CollaFuse: Collaborative Diffusion Models](http://arxiv.org/abs/2406.14429)

**CollaFuse: 協調型拡散モデル**

Simeon Allmendinger, Domenique Zipperling, Lukas Struppek, Niklas Kühl

- 拡散モデルは合成画像生成に有望だが、多くの課題がある
- 放任的学習がクライアントに大きな計算負担を課す問題あり
- 提案方法はクライアントの負担を軽減しつつ分散学習を実現
- CelebAデータセットでの実験で、高いプライバシー保護を証明

拡散モデルを活用する新しい協調学習のあり方なんだね。サーバー側に重い処理を任せることで、クライアントが楽になるのはすごく便利そう！未来のエッジコンピューティングも想像できてワクワクするね。

**Comment:** 13 pages, 7 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, **投稿日時:** 2024-06-20 15:54


- - -

### [Communication-efficient Vertical Federated Learning via Compressed Error Feedback](http://arxiv.org/abs/2406.14420)

**圧縮誤差フィードバックによる通信効率の高い垂直連合学習**

Pedro Valdeira, João Xavier, Cláudia Soares, Yuejie Chi

- 連合学習では通信負荷がボトルネックである
- 垂直連合学習では通信圧縮の理解が限られている
- エラーフィードバックによる圧縮誤差で収束速度を向上
- 数値実験により理論結果を確認、従来手法より大幅に改善

垂直連合学習のエラーフィードバックで通信がこんなに効率的になるなんて驚き！今後の研究も楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, cs.DS, math.OC, **投稿日時:** 2024-06-20 15:40


- - -

### [Communication-Efficient Byzantine-Resilient Federated Zero-Order Optimization](http://arxiv.org/abs/2406.14362)

**通信効率の良いビザンチン耐性を持つ連合ゼロ階最適化**

Afonso de Sá Delgado Neto, Maximilian Egger, Mayank Bakshi, Rawad Bitar

- CYBER-0は、メモリおよび通信効率の高い連合学習のための初のゼロ階最適化アルゴリズム
- MNISTデータセットとRoBERTa-Largeの微調整で、通信とメモリの効率で最新アルゴリズムを上回る
- 理論的に、凸損失関数に対する収束の保証を提供
- サイバー攻撃に耐性があり、高精度を維持

ゼロ階最適化って珍しいよね！これでセキュアな連合学習がもっと広がるといいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-20 14:36


- - -

### [NAC-QFL: Noise Aware Clustered Quantum Federated Learning](http://arxiv.org/abs/2406.14236)

**ノイズ対応クラスタ化量子連合学習 (NAC-QFL)**

Himanshu Sahu, Hari Prabhat Gupta

- 量子デバイスのノイズとスケーラビリティがQMLの課題
- ノイズを評価し、クラスタ化して分散QMLタスクを効率的に配分
- 小規模モデルを低ノイズデバイスに割り当て、通信コストを削減
- 実験評価とノイズの影響を示すデータセットを提供

量子コンピューティングの新しい利用法がすごく楽しみ！これが実現したら、色んな技術がもっと速くなって経済的にもリーズナブルになりそうだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** quant-ph, cs.DC, **投稿日時:** 2024-06-20 12:00


- - -

### [Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning](http://arxiv.org/abs/2406.14217)

**連合学習におけるRLベースの集約による高度なポイズニング攻撃の防御**

Yujing Wang, Hainan Zhang, Sijia Wen, Wangjie Qiu, Binghui Guo

- 連合学習は特に精巧なモデルポイズニング攻撃に脆弱である
- 従来の防御手法は手動で作成された短期的な攻撃に対する更新評価やロバスト集約に焦点を当てている
- 本研究では、クライアントのデータ分布の安定性の観察により、悪意のあるクライアントを認識可能であることを見出した
- 提案手法AdaAggRLは、RLベースの適応集約方法を用い、実験で既存の防御モデルを大幅に上回る結果を示した

高度な攻撃にも対応できる手法の話、中身が気になる！これからのセキュリティ対策に革命が起きるかも🎶



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-06-20 11:33


- - -

### [FLoCoRA: Federated learning compression with low-rank adaptation](http://arxiv.org/abs/2406.14082)

**FLoCoRA: 低ランク適応による連合学習の圧縮**

Lucas Grativol Ribeiro, Mathieu Leonardon, Guillaume Muller, Virginie Fresse, Matthieu Arzel

- LoRA法を連合学習に適用し、ResNet-8で通信コストを4.8倍削減しつつ精度低下を1％未満に抑制
- Affine量子化スキームを組み合わせ、ResNet-18で通信コストを18.6倍削減、精度低下依然1％未満
- 従来のモデル圧縮手法と比較しても強力なメッセージサイズ削減のベースラインを提示
- 低ランク適応によりトレーニング時のメモリ要件も削減

通信コストの削減がすごいって感じ！これならデータいっぱいあっても効率的に扱えそうだね。とっても未来な気がする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, eess.SP, **投稿日時:** 2024-06-20 07:59


- - -

### [Bayes' capacity as a measure for reconstruction attacks in federated learning](http://arxiv.org/abs/2406.13569)

**連合学習における再構築攻撃の測定としてのベイズ容量**

Sayan Biswas, Mark Dras, Pedro Faustini, Natasha Fernandes, Annabelle McIver, Catuscia Palamidessi, Parastoo Sadeghi

- 連合学習でも再構築攻撃が懸念されており、攻撃者は重み更新情報を基に訓練データを推測可能
- プライバシーコミュニティは差分プライバシーを用いたDP-SGDを推奨するが、効果は未確立
- 情報理論的枠組みを用いて再構築脅威モデルを形式化し、ベイズ容量を上限として設定
- 実証結果により、再構築脅威に対するメカニズムの効果を比較するための有効な測定法を提示

プライバシー保護しながら連合学習の安全性を向上させるなんて面白い！新しいアプローチが多くの分野で役立つといいね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, cs.IT, math.IT, **投稿日時:** 2024-06-19 13:58


- - -

### [Image Distillation for Safe Data Sharing in Histopathology](http://arxiv.org/abs/2406.13536)

**病理組織学における安全なデータ共有のための画像蒸留**

Zhe Li, Bernhard Kainz

- 病理組織学は、診断精度の向上、予後判定、および治療戦略の立案に役立つ
- 連合学習がデータ共有やプライバシーの問題を解決してきたが、ドメインシフトやバイアスの課題が残る
- 合成データを使ったデータセット蒸留が情報を圧縮し、制約なく共有可能とする方法を提案
- 人の読解可能な合成画像を用いた分類モデルが実データと遜色ない性能を持つことを示した

この研究、むっちゃ興味深いよね！データ共有の未来が広がりそうだし、医療現場での実用化も楽しみ！

**Comment:** accepted at MICCAI 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-06-19 13:19


- - -

### [A Resource-Adaptive Approach for Federated Learning under Resource-Constrained Environments](http://arxiv.org/abs/2406.13351)

**リソース制約環境下での連合学習のためのリソース適応型アプローチ**

Ruirui Zhang, Xingze Wu, Yifei Zou, Zhenzhen Xie, Peng Li, Xiuzhen Cheng, Dongxiao Yu

- 複数のクライアントが異なるリソース制約を持つ連合学習問題の研究
- クライアントの計算および通信リソースが不足し、速いローカルトレーニングとリアルタイム知識共有が困難
- 提案手法「Fed-RAA」は、クライアントのリソースに基づいてモデル断片を適応的に割り当てる
- MNIST、CIFAR-10、CIFAR-100のデータセットで数値結果が有利であることを示す

リソースによる不公平をうまく解消する方法なのかな！これが成功すれば、色々なデバイスで効率的な連合学習が進むね。将来が楽しみ♪



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-06-19 08:55


- - -

### [Enhancing Automated Audio Captioning via Large Language Models with Optimized Audio Encoding](http://arxiv.org/abs/2406.13275)

**大規模言語モデルと最適化された音声エンコーディングによる自動音声キャプションの強化**

Jizhong Liu, Gang Li, Junbo Zhang, Heinrich Dinkel, Yongqing Wang, Zhiyong Yan, Yujun Wang, Bin Wang

- 統一されたアンサンブル蒸留を用いた事前訓練済み音声エンコーダにより、音響トークンの有効性が向上
- 7Bパラメータを持つLlama 2をデコーダとして使用する利点を検討
- 別の事前訓練済み大規模言語モデルで、不十分な訓練データと注釈の曖昧さに起因するテキストエラーを修正
- -Base (LoRA)により音声エンコーダとテキストデコーダが最適化され、DCASE 2023 Task 6Aの優勝者を上回る33.0 SPIDEr-FLスコアを達成

大規模言語モデルとオーディオエンコードの相乗効果が新しい可能性を引き出しそうでワクワクする！近い将来、この研究が音声認識の質を劇的に向上させるかもしれないね。

**Comment:** Accepted by Interspeech 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.SD, cs.CL, eess.AS, **投稿日時:** 2024-06-19 07:09


- - -

### [A Federated Learning Approach for Multi-stage Threat Analysis in Advanced Persistent Threat Campaigns](http://arxiv.org/abs/2406.13186)

**連合学習アプローチによる高度持続型脅威キャンペーンにおける多段階脅威分析**

Florian Nelles, Abbas Yazdinejad, Ali Dehghantanha, Reza M. Parizi, Gautam Srivastava

- APTは新しい攻撃ベクトルを使用し、署名ベースの検出を回避するため検出が困難
- 有効な検出には複数のクライアントからのデータセットを使用する必要があるが、プライバシーの問題が生じる
- 3フェーズの非教師あり連合学習フレームワークを提案し、パターン抽出と分析を効率化
- パイエルの部分準同型暗号を使用してプライバシーを確保しつつSoTM 34データセットでの有効性を証明

最新の攻撃に適応するための新しい連合学習アプローチって面白そう！プライバシーも守れるし、効率的な検出が期待できるね。



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-19 03:34


- - -

### [Synergizing Foundation Models and Federated Learning: A Survey](http://arxiv.org/abs/2406.12844)

**基盤モデルと連合学習の融合：調査**

Shenghui Li, Fanghua Ye, Meng Fang, Jiaxu Zhao, Yun-Hin Chan, Edith C. -H. Ngai, Thiemo Voigt

- 基盤モデル（大型言語モデル、視覚トランスフォーマ、マルチモーダルモデル）が学術界と産業界に大きな影響を与えている
- 小規模モデルと比較して、基盤モデルはプレトレーニングフェーズで大量のデータを必要とする
- 一般的な基盤モデルはインターネットから収集したデータでプレトレーニング可能だが、ドメイン固有の基盤モデルは専有データが必要でプライバシーの問題が発生
- 連合学習は、異なる参加者からのデータの可用性の壁を破り、プライバシーを保護しながら分散データセットを使用した基盤モデルのカスタマイズと適応を可能にする

基盤モデルと連合学習を組み合わせることで、様々なドメインに特化した強力なモデルがプライバシーを守りながら構築できるようになるんだよね。最新技術がどのようにプライバシーとデータ利用のバランスを取るか、これからの発展が楽しみ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-18 17:58


- - -

### [Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation](http://arxiv.org/abs/2406.12815)

**医療画像における不確実性推定を伴うプライバシー保護型連合学習**

Nikolas Koutsoubis, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

- 連合学習（FL）はプライバシー保護の下で機械学習モデルの訓練を可能にする
- 患者データのプライバシー問題が大規模な訓練データセットの構築を妨げている
- 不確実性推定がFLにおいて重要であり、データの異質性が課題となる
- 現行研究の調査とともに、プライバシー向上とノイズの多い医療画像データの課題解決の方向性を提案

医療分野での連合学習の重要性が分かるね！これからの研究がどのようにプライバシーを守りつつ精度を上げていけるのかに注目したい。

**Comment:** 31 pages, 5 figures, 3 tables, Journal preprint

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, eess.IV, stat.ML, **投稿日時:** 2024-06-18 17:35


- - -

### [Federated Learning with a Single Shared Image](http://arxiv.org/abs/2406.12658)

**連合学習における単一の共有画像の利用**

Sunny Soni, Aaqib Saeed, Yuki M. Asano

- 連合学習はプライベートなトレーニングデータ共有を避け、モデルを協同で訓練する技術
- 既存のFedDFは共通の共有データセットを使用するが、これはプライバシーやストレージの問題で困難
- 本研究では、クライアント間とサーバー間で単一の共有画像のみを使用する新たな知識蒸留法を提案
- 新しい適応型データセットプルーニングアルゴリズムにより、単一画像から最も情報価値の高い切り取り範囲を選択

一枚の画像で全体の連合学習がより効果的に行えるなんて革新的だね！異なるクライアントアーキテクチャも対応できるのはすごい未来な感じ。

**Comment:** 8 Pages, 3 Figures, Appendix 4 Pages, CVPRW 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.LG, **投稿日時:** 2024-06-18 14:26


- - -

### [UIFV: Data Reconstruction Attack in Vertical Federated Learning](http://arxiv.org/abs/2406.12588)

**UIFV: 垂直連合学習におけるデータ再構築攻撃**

Jirui Yang, Peng Chen, Zhihui Lu, Qiang Duan, Yubing Bao

- 垂直連合学習（VFL）は、生データを共有せずに協調機械学習を行う手法である
- 既存のデータ再構築方法はモデルや勾配情報に依存し、VFL適用には限界がある
- 本研究では、UIFVという新しい方法を提案し、中間特徴データを用いて元データを再構築する
- 実験では、提案手法が最先端技術よりも高い攻撃精度を示し、VFLのプライバシーの脆弱性を明らかにした

データ共有なしで協力するのに、まだこんな抜け道があるなんてビックリ！UIFVのような新しい方法で、もっとプライバシーを守れる方法が必要だね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, stat.ML, **投稿日時:** 2024-06-18 13:18


- - -

### [Low-Resource Machine Translation through the Lens of Personalized Federated Learning](http://arxiv.org/abs/2406.12564)

**パーソナライズド連合学習による低リソース機械翻訳へのアプローチ**

Viktor Moskvoretskii, Nazarii Tupitsa, Chris Biemann, Samuel Horváth, Eduard Gorbunov, Irina Nikishina

- MeritFedアルゴリズムに基づく新しいアプローチを提案
- 低リソース機械翻訳のタスクに適用し、その有効性を検証
- 訓練に使用する各言語の影響を追跡できるため、MeritFedは非常に解釈可能
- ターゲットデータセットのサイズ、関連性のない言語の影響、および補助最適化パラメータの効果を分析

MeritFedって、低リソース言語の機械翻訳にも使えるんだね！異なる言語の影響を追跡できるって、かなり役立ちそう💡

**Comment:** 18 pages, 7 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.LG, **投稿日時:** 2024-06-18 12:50


- - -

### [Update Selective Parameters: Federated Machine Unlearning Based on Model Explanation](http://arxiv.org/abs/2406.12516)

**更新選択パラメータ: モデル説明に基づく連合機械学習のアンラーニング**

Heng Xu, Tianqing Zhu, Lefeng Zhang, Wanlei Zhou, Philip S. Yu

- 機械アンラーニングが必要な理由は、特定のトレーニングデータの影響をモデルから除去するため
- 現行の中央集権的なアンラーニング手法では連合学習に不向きであり、全データへのアクセスが前提となる
- 新たな手法はモデル説明に基づき、重要なチャネルのみを調整してデータの影響を削減
- 提案手法は計算コストと通信コストを削減しつつ、モデルの性能を維持することを実験で実証

この論文は連合学習の新しいアプローチだね！モデル説明を活用するアイデア、とってもクールじゃない？

**Comment:** Accepted by IEEE Transactions on Big Data

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, cs.LG, **投稿日時:** 2024-06-18 11:43


- - -

### [Federated Learning with Limited Node Labels](http://arxiv.org/abs/2406.12435)

**ラベルの限定されたノードを持つ連合学習**

Bisheng Tang, Xiaojun Chen, Shaopu Wang, Yuexin Xuan, Zhendong Zhao

- 分散グラフ構造データを扱うための手法として、サブグラフ連合学習（SFL）が注目を集めている
- SFLの一部モデルは、サブグラフ間の欠落エッジの重要性を見落とし、ローカルGNNがグローバル表現を他のパーティのGNNに渡せなくなる
- 既存のSFLモデルは多くのラベル付きデータを必要とし、実用性を制限している
- 提案する新たなSFLフレームワークFedMpaは、少量のデータでMLPモデルを訓練し、連合特徴をローカル構造に伝播

新しいSFLフレームワークが実用性を高める方法についての研究なんて面白そうだね！将来的にもっと現実の応用が増えるかもって感じだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-06-18 09:30


- - -

### [Security and Privacy of 6G Federated Learning-enabled Dynamic Spectrum Sharing](http://arxiv.org/abs/2406.12330)

**6G連合学習対応動的スペクトル共有のセキュリティとプライバシー**

Viet Vo, Thusitha Dayaratne, Blake Haydon, Xingliang Yuan, Shangqi Lai, Sharif Abuadbba, Hajime Suzuki, Carsten Rudolph

- 6G無線通信における動的スペクトル共有が重要
- 連合学習によるスペクトルセンシング技術が注目を集める
- 協調トレーニングの整合性とローカルユーザのスペクトル情報のプライバシーが未解決
- 実践的な攻撃ベクトルと防御の指針を提示

連合学習でプライバシーを保ちながら6Gの通信をより効率的にするなんて、未来のネットワークがもっと便利になりそうでワクワクする！新しいテクノロジーでどんな日常が来るのか、楽しみだね。

**Comment:** 7 pages, 5 figures. The paper is submitted to IEEE Networks for   review

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, cs.ET, cs.LG, cs.NI, **投稿日時:** 2024-06-18 06:54


- - -

### [BadSampler: Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning](http://arxiv.org/abs/2406.12222)

**BadSampler: カタストロフィックフォゲッティングの力を利用したビザンチン耐性連合学習の毒殺攻撃**

Yi Liu, Cong Wang, Xingliang Yuan

- ビザンチン耐性の連合学習における毒殺攻撃の研究がほとんど行われていない
- 本論文では、カタストロフィックフォゲッティングを利用した新たな攻撃BadSamplerを提案
- Clean-labelデータのみを使用し、モデルの一般化誤差を最大化するように訓練データを選択
- 提案手法の有効性と性能を二つの実データセットで評価し、効率的な攻撃が可能であることを示した

これ、めっちゃ興味深いね！毒殺攻撃とか、まるでスパイ映画みたいだし、連合学習がもっと強くなるかもってワクワクするね。

**Comment:** In Proceedings of the 30th ACM SIGKDD Conference on Knowledge   Discovery and Data Mining (KDD' 24), August 25-29, 2024, Barcelona, Spain

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, cs.LG, **投稿日時:** 2024-06-18 02:43


- - -

### [SFedCA: Credit Assignment-Based Active Client Selection Strategy for Spiking Federated Learning](http://arxiv.org/abs/2406.12200)

**SFedCA: スパイキング連合学習のための信用配分に基づくアクティブクライアント選択戦略**

Qiugang Zhan, Jinbo Cao, Xiurui Xie, Malu Zhang, Huajin Tang, Guisong Liu

- スパイキング連合学習は、デバイスが局所データを交換せず低消費電力で協力して学習する
- プライバシー保護機能とエネルギー効率を兼ね備え、マルチメディアデータ処理に革命をもたらす可能性
- 既存手法はクライアントの無作為選択に依存し、統計的異質性がグローバルモデルの収束や精度に影響
- SFedCAは閾値に基づきクライアントを選定し、データ分布のバランスを維持。また、通信ラウンド数を減らすことに成功

この技術で低消費電力で効率的に学習できるとか、未来のガジェットがすごくスマートになりそう！早く実用化されるといいね。

**Comment:** 9 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, cs.ET, cs.MM, cs.NE, **投稿日時:** 2024-06-18 01:56


- - -

### [P3GNN: A Privacy-Preserving Provenance Graph-Based Model for APT Detection in Software Defined Networking](http://arxiv.org/abs/2406.12003)

**P3GNN: ソフトウェア定義ネットワーキングにおけるAPT検出のためのプライバシー保護型プロベナンスグラフベースモデル**

Hedyeh Nazari, Abbas Yazdinejad, Ali Dehghantanha, Fattane Zarrinkalam, Gautam Srivastava

- SDNはネットワーク管理に進展をもたらしたが、APTやゼロデイ攻撃の脅威も増加
- 既存の対策は新しい脅威の検出や共同学習中のデータプライバシーの問題に不十分
- P3GNNは連合学習と準同型暗号を組み合わせ、データ機密性と勾配の整合性を強化
- 無監督学習で攻撃を検知し、DARPA TCE3データセットで高い精度と低い誤検知率を実現

連合学習と準同型暗号の組み合わせってすごいね！これなら新しい脅威にも対応できるから安心じゃん？



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-17 18:14


- - -

### [Feasibility of Federated Learning from Client Databases with Different Brain Diseases and MRI Modalities](http://arxiv.org/abs/2406.11636)

**クライアントデータベースから異なる脳疾患とMRIモダリティを用いた連合学習の実現可能性**

Felix Wagner, Wentian Xu, Pramit Saha, Ziyun Liang, Daniel Whitehouse, David Menon, Natalie Voets, J. Alison Noble, Konstantinos Kamnitsas

- 特定の脳疾患用のセグメンテーションモデルは固定されたMRIモダリティセットで訓練される
- 連合学習を用いて異なる脳疾患と多様なMRIモダリティで単一モデルの訓練を試みる
- 全てのクライアントデータベースのモダリティをカバーする入力チャンネルやランダムなモダリティドロップの訓練を導入
- 7つの脳MRIデータベースで評価し、新規データベースでも高いセグメンテーション性能を確認

異なる脳疾患やモダリティの組み合わせでも、連合学習が有効なんて面白そう！将来はもっと多くの病気やデータに対応できるモデルが出てきてほしいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.CV, cs.LG, I.4.9; I.4.6; I.2.11; I.4.0, **投稿日時:** 2024-06-17 15:16


- - -

### [Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs](http://arxiv.org/abs/2406.11569)

**空中連合メタ学習による事前トレーニングと個別調整: 収束と一般化のトレードオフ**

Haifeng Wen, Hong Xing, Osvaldo Simeone

- 大規模言語モデルなどのAIアプリでは、事前トレーニング後のファインチューニングが主流
- 連合学習（FL）が進み、事前トレーニングが中央集権型から分散型に移行中
- メタ学習ベースの個別FLは、基本的なパーソナライズを超え、新しいエージェントやタスクへの一般化を目指す
- 無線設定での一般化と収束のトレードオフを分析、チャンネルの欠陥が一般化を助ける一方で収束を悪化させる

無線通信を利用してAIモデルをパーソナライズするなんて、未来を感じるね。新しい技術がどんな風に役立つか楽しみ！

**Comment:** 37 pages, 7 figures, submitted for possible journal publication

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.IT, eess.SP, math.IT, **投稿日時:** 2024-06-17 14:06


- - -

### [Federated Active Learning Framework for Efficient Annotation Strategy in Skin-lesion Classification](http://arxiv.org/abs/2406.11310)

**皮膚病変分類における効率的なアノテーション戦略のための連合能動学習フレームワーク**

Zhipeng Deng, Yuqiao Yang, Kenji Suzuki

- 連合学習（FL）は複数の機関がプライベートデータを共有せずにモデルを共同で訓練できる
- 医療シナリオではデータのアノテーションに専門知識と労働力が必要であり、FLにおいて重大な問題
- 提案する連合能動学習（FedAL）フレームワークは、FLの下で定期的かつ対話的にALを実行する
- 実データセットで検証し、50%のサンプルで最先端の性能を達成、他のAL手法より優れた結果を示す

連合能動学習がどんな未来を切り開くのか気になる！これで医療データの負担が減れば、多くの人が救われそうだよね。

**Comment:** 14 pages, 3 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.LG, **投稿日時:** 2024-06-17 08:16


- - -

### [Save It All: Enabling Full Parameter Tuning for Federated Large Language Models via Cycle Black Gradient Descent](http://arxiv.org/abs/2406.11187)

**すべてを保存：Cycle Black Gradient Descentによる連合大規模言語モデルの完全なパラメータチューニングの実現**

Lin Wang, Zhichao Wang, Xiaoying Tang

- 大規模言語モデル（LLMs）の登場により、深層学習のパラダイムが革命的に変わった
- 連合学習（FL）では、LLMsの事前学習やファインチューニングが計算資源やメモリ消費、通信ボトルネックに直面する
- 提案手法FedCyBGDは、Cycle Block Gradient Descentを用いて周期的にモデルを更新し、通信や計算、メモリコストを削減する
- FedCyBGDは選択されたブロックの更新とアップロードだけで完全なパラメータ学習を可能にし、FL LLMトレーニングで最先端の性能を実現

この方法を使えば、みんなのパソコンの負担が軽くなるってことかな？本当に実用化されたら影響大きそうでワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-06-17 03:49


- - -

### [Federated Face Forgery Detection Learning with Personalized Representation](http://arxiv.org/abs/2406.11145)

**個別化表現による連合型顔偽造検出学習**

Decheng Liu, Zhan Dang, Chunlei Peng, Nannan Wang, Ruimin Hu, Xinbo Gao

- 深層生成技術は高品質な偽動画を作成でき、深刻な社会的脅威である
- 連合学習戦略により、データのプライバシーを保護しつつモデルパラメータを集約
- クライアントごとの個別化表現学習で、検出性能を向上
- 公開顔偽造検出データセットの実験で、最先端手法と比べて優れた性能を示した

個別化表現で性能向上とか新しい感じでワクワクする！実用化が進んだら、偽動画の脅威も怖くなくなるかもね。楽しみ〜。

**Comment:** The code is publicly available

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-06-17 02:20


- - -

### [Leveraging Foundation Models for Multi-modal Federated Learning with Incomplete Modality](http://arxiv.org/abs/2406.11048)

**基礎モデルを活用した不完全モダリティによるマルチモーダル連合学習**

Liwei Che, Jiaqi Wang, Xinyue Liu, Fenglong Ma

- 連合学習は分散データ環境での共同訓練をプライバシー保証と共に実現
- クライアントが複数のデータモダリティを保有する現実的なシナリオに注目
- モダリティ欠損問題を解決するためFedMVPを提案し、事前訓練モデルを利用
- モデルは現実世界の画像とテキスト分類データセットで優れた性能を示す

異なるモダリティ間でも連合学習を効率的に行えるってすごい！これが実用化されたら、もっと複雑なデータもプライバシーを守りながら分析できるようになるかもね。

**Comment:** Accepted by ECML-PKDD 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-16 19:18


- - -

### [Promoting Data and Model Privacy in Federated Learning through Quantized LoRA](http://arxiv.org/abs/2406.10976)

**量子化されたLoRAによる連合学習におけるデータおよびモデルプライバシーの促進**

JianHao Zhu, Changze Lv, Xiaohua Wang, Muling Wu, Wenhao Liu, Tianlong Li, Zixuan Ling, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang

- 通常の連合学習は異なるエッジデバイス間でデータのプライバシーを保護
- 大規模言語モデル（LLMs）の開発には多くのデータと計算リソースが必要で、それは知的財産である
- 量子化されたモデルパラメータを分配することで、データとモデルの両方のプライバシーを保護
- LoRAを使った量子化戦略により通信コストを大幅に削減し、リソース効率の良い学習を実現

この方法で通信コストを削減しながら、データとモデルのプライバシーも守れるなんてすごいよね！未来の連合学習がもっと使いやすくなりそう、楽しみだな～。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, cs.CR, **投稿日時:** 2024-06-16 15:23


- - -

### [Linkage on Security, Privacy and Fairness in Federated Learning: New Balances and New Perspectives](http://arxiv.org/abs/2406.10884)

**連合学習におけるセキュリティ、プライバシー、公平性の結びつき：新たなバランスと新しい視点**

Linlin Wang, Tianqing Zhu, Wanlei Zhou, Philip S. Yu

- モバイルデバイスや銀行システム、ヘルスケア、IoTシステムで連合学習が急速に普及中
- この研究では、プライバシー漏洩、セキュリティ脅威、公平性の相互関係を詳述
- 公平性とプライバシー、セキュリティと勾配共有のトレードオフを指摘
- 公平性がプライバシーとセキュリティ間の橋渡しとして機能し得る

プライバシーと公平性のバランスなんて難しそうだけど、めっちゃおもしろいね！未来の連合学習モデルがどんどん進化して、安全かつ公平になるといいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-06-16 10:31


- - -

### [Knowledge Distillation in Federated Learning: a Survey on Long Lasting Challenges and New Solutions](http://arxiv.org/abs/2406.10861)

**連合学習における知識蒸留：長年の課題と新たな解決策に関する調査**

Laiqiao Qin, Tianqing Zhu, Wanlei Zhou, Philip S. Yu

- 連合学習はデータをローカライズしたまま複数のクライアントがモデルを訓練する分散型プライバシー保護機械学習である
- 課題にはプライバシーリスク、データ異質性、通信のボトルネック、およびシステムの異質性が含まれる
- 知識蒸留はモデル圧縮および強化アルゴリズムとして2020年以降広く適用されている
- 知識蒸留の連合学習における適用例を包括的に調査し解決策を提示

知識蒸留が連合学習の課題をどう克服できるかを明らかにするなんて面白そう！未来の研究方向も示して、これからの進展が楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-16 09:12


- - -

### [Federated Learning Optimization: A Comparative Study of Data and Model Exchange Strategies in Dynamic Networks](http://arxiv.org/abs/2406.10798)

**連合学習最適化：動的ネットワークにおけるデータとモデル交換戦略の比較研究**

Alka Luqman, Yeow Wei Liang Brandon, Anupam Chattopadhyay

- 大規模な動的連合学習において、データとモデルのどちらを共有するべきかが重要な課題
- デバイス間での生データ、合成データ、（部分）モデル更新の交換を比較
- 基礎モデルの文脈でこれらの交換戦略の影響を詳細に調査
- 時間制限のある知識移転効率が最大で9.08%異なることが判明

効率的なデータとモデル交換ってどれがいいんだろうね？この研究で明らかになった9.08%の違い、実用的にどのくらい役立つのか気になるな～



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-16 03:46


- - -

### [Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models](http://arxiv.org/abs/2406.10630)

**連合指示調整における大規模言語モデルの新たな安全攻撃と防御**

Rui Ye, Jingyi Chai, Xiangrui Liu, Yaodong Yang, Yanfeng Wang, Siheng Chen

- 連合学習（FL）は、複数の当事者がデータを共有せずに協力して大規模言語モデル（LLM）を微調整できる
- この研究では、FedITの安全調整の脆弱性を暴露し、シンプルだが効果的な攻撃手法を提案
- 悪意のあるクライアントは自動生成された攻撃データを使い、FedITシステムの安全性を損なう
- 提案された防御法により、多くの既存のFL防御法が効果的でない中で、攻撃されたLLMの安全性を大幅に向上

安全性の調整がこんなに簡単に損なわれるのって怖いね。でも、新しい防御法がちゃんと対策できるなら、もっと安心して使えそう。楽しみだな。

**Comment:** 18 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.AI, cs.CR, cs.MA, **投稿日時:** 2024-06-15 13:24


- - -

### [Federated Neural Radiance Field for Distributed Intelligence](http://arxiv.org/abs/2406.10474)

**分散インテリジェンスのための連合ニューラルラジアンスフィールド**

Yintian Zhang, Ziyu Shao

- ARやVR応用における新規視点合成（NVS）の重要性
- Neural Radiance Field（NeRF）のNVSタスクでの性能優位性
- データプライバシーを保持しつつ異なるデータ所有者の画像を活用するFedNeRF
- 機能的多様でリソース豊富な連合学習テストベッドの構築とFedNeRFアルゴリズムの実験

FedNeRFってめっちゃおもしろそう！これで、異なる場所にあるデータでも効率的に活用できちゃうんだって。新しいAR/VR体験がさらに進化するかもね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-06-15 02:32


- - -

### [Byzantine-Robust Decentralized Federated Learning](http://arxiv.org/abs/2406.10416)

**ビザンチン耐性分散型連合学習**

Minghong Fang, Zifan Zhang, Hairi, Prashant Khanduri, Jia Liu, Songtao Lu, Yuchen Liu, Neil Gong

- 連合学習（FL）は、複数のクライアントがプライベートな訓練データを公開せずに協力して機械学習モデルを訓練する技術である
- 従来の連合学習は中央サーバーを介して調整されるが、スケーラビリティと信頼依存性の問題がある
- 分散型連合学習（DFL）はサーバーレスかつピアツーピア方式でモデルを共同訓練するが、完全に分散型であるため攻撃に弱い
- 新アルゴリズム「BALANCE」は、クライアントがローカルモデルを基準に受信モデルが悪意かどうかを判断し、防御力と収束保証を提供する

これは革新的だね！完全ピアツーピアでの連合学習、未来のAIインフラに道を開く革新かも！

**Comment:** To appear in ACM Conference on Computer and Communications Security   2024 (CCS '24)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, cs.LG, **投稿日時:** 2024-06-14 21:28


- - -

### [Federated Learning with Flexible Architectures](http://arxiv.org/abs/2406.09877)

**柔軟なアーキテクチャを用いた連合学習**

Jong-Ik Park, Carlee Joe-Wong

- 従来の連合学習はクライアントの計算および通信能力のばらつきに対応できず非効率
- FedFAはクライアントごとに異なる幅と深さのモデルをトレーニング可能にする方法を提案
- レイヤーグラフティング技術を導入し、全クライアントの貢献を統一的にグローバルモデルに統合
- スケーラブルな集約法により重みの差異を管理し、従来の手法より優れた性能およびバックドア攻撃の耐性向上

多様なデバイスに対応するための工夫が面白いね。バックドア攻撃に強いってのも、これからの普及に大事だよね!



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-06-14 09:44


- - -

### [Federated Learning driven Large Language Models for Swarm Intelligence: A Survey](http://arxiv.org/abs/2406.09831)

**連合学習による大規模言語モデルの群知能への応用：調査**

Youyang Qu

- 連合学習（FL）は大規模言語モデル（LLMs）の訓練において、データプライバシーと分散化の課題に対応
- 機械学習の文脈での「忘却の権利」に対応するため、モデルから個々のデータ貢献を安全に削除する「機械アンラーニング」に注目
- 摂動技術、モデル分解、インクリメンタル学習などの効果的なアンラーニング戦略の調査
- 最近の文献からケーススタディや実験結果を基に、実際のシナリオでの方法の有効性と効率性を評価

連合学習でデータプライバシーを守りながらモデルを訓練できるのはすごいよね！これからも倫理と技術の両立にもっと発展しそう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CL, cs.NE, **投稿日時:** 2024-06-14 08:40


- - -

### [Privacy-preserving Quantification of Non-IID Degree in Federated Learning](http://arxiv.org/abs/2406.09682)

**連合学習における非IID度のプライバシー保護定量化**

Yuping Yan, Yizhi Wang, Yingchao Yu, Yaochu Jin

- 連合学習は、生データの共有を避けつつ複数の協力者で機械学習を行う方法だが、非IIDデータセットが課題。
- 非IIDデータが精度低下や効率減少を引き起こし、実装の妨げとなっている。
- 初めて累積分布関数（CDF）を用いた非IID度の定量的定義を提案。
- 完全準同型暗号を用いて非IID度を推定し、CIFAR-100データセットで効果を検証。

新しいアプローチで連合学習がもっと効率化されそう！これでクライアント間のデータの違いも解消しやすくなるね。

**Comment:** 8 pages, 8 figures, FL@FM-IJCAI'24

**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-14 03:08


- - -

### [Heterogeneous Federated Learning with Convolutional and Spiking Neural Networks](http://arxiv.org/abs/2406.09680)

**畳み込みおよびスパイキングニューラルネットワークを用いた異構連合学習**

Yingchao Yu, Yuping Yan, Jisong Cai, Yaochu Jin

- 連合学習（FL）は分散データ上でモデルを訓練しながらデータのプライバシーを守る
- 現在のFLシステムは同種のモデルを前提とするが、実際には異なるAIモデルを使用することが増えてきた
- 異なるモデルを使うことで特定のタスクや要件に適応しやすく、エッジコンピューティングプラットフォームの柔軟性を高める
- CNNとSNNを組み合わせた融合フレームワークが最良の性能を示す

複数のモデルが絡むと競争抑圧が見られるんだって、面白い！これからのエッジコンピューティング技術がどう進化するのか楽しみになるね。

**Comment:** 8 pages, 5 figures, FL@FM-IJCAI'24

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-14 03:05
