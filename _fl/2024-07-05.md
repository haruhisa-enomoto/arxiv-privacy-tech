---
title: 連合学習 (2024-07-05 ~ 2024-07-11)
date: 2024-07-05
---

連合学習に関する論文まとめ (2024-07-05 ~ 2024-07-11)


- - -

### [DFedSat: Communication-Efficient and Robust Decentralized Federated Learning for LEO Satellite Constellations](http://arxiv.org/abs/2407.05850)

**DFedSat: LEO衛星コンステレーションのための通信効率が高く堅牢な分散連合学習**

Minghao Yang, Jingjing Zhang, Shengyun Liu

- DFLは衛星間の直接通信を可能にし、従来の集中型アプローチの問題を解決する
- DFedSatは、それぞれの衛星軌道面内外での適応モデル集約を用いて訓練プロセスを迅速化
- 自己補償メカニズムが組み込まれ、通信失敗に対する耐久性を向上させる
- DFedSatは、従来のDFLベースラインに比べ、収束速度や通信効率で優れることを実証

宇宙を駆け巡るAIって、すごく未来っぽいね！いつか自分たちもそんな研究に関わってみたいな。

**Comment:** 13 pages, 10 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-07-08 12:00


- - -

### [FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging](http://arxiv.org/abs/2407.05800)

**FedMRL: 医用画像のためのデータ不均一性対応型連合マルチエージェント深層強化学習**

Pranab Sahoo, Ashutosh Tripathi, Sriparna Saha, Samrat Mondal

- クライアント間のデータ不均一性が存在し、これが連合学習の実用化の課題
- 公正性を確保するため新しい損失関数を導入し、最終的なグローバルモデルのバイアスを防ぐ
- マルチエージェント強化学習を使用して個別ローカル目的関数の収束をグローバル最適に導く
- サーバ側で自己組織化マップを用いた適応的ウェイト調整方法を統合し、クライアントのデータ分布シフトに対応

医用画像を使った連合強化学習の可能性が広がりそうでワクワクするね！この手法が他の分野でも応用できたらすごいと思う。

**Comment:** Accepted to MICCAI 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, cs.DC, **投稿日時:** 2024-07-08 10:10


- - -

### [Gradient Diffusion: A Perturbation-Resilient Gradient Leakage Attack](http://arxiv.org/abs/2407.05285)

**勾配拡散: 摂動耐性のある勾配漏洩攻撃**

Xuan Liu, Siqi Cai, Qihua Zhou, Song Guo, Ruibin Li, Kaiwei Lin

- 連合学習における勾配漏洩攻撃の脅威に対処するため、勾配保護が重要である
- 差分プライバシーのような摂動ベースのメカニズムが一般的だが、摂動の頑強性は注入されたノイズに依存
- 本研究は摂動逆プロセス中の摂動レベルを捕捉し、摂動回復モデルを構築する
- 提案手法PGLAは既存モデルに比べて最良の勾配復元とデータ回復を実現

連合学習の安全性、もう一度考え直さないと！PGLAが広まったらどんな防御策が取られるのか、未来が楽しみだね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-07-07 07:06


- - -

### [BFLN: A Blockchain-based Federated Learning Model for Non-IID Data](http://arxiv.org/abs/2407.05276)

**BFLN: 非IIDデータのためのブロックチェーンベースの連合学習モデル**

Yang Li, Chunhe Xia, Dongchi Huang, Lin Sun, Tianbo Wang

- 連合学習は、各クライアントに分散しているローカルデータを利用するため、プライバシーとセキュリティが向上する
- 非均衡なデータ分布は、データが独立かつ同一分布（IID）を仮定する従来の連合学習にとって課題である
- 提案モデルBFLNは、ブロックチェーン技術と新しい集約方法およびインセンティブアルゴリズムを組み合わせ、非IIDデータの精度を向上させる
- 公開データセットの実験で、BFLNは最先端モデルと比較してトレーニングの精度を向上させ、個別化された連合学習の持続可能なインセンティブメカニズムを提供する

ブロックチェーン技術を使って連合学習の課題解決なんて、まるでSFの世界みたい！この研究が実用化されたら、色んな分野でセキュリティと効率がさらにUPしそうだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-07-07 06:21


- - -

### [Federated Knowledge Transfer Fine-tuning Large Server Model with Resource-Constrained IoT Clients](http://arxiv.org/abs/2407.05268)

**連合知識転送による大規模サーバーモデルのリソース制約付きIoTクライアントでの微調整**

Shaoyuan Chen, Linlin You, Rui Liu, Shuo Yu, Ahmed M. Abdelmoniem

- 大規模モデルのトレーニングは高品質データの不足に直面している
- IoTでの学習はクライアントのプライベートかつ異種データの調整が困難
- KOALAを提案し、連合学習と知識蒸留を用いて大規模モデルを更新
- 実験結果は、従来の方法と比較してローカルストレージと計算リソースの大幅な削減を証明

分散した小規模データを使いながらも、大規模モデルのトレーニングができるようになるのはすごいね！KOALAがどれだけ効率的か、もっと知りたくなったよ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, **投稿日時:** 2024-07-07 05:46


- - -

### [Synthetic Data Aided Federated Learning Using Foundation Models](http://arxiv.org/abs/2407.05174)

**基盤モデルを利用した合成データ支援連合学習**

Fatima Abacha, Sin G. Teo, Lucas C. Cordeiro, Mustafa A. Mustafa

- 連合学習（FL）は、非独立同分布のデータ分布によりデータの不均一性問題に直面
- DPSDA-FLを提案、データの均一化を支援し、局所モデルのトレーニングを改善
- 差分プライバシーを適用した合成データで局所モデルを強化し、基盤モデルを活用
- CIFAR-10データセットで評価し、グローバルモデルの分類精度と再現率が最大26%および9%向上

連合学習に合成データを使う発展が面白いね！プライバシーを守りながら精度が上がる将来に期待大♪



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-07-06 20:31


- - -

### [Impact of Network Topology on Byzantine Resilience in Decentralized Federated Learning](http://arxiv.org/abs/2407.05141)

**ネットワークトポロジーが分散型連合学習におけるビザンチン耐性に与える影響**

Siddhartha Bhattacharya, Daniel Helo, Joshua Siegel

- 連合学習は、ユーザー間でトレーニングデータを共有せずに機械学習モデルを共同トレーニングする
- 分散型連合学習は、中央集約サーバ不要のピアツーピアでモデルをトレーニングする新しいパラダイム
- ビザンチンノードの影響を考慮し、複雑なネットワークトポロジーでのビザンチン耐性を評価
- 大規模で非完全に接続されたネットワークでは、最新のビザンチン耐性集約戦略は耐性が弱いことが判明

分散型連合学習って、本当にワクワクする未来が待ってる感じだよね! でも、まだ課題も多そうで、これからの研究がとても楽しみ！

**Comment:** 8 pages, 6 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, I.2.11; C.4; C.2.4, **投稿日時:** 2024-07-06 17:47


- - -

### [A Joint Approach to Local Updating and Gradient Compression for Efficient Asynchronous Federated Learning](http://arxiv.org/abs/2407.05125)

**効率的な非同期連合学習のためのローカル更新と勾配圧縮の統合アプローチ**

Jiajun Song, Jiajun Luo, Rongwei Lu, Shuzhao Xie, Bin Chen, Zhi Wang

- 非同期連合学習はデバイスの異質性や低帯域幅環境による古いモデル更新問題に直面
- 従来のアプローチはローカル更新か勾配圧縮のどちらか一方に焦点を当てるが両方は扱わない
- 新アプローチはローカル更新頻度と勾配圧縮率の相互作用が収束速度に与える影響を検討
- 提案するFedLuckフレームワークは通信消費を56%、訓練時間を平均55%削減し、競争力を実証

非同期連合学習の効率化を目指す新しい方法、すごく興味深い！多様な環境でも効果があるのが楽しみだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, **投稿日時:** 2024-07-06 16:19


- - -

### [FedTSA: A Cluster-based Two-Stage Aggregation Method for Model-heterogeneous Federated Learning](http://arxiv.org/abs/2407.05098)

**FedTSA: モデル異種連合学習のためのクラスタベース二段階集約法**

Boyu Fan, Chenrui Wu, Xiang Su, Pan Hui

- システムの異種性がFLの大きな課題であり、既存の手法はこれを十分に考慮していない
- 実際のFLでは各クライアントのハードウェア資源が異なり、それが学習タスクに影響する
- FedTSAはクライアントの能力に基づいたクラスタリングと二段階集約、異種モデルの相互学習を提案
- 実験の結果、FedTSAは既存のベースラインを上回り、様々な要因がモデル性能に影響を与えることを示した

システム異種性の課題に対してこんなにスマートなアプローチが出てくるなんて、私も研究したくなっちゃうかも〜！将来のFLに革命をもたらすかもしれないよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-07-06 14:59


- - -

### [Beyond the Federation: Topology-aware Federated Learning for Generalization to Unseen Clients](http://arxiv.org/abs/2407.04949)

**連合を超えて: 未見クライアントへの一般化のためのトポロジー対応連合学習**

Mengmeng Ma, Tang Li, Xi Peng

- 既存の連合学習はフェデレーション内のデータ異質性に対応するが、未見クライアントには効果が低い
- 大規模分散設定では高コストなため、新手法もスケーリングに課題
- トポロジー対応連合学習(TFL)を提案し、クライアントの関係性をグラフで表現
- クライアントトポロジー学習とトポロジー上の学習モジュールで効率的に強固なモデルを構築

新しいTFL手法がどれだけ効果的に未見クライアントへの一般化を達成するか気になるな！これが実用化されたら、もっと多様なデータを分析できそうでワクワクするね。

**Comment:** ICML 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-07-06 03:57


- - -

### [Smart Sampling: Helping from Friendly Neighbors for Decentralized Federated Learning](http://arxiv.org/abs/2407.04460)

**スマートサンプリング: 分散型連合学習のためのフレンドリーネイバーズからの支援**

Lin Wang, Yang Chen, Yongxin Guo, Xiaoying Tang

- 分散型連合学習は、プライバシーを保ちながら知識を共有し通信コストを削減する
- 分散型FLは中央サーバーを必要とせず、クライアント間の直接通信が可能でリソース節約
- AFIND+アルゴリズムは有益な隣接ノードを識別し、選択するノード数を適応的に調整
- AFIND+は他のサンプリングアルゴリズムより優れた性能を示し、既存の最適化とも互換性あり

分散型の連合学習って、中央サーバーなしで済むからすごく画期的だと思う！友達のネットを通じて良いところを学ぶのってまるで勉強会みたいで、これからもっと普及しそうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-07-05 12:10


- - -

### [A Unified Learn-to-Distort-Data Framework for Privacy-Utility Trade-off in Trustworthy Federated Learning](http://arxiv.org/abs/2407.04751)

**信頼できるフェデレーテッドラーニングにおけるプライバシーと有用性のトレードオフを実現する統一的なデータ歪曲学習フレームワーク**

Xiaojin Zhang, Mingcong Xu, Wei Chen

- フェデレーテッドラーニングにおけるプライバシーと有用性の均衡を理論的に紹介
- プライバシー保護メカニズムの歪曲を学習変数としてモデル化し、モデルパラメータと共同最適化
- データ歪曲に基づくプライバシー保護メカニズムの適用可能性を実証
- 関連領域（対抗訓練、入力の堅牢性、学習不能な事例）との繋がりを強調

プライバシーを守りつつどうやって有用性を保つかのバランスが大事なんだね！実際の応用が期待できそうでワクワクする～。未来の技術に一歩近づけそうで面白そうだなぁ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-07-05 08:15
