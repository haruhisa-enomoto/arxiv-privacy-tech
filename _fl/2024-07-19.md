---
title: 連合学習 (2024-07-19 ~ 2024-07-25)
date: 2024-07-19
---

連合学習に関する論文まとめ (2024-07-19 ~ 2024-07-25)


- - -

### [SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment](http://arxiv.org/abs/2407.18387)

**同質環境における自己調整クラスタ連合学習 (SCALE)**

Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Zahidur Talukder, Syed Bahauddin

- 連合学習には通信の非効率性や中央インフラへの依存が課題である
- 新手法はエッジサーバーへの依存を排除しデータの類似性などに基づいて動的にクラスタを形成
- ハイブリッド分散集約プロトコルで局所モデル訓練とピアツーピアの重み交換を行い通信オーバーヘッドを削減
- 乳癌データセットで検証しながら、訓練遅延やエネルギー消費を減少させつつ通信オーバーヘッドを10分の1に削減

この研究は、効率面とプライバシー面で大きく進化しそうだね！将来的に連合学習の標準になりそうな予感がする！

**Comment:** This research article got accepted in COMPSAC conference and going to   be published to IEEE

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.AI, cs.ET, cs.LG, cs.PF, **投稿日時:** 2024-07-25 20:42


- - -

### [FADAS: Towards Federated Adaptive Asynchronous Optimization](http://arxiv.org/abs/2407.18365)

**FADAS：連合適応非同期最適化に向けて**

Yujia Wang, Shiqiang Wang, Songtao Lu, Jinghui Chen

- 連合学習は、プライバシーを保護した機械学習のための広く採用されているトレーニング手法
- 従来の同期集約設計は、大規模モデルの適応的連合最適化の実装における課題
- FADASという非同期更新を取り入れた新しい適応的連合最適化手法を提案
- 提案手法の収束速度を理論的に確立し、他の非同期連合学習ベースラインよりも優れた性能を実証

非同期更新の導入や遅延調整が、実際の使用にどんな効果をもたらすのか楽しみだな。その最先端な技術、ぜひ使ってみたいね！

**Comment:** Accepted by ICML 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, math.OC, **投稿日時:** 2024-07-25 20:02


- - -

### [Generative AI like ChatGPT in Blockchain Federated Learning: use cases, opportunities and future](http://arxiv.org/abs/2407.18358)

**ブロックチェーン連合学習におけるChatGPTのような生成的AI：ユースケース、機会、未来**

Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Jannatul Ferdaus, Mahedi Hasan, Sameera Pisupati, Shanmukh Mathukumilli

- 連合学習はデータを共有せずに分散データで機械学習モデルをトレーニングするアプローチ
- 生成的AIの組み込みにより、プライバシー保護やデータ拡充、モデルのカスタマイズが可能
- 生成的AIは生成的敵対ネットワーク（GAN）や変分オートエンコーダ（VAE）を用い、合成データを生成
- 合成データはデータ不足問題に対処し、頑健なモデル開発を助ける

連合学習と生成的AIの組み合わせ、すごく革新的だね！これでプライバシーを守りつつ、もっと個別化されたモデルが作れそうでわくわくする！

**Comment:** We are going to submit this research article into a conference which   is best fit for this topic

**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-07-25 19:43


- - -

### [Sparse Incremental Aggregation in Multi-Hop Federated Learning](http://arxiv.org/abs/2407.18200)

**マルチホップ連合学習におけるスパースインクリメンタルアグリゲーション**

Sourav Mukherjee, Nasrin Razmi, Armin Dekorsy, Petar Popovski, Bho Matthiesen

- 連合学習をマルチホップ通信環境で調査し、特に衛星間リンクでの適用を検討
- 各中間ホップでのインクリメンタルアグリゲーションにより通信効率を大幅に向上
- 勾配スパース化の下でインクリメンタルアグリゲーションの効果が減少する問題を解明
- 新たな関連スパース化手法を提案し、通信効率が15倍、最先端のスパースIAと比較して11倍改善

勾配スパース化の問題点を解決しつつ効率を上げるなんて、すごいじゃん！連合学習がさらに実用的になりそうね。

**Comment:** This paper is accepted for the 25th IEEE International Workshop on   Signal Processing Advances in Wireless Communications (SPAWC) conference

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, eess.SP, **投稿日時:** 2024-07-25 17:09


- - -

### [Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review](http://arxiv.org/abs/2407.18096)

**IoT向けの連合学習におけるプライバシー脅威と対策: 系統的レビュー**

Adel ElZemity, Budi Arief

- IoT環境での連合学習は、分散データを活用するが、プライバシーとセキュリティの懸念を引き起こす
- 系統的文献レビューを通じ、49本の論文を分析しIoTでのプライバシー脅威と対策を評価
- 推論攻撃やポイズニング攻撃、盗聴などの脅威を特定し、差分プライバシーや秘密計算などの防御策を検討
- 軽量な防御策やブロックチェーンなどの新技術を活用し、IoTの変動ネットワーク条件下でFLのプライバシーを向上させる必要がある

IoTと連合学習とか、面白そう！新しい技術でどうやって脅威に対応するか、もっと知りたいなぁ。未来の研究に繋がる話ばかりでわくわくするね！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-07-25 15:01


- - -

### [Lightweight Industrial Cohorted Federated Learning for Heterogeneous Assets](http://arxiv.org/abs/2407.17999)

**異種資産向け軽量産業用コホート連合学習**

Madapu Amarlingam, Abhishek Wani, Adarsh NL

- 連合学習(FL)は、データを共有せずにクライアント間で学習を交換することにより、分散機械学習(ML)モデルを訓練するための最も広く採用されている協調学習手法である
- しかし、FLはデータの類似性や均質性が前提となっており、産業用環境には特化されていない
- 提案する軽量産業用コホートFL(LICFL)アルゴリズムは、モデルパラメータを使用してコホーティングを行い、データの異質性に起因する欠点を軽減する
- 数値実験を通じて、提案アルゴリズムの有効性を実証し、既存の手法と比較した結果、性能向上が確認された

産業用データが対象だから、現場での実用性が高そう！FLの質を保ちながらもデータの異質性を考慮したアプローチ、これから増えそうな感じするよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, eess.SP, **投稿日時:** 2024-07-25 12:48


- - -

### [HF-Fed: Hierarchical based customized Federated Learning Framework for X-Ray Imaging](http://arxiv.org/abs/2407.17780)

**HF-Fed: X線画像のための階層的なカスタマイズされた連合学習フレームワーク**

Tajamul Ashraf, Tisha Madame

- X線技術は非侵襲的検査で重要だが、放射線リスクが課題
- 従来の深層学習法はデータ集中化が必要で、プライバシー問題がある
- HF-Fedは問題を局所データ適応と全体的なX線画像に分解して解決
- 実験結果はデータ共有なしで競争力のある性能を示し、医療分野の連合学習に寄与

連合学習を活用することで、各病院のデータを共有せずに高品質なX線画像を実現するアプローチは未来的！将来的にさらに多様な医療画像に応用できるかもね。



**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.CV, **投稿日時:** 2024-07-25 05:21


- - -

### [DualFed: Enjoying both Generalization and Personalization in Federated Learning via Hierachical Representations](http://arxiv.org/abs/2407.17754)

**DualFed：階層的表現を利用した連合学習での一般化と個人化の両立**

Guogang Zhu, Xuefeng Liu, Jianwei Niu, Shaojie Tang, Xinghao Wu, Jiayuan Zhang

- 個人化連合学習（PFL）では、モデルの一般化と効果的な個人化を同時に達成することが困難
- 階層的アーキテクチャを持つ深層モデルを利用し、複数の層からの表現を組み合わせるアプローチを提案
- DualFedはデュアル表現を直接生成する新手法で、一般化と個人化を簡易化し最適化
- 多くの実験でDualFedが他のFL手法よりも優れていることを示した

一般化と個人化の両方をうまく実現するってすごく難しそうだけど、この方法ならできちゃうんだね。使い方次第で色んなアプリケーションに役立ちそうだって思ったよ。

**Comment:** Accepted by ACM MutltiMedia 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-07-25 04:09


- - -

### [Spiking Neural Networks in Vertical Federated Learning: Performance Trade-offs](http://arxiv.org/abs/2407.17672)

**スパイキングニューラルネットワークを用いた垂直連合学習の性能トレードオフ**

Maryam Abbasihafshejani, Anindya Maiti, Murtuza Jadliwala

- 垂直連合学習は、異なる特徴を持つクライアント間でデータを共有しないモデル訓練方法
- SNNはANNに比べてエネルギー効率が高く、端末での高速かつ高精度な処理が可能
- SNNモデルの適用性を評価するため、モデル分割ありとなしの2つの連合学習アーキテクチャを実装
- CIFARデータセットを用いて評価し、SNNの精度はANNと同等でありながらエネルギー効率が高いことを示した

SNNがこれからの連合学習でもっと使われるかもね。効率良くなるなら、もっと多くのデバイスでも使えるようになるよ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-07-24 23:31


- - -

### [A Hybrid Federated Kernel Regularized Least Squares Algorithm](http://arxiv.org/abs/2407.17228)

**ハイブリッド連合カーネル正則化最小二乗アルゴリズム**

Celeste Damiani, Yulia Rodina, Sergio Decherchi

- 連合学習はプライバシー保護の重要な場面で有用な戦略
- 臨床データに加え、オミクス特徴も含まれるため、データは病院とオミクスセンターに分散
- サンプルと特徴が分散したハイブリッド環境で効率的なカーネル正則化最小二乗アルゴリズムを提案
- データセットで検証し、攻撃対策のセキュリティ措置も議論

データがいろんな場所に散らばってても効率的に学習できるってすごい！これからの医療で大活躍しそうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** stat.ML, cs.LG, **投稿日時:** 2024-07-24 12:32


- - -

### [SFPrompt: Communication-Efficient Split Federated Fine-Tuning for Large Pre-Trained Models over Resource-Limited Devices](http://arxiv.org/abs/2407.17533)

**SFPrompt：リソース制限デバイス上で大規模事前学習モデルの通信効率の良い連合分割微調整**

Linxiao Cao, Yifei Zhu, Wei Gong

- 従来の微調整方法は、プライバシー懸念でデータにアクセスできない場合に不可能
- SFPromptは分割学習と連合学習を組み合わせ、リソース制限デバイスでの計算負荷を軽減
- 新しいデータセット剪定アルゴリズムとローカル損失更新戦略で通信コストを削減
- SFPromptは連合学習の完全な微調整に比べ、計算リソースを0.46%使用し、通信コストを53%削減

この研究、未来感満載で楽しい感じがする！特にリソース制限のあるデバイスでも使えるように工夫されてるのってすごく実用的だね～！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-07-24 04:22


- - -

### [Federated Automatic Latent Variable Selection in Multi-output Gaussian Processes](http://arxiv.org/abs/2407.16935)

**連合学習による多出力ガウス過程における自動潜在変数選択**

Jingyi Gao, Seokhyun Chung

- 連合学習を用いて多出力ガウス過程の潜在プロセス数を自動選択
- 中央サーバへのデータ集中によるプライバシーリスクと計算負荷を回避
- スパイク・スラブ事前分布で必要な潜在プロセスのみを自動選択
- リチウムイオン電池劣化や気温データのシミュレーションで有効性を確認

最初に読んだとき、連合学習でプライバシーを守りつつ効率よく推論する部分が気になったよ！応用範囲も広そうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** stat.ML, cs.LG, **投稿日時:** 2024-07-24 02:03


- - -

### [Inference Load-Aware Orchestration for Hierarchical Federated Learning](http://arxiv.org/abs/2407.16836)

**推論負荷に対応した階層型連合学習のオーケストレーション**

Anna Lackinger, Pantelis A. Frangoudis, Ivan Čilić, Alireza Furutanpey, Ilir Murturi, Ivana Podnar Žarko, Schahram Dustdar

- 階層型連合学習(HFL)は通信コスト削減とサーバ負荷分散のため、中間集約ノードを導入
- モデルレプリカがクライアント端末、中間ノード、グローバルサーバに分散配置される
- トレーニングと推論のプロセスが結合し、共同オーケストレーションが必要になる
- 提案手法により推論遅延が大幅に低減し、通信コストもフラットな連合学習に比べて劇的に削減

HFLのオーケストレーションが上手くいくと、推論の速度がすごく向上するみたい！移動体や交通関係での継続学習に使えたら、未来の交通システムがもっと賢くなりそうでワクワクするね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-07-23 21:01


- - -

### [Theoretical Analysis of Privacy Leakage in Trustworthy Federated Learning: A Perspective from Linear Algebra and Optimization Theory](http://arxiv.org/abs/2407.16735)

**信頼できる連合学習におけるプライバシー漏洩の理論的分析: 線形代数と最適化理論の視点から**

Xiaojin Zhang, Wei Chen

- 連合学習はプライバシーを守りながらの共同モデル訓練が可能だが、データ再構成攻撃などの脅威に対して脆弱
- 線形代数の視点では、バッチデータのヤコビ行列がフルランクでない場合、同じモデル更新を生成する複数のデータバッチが存在し、ある程度のプライバシーが保証されることを証明
- 特定バッチサイズによりデータ再構成攻撃を防ぐための十分条件を導出
- 最適化理論の視点から、バッチサイズや歪みの程度などに基づくプライバシー漏洩の上限を設定し、連合学習の様々な要素とプライバシー漏洩の関係についての洞察を提供

連合学習がこれからもっと普及したら、こんな風にプライバシーが守られる仕組みって本当に重要になるよね。研究が進んでいく中で、より安全な学習方法が増えるのはすごく楽しみ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, cs.LG, stat.ML, **投稿日時:** 2024-07-23 16:23


- - -

### [COALA: A Practical and Vision-Centric Federated Learning Platform](http://arxiv.org/abs/2407.16560)

**COALA: 実用的でビジョン中心の連合学習プラットフォーム**

Weiming Zhuang, Jian Xu, Chen Chen, Jingtao Li, Lingjuan Lyu

- COALAは、15のコンピュータビジョンタスクで連合学習をサポートし、複数タスクを同時に扱う
- 監視された連合学習に加え、半監視および未監視の連合学習もベンチマークする
- 静的データに加え、現実世界での連続的に変化するデータに対応した連合学習にも対応
- 分割モデルや異なるクライアント間での異なるモデルを用いた連合学習をベンチマーク

これから連合学習の新しい可能性を見つけることができそう！データの種類によっても色々試せるみたいだから、めっちゃ面白そうじゃない？

**Comment:** ICML'24

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.DC, **投稿日時:** 2024-07-23 15:14


- - -

### [On ADMM in Heterogeneous Federated Learning: Personalization, Robustness, and Fairness](http://arxiv.org/abs/2407.16397)

**異質連合学習におけるADMMの活用: パーソナライズ、ロバスト性、公平性**

Shengkun Zhu, Jinshan Zeng, Sheng Wang, Yuan Sun, Xiaodong Li, Yuan Yao, Zhiyong Peng

- 統計的な異質性は連合学習における精度、公平性、ロバスト性に緊張を生む主要な原因
- パーソナライズ連合学習(PFL)は、個人のモデルを開発し、統計的な異質性の影響を軽減
- 既存のPFLフレームワークはパーソナライズモデルの性能向上に焦点を当て、グローバルモデルを軽視
- 提案するFLAMEフレームワークは、ADMMを活用してパーソナライズとグローバルモデルの両方をトレーニング

FLAMEのフレームワークは、新しいモデル選択戦略を通じて、多様なデータを持つクライアントに対応するのが面白そうだよね。お互いに良い成績が出せるようサポートし合えるかも！

**Comment:** arXiv admin note: text overlap with arXiv:2311.06756

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-07-23 11:35


- - -

### [Federated Learning for Face Recognition via Intra-subject Self-supervised Learning](http://arxiv.org/abs/2407.16289)

**顔認識のための連合学習：被写体内自己教師あり学習によるアプローチ**

Hansol Kim, Hoyeol Choi, Youngjun Kwak

- 顔認識の連合学習（FL）は、個々のクライアントのモデルを集約し、一般化された顔認識モデルを構築
- 既存の研究では自己教師あり学習の不足と複数被写体の対応が課題
- 提案するFedFSは、被写体を固定せずに個別化された顔認識モデルを訓練する新しいFLアーキテクチャ
- FedFSは、適応的なラベル構築と被写体内自己教師あり学習を活用し、精度と安定性を向上

FedFSって新しい連合学習のアーキテクチャなんだって！自己教師あり学習を活用するアイデアがすごく興味深いね。実験結果も良好らしいし、もっと詳しく知りたいな。

**Comment:** Accepted at the The 35th British Machine Vision Conference 2024 (BMVC   2024), Glasgow, UK. Youngjun Kwak is corresponding author

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.AI, cs.LG, **投稿日時:** 2024-07-23 08:43


- - -

### [Tackling Feature-Classifier Mismatch in Federated Learning via Prompt-Driven Feature Transformation](http://arxiv.org/abs/2407.16139)

**連合学習における特徴-分類器の不一致問題をプロンプト駆動の特徴変換で解決**

Xinghao Wu, Jianwei Niu, Xuefeng Liu, Mingjia Shi, Guogang Zhu, Shaojie Tang

- 連合学習（FedAvg）はデータの異質性によりグローバルモデルの性能が低下
- FedAvgの特徴抽出器が多くのPFL（パーソナライズド連合学習）手法より優れている
- ローカル特徴を線形変換し分類器に合わせるとFedAvgはほとんどのPFL手法を凌駕
- 提案手法FedPFTはプロンプト駆動の特徴変換モジュールで特徴と分類器の不一致を解決

FedPFTがどの程度成果を出せるか非常に興味深い！連合学習の新しいアプローチが、特にパーソナライズにどれだけ役立つか見てみたいな。

**Comment:** 23 pages, 9 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-07-23 02:52


- - -

### [A Life-long Learning Intrusion Detection System for 6G-Enabled IoV](http://arxiv.org/abs/2407.15700)

**6G対応IoVのための生涯学習型侵入検知システム**

Abdelaziz Amara korba, Souad Sebaa, Malik Mabrouki, Yacine Ghamri-Doudane, Karima Benatchba

- 6G技術は超高速データレートとシームレスなネットワークカバレッジを持つが、IoVに新たなサイバー脅威をもたらす
- 既存システムでは急速に進化する脅威に動的に適応し学ぶ能力が不足している
- クラスインクリメンタル学習と連合学習を組み合わせた新しい侵入検知システムを提案している
- 包括的な実験結果では、新たなサイバー攻撃パターンの学習で高い適応力、精度、低い誤検知率を示した

この論文、6GのIoVの未来が見える感じがしてすごくエキサイティング！連合学習とクラスインクリメンタル学習の組み合わせがすごいんじゃない？



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-07-22 15:07


- - -

### [A New Theoretical Perspective on Data Heterogeneity in Federated Optimization](http://arxiv.org/abs/2407.15567)

**連合最適化におけるデータ不均一性に関する新しい理論的視点**

Jiayi Wang, Shiqiang Wang, Rong-Rong Chen, Mingyue Ji

- データ不均一性が連合学習の収束率に悪影響を与える
- 提案された新しい仮定は、従来の仮定よりも弱く、実用化が期待できる
- 提案手法で収束上限が大幅に削減されることを示した
- 実験で理論的発見が実証され、具体的な改善が確認された

新しい視点からデータ不均一性にアプローチし、実際のパフォーマンス向上につなげる研究って面白そう！もっと効率的な連合学習が可能になるかもね。

**Comment:** ICML 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, cs.IT, math.IT, math.OC, **投稿日時:** 2024-07-22 11:52


- - -

### [The Diversity Bonus: Learning from Dissimilar Distributed Clients in Personalized Federated Learning](http://arxiv.org/abs/2407.15464)

**多様性ボーナス：個別連合学習における異なる分散クライアントから学ぶ**

Xinghao Wu, Xuefeng Liu, Jianwei Niu, Guogang Zhu, Shaojie Tang, Xiaotian Li, Jiannong Cao

- 個別連合学習（PFL）はクライアントが個別モデルを共同学習するためのフレームワーク
- これまでの研究は、類似データのクライアント間での利益を前提とした手法を開発
- DiversiFedは異なるデータ分布のクライアントからも利益を得るための新手法を提案
- 実験結果は、DiversiFedが類似データのクライアントを超えて学習効果を向上させることを示した

多様なクライアントと協力することで予想外の学びがあるなんて面白いね！これから連合学習がより広がっていきそうだね〜

**Comment:** 14 pages, 9 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-07-22 08:24


- - -

### [Resource-Efficient Federated Multimodal Learning via Layer-wise and Progressive Training](http://arxiv.org/abs/2407.15426)

**層ごとの段階的訓練による資源効率的な連合マルチモーダル学習**

Ye Lin Tun, Chu Myaet Thwal, Minh N. H. Nguyen, Choong Seon Hong

- マルチモーダル学習はデータ形式の違いを統合し、複雑なタスクに対応するために重要である
- 従来の連合学習は、マルチモーダルデータに対応するためにリソースが多く必要となる
- LW-FedMMLは層ごとの分割訓練を提案し、メモリと計算リソース、通信コストを大幅に削減
- Prog-FedMMLはリソース効率は劣るが、性能向上の可能性があり、資源制約の少ないシナリオで有用

計算リソースが少ない中でも、大規模なのにちゃんとプライバシーも守れるなんてスゴい！実際のアプリケーションにどう導入されていくのか、未来が楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-07-22 07:06


- - -

### [Tackling Selfish Clients in Federated Learning](http://arxiv.org/abs/2407.15402)

**連合学習における利己的なクライアントへの対処方法**

Andrea Augello, Ashish Gupta, Giuseppe Lo Re, Sajal K. Das

- 連合学習は、参加者が自分のデータを公開せずに共同でモデルを訓練する分散型機械学習パラダイム
- 利己的なクライアントが意図的にトレーニングプロセスを改ざんし、グローバルモデルを自分のローカルモデルに偏らせる問題を提起
- 提案する新しいロバストな集約戦略（RFL-Self）は、受信した更新情報から真の更新を推定し、自己中心性の影響を緩和
- MNISTとCIFAR-10データセットでの実験結果により、2%の利己的なクライアントが精度を最大36%減少させるが、RFL-Selfはその効果を緩和することができる

利己的なクライアントまで考慮する技術とかすごく未来っぽい！この辺詳細に勉強したら、自分の研究にも役立つかもね。

**Comment:** 10 pages, 16 figures. European Conference on Artificial Intelligence   (ECAI) 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-07-22 06:08


- - -

### [Poisoning with A Pill: Circumventing Detection in Federated Learning](http://arxiv.org/abs/2407.15389)

**ピルを用いた毒物混入：連合学習における検出回避**

Hanxi Guo, Hao Wang, Tao Song, Tianhang Zheng, Yang Hua, Haibing Guan, Xiangyu Zhang

- 連合学習はデータプライバシー保護に強みがあるが分散的で反復的な性質から攻撃に脆い
- 既存の防御策はモデル更新パラメータを均一に操作する攻撃を検出するがより精巧な攻撃には弱い
- 提案するアプローチは既存の攻撃を強化し、検出を回避する「ピル」構造で毒を混入
- 実験結果では、提案手法が全ての一般的な防御策を回避し、エラーレートが最大7倍上昇

連合学習を改善するための新しい防御策を考えないといけないってことでドキドキするね。精巧な攻撃にどう対抗するか、もっと研究が進むと面白そう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-07-22 05:34


- - -

### [A Learning-Based Attack Framework to Break SOTA Poisoning Defenses in Federated Learning](http://arxiv.org/abs/2407.15267)

**連合学習における最先端のデータ汚染防御を破る学習ベースの攻撃フレームワーク**

Yuxin Yang, Qiang Li, Chenfei Nie, Yuan Hong, Meng Pang, Binghui Wang

- 連合学習はデータプライバシーを保護するが、データ汚染攻撃に脆弱である
- 多くの防御策は堅牢なアグリゲーターで対策してきたが、全て破られている
- 新しい堅牢なアグリゲーターも設計されるが、特定の攻撃手法により依然脆弱である
- 最適化ベースの攻撃フレームワークを提案し、有効性を複数のデータセットで検証

次々と新しい防御策が登場しても、また新たな攻撃がそれを破ってくるなんて、本当にイタチごっこだよね。でも、それが技術の進歩を促すんだと思うとワクワクするね！

**Comment:** This is an extended version of our CIKM 2024 paper

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-07-21 21:02


- - -

### [PUFFLE: Balancing Privacy, Utility, and Fairness in Federated Learning](http://arxiv.org/abs/2407.15224)

**PUFFLE: 連合学習におけるプライバシー、ユーティリティ、および公平性のバランス**

Luca Corbucci, Mikko A Heikkila, David Solans Noguero, Anna Monreale, Nicolas Kourtellis

- 公平性、プライバシー、ユーティリティの同時達成は困難であり、しばしば十分に探求されていない
- 多くの取り組みは三要素のうち二つに注力し、残り一つを無視している
- PUFFLEは、連合学習におけるこれら三要素のバランスを探索するための高次パラメータ化アプローチを提案
- データセット、モデル、データ分布の多様性に対応しつつモデル不公平性を最大75%削減し、プライバシーを維持しながら最悪の場合でもユーティリティは最大17%減少に留める

公平性とプライバシーって大事だもんね！みんなが安心して使える技術にするため、PUFFLEのアプローチには期待しちゃう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, cs.CY, **投稿日時:** 2024-07-21 17:22


- - -

### [Privacy-Preserving Multi-Center Differential Protein Abundance Analysis with FedProt](http://arxiv.org/abs/2407.15220)

**プライバシー保護型多施設差分タンパク質量解析のためのFedProt**

Yuliya Burankova, Miriam Abele, Mohammad Bakhtiari, Christine von Törne, Teresa Barth, Lisa Schweizer, Pieter Giesbertz, Johannes R. Schmidt, Stefan Kalkhof, Janina Müller-Deile, Peter A van Veelen, Yassene Mohammed, Elke Hammer, Lis Arend, Klaudia Adamowicz, Tanja Laske, Anne Hartebrodt, Tobias Frisch, Chen Meng, Julian Matschinske, Julian Späth, Richard Röttger, Veit Schwämmle, Stefanie M. Hauck, Stefan Lichtenthaler, Axel Imhof, Matthias Mann, Christina Ludwig, Bernhard Kuster, Jan Baumbach, Olga Zolotareva

- 質量分析によるタンパク質の定量解析がプロテオミクスを革新
- 複数施設からのデータ共有で統計的有意性が向上するが、プライバシーの問題が発生
- FedProtは、連合学習と加法秘密分散を利用して分散データの差分タンパク質量解析をプライバシー保護の下で実現
- FedProtの結果は、既存の手法と同等の精度を達成し、最も正確なメタ解析手法より優れていることが確認された

これはかなりの革新ね！複数の施設が協力できると、もっとデータが有効活用できそうだね！🌸

**Comment:** 52 pages, 16 figures, 12 tables. Last two authors listed are joint   last authors

**トピック:** [連合学習](../../fl), **カテゴリ:** q-bio.QM, cs.LG, **投稿日時:** 2024-07-21 17:09


- - -

### [Addressing Data Heterogeneity in Federated Learning of Cox Proportional Hazards Models](http://arxiv.org/abs/2407.14960)

**連合学習におけるCox比例ハザードモデルのデータ異質性の解決**

Navid Seidi, Satyaki Roy, Sajal K. Das, Ardhendu Tripathy

- 病院間や医療専門家間の疾患プロファイルと治療法の多様性が、患者中心のパーソナライズ戦略の必要性を強調
- 疾患進行の類似性を活かして生存分析の予測モデルを向上させるため、連合学習の枠組みが有効
- Cox比例ハザードモデルにおいてデータの異質性を緩和し、モデル性能を向上させるアプローチを提案
- 特徴ベースのクラスタリングとイベントベースの報告戦略を用いて、モデル精度や適応力を向上させる

連合学習を使って病院のデータをまとめて活用するなんてすごいかも！これで患者さんの予測ももっと正確になるといいね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, stat.AP, stat.ML, **投稿日時:** 2024-07-20 18:34


- - -

### [Decentralized Federated Anomaly Detection in Smart Grids: A P2P Gossip Approach](http://arxiv.org/abs/2407.15879)

**スマートグリッドにおける分散型連合異常検出：P2Pゴシップアプローチ**

Muhammad Akbar Husnoo, Adnan Anwar, Md Enamul Haque, A. N. Mahmood

- スマートグリッドのセキュリティとプライバシー懸念が強まり、強固な侵入検出システムの需要が増加
- 連合学習がデータ共有なしで攻撃検出モデルの協調訓練を実現。しかし、集中型アグリゲータに依存しプライバシー漏洩のリスクも
- ランダムウォークとエピデミックゴシッププロトコルを用いた新しい分散型連合異常検出スキームを提案
- 実験結果でランダムウォークが高性能を示し、通信遅延や遅延ノードの影響を軽減しつつ、従来の連合学習よりも35%トレーニング時間を短縮

これはすごく興味深い論文ね！ランダムウォークプロトコルがエピデミックよりも効率的に機能するなんて、高校のネットワーク授業でもちょっと触れてみたいかも。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, cs.DC, cs.LG, **投稿日時:** 2024-07-20 10:45


- - -

### [FedPartWhole: Federated domain generalization via consistent part-whole hierarchies](http://arxiv.org/abs/2407.14792)

**FedPartWhole: 一貫したパート・ホール階層による連合ドメイン一般化**

Ahmed Radwan, Mohamed S. Shehata

- 連合ドメイン一般化は未見のドメインへの一般化とデータプライバシー制約の両立の課題に取り組む
- 提案するアーキテクチャは、背骨モデル構造から問題にアプローチし、パートとホールの階層構造を強調
- 画像解析ツリーの特徴表現を明確に取り入れ、モデル一般化に成功した初の研究
- 比較可能なサイズのCNNより12%以上の性能向上を実現し、インタープリタブルである点が信頼性を高める

独自のバックボーンアプローチで、CNNを超える性能向上だって！とても使いやすそうな技術だから、将来の技術標準になるかもね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-07-20 07:43


- - -

### [Universal Medical Imaging Model for Domain Generalization with Data Privacy](http://arxiv.org/abs/2407.14719)

**データプライバシーを考慮したドメイン一般化のための普遍的な医療画像モデル**

Ahmed Radwan, Islam Osman, Mohamed S. Shehata

- 医療画像分野におけるドメイン一般化は、公開されているラベル付きデータセットの制約により難しい
- フェデレーテッドラーニングを用い、ローカルデータセットへの直接アクセスを排除しつつ、複数のローカルモデルから知識をグローバルモデルに移行
- グローバルモデルは多様な医療画像タスクを実行可能であり、トレーニングに使用されたプライベートデータセットの機密性も保持
- 8つの異なる医療画像アプリケーションに対して広範な実験を行い、幾つか異なるドメインからのデータ分布の中でマスクされた画像モデリング技術に基づく最新のベースラインを上回る改善を実証

データプライバシーを守りながら、いろんな医療分野で使えるモデルを作るなんて面白そう！今後の医療の進化に大いに役立ちそうだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.CV, **投稿日時:** 2024-07-20 01:24


- - -

### [Universally Harmonizing Differential Privacy Mechanisms for Federated Learning: Boosting Accuracy and Convergence](http://arxiv.org/abs/2407.14710)

**連合学習のための普遍的調和差分プライバシー手法: 精度と収束の向上**

Shuya Feng, Meisam Mohammady, Hanbin Hong, Shenao Yan, Ashish Kundu, Binghui Wang, Yuan Hong

- 差分プライバシーを用いた連合学習は、プライバシーを保証しつつモデルを共同で訓練する技術である
- 提案されたUDP-FLは、ガウスモーメント会計手法と任意のランダム化メカニズムを調和させる初の手法
- Rénysi差分プライバシーの概念を介してプライバシー予算を調和させ、モデルの精度と収束を向上
- UDP-FLは最新の手法と比較して、プライバシー保証とモデル性能の両面で優れたパフォーマンスを示す

これって連合学習の未来を変えちゃうかも！？他の手法より優れてるってところが特に気になるよね！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-07-20 00:11


- - -

### [Personalized Multi-tier Federated Learning](http://arxiv.org/abs/2407.14251)

**個別化されたマルチティア連合学習**

Sourasekhar Banerjee, Ali Dadras, Alp Yurtsever, Monowar Bhuyan

- 個別化された連合学習の課題は、低コスト通信でデータの統計的異質性を捉え、デバイスごとにカスタマイズされた性能を得ること
- デバイス間で既知のチーム構造がある場合、最適化された個別のローカルモデルを得るために、マルチティアアーキテクチャの個別連合学習(PerMFL)を導入
- PerMFLは、理論的保証を提供し、滑らかな強凸問題で線形収束率を、滑らかな非凸問題で準線形収束率を示す
- 管理された数値実験でPerMFLの強力な経験的性能を実証し、複数の個別連合学習タスクで最先端技術を上回る成果を上げた

新しいアルゴリズムが最先端より優れているんだって！個々のチームに合わせた学習方法ってどんな感じなんだろう？未来感がすごくてワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, math.OC, **投稿日時:** 2024-07-19 12:31


- - -

### [Where is the Testbed for my Federated Learning Research?](http://arxiv.org/abs/2407.14154)

**連合学習研究のための実験環境はどこにあるのか？**

Janez Božič, Amândio R. Faustino, Boris Radovič, Marco Canini, Veljko Pejović

- 中央集権型AIから分散型AIへの進展が重要だが、連合学習（FL）の評価が不十分
- 現実のFL実験は多様なクライアントデバイスとデータセットによる評価で難航
- CoLExTを提案し、カスタムFLアルゴリズムの実験を効率化、多種多様なエッジデバイスで使用可能
- FLアルゴリズムの移植は最小限の開発者関与で可能、計測ツールがリソースの使用オーバーヘッドを抑える

CoLExTってすごい便利そう！いろんなデバイスで試せるから、もっと現実的な感じで使えそうだよね。この研究でどんな新しい発見があるのか楽しみ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-07-19 09:34
