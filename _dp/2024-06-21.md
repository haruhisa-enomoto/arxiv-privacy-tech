---
title: 差分プライバシー (2024-06-21 ~ 2024-06-27)
date: 2024-06-21
---

差分プライバシーに関する論文まとめ (2024-06-21 ~ 2024-06-27)


- - -

### [Enhancing Federated Learning with Adaptive Differential Privacy and Priority-Based Aggregation](http://arxiv.org/abs/2406.18491)

**適応差分プライバシーと優先順位ベースの集約による連合学習の強化**

Mahtab Talaei, Iman Izadi

- 連合学習はローカルデータセットなしでグローバルモデルを開発
- モデル更新の取得が情報漏洩の可能性を含む、モデルインバージョン攻撃のリスク
- 差分プライバシーによりパラメータにノイズを追加しプライバシーを保護
- デバイス間の異質性を考慮し、時間的に変動する影響因子で収束性を向上

デバイスごとのリソース差を考慮したカスタマイズされたプライバシー保護、革新的ね！未来のFLはますます強力になりそう。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-06-26 16:55


- - -

### [Beyond Statistical Estimation: Differentially Private Individual Computation in the Shuffle Model](http://arxiv.org/abs/2406.18145)

**統計推定を超えて：シャッフルモデルにおける差分プライバシーのための個別計算**

Shaowei Wang, Changyu Dong, Di Wang, Xiangfu Song

- シャッフルモデルは非信頼当事者間での非集中型計算で威力発揮し、匿名化とメッセージの順序入れ替えによりプライバシーと有用性を向上
- 従来の手法で計算困難または有用性損失が大きい空間クラウドソーシング、組み合わせ最適化、位置ベースのソーシャルシステム、インセンティブ付き連合学習において、シャッフルプライバシー増幅の実現可能性を探る
- メッセージ認証や結果アクセス制御などの重要なセキュリティ機能を提供しつつ、プライバシー強化効果を維持する新たなシャッフルモデルを提案
- 実験結果: 非プライベート設定に対しエラー最大90％削減、100％-300％有用性向上し、適切なプライバシー予算で実用的

シャッフルモデルって、すごく面白そう！特に連合学習でこれだけ効果が出るなら、未来の技術革新に大いに貢献しそうだよね！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-06-26 07:53


- - -

### [Protecting the 'Stop Using My Data' Right through Blockchain-assisted Evidence Generation](http://arxiv.org/abs/2406.17694)

**ブロックチェーンを利用した「データ使用停止権」の保護**

Fan Zhang, Peng Liu

- 個人データの利用停止要求は基本的な権利であるが、既存の対策（例：暗号化データ消去、差分プライバシー）では対応が不十分
- データ取得後の権利侵害を防ぐための証拠生成フレームワークを初めて開発
- 「データ使用停止権」の問題を定式化し、ブロックチェーンを用いた証拠生成システムを設計・実装
- 証拠生成プロトコルの有効性を検証し、99%以上の成功率を達成

ブロックチェーンで証拠を作るなんてすごい技術！これが普及すれば、もっとプライバシーが守られる世の中になるかも♡



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-25 16:32


- - -

### [Robust Gray Codes Approaching the Optimal Rate](http://arxiv.org/abs/2406.17689)

**最適レートに迫るロバストなグレイコード**

Roni Con, Dorsa Fathollahi, Ryan Gabrys, Mary Wootters, Eitan Yaakobi

- ロバストなグレイコードは、ノイズが含まれても元の整数に近い値を復元できる
- この研究では、レート$1 - H_2(p) - \varepsilon$の近最適な構造を提案
- 提案されたコードは効率的にエンコード可能であり、高いノイズ耐性を持つ
- 効率的なデコードアルゴリズムにより推定誤差が小さいことが証明された

ロバストなグレイコードはプライバシー技術としても重要だね！ノイズに強いのってすごく未来を感じるよ。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.IT, cs.DS, math.IT, **投稿日時:** 2024-06-25 16:28


- - -

### [Capacity-Achieving Gray Codes](http://arxiv.org/abs/2406.17669)

**容量達成グレイコード**

Venkatesan Guruswami, Hsin-Po Wang

- 差分プライバシーのために整数をラプラスノイズかBSCノイズで曖昧にする方法を紹介
- BSCノイズを利用して整数をバイナリ文字列に変換する方法が柔軟である
- 提案された実装は、BSCの容量を正の誤り指数で達成する
- 古い実装に比べ、提案された「コーディドグレイコード」が誤り訂正機能を追加

誤り訂正機能付きグレイコードの実装って、すごく未来感あるよね！これからのプライバシー技術がもっと強くなりそうってワクワクする～。

**Comment:** 10 pages, 3 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.IT, cs.DS, math.IT, **投稿日時:** 2024-06-25 15:58


- - -

### [Privacy Preserving Reinforcement Learning for Population Processes](http://arxiv.org/abs/2406.17649)

**人口過程におけるプライバシー保護強化学習**

Samuel Yang-Zhao, Kee Siong Ng

- 動的に相互作用する大規模な人口を対象とするRLアルゴリズムにおけるプライバシー保護の問題を考察
- ベイズ的セマンティクスを通じて、相関データを含む人口過程に対する差分プライバシーの分析を実施
- 任意のRLアルゴリズムを差分プライバシー対応とするメタアルゴリズムを提案、各時点での状態および報酬信号をプライバタイズ
- 理論的に、プライベート化した状態に対する価値関数近似誤差が、人口サイズおよびプライバシー予算の増加に伴い迅速に減少することを証明

人口過程におけるプライバシー保護の問題って、実生活に応用できる可能性が豊富でワクワクするね。この技術が進歩すると、安全にデータを使用してより良い社会が期待できそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-06-25 15:41


- - -

### [Towards Efficient and Scalable Training of Differentially Private Deep Learning](http://arxiv.org/abs/2406.17298)

**差分プライバシー深層学習の効率的かつスケーラブルな訓練に向けて**

Sebastian Rodriguez Beltran, Marlon Tobaben, Niki Loppi, Antti Honkela

- 差分プライバシー確保のための確率的勾配降下法（DP-SGD）の利便性低下が従来から問題視されている
- 実用面でのもう一つの大きな問題として、DP-SGDの計算コストの高さがある
- 本研究ではDP下で深層学習モデルを訓練する際の計算コストを定量的に評価し、低減方法を評価
- 効率的なDP-SGD実装や低精度での訓練、最大80GPUを用いたスケーリング挙動を研究

DP深層学習って、よりプライベートにするためのコストがすごく高いんだね！でも、もっと効率的な方法を探るってワクワクするし、80GPUまでスケールできると想像するとすごい😳💡

**Comment:** 15 pages, 12 figures, Accepted to the Workshop on Advancing Neural   Network Training at International Conference on Machine Learning (WANT@ICML   2024)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-06-25 06:04


- - -

### [Lomas: A Platform for Confidential Analysis of Private Data](http://arxiv.org/abs/2406.17087)

**Lomas: プライベートデータの機密解析のためのプラットフォーム**

Damien Aymon, Dan-Thuy Lam, Lancelot Marti, Pauline Maury-Laribière, Christine Choirat, Raphaël de Fondeville

- 公共サービスが収集する大量のデータが未活用である状況を解決するために、Lomasを提案
- データに直接アクセスせずに承認された研究者や政府アナリストがプライベートデータセット上でアルゴリズムを実行可能
- 差分プライバシーで結果を保護し、識別可能な情報抽出を無効化
- プライバシーを維持しながら公共サービスのデータから価値ある洞察を得られるようにする

データの保護と有効活用、両方を同時に達成するなんてすごいね！この技術、公衆衛生の改善にも役立ちそうで、未来が楽しみだよね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-24 19:16


- - -

### [On Computing Pairwise Statistics with Local Differential Privacy](http://arxiv.org/abs/2406.16305)

**局所差分プライバシーを用いたペア統計の計算について**

Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Adam Sealfon

- ペア統計の計算問題研究、局所モデルでの差分プライバシー利用
- 重要なメトリクス（ケンドールのτ係数、AUC、ジニ係数など）を計算
- 差分プライバシーアルゴリズムの技術を活用し、斬新で汎用的なアルゴリズムを提案
- 線形クエリのDPアルゴリズム技術を利用してペア統計を計算

ペア統計を局所差分プライバシーで計算する方法がすごく気になった！この技術が広まれば更にプライバシー守りつつデータ解析できそうだよね。

**Comment:** Published in NeurIPS 2023

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, cs.CR, **投稿日時:** 2024-06-24 04:06


- - -

### [Privacy Preserving Machine Learning for Electronic Health Records using Federated Learning and Differential Privacy](http://arxiv.org/abs/2406.15962)

**連合学習と差分プライバシーを用いた電子カルテのプライバシー保護機械学習**

Naif A. Ganadily, Han J. Xia

- 電子カルテは診断、治療、費用などの個人情報を含む
- 機械学習は患者データを分析し、ケアの改善に役立つ
- 社会保障番号や住所などの機密情報が含まれているため、プライバシー保護技術が必要
- 連合学習と差分プライバシーを用いて、これらの機械学習モデルのプライバシーを保護することが重要

プライバシー保護しながら医療データを活用できるってすごいよね。未来の医療がもっと効率的になる予感。

**Comment:** 5 pages, 12 figures

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.ET, **投稿日時:** 2024-06-23 00:01


- - -

### [Credit Attribution and Stable Compression](http://arxiv.org/abs/2406.15916)

**クレジットの付与と安定した圧縮**

Roi Livni, Shay Moran, Kobbi Nissim, Chirag Pabbaraju

- クレジットの付与はさまざまな分野で重要で、生成モデルにも必要
- 差分プライバシーの緩和版を提案、特定のデータポイントに対する安定性保証を弱める
- 新しいフレームワークは既存の安定性概念を拡張、PAC学習の枠内でその表現力を検討
- アルゴリズムの学習可能性を包括的に特徴付け、今後の研究方向を提案

クレジットの付与を学習アルゴリズムで真剣に考えるなんて、面白い発想だよね。今後の応用が楽しみだな！

**Comment:** 15 pages, 1 figure

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ML, **投稿日時:** 2024-06-22 18:40


- - -

### [Privacy Implications of Explainable AI in Data-Driven Systems](http://arxiv.org/abs/2406.15789)

**データ駆動システムにおける説明可能なAIのプライバシーへの影響**

Fatima Ezzeddine

- 機械学習モデルは強力だが、透明性の欠如が信頼を損なう
- 説明可能なAI（XAI）技術が内部決定プロセスを説明するフレームワークを提供
- データには敏感な情報が含まれ、差分プライバシーなどの技術が重要
- XAIとプライバシー保護技術は対立し、プライバシー侵害攻撃のリスクがある

データの透明性とプライバシーのバランスをどうとるかが超重要！未来のAIシステムがどう進化するか楽しみ～。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-06-22 08:51


- - -

### [The Privacy-Utility Trade-off in the Topics API](http://arxiv.org/abs/2406.15309)

**Topics APIにおけるプライバシーと有用性のトレードオフ**

Mário S. Alvim, Natasha Fernandes, Annabelle McIver, Gabriel H. Nunes

- サードパーティのクッキーの廃止がプライバシー配慮型広告手法の提案を促進
- GoogleのTopics APIが粗い粒度の広告トピックを提供することでプライバシーを保護
- 再識別リスクと広告会社への有用性を理論的に評価
- 理論モデルを実証データで検証し、未知の副次情報を持つ攻撃者に対する上限を提示

Googleの新技術、面白そう！みんなが安心してネットを使える未来が見えてきたね🎶

**Comment:** CCS '24 (to appear)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-21 17:01
