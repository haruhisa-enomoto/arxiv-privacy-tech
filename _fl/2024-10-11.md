---
title: 連合学習 (2024-10-11 ~ 2024-10-17)
date: 2024-10-11
---

連合学習に関する論文まとめ (2024-10-11 ~ 2024-10-17)


- - -

### [Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks](http://arxiv.org/abs/2410.12772)

**分散型無線ネットワークにおけるモジュレーション分類のための連合学習のワクチン化**

Hunmin Lee, Hongju Seong, Wonbin Kim, Hyeokchan Kwon, Daehee Seo

- 自動モジュレーション分類は、効率的で信頼性のある通信サービスに重要
- 既存のFLモデルは非IID環境で最適な学習収束を妨げる課題に直面
- FedVaccineはノイズ耐性を強化し過学習を軽減する新たなFLモデル
- インテグレーション困難を克服し、性能改善と信頼性の向上を実証

なるほど、連合学習にノイズを意図的に加えるなんて面白いね！今後、ノイズが多い現場でも安心して使える技術が増えそうって思った！ 😊📡



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.AI, **投稿日時:** 2024-10-16 17:48


- - -

### [Federated Learning and Free-riding in a Competitive Market](http://arxiv.org/abs/2410.12723)

**競争市場における連合学習とフリーライディング**

Jiajun Meng, Jing Chen, Dongfang Zhao, Lin Liu

- 連合学習はプライバシーを守りつつ、競争市場で技術向上を目指す協力技術
- フリーライディング行動が企業の情報提供意欲を阻害し、連合学習の形成を困難にする可能性
- 情報量が少ない企業は常にフリーライディングが有利で、競争が過激でない場合にのみ連合学習を形成
- 連合学習が形成されると全関係者が利益を得る「全員が勝つ」状況が存在

フリーライダーの問題って、協力しようとする企業にとって大きな壁だよね。でも、この論文では「All-Win」な状況もあるってことが示されてとってもワクワク！未来の市場の在り方に超期待だね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.GT, econ.TH, **投稿日時:** 2024-10-16 16:31


- - -

### [Disentangling data distribution for Federated Learning](http://arxiv.org/abs/2410.12530)

**連合学習のためのデータ分布の解きほぐし**

Xinyuan Zhao, Hanlin Gu, Lixin Fan, Qiang Yang, Yuxing Han

- 連合学習は、データプライバシーを損なわずに分散クライアントのプライベートデータを用いてグローバルモデルを共同訓練する技術
- クライアント間のデータ分布の絡まりが広範な適用の妨げとなっている
- データ分布を解きほぐすことで、1回のコミュニケーションラウンドで分散システムと同等の効率が実現可能と示す
- FedDistrアルゴリズムを提案し、データ分布を安定して分離・復元し、従来の方法を上回るモデル効率を実証

新しい連合学習のアプローチが効率を劇的に改善しちゃうなんて！これって分散型AIの時代がもっと早く来る予感がする。すごくエキサイティングでワクワクしちゃうね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, **投稿日時:** 2024-10-16 13:10


- - -

### [TPFL: A Trustworthy Personalized Federated Learning Framework via Subjective Logic](http://arxiv.org/abs/2410.12316)

**信頼できる個人化連合学習フレームワーク: 主観論理を用いたアプローチ**

Jinqian Chen, Jihua Zhu

- 連合学習はデータのプライバシーを守りつつ共同でモデルを訓練する技術
- TPFLフレームワークは主観論理を用いて信頼性を向上させる
- データの不均一性を軽減して、安全で信頼性のある学習を実現
- 悪意ある攻撃やドメインシフトに対する耐性を持ち、高ステークな状況でも信頼性を示す

連合学習って便利だけど、データの信頼性も大事なんだね。TPFLフレームワークで信頼性が上がるなら、もっと安心して使える未来が来るかも！安全と信頼性の確保は重要だし、これからもどんな展開があるか楽しみだね。

**Comment:** 17 Pages with Appendix

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, 68T05, **投稿日時:** 2024-10-16 07:33


- - -

### [Age-of-Gradient Updates for Federated Learning over Random Access Channels](http://arxiv.org/abs/2410.11986)

**ランダムアクセスチャネル上の連合学習のための勾配更新年齢**

Yu Heng Wu, Houman Asgari, Stefano Rini, Andrea Munari

- ランダムアクセスチャネルで深層ニューラルネットワークの訓練を連合学習で行う問題を研究
- 勾配更新の新しいポリシー「勾配の鮮度」が提案され、informationの年齢に類似した解釈
- トップ-Kスパーシフィケーションとメモリー蓄積を用いた勾配圧縮と誤差修正戦略を設計
- 数値シミュレーションで、新ポリシー「Age-of-Gradient」が他のポリシーに比べて優れた性能

このアプローチ、勾配の「鮮度」っていうアイデア、面白そう！やっぱり通信とか連合学習って難しいけど、みんなが使いやすくなるといいなって思うよね。どんなふうに実際に役立つのか、ちょっと気になる！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-10-15 18:49


- - -

### [Federated Learning framework for LoRaWAN-enabled IIoT communication: A case study](http://arxiv.org/abs/2410.11612)

**LoRaWAN対応IIoT通信のための連合学習フレームワーク:ケーススタディ**

Oscar Torres Sanchez, Guilherme Borges, Duarte Raposo, André Rodrigues, Fernando Boavida, Jorge Sá Silva

- IIoTシステムでの異常検知は運用効率の改善に重要だが、リソース制約が課題
- 連合学習により、プライバシーを守りつつ分散モデルトレーニングが可能
- LoRaWANを用いたIIoTプロトタイプで異常検知を実施し、成果を中央集権モデルと比較
- 機械ごとのデータ分布が異なる中でも連合学習モデルは高精度を達成し、将来の実装ガイドラインを提示

連合学習で、プライバシーを守りつつ高精度な異常検知ができるなんてすごい！これが広まれば、産業現場でもっとスマートな予防保全ができるようになりそうだよね。IIoTとLoRaWANの組み合わせも最新技術って感じでワクワクする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, cs.NI, **投稿日時:** 2024-10-15 13:48


- - -

### [Why Go Full? Elevating Federated Learning Through Partial Network Updates](http://arxiv.org/abs/2410.11559)

**完全更新をやめる理由：部分的なネットワーク更新による連合学習の向上**

Haolin Wang, Xuefeng Liu, Jianwei Niu, Wenkai Guo, Shaojie Tang

- 連合学習は分散機械学習のパラダイムで、ユーザーデータのプライバシーを保護する手法
- 従来の連合学習では、全てのモデルパラメータを更新・平均化するが、層間協力がうまくいかずモデル収束が遅くなる
- 層の不一致問題を解決するため、FedPartという手法を導入、一部の層のみを更新する
- FedPartは、収束速度や精度で完全更新より優れ、通信・計算負荷も削減する

部分的な層更新のアイデアって画期的かも！これでモデルの収束が速くなるなら、色々な分野に活用できそうだね。通学途中にこの話しようよ！

**Comment:** 27 pages, 8 figures, Accepted to NeurIPS 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-15 12:49


- - -

### [Data Quality Control in Federated Instruction-tuning of Large Language Models](http://arxiv.org/abs/2410.11540)

**大規模言語モデルの連合学習におけるデータ品質管理**

Yaxin Du, Rui Ye, Fengting Yuchi, Wanru Zhao, Jingjing Qu, Yanfeng Wang, Siheng Chen

- 連合学習はプライバシーを保護しつつデータ量を拡大するが、データの質に関する問題は未解決である
- 提案されたFedDQCフレームワークはデータ品質を測定しフィルタリングや階層型学習を促進する
- 各クライアントの指示-応答整合性を用いてノイズのあるデータを効率的に識別するための指標を導入
- 提案手法は中央集権型のベースラインと比較して、混合品質のデータでのモデル性能を向上させる

データの質ってすんごく大事なんだね！これでより良いAIが作れるなんて未来が楽しみだよね。やっぱり常に学び続ける姿勢が大事なんだなって改めて思ったよ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-15 12:14


- - -

### [FOOGD: Federated Collaboration for Both Out-of-distribution Generalization and Detection](http://arxiv.org/abs/2410.11397)

**FOOGD: 外部分布の一般化と検出のための連合協調**

Xinting Liao, Weiming Liu, Pengyang Zhou, Fengyuan Yu, Jiahe Xu, Jun Wang, Wenjie Wang, Chaochao Chen, Xiaolin Zheng

- 連合学習はクライアントモデルと協力してグローバルな知識を捉えるが、分布外データに対する信頼性に課題がある
- FOOGDはクライアントごとの確率密度を推定し、信頼性の高いグローバル分布を導き出す手法を提案
- SM3Dが前提条件なしでスコアモデルを推定し、意味シフトデータを検出する
- 経験的評価で、三つの大きな利点が確認され、分散分布の推定や意味シフトデータ検出等で優れている

この技術、未来の連合学習の新しい可能性を感じる！FOOGDがどんな風に応用されていくのか、すごく楽しみだなー。みんなでアイデアをシェアしながら進化していきそう！

**Comment:** NeurIPS 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-15 08:39


- - -

### [WPFed: Web-based Personalized Federation for Decentralized Systems](http://arxiv.org/abs/2410.11378)

**WPFed: 分散システム向けのウェブベース個別連合**

Guanhua Ye, Jifeng He, Weiqing Wang, Zhe Xue, Feifei Kou, Yawen Li

- 分散型学習はプライバシーと信頼が重要な環境で協調モデル訓練に不可欠
- WPFedは、最適な隣接選択が可能な完全分散型のウェブベース学習枠組み
- Locality-Sensitive Hashingを用いてデータプライバシーを保ちながら最適な隣接を決定
- ブロックチェーンによる透明性と検証性を組み込み、システムの安全性を向上

WPFedって、なんだか未来の世界を覗いてるみたいでワクワクしちゃうよね！でも、みんなが安全にネットで協力できるってすごいことだと思うな。これを使ってどんな新しいアプリが生まれるんだろう？



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-10-15 08:17


- - -

### [Secure Stateful Aggregation: A Practical Protocol with Applications in Differentially-Private Federated Learning](http://arxiv.org/abs/2410.11368)

**セキュア状態集計: 差分プライバシー連合学習における実用的なプロトコル**

Marshall Ball, James Bell-Clark, Adria Gascon, Peter Kairouz, Sewoong Oh, Zhiye Xie

- 相関ノイズを使った連合学習(DP-FTRL)は独立ノイズ(DP-SGD)よりも精度が高いが、信頼できる中央サーバーが必要。
- 信頼できない単一サーバー環境でもDP-FTRLを実現するために、シンプルなデータ構造"セキュア状態集計"を提案。
- Ring Learning with Errorsを仮定して、このプロトコルを高次元データ環境でスケーラブルに実現。
- 提案手法でプライバシーを維持しつつ、既存の技術よりも高いDPFLの性能を実現することが可能。

セキュア状態集計のアイデア、なんか最先端って感じで面白そうだね！応用も多そうだから、これからのプライバシー技術の進化に期待しちゃうね。学校のプロジェクトで取り上げたら注目されそうかも！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-15 07:45


- - -

### [Backdoor Attack on Vertical Federated Graph Neural Network Learning](http://arxiv.org/abs/2410.11290)

**垂直連合グラフニューラルネットワーク学習におけるバックドア攻撃**

Jirui Yang, Peng Chen, Zhihui Lu, Ruijun Deng, Qiang Duan, Jianping Zeng

- 連合学習とグラフニューラルネットワークを組み合わせた技術で、隔離されたグラフデータを使う。
- 垂直連合型ではデータ特徴とラベルを参加者間で分散し、同じサンプル空間を持つ。
- データ・ラベルにアクセスできない環境下で、有効なバックドア攻撃方法BVGを初提案。
- 実験でBVGの高い攻撃成功率と、メインタスク精度への影響が最小限であることを示した。

バックドア攻撃って怖いけど、BVGみたいな革新的な方法でそういう脆弱性を突くってスリリング！防御方法もどんどん進化して、より強固なプライバシー技術が生まれるといいね。未来の技術進化が楽しみ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-15 05:26


- - -

### [FedCCRL: Federated Domain Generalization with Cross-Client Representation Learning](http://arxiv.org/abs/2410.11267)

**FedCCRL: クロスクライアント表現学習による連合ドメイン一般化**

Xinpeng Wang, Xiaoying Tang

- ドメイン一般化は未見のドメインにも適用できるモデルを訓練することを目指すが、連合学習ではクライアントがデータを直接共有できないので適用が難しい
- FedCCRLはプライバシーを守りつつ、未見のドメインへの一般化能力を向上させるための新たな方法を提案
- 負担少なく、ドメイン固有特徴を伝えるためのMixStyleと、ドメイン非依存特徴を変動させるAugMixを適用
- 表現の整合性を確保するために、監督付きコントラスト損失とJensen-Shannon発散を利用

この新提案の「FedCCRL」って、連合学習にも対応できるからすごく面白そうだよね。どんなドメインにもビシッと対応できて、しかもプライバシーも守られちゃうって最高かも！未来のデータ解析がもっとスムーズになりそうでワクワクするね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-15 04:44


- - -

### [Adversarially Guided Stateful Defense Against Backdoor Attacks in Federated Deep Learning](http://arxiv.org/abs/2410.11205)

**連合深層学習におけるバックドア攻撃に対する敵対的ガイド付きステートフル防御**

Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay Jha

- 連合学習はバックドア攻撃に脆弱で、現状の防御策は不自然な仮定に依存している
- 敵対的バイアスと過信を利用し、新しい防御手法AGSDを提案
- AGSDは信頼指数を指標として、各クライアントの信頼度を適応的に管理する
- 現実的な連合学習環境で、AGSDは最小限の精度低下で効果的に防御可能

敵対的ガイドを使った防御手法って、まるでスパイ映画のようだね！不自然な仮定なしでの効果的な防御が可能になるなんて、ますます連合学習が安全になりそう！ちょっと探偵の気分で、自分も試してみたくなっちゃうかも？😄

**Comment:** 16 pages, Accepted at ACSAC 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.CV, **投稿日時:** 2024-10-15 02:45


- - -

### [Federated Data-Efficient Instruction Tuning for Large Language Models](http://arxiv.org/abs/2410.10926)

**大規模言語モデルのための連合データ効率指令チューニング**

Zhen Qin, Zhaomin Wu, Bingsheng He, Shuiguang Deng

- 指令チューニングは、多様な指令データにより大規模言語モデル（LLM）の応答性を向上
- 連合学習はクライアント側データを活用し、指令データの供給源を拡大している
- 従来の方法は全データを使用し過剰な計算負荷と過学習のリスクがあった
- 提案手法FedHDSは代表的なデータサブセットを使用しデータ効率を向上

連合学習でのデータ効率化って、めちゃイケてない？このFedHDSなら大量のデータ持ってなくても、うまくモデルをチューニングできちゃうってすごいよね。これからはもっと賢いAIが増えてくるのかな、楽しみ！

**Comment:** 11 pages. Ongoing work

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CL, **投稿日時:** 2024-10-14 15:05


- - -

### [Mobility-Aware Federated Learning: Multi-Armed Bandit Based Selection in Vehicular Network](http://arxiv.org/abs/2410.10451)

**モビリティ対応連合学習：車両ネットワークにおけるマルチアームドバンディットに基づく選択**

Haoyu Tu, Lin Chen, Zuguang Li, Xiaopei Chen, Wen Wu

- 車両ネットワークで連合学習を行うための車両選択問題を研究
- 車両の移動に対応した連合学習スキームを設計し、訓練の失敗を回避
- リアルタイムでの成功訓練参加率を利用し、車両選択を実施
- マルチアームドバンディットアルゴリズムで訓練損失と遅延を最小化し、28\%速く収束

車両が動いている中でも効率的に連合学習ができるってすごいね！未来の車載ネットワークがもっと賢くなりそうでワクワクする。

**Comment:** Accepted by 2024 IEEE Globecom Workshops (GC Wkshps)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-14 12:45


- - -

### [A few-shot Label Unlearning in Vertical Federated Learning](http://arxiv.org/abs/2410.10922)

**垂直連合学習における数ショットラベル学習解除**

Hanlin Gu, Hong Xi Tae, Chee Seng Chan, Lixin Fan

- 垂直連合学習でのラベル学習解除の課題に注目し、ラベル漏洩リスクを軽減する方法を提案
- データの不足を補うために多様体ミックスアップを用い、埋め込みを増強しラベル情報を削除
- 埋め込み増強と勾配上昇を組み合わせ、数秒でラベル情報の解除が可能に
- 多様なデータセットで効果とスケーラビリティを検証し、プライバシー・効率を両立

垂直連合学習でのラベル学習解除なんて本当に興味深いね！速やかにラベル情報を削除できるなら、プライバシーと効率が同時に守られちゃうし、新しい扉を開けちゃうかもね！

**Comment:** We introduce the first method for label unlearning in vertical   federated learning (VFL), focused on preventing label leakage by the active   party

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.CV, **投稿日時:** 2024-10-14 12:08


- - -

### [ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization](http://arxiv.org/abs/2410.10238)

**ForgeryGPT: 説明可能な画像偽造検出と定位のための多モーダル大規模言語モデル**

Jiawei Li, Fanrui Zhang, Jiaying Zhu, Esther Sun, Qiang Zhang, Zheng-Jun Zha

- 視覚的推論と説明生成に強みを持つGPT4oなどの多モーダル大規模言語モデルには、画像偽造検出と定位における課題がある
- ForgeryGPTは高次の法医学的知識を多様な言語特徴空間から取得し、説明生成と対話を可能にする新しい大規模言語モデル
- Mask-Aware Forgery Extractorを統合し、偽造箇所の正確なマスク情報を抽出し、細かい偽造の詳細をピクセル単位で理解する
- 三段階のトレーニング戦略とデータセットにより、視覚と言語のモダリティを調整し、偽造検出と指示に従う能力を向上

Forged imagesを検出して説明するためのこの新しいアプローチ、ちょっとワクワクしちゃうね。技術が進化すると、どんな偽造も見抜ける日が来るかも！

**Comment:** 16 pages, 14 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.AI, **投稿日時:** 2024-10-14 07:56


- - -

### [Fed-piLot: Optimizing LoRA Assignment for Efficient Federated Foundation Model Fine-Tuning](http://arxiv.org/abs/2410.10200)

**Fed-piLot: 効率的な連合学習のためのLoRA割り当て最適化**

Zikai Zhang, Jiahao Xu, Ping Liu, Rui Hu

- 基盤モデルの微調整でデータプライバシーを保つため、連合学習が標準枠組みとして登場
- LoRAモジュールを使用した連合FMsは、効率的かつプライバシーを確保
- Fed-piLotは、異なるメモリ容量を持つクライアント向けにLoRA割り当て最適化を提案
- 異種性の影響を緩和するためにSpatial-Temporalモデル集約を導入

連合学習の中でも効率とプライバシーを同時に追求してるのってすごいね！LoRA割り当ての最適化とは、意外と奥が深そうで面白そうだなって思ったよ。これからの展開が楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-10-14 06:36


- - -

### [Mixture of Experts Made Personalized: Federated Prompt Learning for Vision-Language Models](http://arxiv.org/abs/2410.10114)

**個別化されたエキスパートの混合: ビジョン・言語モデルのための連合プロンプト学習**

Jun Luo, Chen Chen, Shandong Wu

- ビジョン・言語モデル(VLMs)向けプロンプト学習が多様なタスクで有用性を示している
- 現在の連合プロンプト学習はグローバルモデルのダウンロードに制限がある
- 個別化されたプロンプト学習のため、pFedMoAPを提案し、ローカルおよび非ローカルな専門家を活用
- pFedMoAPは従来の方法を超える結果を示し、CLIP向け連合学習で有効性を確認

ビジョンと言語を結びつける技術って、なんか未来っぽくてワクワクするよね！特に個別化されたエキスパートでお互いに学び合うところが魅力的。これからもっと応用されていったら、身近なものにも使われるかもね。

**Comment:** 16 pages, 4 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, cs.CV, **投稿日時:** 2024-10-14 03:05


- - -

### [Improving accuracy and convergence of federated learning edge computing methods for generalized DER forecasting applications in power grid](http://arxiv.org/abs/2410.10018)

**一般化されたDER予測アプリケーション向け電力網における連合学習エッジコンピューティング手法の精度と収束の改善**

Vineet Jagadeesan Nair, Lucas Pereira

- 連合学習(FL)の手法を改良し、非IIDデータでも性能向上を図る
- 再生可能エネルギーや蓄電といった分散エネルギー資源(DER)の予測に注力
- 標準化されたFLモデルを多様なDERに応用できるように工夫
- 業界知識を導入し、通信コストを削減しつつ収束速度を向上

電力網と連合学習ってかけ離れてるみたいだけど、一緒にやると新しい予測の方法が見つかるんだね！エコにもつながりそうでワクワクしちゃう！

**Comment:** Presented at the NeurIPS 2022 Tackling Climate Change with Machine   Learning workshop

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, cs.SY, eess.SY, **投稿日時:** 2024-10-13 21:34


- - -

### [Efficient Federated Unlearning under Plausible Deniability](http://arxiv.org/abs/2410.09947)

**もっともらしい否認の下での効率的な連合学習の忘却**

Ayush K. Varshney, Vicenç Torra

- 欧州のGDPRや米国のCCPAは、ユーザーにデータ削除の権利を与える
- 従来の機械学習では、モデルのパラメータを変えずにデータ削除と偽る事が可能
- 提案手法は、サーバーがクライアントの参加を否認できるプライバシーモデルを活用
- 新手法は学習後でも差分プライバシーを満たしつつ、メモリと再訓練時間を大幅に削減

効率的な連合学習の忘却を実現するってちょっとワクワクするよね！30倍もメモリ節約ってすごくない？しかも再訓練時間まで大幅減少！この研究でプライバシー保護がもっと進むといいな。

**Comment:** This paper has been accepted for publication in the journal track   (Springer Machine Learning) of ACML 2024. Published version will be available   after the conference. The source code is available at   https://github.com/Ayush-Umu/Federated-Unlearning-under-Plausible-Deniability

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-10-13 18:08


- - -

### [FedECADO: A Dynamical System Model of Federated Learning](http://arxiv.org/abs/2410.09933)

**FedECADO: 連合学習の動的システムモデル**

Aayushya Agarwal, Gauri Joshi, Larry Pileggi

- 連合学習の課題は異質なデータ分布や計算負荷の不一致によるモデル更新の不整合
- FedECADOは動的システムモデルを使い、非IIDデータを集約感度モデルで対処
- ヘテロな計算問題には適応ステップサイズ選択のマルチレート手法を設計
- FedProxやFedNovaなどと比較し、FedECADOは異質なシナリオでより高い分類精度を達成

新しいアルゴリズムがどれくらい現実世界で役立つのか気になるね！みんなのデータを連合学習で安全に利用しつつ成果出せたら、未来のアプリケーションがもっと豊かになりそう！💕



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.SY, eess.SY, **投稿日時:** 2024-10-13 17:26


- - -

### [Uncovering Attacks and Defenses in Secure Aggregation for Federated Deep Learning](http://arxiv.org/abs/2410.09676)

**連合学習における安全な集約の攻撃と防御の発見**

Yiwei Zhang, Rouzbeh Behnia, Attila A. Yavuz, Reza Ebrahimi, Elisa Bertino

- 連合学習はデータのローカリティを保持しつつグローバルモデルを学習するが、データプライバシーは脆弱。
- MicroSecAggは通信の複雑さを軽減する単一サーバーセキュア集約プロトコルを提案。
- MicroSecAggにはセキュリティの欠陥があり、予測可能なマスキング値を利用されてユーザープライバシーが危険にさらされる。
- 脆弱性を緩和するために、マスキング戦略の動的かつ予測不可能な実装が必要であり、その対策を提案。

プライバシーを守りつつ連合学習モデルを進化させるって大変だね。新しい攻撃手法を見つけて、それに対する対策も考えるって、技術者さんたちは本当にすごい！これから安全な連合学習がもっと進化するのが楽しみだな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-10-13 00:06


- - -

### [Breaking the Memory Wall for Heterogeneous Federated Learning via Model Splitting](http://arxiv.org/abs/2410.11577)

**ヘテロジニアス連合学習のためのモデル分割によるメモリの壁突破**

Chunlin Tian, Li Li, Kahou Tam, Yebo Wu, Chengzhong Xu

- 連合学習はデータプライバシーを保ちながらモデルを共有するが、デバイスのメモリ制約が問題
- スマートスプリットはモデル分割でメモリ負荷を削減しつつ、学習進行と精度を保証
- 中央マネージャーがメモリ予算などを考慮し、各デバイスの参加を動的に管理
- テスト結果では、最大94%の遅延削減とメモリ100倍の節約を達成し、精度も向上

この技術がうまく動けば、スマートフォンとかのメモリもちっちゃい端末でもすごいモデル動かせるようになりそう！これからさらにすごいこといっぱいできるようになっちゃうかもね！

**Comment:** Accepted by TPDS

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, **投稿日時:** 2024-10-12 18:23


- - -

### [Exact Aggregation for Federated and Efficient Fine-Tuning of Foundation Models](http://arxiv.org/abs/2410.09432)

**基盤モデルの連合および効率的な微調整のための正確な集約**

Raghav Singhal, Kaustubh Ponkshe, Praneeth Vepakomma

- LoRAの連合学習環境での適用は、複数クライアントにデータが分散するため課題がある
- 既存手法はLoRAアダプタを伝統的な連合平均化に頼り、正確な更新を実現できない
- FedEx-LoRAは残差誤差項を追加し、低い計算および通信負荷で正確な更新を達成
- NLUとNLGタスクでの性能向上を示し、提案手法の簡潔さと効率性を強調

この論文、めっちゃ面白そう！提案手法が簡単なのに効果的ってのがすごい。いろんなタスクに適用できるってことは、将来もっとたくさんのモデルでも役立ちそうだね！

**Comment:** RS and KP contributed equally to this work: 18 Pages, 9 Figures, and   8 Tables. Another version of the paper accepted at NeurIPS 2024 Workshop on   Fine-Tuning in Modern Machine Learning: Principles and Scalability

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.CL, cs.CV, **投稿日時:** 2024-10-12 08:22


- - -

### [Enhanced Federated Anomaly Detection Through Autoencoders Using Summary Statistics-Based Thresholding](http://arxiv.org/abs/2410.09284)

**集約統計に基づく閾値設定による強化された連合異常検知**

Sofiane Laridi, Gregory Palmer, Kam-Ming Mark Tam

- 連合学習における異常検知はデータが分散し、分布が非IIDであるため困難
- 要約統計を利用し、連合学習環境でより正確かつ堅牢な異常検知を実現
- クライアント間の要約統計を集約し、プライバシーを保持しつつ最適な閾値を計算
- 公開データセットを使用した実験で、提案手法が既存のものより優れていると証明

連合学習って、データを分散させつつ異常をうまく見つけるのってすごく難しそう。だけど、この研究が提案する方法で、もっと賢く、かつプライバシーを守りながらデータを扱えるみたいだから、安心して利用できそうだね。これからの技術進化にも期待が高まっちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-11 22:21


- - -

### [Evaluating Federated Kolmogorov-Arnold Networks on Non-IID Data](http://arxiv.org/abs/2410.08961)

**非独立同分布データにおける連合コルモゴロフ・アーノルドネットワークの評価**

Arthur Mendonça Sasse, Claudio Miceli de Farias

- 連合コルモゴロフ・アーノルドネットワーク（F-KANs）の評価はまだ初期段階にある
- Bスプラインとラジアル基底関数を用いたKANsとMLPsを比較
- MNIST分類タスクで100名のクライアントによる非独立同分布パーティションを用いた
- スプライン-KANsはMLPsと同等の精度を半分のラウンドで達成し、計算時間はやや増加

F-KANsは精度が高いのに効率も良さそう！非独立データでの連合学習って、便利そうな未来を感じちゃうね。

**Comment:** 10 pages, 5 figures, for associated code see   https://github.com/artsasse/fedkan

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-11 16:30


- - -

### [The Effect of Personalization in FedProx: A Fine-grained Analysis on Statistical Accuracy and Communication Efficiency](http://arxiv.org/abs/2410.08934)

**FedProxにおけるパーソナライゼーションの効果：統計精度と通信効率の詳細分析**

Xin Yu, Zelin He, Ying Sun, Lingzhou Xue, Runze Li

- FedProxは正則化を通じてモデルのパーソナライゼーションを可能にする連合学習法
- 正則化の強度を決めることは難しく、不適切な設定は精度を低下させうるリスクがある
- 正則化が統計精度に与える影響を分析し、適切な強度設定の理論的ガイドラインを提供
- 個別化は通信複雑度を低下させ、計算コストの追加なしに効率を向上させることが示された

FedProxってただの連合学習じゃないんだねー！正規化をうまく設定することで、通信も効率化できるなんてすごいね！どんなデータセットでもうまくいくなんて、未来の技術の一歩を感じちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** stat.ML, cs.DC, cs.LG, math.ST, stat.CO, stat.TH, **投稿日時:** 2024-10-11 16:00


- - -

### [Federated Learning in Practice: Reflections and Projections](http://arxiv.org/abs/2410.08892)

**実践における連合学習: 振り返りと展望**

Katharine Daly, Hubert Eichner, Peter Kairouz, H. Brendan McMahan, Daniel Ramage, Zheng Xu

- 連合学習は複数のエンティティがデータを交換せずに共同でモデルを学習する技術
- GoogleやApple、Metaのシステムは、連合学習の実際の適用例を示している
- 課題はサーバー側の差分プライバシー保証の検証や異種デバイス間の調整
- 新たな連合学習フレームワークはプライバシー原則を優先し、未来の課題に対応

連合学習ってすごいね！みんなでデータをシェアせずに、匿名で一緒に学習できるなんて、まるで未来の技術みたい。これからさらに進化していくと、もっと便利なことができそうでワクワクするね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-11 15:10


- - -

### [Unlocking FedNL: Self-Contained Compute-Optimized Implementation](http://arxiv.org/abs/2410.08760)

**FedNLの解明: 自律的かつ計算最適化された実装**

Konstantin Burlachenko, Peter Richtárik

- 連合学習は分散型で学習モデルを共同訓練し、データ共有を不要にするパラダイム
- FedNLアルゴリズムは第二次手法をFLに適用する進展を示したがプロトタイプには課題がある
- FedNL-LS, FedNL-PPをシングル・マルチノード設定で実装し、壁時計時間を1000倍短縮
- 実用的な圧縮器を提案し、FedNLの理論を実現する新しい圧縮手法を導入

連合学習の現実的なチューニングってすごくクール！プロトタイプの_TIME短縮_により実用性が飛躍的にアップしそうだね。ますます連合学習の普及が進みそうで楽しみだなぁ。

**Comment:** 55 pages, 12 figures, 12 tables

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.MS, cs.PF, math.OC, G.4; C.3; I.2.11, **投稿日時:** 2024-10-11 12:19


- - -

### [Gradients Stand-in for Defending Deep Leakage in Federated Learning](http://arxiv.org/abs/2410.08734)

**連合学習における深層リーク防御のための勾配の代替案**

H. Yi, H. Ren, C. Hu, Y. Li, J. Deng, X. Xie

- 連合学習は、感度の高いデータをローカルにしてモデル勾配のみをサーバーに送信しプライバシーを保護する手法。
- FLの勾配交換に脆弱性が指摘されており、新手法「AdaDefense」でこれを防ぐ。
- ローカル勾配の代わりにスタンドインを使用し、勾配リークを防ぎながらモデルの性能を維持する。
- 理論的枠組みによってプライベート情報の漏えいを防ぐ手法の有効性を立証し、ベンチマーク実験でモデルの一貫性と安全性を確認。

勾配リークってそんなに危ないんだね！でも、「AdaDefense」でそれを防ぎつつも性能も落ちないなんて、すごく興味深い！これからのプライバシー技術に大きな貢献しそうだよね。❤️



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, **投稿日時:** 2024-10-11 11:44


- - -

### [DistDD: Distributed Data Distillation Aggregation through Gradient Matching](http://arxiv.org/abs/2410.08665)

**DistDD: 勾配マッチングによる分散データ蒸留集約**

Peiran Wang, Haohan Wang

- DistDDは連合学習での通信を減らし、クライアント上で直接データを蒸留する手法
- 従来のモデル更新を要さず、一度の蒸留でグローバルなデータセットを抽出しプライバシーを確保
- DistDDで得たデータは、連合学習のパラメータ調整やニューラルアーキテクチャ検索に活用できる
- 実験結果で非独立同分布や誤ラベルデータにも頑強で、コミュニケーションコスト削減を証明

DistDDってすごく未来が見えるね！データを効率的に使って、もっと賢いAIモデルができそうな予感！私たちの身近なところでも役立つ日が楽しみ〜。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-11 09:43


- - -

### [Training on Fake Labels: Mitigating Label Leakage in Split Learning via Secure Dimension Transformation](http://arxiv.org/abs/2410.09125)

**偽ラベルでの訓練: 安全な次元変換によるスプリットラーニングでのラベル漏洩軽減**

Yukun Jiang, Peiran Wang, Chengguo Lin, Ziyue Huang, Yong Cheng

- スプリットラーニングはラベルリークに対する脆弱性があり、防御策は効果が限定的または影響が大きい
- 提案手法はラベル推論攻撃を防ぎつつ、モデルの有用性も維持
- 独自の次元変換モジュールと勾配正規化アルゴリズムでラベル漏洩を防ぐ
- 実験で複数の攻撃を検証し、既存手法より優れた防御効果を示す

次元変換や勾配正規化でラベル漏洩を防ぐってすごくクール！実際のデータセットでこれだけの効果が出るなら、今後の研究にも期待できそうだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-11 09:25


- - -

### [GAI-Enabled Explainable Personalized Federated Semi-Supervised Learning](http://arxiv.org/abs/2410.08634)

**GAIを活用した説明可能な個別化連合半教師あり学習**

Yubo Peng, Feibo Jiang, Li Dong, Kezhi Wang, Kun Yang

- 連合学習はモバイルユーザーのAIモデル訓練に使われるが、ラベル不足やデータの非IID性、説明不能性などの課題がある
- 提案するXPFLフレームワークは、生成AIを用いた個別化連合半教師あり学習GFedでローカルFLモデルを強化
- グローバル集約では、ローカルとグローバルFLモデルの知識を特定の割合で融合し、個別化を保ちながら知識を共有
- FLモデルの説明性を向上させるため、決定木とt-SNEを活用してモデルの入力と出力や集約前後の可視化を実現

生成AIを使ってラベル不足を補うアイデア、めっちゃ新しい！モデルの融合方法もよく考えられてて、個別化のまま力を合わせる感じがいいと思った～。可視化の部分も面白そう、データが目に見えるってすごいよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.IT, math.IT, **投稿日時:** 2024-10-11 08:58


- - -

### [SoK: Verifiable Cross-Silo FL](http://arxiv.org/abs/2410.09124)

**知識の体系化: 検証可能なクロスサイロ連合学習**

Aleksei Korneev, Jan Ramon

- 連合学習は、複数のデバイス上のデータを使い機械学習モデルを訓練するアプローチ
- 医療や金融分野でのクロスサイロ連合学習は、参加者が中規模で、各参与者はよく知られる組織
- 悪意ある参加者が訓練手順を乱し、偏った結果や計算負荷の軽減を狙う可能性がある
- 検証可能なプロトコルの開発が進行中で、ゼロ知識証明のコスト削減方法も議論

検証可能なプロトコルって、すごく面白そう！これでみんなが正しく連携して学習できるなんて、高校生の私たちも何か協力して一緒に新しいアイデアを生み出せるかもね！未来に向けてワクワクするよ！



**トピック:** [連合学習](../../fl), [ゼロ知識証明](../../zkp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-11 07:39


- - -

### [Accelerated Distributed Stochastic Non-Convex Optimization over Time-Varying Directed Networks](http://arxiv.org/abs/2410.08508)

**時間変動する有向ネットワークにおける加速分散確率非凸最適化**

Yiyue Chen, Abolfazl Hashemi, Haris Vikalo

- 信号処理やコンピュータビジョン、自然言語処理など分散学習システムの応用で注目される。
- 時間変動する有向ネットワークをモデル化、通信遅延やストラグラー効果を考慮した分布設定。
- 勾配追跡とモメンタム付き確率的勾配降下法を用いて、非凸最適化問題を解決するアルゴリズムを提案。
- 提案手法は既存手法を上回る性能を示し、様々な学習タスクで有効であることを実証。

分散学習システムが活躍する未来がますます近づいてきた感じ！この手法でさらに色んなタスクが効率よくできちゃうのかな？MNISTやCIFAR-10みたいな有名な学習タスクで試されてるところもすごく興味深いね！

**Comment:** This work has been accepted at IEEE Transactions on Automatic Control

**トピック:** [連合学習](../../fl), **カテゴリ:** eess.SY, cs.SY, **投稿日時:** 2024-10-11 04:18
