---
title: 差分プライバシー (2024-08-09 ~ 2024-08-15)
date: 2024-08-09
---

差分プライバシーに関する論文まとめ (2024-08-09 ~ 2024-08-15)


- - -

### [Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation](http://arxiv.org/abs/2408.08107)

**異質なコミュニティレベルでのメーター背後の太陽光発電の通信に強くプライバシーを安全にする分散推定**

Jinglei Feng, Zhengshuo Li

- メーター背後の太陽光発電システムの増加により、配電系統計画とスケジュールが複雑になる
- 従来の連合学習方法は、異質性、通信障害、悪意のあるプライバシー攻撃などの課題に直面している
- 提案手法はマルチタスク連合学習を採用し、全コミュニティの共通および固有の特徴を学習する
- 差分プライバシーメカニズムを使用し、動的なプライバシーバジェット配分戦略を採用してプライバシー攻撃に対抗

通信もプライバシーもバッチリで、未来のエネルギー管理に貢献しそう！これが実現したら、もっと効率よく安全に電力を使えるね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** eess.SY, cs.SY, **投稿日時:** 2024-08-15 12:11


- - -

### [Practical Considerations for Differential Privacy](http://arxiv.org/abs/2408.07614)

**差分プライバシーの実践的考察**

Kareem Amin, Alex Kulesza, Sergei Vassilvitskii

- 差分プライバシーは統計データ公開の金字塔であるが、普及の障壁もある
- 政府、企業、学界で使用され、その数理的な保証が特徴
- 攻撃者の知識と強さを最悪ケースとして仮定する強力なフレームワーク 
- 日常的なデータ利用と保護での普及はまだ限定的である

この論文、実践例とかも述べてるのかな？差分プライバシーの具体的な普及方法が書かれてたら、もっと知りたいかも。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-08-14 15:28


- - -

### [Improved Counting under Continual Observation with Pure Differential Privacy](http://arxiv.org/abs/2408.07021)

**純粋な差分プライバシーを用いた連続観察下での計数の改善**

Joel Daniel Andersson, Rasmus Pagh, Sahel Torkamani

- 差分プライバシーの連続観察下での計数問題は広く研究されている
- 従来の$\varepsilon$-差分プライバシーでの平均二乗誤差の改善はなかった
- この論文は、二項木メカニズムの新たな一般化に基づき、誤差を約4倍に削減
- 提案手法は、従来のガウスノイズを用いたメカニズムよりも$\delta$が十分に小さい場合に優れた精度を示す

この研究の新しいメカニズムはすごく興味深いね。今後の差分プライバシーの応用に大きなインパクトを与えそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DS, **投稿日時:** 2024-08-13 16:36


- - -

### [The Complexities of Differential Privacy for Survey Data](http://arxiv.org/abs/2408.07006)

**調査データにおける差分プライバシーの複雑性**

Jörg Drechsler, James Bailie

- 複数段階のデータ生成過程が差分プライバシーの実装を困難にする
- 複雑なサンプリングデザインが原因でプライバシー増幅が限られる
- 調査加重推定の影響が差分プライバシーの効力に関係
- 欠測値の代入や無回答調整の点でも課題がある

調査データに差分プライバシーを適用する難しさが伝わるね。でも、それを乗り越えたら新しい標準が生まれるかもってワクワクするよ！

**Comment:** 18 pages, 2 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ME, cs.CR, **投稿日時:** 2024-08-13 16:15


- - -

### [Faster Private Minimum Spanning Trees](http://arxiv.org/abs/2408.06997)

**高速なプライベート最小全域木**

Rasmus Pagh, Lukas Retschmeier

- クラスタリングや合成データ生成に動機づけられ、重み付き差分プライバシー下での最小全域木の公開問題を検討
- 既存の手法では、重み行列の各エントリにノイズを加えたり、特定のアルゴリズムの実行中にノイズを加える方法がある
- 新しいアルゴリズムは、従来の手法と同等の使用性で、計算時間を$O(m + n^{3/2}\log n)$に短縮を実現
- 実験結果が、利用効率または実行時間のどちらにおいても、既存のアルゴリズムを大幅に改善することを示している

差分プライバシーを保持しながらも計算効率をかなり上げられるところがすごいよね！これでクラスタリングとか合成データの生成がもっと簡単になりそう。



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.DS, cs.CR, cs.LG, **投稿日時:** 2024-08-13 16:00


- - -

### [Deep Learning with Data Privacy via Residual Perturbation](http://arxiv.org/abs/2408.05723)

**残差摂動によるデータプライバシーを伴う深層学習**

Wenqi Tao, Huaming Ling, Zuoqiang Shi, Bao Wang

- ディープラーニングにおけるプライバシー保護は重要で、既存の手法はプライバシーを守るが、実用性の低下や計算過負荷の問題がある
- 本研究では、ガウスノイズをResNetの各残差写像に注入する確率微分方程式に基づいた摂動を提案
- 理論的には、この残差摂動が差分プライバシーを保証し、ディープラーニングの一般化ギャップを減少させると証明
- 経験的には、この手法が計算効率が高く、メンバーシッププライバシーを犠牲にせずに最新の差分プライバシーを用いた確率的勾配降下法よりも優れていることを示した

これめっちゃ面白そうじゃない？プライバシーを守りながらも性能を落とさない方法がどれだけ普及するか今後が楽しみ！これから色んなアプリやサービスがもっと安全に使えるようになりそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.CV, **投稿日時:** 2024-08-11 08:26


- - -

### [The Bandit Whisperer: Communication Learning for Restless Bandits](http://arxiv.org/abs/2408.05686)

**バンディットのささやき者: 静動的バンディットのためのコミュニケーション学習**

Yunfan Zhao, Tonghan Wang, Dheeraj Nagaraj, Aparna Taneja, Milind Tambe

- 連続アームバンディット(RMABs)に強化学習を適用することで、資源制約と時間的動態を持つ配分問題に対処する
- しかし、従来のRMABモデルはデータ収集プロトコルの違いや差分プライバシーによる意図的なノイズなどのデータエラーの課題を無視している
- 初のコミュニケーション学習アプローチを提案し、どのアームがコミュニケーションに関与することでデータエラーの影響を軽減するかを研究
- Qネットワークアーキテクチャを使用し、メッセージの共同効用を考慮したコミュニケーション戦略を学習することで、RMABの性能が大幅に向上することを理論的および実証的に確認

リアルタイムでデータエラーに対処できるなんて、この研究ってきっと実用的でスゴい！未来のAIがもっと賢くなりそうだね、ワクワクする！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.MA, **投稿日時:** 2024-08-11 03:39


- - -

### [Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions](http://arxiv.org/abs/2408.05212)

**大規模言語モデルにおけるプライバシー保護: 現在の脅威と解決策に関する調査**

Michele Miranda, Elena Sofia Ruzzetti, Andrea Santilli, Fabio Massimo Zanzotto, Sébastien Bratières, Emanuele Rodolà

- 大規模言語モデル（LLMs）は様々な分野で応用されているが、巨大なデータセットの使用によりプライバシー問題が顕著である
- LLMsはデータを記憶し、機密情報を露呈するリスクがあることが指摘されている
- 差分プライバシーの導入や訓練データセットの匿名化など、包括的なプライバシー保護手法を提案している
- 現在の取り組みとツール、そしてプライバシー保護のための今後の方向性について詳しくレビューしている

これ面白そう！LLMsのプライバシー問題って、たしかに今後もっと重要になりそうだし、安心して使えるAIシステムが増えるといいよね。

**Comment:** GitHub repository:   https://github.com/michele17284/Awesome-Privacy-Preserving-LLMs

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.CL, cs.LG, **投稿日時:** 2024-08-10 05:41


- - -

### [PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks](http://arxiv.org/abs/2408.05092)

**PriPHiT: 階層的な深層ニューラルネットワーク訓練におけるプライバシー保護**

Yamin Sepehri, Pedram Pad, Pascal Frossard, L. Andrea Dunbar

- 深層ニューラルネットワークの訓練はクラウドサーバー上で行われることが多く、プライバシーリスクがある
- エッジデバイスとクラウドを併用し、センシティブな内容をクラウドに送信せずに訓練を行う方法を提案
- エッジでの早期終了とノイズ追加を利用し、差分プライバシーを保証
- 多様な顔属性のデータセットで試験し、優れた性能を示した上、ホワイトボックス攻撃や再構成攻撃に対する防御を実証

クラウドに頼る技術でも、個人情報の漏えい防げるなんて期待できるよね！色んな攻撃にも耐えうるだなんて、安心して使えそう！

**Comment:** 16 pages, 16 figures, 6 tables

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CV, cs.CR, cs.DC, cs.LG, eess.IV, I.2.10; I.2.6; I.2.11; K.4.1, **投稿日時:** 2024-08-09 14:33


- - -

### [Locally Private Histograms in All Privacy Regimes](http://arxiv.org/abs/2408.04888)

**全てのプライバシーレジームにおける局所的プライバシーヒストグラム**

Clément L. Canonne, Abigail Gentle

- ヒストグラム（頻度推定）はデータ分析の基本手法であり、差分プライバシーの下で広く研究されている
- 局所モデルでのヒストグラム計算は最近の研究の焦点であり、高いプライバシー状態での最適な$\ell_\infty$エラーを達成するアルゴリズムが提案されている
- 中・低プライバシーレジーム(大きな$\varepsilon$)における研究は不明確であり、この研究ではこの領域での局所的プライバシーヒストグラムのエラー境界を解明
- 理論的知見は新しい解析方法から得られ、既存のアルゴリズムの全プライバシーレジームにおける性能と特性を実証的に比較

プライバシーの高低で性能がどう変わるのか気になるよね！エラー境界の発見とか新しい解析がどんな風に役立つのか楽しみ！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, cs.CR, cs.DM, **投稿日時:** 2024-08-09 06:22
