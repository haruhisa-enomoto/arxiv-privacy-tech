---
title: 連合学習 (2024-11-08 ~ 2024-11-14)
date: 2024-11-08
---

連合学習に関する論文まとめ (2024-11-08 ~ 2024-11-14)


- - -

### [Towards efficient compression and communication for prototype-based decentralized learning](http://arxiv.org/abs/2411.09267)

**プロトタイプベースの分散学習における効率的な圧縮と通信に向けて**

Pablo Fernández-Piñeiro, Manuel Ferández-Veiga, Rebeca P. Díaz-Redondo, Ana Fernández-Vilas, Martín González-Soto

- プロトタイプベースの連合学習では、モデルパラメータの交換をプロトタイプや量子化データの送信に置き換える。
- 中央集約型のプロトタイプなしによる分散学習は、動的な学習タスクに適応が早くなる。
- プロトタイプの冗長性を削減するために、有用なプロトタイプのみを更新メッセージで送信し、クラスタリングを使う。
- 並列ゴシッピングを使用し、通信負荷を削減しつつ収束率を維持する。

プロトタイプを使った効率的な学習ってなんかイケてる！IoTと相性良さそうだし、未来の通信技術に広がりそうでワクワクするね。

**Comment:** 15 pages, 2 tables, 7 figures, 6 algorithms

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-14 08:08


- - -

### [SAFELOC: Overcoming Data Poisoning Attacks in Heterogeneous Federated Machine Learning for Indoor Localization](http://arxiv.org/abs/2411.09055)

**SAFELOC: 異種連合学習によるインドアローカライゼーションにおけるデータポイズニング攻撃の克服**

Akhil Singampalli, Danish Gufran, Sudeep Pasricha

- インドアローカライゼーションの精度は、デバイスの多様性やデータポイズニング攻撃によって低下しやすい
- SAFELOCという新しいフレームワークを提案し、これらの課題下でもローカライゼーションの誤差を最小化する
- 連合学習を利用することでユーザーデータのプライバシーを守りつつ、データポイズニング検出と位置特定を行う
- 実験では、既存フレームワークに比べ誤差5.9倍、最悪誤差7.8倍、推論遅延2.1倍の改善を実現

面白そう！デバイスが異なっても性能が上がるんだね。セキュリティとプライバシーを両立させて、将来のアプリケーションに役立ちそうでワクワクする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-11-13 22:28


- - -

### [FedSub: Introducing class-aware Subnetworks Fusion to Enhance Personalized Federated Learning in Ubiquitous Systems](http://arxiv.org/abs/2411.08699)

**FedSub: ユビキタスシステムにおけるパーソナライズ連合学習向上のためのクラス認識サブネットワーク融合の導入**

Mattia Giovanni Campana, Franca Delmastro

- ユビキタスシステムでは、プライバシーを守りつつユーザの多様な行動に適応するモデルが重要である。
- 既存の手法は、パーソナライズと一般化のバランスが取れず、グローバルモデルに依存しがちである。
- FedSubは、クラス認識プロトタイプとサブネットワークを用いて個別化を強化する新手法である。
- FedSubは、実験によりリアルなシナリオでのデータヘテロ性に対処し、最高精度を達成した。

FedSubってすごくない？個々の特性を活かしたパーソナライズされたモデルって、未来の技術でめっちゃ期待できる！これからのウェアラブルデバイスとか、どんどんユーザーに合ったサービスになっていくんだろうなぁ。

**Comment:** Submitted to Proceedings of the ACM on Interactive, Mobile, Wearable   and Ubiquitous Technologies (IMWUT)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-13 15:42


- - -

### [On the Convergence of Continual Federated Learning Using Incrementally Aggregated Gradients](http://arxiv.org/abs/2411.07959)

**増分的に集約された勾配を用いた継続的連合学習の収束について**

Satish Kumar Keshri, Nazreen Shah, Ranjitha Prasad

- 継続的連合学習（CFL）は、ストリーミングデータから学び効率、プライバシー、スケーラビリティを向上させる手法である
- CFLの課題は、古いタスクの精度が新しいタスクの学習で低下する、いわゆるグローバル破滅的忘却に対処することである
- 提案手法C-FLAGは、メモリ上のエッジベースの勾配更新と現在のデータに基づく集約勾配からなる新しい再生メモリベースの連合戦略である
- C-FLAGはタスク間での破滅的忘却を最小化し、収束速度$O(1/\sqrt{T})$を達成して多くの最先端手法を上回る性能を示した

この研究おもしろそう！C-FLAGでタスクを忘れないっていう発想、新しいかも！AIがもっと賢くなる予感がするね。しかも、プライバシーを守りながら学習するって期待できる～！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-11-12 17:36


- - -

### [A Stochastic Optimization Framework for Private and Fair Learning From Decentralized Data](http://arxiv.org/abs/2411.07889)

**プライバシーと公正さを両立した分散データからの学習のための確率的最適化フレームワーク**

Devansh Gupta, A. S. Poornash, Andrew Lowy, Meisam Razaviyayn

- 連合学習モデルのプライバシーと公正性の課題に対抗するアルゴリズムを開発
- 各シロデータの記録レベル差分プライバシー（ISRL-DP）を満たす
- 公正性として、人口平等や均等的成果を促進できる
- 以前は必要だった強凸性なしに、緩やかな滑らかさでの収束を保証

データのプライバシーも守りつつ、公正な結果を導くなんてすごくない？これ、社会にめちゃ貢献できそうな技術だよね！新しい方法でシロデータを守るなんて、聞くだけでワクワクしちゃう！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-12 15:51


- - -

### [Federated Learning for Discrete Optimal Transport with Large Population under Incomplete Information](http://arxiv.org/abs/2411.07841)

**連合学習を用いた大規模な不完全情報下での離散的最適輸送**

Navpreet Kaur, Juntao Chen, Yingdong Lu

- 最適輸送は資源の効率的な配分を目指すが、大規模で異質な集団においてスケーリングが難しい
- 既知のタイプ分布では、資源配分を最適化するための分散アルゴリズムを提案
- タイプ分布が未知の場合、プライバシーを保った連合学習アプローチを開発
- ケーススタディによって提案アルゴリズムの性能を評価し効果を実証

連合学習で巨大で多様な集団を効率的に扱うチャレンジ、面白そう！プライバシーを守りながらの最適化だから、実用的な応用も期待できるね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.AI, **投稿日時:** 2024-11-12 14:46


- - -

### [Efficient Federated Finetuning of Tiny Transformers with Resource-Constrained Devices](http://arxiv.org/abs/2411.07826)

**リソースが限られたデバイスでの小型トランスフォーマーの効率的な連合微調整**

Kilian Pfeiffer, Mohamed Aboelenien Ahmed, Ramin Khalili, Jörg Henkel

- 大規模言語モデルは多くのデータと高いリソースを要求するが、リソースが限られた環境では困難がある
- LoRAは連合学習でパラメータ効率は良いが、メモリとFLOPsの効率が悪いことがわかった
- 新しい層の微調整スキームは、リソース制約のあるデバイスでも事前訓練されたNNを活用可能にする
- 提案手法は現在の最先端技術を超え、同質または異質な計算とメモリ制約において高い精度を達成した

デバイスの制約がある中でも、しっかりと先端技術を活かしつつ効率を高める工夫が面白そう！新しい微調整スキーム、ぜひ試してみたいね。連合学習の世界もますます広がりそうで楽しみ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-11-12 14:22


- - -

### [Dual-Criterion Model Aggregation in Federated Learning: Balancing Data Quantity and Quality](http://arxiv.org/abs/2411.07816)

**連合学習におけるデュアル基準モデル集約: データ量と質のバランス**

Haizhou Zhang, Xianjia Yu, Tomi Westerlund

- 連合学習ではクライアントのデータを交換せずにモデルを共有する手法が主流
- 従来の集約アルゴリズムはデータを量的に評価しがちで、質的な違いを無視
- 本研究は、データ量と質を考慮したデュアル基準の集約アルゴリズムを提案
- 提案手法はCIFAR-10などで既存の最先端手法を上回る性能を示した

これって、データの量だけじゃなくて質もバランスよく考えるのがポイントなんだね！クライアントのデータがバラバラでもちゃんと貢献できるのが面白いな〜。

**Comment:** 6 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-12 14:09


- - -

### [Federated Low-Rank Adaptation with Differential Privacy over Wireless Networks](http://arxiv.org/abs/2411.07806)

**差分プライバシーを用いた無線ネットワーク上の連合低ランク適応**

Tianqu Kang, Zixin Wang, Hengtao He, Jun Zhang, Shenghui Song, Khaled B. Letaief

- 大規模モデルの連合学習はプライバシー保護の問題を軽減する。
- LoRAの利用で計算負荷を減らし効率的にモデル微調整が可能。
- 分割されたFMがデバイス間で共有されプライバシー攻撃の懸念。
- 無線チャンネルノイズを利用し差分プライバシーを実現。

差分プライバシーの工夫が面白いね！通信の「ノイズ」を役立てちゃうなんて発想がユニークだし、これは革新的な無線通信のプライバシー保護の手法になる予感！

**Comment:** 6 pages, 3 figures, submitted to IEEE ICC 2025

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, eess.SP, **投稿日時:** 2024-11-12 14:01


- - -

### [ALANINE: A Novel Decentralized Personalized Federated Learning For Heterogeneous LEO Satellite Constellation](http://arxiv.org/abs/2411.07752)

**ALANINE: 異種LEO衛星コンステレーション向けの新たな分散個別連合学習**

Liang Zhao, Shenglin Geng, Xiongyan Tang, Ammar Hawbani, Yunhe Sun, Lexi Xu, Daniele Tarchi

- 最近のLEO衛星コンステレーションは、通信やナビゲーション、リモートセンシングなど多様な機能の統合で成長。
- データの多様性や異なる画像解像度の不一致が、衛星間の効率的な共同計算の妨げになっている。
- ALANINEは分散型FLで衛星画像超解像を行い、個別化PFLにより各衛星データの特性に対応。
- モデル剪定技術を活用し、モデルの複雑さと伝送効率を最適化、データ処理の精度向上を実現。

LEO衛星の世界ってなんか未来っぽくてワクワクするね！データの個別化も、宇宙での通信がもっと身近になりそうな予感！🌟

**Comment:** 14 pages, 8 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-11-12 12:23


- - -

### [Collaborative and Federated Black-box Optimization: A Bayesian Optimization Perspective](http://arxiv.org/abs/2411.07523)

**協調型および連合型ブラックボックス最適化：ベイズ最適化の視点**

Raed Al Kontar

- 連合型ブラックボックス最適化における分散実験、異質性、プライバシーが課題
- グローバル、ローカル、予測の3つのフレームワークを提案し、課題に対応
- ローカルフレームワークでは最小限の情報共有で意思決定を支援
- ベイズ最適化を用い、記述的・予測的から処方的な学習への移行を目指す

ベイズ最適化を使って連合学習をもっとステキな方向に持っていくのってワクワクするね。これが進化したら私たちの日常でも活用されるかもしれないよ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, stat.ML, **投稿日時:** 2024-11-12 03:47


- - -

### [Federated Learning Client Pruning for Noisy Labels](http://arxiv.org/abs/2411.07391)

**雑音ラベルのための連合学習クライアントプルーニング**

Mahdi Morafah, Hojin Chang, Chen Chen, Bill Lin

- 連合学習はデータプライバシーを保持しつつモデルをトレーニングするが、ノイズの多いラベルが課題
- 既存手法はラベル修正や堅牢なトレーニングだが、高ノイズ下で効果が限定的
- ClipFLはノイズクライアントを識別し除外する新たなフレームワークでNCSを用いる
- ClipFLは雑音クライアント識別、性能向上、速い収束、通信コスト削減を達成

ノイズがある中でも効率的に連合学習できるのってすっごく重要だよねー。クライアントのプルーニングでより正確に学べるのは、未来のAIを賢くしてくれそうな気がする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, cs.DC, **投稿日時:** 2024-11-11 21:46


- - -

### [TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on Pre-trained Language Models](http://arxiv.org/abs/2411.07224)

**TempCharBERT: 事前学習済み言語モデルに基づく継続的なアクセス制御のためのキー入力動力学**

Matheus Simão, Fabiano Prado, Omar Abdul Wahab, Anderson Avila

- デジタル環境での信頼できる認証と継続的なアクセス制御が重要。
- 個々のタイピングスタイルで個人を識別するキー入力動力学（KD）が注目される。
- 事前学習済み言語モデル（PLM）を活用し、タイピングの時間的特徴を考慮するTempCharBERTを提案。
- TempCharBERTを連合学習で訓練し、データプライバシーを向上する可能性を示した。

なんかTempCharBERTって未来感がいっぱい！タイピングの仕方で個人を特定できるなんておもしろいね。これで安全性もプライバシーも強化できるのかな。進化が待ち遠しいね💻✨

**Comment:** Accepted at WIFS 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.CL, **投稿日時:** 2024-11-11 18:44


- - -

### [Revisiting Ensembling in One-Shot Federated Learning](http://arxiv.org/abs/2411.07182)

**ワンショット連合学習におけるアンサンブルの再考**

Youssef Allouah, Akash Dhasade, Rachid Guerraoui, Nirupam Gupta, Anne-Marie Kermarrec, Rafael Pinot, Rafael Pires, Rishi Sharma

- 連合学習は生データを共有せずにモデルを訓練できるが、通信コストが高い。
- ワンショット連合学習は単一の通信ラウンドでコストを削減するが、精度にギャップがある。
- FENSは、ワンショット連合学習の通信効率を保持しながら連合学習に近い精度を達成。
- CIFAR-10データで、FENSは最新ワンショット手法より最大26.9%精度向上、通信量も低減。

このアプローチ、すごく効率的かつ精度も高めているみたいでびっくり！特にデータをあまり共有せずに高い精度を出す方法が、未来のいろんなデータを守りながら学習する時代にぴったりだよね。

**Comment:** Accepted at NeurIPS 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-11-11 17:58


- - -

### [WassFFed: Wasserstein Fair Federated Learning](http://arxiv.org/abs/2411.06881)

**WassFFed: ワッサースタインに基づく公平な連合学習**

Zhongxuan Han, Li Zhang, Chaochao Chen, Xiaolin Zheng, Fei Zheng, Yuyuan Li, Jianwei Yin

- 連合学習では地理的に分散した多様なユーザーグループのデータを公平に扱う必要がある
- 現行の方法では代理関数で得られる公正な最適化結果と公正な分類結果の整合性が取れない
- 非独立同分布（non-IID）のデータで局所モデルの集約が全体の公正性を保証しない
- WassFFedはワッサースタイン重心を使用し、局所モデルをグローバル出力に近づけ一貫性を確保

ワッサースタイン距離を使って公平性を高めるアプローチって斬新だね！データ分散の問題が解決されれば、より多くの応用が期待できそう。興味が尽きないテーマだな～。

**Comment:** Submitted to TKDE

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, stat.ML, **投稿日時:** 2024-11-11 11:26


- - -

### [Model Partition and Resource Allocation for Split Learning in Vehicular Edge Networks](http://arxiv.org/abs/2411.06773)

**車両エッジネットワークにおける分割学習のためのモデル分割とリソース割り当て**

Lu Yu, Zheng Chang, Yunjian Jia, Geyong Min

- 自動運転技術と車両ネットワークの統合はプライバシー保持や通信効率の課題を生む
- U字型分割連合学習フレームワーク (U-SFL) がプライバシーを強化し複数車両で並列処理を可能にする
- セマンティック対応オートエンコーダー (SAE) がデータ伝送効率を高め通信遅延を低減
- 深層強化学習（DRL）アルゴリズムがリソース割り当てと分割点選択のNP困難問題を解決

ふむふむ、この研究って、まるで『未来の交通』そのものだね！同時並行でめっちゃ効率的に自動運転が進んで行く未来、わたしたちの生活も楽しくなっちゃう気がするよ！

**Comment:** arXiv admin note: text overlap with arXiv:2306.12194 by other authors

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-11-11 07:59


- - -

### [Sketched Adaptive Federated Deep Learning: A Sharp Convergence Analysis](http://arxiv.org/abs/2411.06770)

**スケッチ適応型連合深層学習: 鋭い収束解析**

Zhijie Chen, Qiaobo Li, Arindam Banerjee

- 勾配圧縮と適応最適化を組み合わせることで、通信ラウンド数と通信量を削減できる。
- 線形依存で高コストだった通信量を、対数的な依存関係にする理論的収束解析を提案。
- 現在の分析とは異なり、異方性曲率を利用することでスケッチノイズを改善。
- i.i.d.環境では速い収束を示し、非i.i.d.環境でも収束の証明ができる。

理論的な根拠を実証データで裏付けているのがすごく心強いなあ。さらに、この方法が最先端と競えるレベルってのも面白いね！新しい通信効率の技術が実現する未来、楽しみだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-11 07:51


- - -

### [Using Diffusion Models as Generative Replay in Continual Federated Learning -- What will Happen?](http://arxiv.org/abs/2411.06618)

**連続連合学習における生成的リプレイとしての拡散モデルの使用 -- 何が起こるか？**

Yongsheng Mei, Liangqi Yuan, Dong-Jun Han, Kevin S. Chan, Christopher G. Brinton, Tian Lan

- 連合学習ではデータ分布が動的に変化するため、継続的学習の問題が発生する
- 主な課題は壊滅的忘却と非IIDな入力データで、従来の解決策は履歴データのリプレイかGANを使用
- 新しい枠組みDCFLは条件付き拡散モデルで合成データを生成し、動的データ分布のずれを軽減
- 提案手法は収束境界を提供し、複数データセットでの効果的な性能を実証

条件付き拡散モデルを使って連合学習を改善するなんて、めっちゃ斬新じゃない？どんなデータセットでもうまくいくようになるかも、未来が楽しみだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-11-10 22:48


- - -

### [Protection against Source Inference Attacks in Federated Learning using Unary Encoding and Shuffling](http://arxiv.org/abs/2411.06458)

**連合学習におけるユニコードとシャッフルを用いたソース推論攻撃からの保護**

Andreas Athanasiou, Kangsoo Jung, Catuscia Palamidessi

- 連合学習（FL）では、データを公開せずにクライアントがモデルを共同で訓練
- ソース推論攻撃（SIA）では中央サーバーが特定データの所有クライアントを特定可能
- ユニコードとシャッフルを用い中央サーバーからの情報推論を防止
- 定量化を導入し、通信コストを抑えつつSIAの精度を低下させた

シャッフルすることで攻撃を防ぐなんて発想が面白いね！これがうまくいくなら、もっとプライバシーが守られる未来がくるかも！

**Comment:** CCS 2024 - The ACM Conference on Computer and Communications   Security, ACM, Oct 2024, Salt Lake City, United States

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-11-10 13:17


- - -

### [Client Contribution Normalization for Enhanced Federated Learning](http://arxiv.org/abs/2411.06352)

**強化された連合学習のためのクライアント寄与標準化**

Mayank Kumar Kundalwal, Anurag Saraswat, Ishan Mishra, Deepak Mishra

- スマートフォンなどのモバイルデバイスのデータは分散的かつ異質で、従来の集中型機械学習に課題を与える。
- 連合学習（FL）は、データ共有なしで分散デバイス間でグローバルモデルを協力的に訓練できる。
- 本研究は、クライアント間の統計的不均一性をデータ依存の視点で捉え平均潜在表現で寄与を正規化する手法を提案。
- 多様なデータセットで実験を行い、モデルの精度と一貫性の大幅な向上を確認し、FLの信頼性を改善。

技術者さんたちは、連合学習の進化を追求しているんだね！クライアントのデータのばらつきを平均化することで、もっと正確なモデルが作れるようになるなんて、ほんとスゴイよね。未来の機械学習の発展が楽しみ♪

**Comment:** Accepted at IEEE INDICON 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-10 04:03


- - -

### [TinyML NLP Approach for Semantic Wireless Sentiment Classification](http://arxiv.org/abs/2411.06291)

**セマンティックワイヤレス感情分類のためのTinyML NLPアプローチ**

Ahmed Y. Radwan, Mohammad Shehab, Mohamed-Slim Alouini

- NLPはユーザープライバシーを侵害しがちで、デバイス負荷が大きい
- 連合学習はプライバシー保護が強いがエネルギー消費が高い
- 分割学習はエネルギー効率が良く、プライバシーを守るTinyML手法として注目
- 分割学習は高精度を維持しながら処理電力とCO2排出を削減

分割学習が注目されているのはおもしろいね！プライバシーも環境も守れるなんて、未来の技術だなって思う！違う手法をうまく組み合わせて、より良いソリューションが開発されるのが楽しみ！

**Comment:** Submitted for WCNC-2025, Under Review

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.IT, math.IT, 68T50, 94A12, I.2.7; C.2.1, **投稿日時:** 2024-11-09 21:26


- - -

### [Federated Split Learning for Human Activity Recognition with Differential Privacy](http://arxiv.org/abs/2411.06263)

**連合スプリット学習による差分プライバシーを活用した人の行動認識**

Josue Ndeko, Shaba Shaon, Aubrey Beal, Avimanyu Sahoo, Dinh C. Nguyen

- 新たなFSL-DPフレームワークにより、人の行動認識精度が向上
- 従来の連合学習に比べ、FSLフレームワークが精度と損失面で優れている
- プライバシー保証とモデル精度のバランスを探るため、DPメカニズムのデータ設定を調査
- FSLフレームワークは通信時間が短く、効率性と効果的な性能を示す

この技術が進化すれば、私たちのデバイスはもっと賢くなるかもね！実生活のデータでテストされたっていうのも頼もしいな。連合スプリット学習…響きからしてなにかすごそう！

**Comment:** Accepted to IEEE Consumer Communications and Networking Conference   (CCNC), 6 pages

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-11-09 19:32


- - -

### [A Sharded Blockchain-Based Secure Federated Learning Framework for LEO Satellite Networks](http://arxiv.org/abs/2411.06137)

**LEO衛星ネットワーク向けのシャードブロックチェーンを用いた安全な連合学習フレームワーク**

Wenbo Wu, Cheng Tan, Kangcheng Yang, Zhishu Shen, Qiushi Zheng, Jiong Jin

- LEO衛星ネットワークは宇宙ベースのAIアプリケーションに必須だが、サイバー攻撃リスクが高まっている
- 従来のモデルでは、地上ステーションへの送信に注力し、衛星特有のセキュリティ問題を見過ごしがち
- SBFL-LEOはシャードブロックチェーン技術を活用、衛星に特定の役割を割り振り通信信頼性を向上
- 新手法はモデル精度やエネルギー効率を向上し、攻撃耐性を強化する実験結果が示された

ブロックチェーンと連合学習を組み合わせて、衛星間通信の安全性をアップするなんてすごい！これからの宇宙AI時代に欠かせない技術になりそうだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, **投稿日時:** 2024-11-09 10:22


- - -

### [Personalized Hierarchical Split Federated Learning in Wireless Networks](http://arxiv.org/abs/2411.06042)

**ワイヤレスネットワークにおける個別化された階層型分割連合学習**

Md-Ferdous Pervej, Andreas F. Molisch

- ワイヤレスネットワークでは、リソース制約で分散クライアントによる大規模MLが難しい。
- 分割連合学習により、クライアント側のブロックのみでモデルを訓練し負荷を軽減。
- 個々のタスクに適した個別モデルが必要で、パーソナライズされた学習アルゴリズムを提案。
- 分割モデルの影響を理論的に分析し、クライアントごとに微調整したモデルで精度が向上。

ワイヤレスネットワークって大変そうだけど、みんなに合ったやり方を見つけていくのすごく面白そう！未来はもっと個々に最適化されたネットワーク環境になりそうだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.NI, cs.SY, eess.SY, **投稿日時:** 2024-11-09 02:41


- - -

### [IPMN Risk Assessment under Federated Learning Paradigm](http://arxiv.org/abs/2411.05697)

**連合学習パラダイムにおけるIPMNリスク評価**

Hongyi Pan, Ziliang Hong, Gorkem Durak, Elif Keles, Halil Ertugrul Aktas, Yavuz Taktak, Alpay Medetalibeyoglu, Zheyuan Zhang, Yury Velichko, Concetto Spampinato, Ivo Schoots, Marco J. Bruno, Pallavi Tiwari, Candice Bolan, Tamas Gonda, Frank Miller, Rajesh N. Keswani, Michael B. Wallace, Ziyue Xu, Ulas Bagci

- IPMNの正確な分類は早期介入が必要な高リスクケースを特定するために重要
- 複数の医療機関から得たMRIデータセットを用いた連合学習フレームワークを構築
- DenseNet-121を用いて、中央集権型と連合型での分類精度の比較を実施
- データプライバシーを保ちながら、連合学習は中央集権型に劣らない高い分類精度を達成

多くの病院のデータを集めているのがすごい！プライバシーを守りながら精度も保てるなんて、未来の医療がもっと安全で効率的になりそうだね。手術とか治療の精度が上がったら、患者さんも安心できるし、きっと嬉しいよね！



**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.DC, cs.LG, **投稿日時:** 2024-11-08 16:52


- - -

### [Network EM Algorithm for Gaussian Mixture Model in Decentralized Federated Learning](http://arxiv.org/abs/2411.05591)

**分散型連合学習におけるガウス混合モデルのためのネットワークEMアルゴリズム**

Shuyuan Wu, Bin Du, Xuetong Li, Hansheng Wang

- 従来のEMアルゴリズムの拡張は、クライアント間でデータが異なると精度が低下し、収束が難しい。
- 異質なデータに対応するため、現在と過去の推定を組み合わせるモーメントネットワークEM(MNEM)アルゴリズムを提案。
- 混合成分の分離が難しい場合に対処するため、部分的にラベル付けされたデータを活用する準教師ありMNEM(semi-MNEM)を開発。
- MNEMは適切な条件下で全体サンプル推定器に匹敵する統計的効率を達成し、semi-MNEMは収束速度を改善する。

仲良しな高校3年の女の子風な感想

今回の研究、連合学習のデータ活用が進化しててすごく面白そう！異質なデータもカバーできるから、いろんな現場で活躍しそうだね。挑戦的な課題に取り組んでいて、研究の未来に期待大だよ！



**トピック:** [連合学習](../../fl), **カテゴリ:** stat.ML, cs.LG, **投稿日時:** 2024-11-08 14:25


- - -

### [QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning](http://arxiv.org/abs/2411.05260)

**QuanCrypt-FL: 剪定付き量子化準同型暗号による安全な連合学習**

Md Jueal Mia, M. Hadi Amini

- 連合学習はプライベートデータ交換なしで共同モデル訓練を可能にするが、推論攻撃に脆弱。
- 準同型暗号はプライバシー保護に有用だが、通信オーバーヘッドが増加し計算負担が大きい。
- QuanCrypt-FLは低ビット量子化と剪定を組み合わせて攻撃耐性を強化しつつ計算コストを削減する。
- 既存の方法より優れた性能を実証し、暗号化や推論速度を大幅に改善している。

連合学習におけるプライバシー保護がしっかり考えられてていい感じだね！剪定とか量子化の工夫で効率を上げてるところもクールで、これなら安心してモデル訓練に挑めるね！



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, cs.AI, cs.DC, **投稿日時:** 2024-11-08 01:46
