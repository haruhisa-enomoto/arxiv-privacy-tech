---
title: 差分プライバシー (2024-10-04 ~ 2024-10-10)
date: 2024-10-04
---

差分プライバシーに関する論文まとめ (2024-10-04 ~ 2024-10-10)


- - -

### [Private Language Models via Truncated Laplacian Mechanism](http://arxiv.org/abs/2410.08027)

**切断ラプラス機構を用いたプライベート言語モデル**

Tianhao Huang, Tao Yang, Ivan Habernal, Lijie Hu, Di Wang

- 深層学習モデルはプライバシー攻撃に弱く、既存手法はプライバシー強度の限界がある
- 切断ラプラス機構を高次元に拡張し、プライベートな単語埋め込み手法を提案
- 提案手法は既存手法よりも分散が低く、理論的に優れていると示される
- 実験で高プライバシー状況でも非プライベートな場合と比較して性能低下を最小限に抑えた

新しいプライベートな手法ってすごいね！異次元のアイディアで、これからもっと安心してAIを使える時代がくるかもってワクワクする。

**Comment:** Accepted by EMNLP 2024, Main Track

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CL, cs.AI, cs.LG, **投稿日時:** 2024-10-10 15:25


- - -

### [Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning](http://arxiv.org/abs/2410.07738)

**マルチドメインプロトタイプによる連合学習適応の強化**

Jingyuan Zhang, Yiyang Duan, Shuaicheng Niu, Yang Cao, Wei Yang Bryan Lim

- 連合ドメイン適応は異なるデータドメインでの学習が課題で、データの異質性が原因で勾配更新が分散しがち
- 新しいフレームワークMPFTを提案し、カテゴリ固有のデータから得た情報で事前学習モデルを微調整
- サーバー側での有効な学習を通じプライバシーを守りつつ、クライアントへ最適化されたアダプタを配布
- MPFTは単一通信ラウンドで収束し、計算と通信コストを削減しつつ高い精度を実現

この研究なんだか面白そう！MPFTって方法で、効率よくプライバシーもバッチリ守りつつ性能を向上させてるのいい感じ。プロトタイプを使った攻撃の検証も含めて、AI担当者には助かる技術になるかもね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-10 09:15


- - -

### [Adaptive Batch Size for Privately Finding Second-Order Stationary Points](http://arxiv.org/abs/2410.07502)

**プライバシーを考慮した二次定常点の適応バッチサイズの発見**

Daogao Liu, Kunal Talwar

- 差分プライバシー制約下でFOSPとSOSPの間にはギャップがある
- 既存研究により、$\alpha$-SOSPの発見に関する具体的なアルゴリズムが示されている
- SpiderBoostアルゴリズムを基に適応バッチサイズとバイナリツリーメカニズムを提案
- 提案手法によりFOSPの状態に匹敵するコストでSOSPを発見可能に

差分プライバシーを守りながら二次定常点を見つけるなんて、すごくチャレンジングな問題に挑んでるね！この研究が進むと、もっと安全で効率的なイノベーションができるようになるかも！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DS, stat.ML, **投稿日時:** 2024-10-10 00:34


- - -

### [Bayes-Nash Generative Privacy Protection Against Membership Inference Attacks](http://arxiv.org/abs/2410.07414)

**Bayes-Nash生成的プライバシー保護：メンバーシップ推論攻撃に対抗するために**

Tao Zhang, Rajagopal Venkatesaraman, Rajat K. De, Bradley A. Malin, Yevgeniy Vorobeychik

- データ共有は重要だが、個人の参加が重要視されメンバーシップ推論攻撃がプライバシーを脅かす。
- プライバシー保護のためにベイズゲームモデルを提案し、それにより期待効用とプライバシー損失を最小化する。
- Bayes-Nash生成的プライバシーとリスクを導入し、攻撃者の異なる好みにも強いプライバシーと効用のバランスを図る。
- 理論および実証的に、自分たちの方法が要約統計のプライバシー保護において最新の方法を上回ることを示す。

ベイズゲームでプライバシーを守ろうとする発想が面白いね！攻撃者の動きに応じた戦略が練られてるとは、データの世界での駆け引きみたい！将来こういった技術がもっと普及すれば、より安心して情報を共有できる社会が訪れるのかも。

**Comment:** arXiv admin note: substantial text overlap with arXiv:2406.01811

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-09 20:29


- - -

### [Private and Communication-Efficient Federated Learning based on Differentially Private Sketches](http://arxiv.org/abs/2410.05733)

**差分プライベートスケッチに基づくプライバシーと通信効率の良い連合学習**

Meifan Zhang, Zhanhong Xie, Lihua Yin

- 連合学習ではプライバシーの漏洩リスクと通信の非効率が課題
- DPSFLは差分プライバシースケッチを使用し通信効率とプライバシーを向上
- 勾配クリッピングはノイズの影響を抑えるがバイアスを生むため性能に悪影響
- DPSFL-ACは適応クリッピングによりバイアスを軽減し優れた性能を実証

連合学習って、ただ共有すればいいってもんじゃないのが面白いね！DPSFLでプライバシーも通信も改善できちゃうなんて、実用化されたらすごく便利そうだし、頼もしいなって思っちゃう！💡



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-08 06:50


- - -

### [KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server](http://arxiv.org/abs/2410.05725)

**KnowledgeSG: サーバからの知識蒸留によるプライバシー保護付き合成テキスト生成**

Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang

- 大規模言語モデルの記憶化でプライバシー懸念が生じる
- 合成データ利用は性能向上とプライバシー保護の両立が難しい
- KnowledgeSGは、差分プライバシーと知識蒸留で品質と性能を向上
- 連合学習に着想を得て、モデルをクライアント・サーバ間で共有しプライバシーを保護

この方法は、プライバシーも守りつつ性能も上げるなんてすごくおもしろそう！医療や金融みたいなデータが重要でセンシティブな分野でもうまくいくなら、めっちゃ役立ちそうだね。どんな時代が来るんだろう、ワクワクする～！

**Comment:** EMNLP 2024 Main

**トピック:** [連合学習](../../fl), [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-10-08 06:42


- - -

### [A Blockchain-Enhanced Framework for Privacy and Data Integrity in Crowdsourced Drone Services](http://arxiv.org/abs/2410.05653)

**ブロックチェーン強化型フレームワークによる群衆からのドローンサービスのプライバシーとデータ完全性**

Junaid Akram, Ali Anaissi

- 消費者向けドローンをブッシュファイア管理に統合し、サービス改善とデータプライバシーに対処
- ブッシュファイア当局がデータを利用し、ドローン運営者が提供する市場を形成
- データ提供者のプライバシーを局所的差分プライバシーで保護し、プライバシー基準に準拠
- ブロックチェーンで公正なデータと料金交換を促進し、不変の記録で責任を強化

災害管理にドローンを使うってすごく活用されてるよね！このシステムでなら、みんなにとって安全で信頼できる情報が飛び交う未来が見えてきそうだよ。大規模への適応もばっちりだから、実際の現場でも活躍してくれるかも！

**Comment:** 8 pages, 5 figures, accepted and to be published in the proceedings   of 22nd International Conference on Service-Oriented Computing (ICSOC 2024)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-08 03:08


- - -

### [Privacy Vulnerabilities in Marginals-based Synthetic Data](http://arxiv.org/abs/2410.05506)

**周辺確率に基づく合成データのプライバシー脆弱性**

Steven Golob, Sikha Pentyala, Anuar Maratkhan, Martine De Cock

- 合成データ生成（SDG）は実データと似つつ個人情報を排除することを目指している
- 数多くのSDGアルゴリズムは強力な差分プライバシー保証を提供している
- 周辺確率を保持するSDGアルゴリズムには個人情報が漏洩する危険があると判明
- 新たなメンバーシップ推論攻撃MAMA-MIAを使い、脆弱性が効率的に暴かれる

個人情報の安全性って、どんな技術でも100%確保するのは難しいんだね。それでも続々と新しい手法が開発されててすごいと思う！どんな対策がこれから登場するのかすっごく楽しみ〜！



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), [PETs](../../pets), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-10-07 21:24


- - -

### [Testing Credibility of Public and Private Surveys through the Lens of Regression](http://arxiv.org/abs/2410.05458)

**回帰の視点から見る公共およびプライベート調査の信頼性**

Debabrota Basu, Sourav Chakraborty, Debarshi Chanda, Buddha Dev Das, Arijit Ghosh, Arnab Ray

- サンプル調査が母集団の信頼できる表現かどうかを回帰分析でテストするアルゴリズムを設計
- Gaussian Differential Privacyを用いて、信頼性の検証を差分プライバシー下の調査にも拡張
- 提案したアルゴリズムで、ノイズがあるデータから線形回帰モデルを学習することが可能
- リアルデータと合成データでアルゴリズムの性能を数値的に実証し、理論的な正しさを証明

サンプル調査とプライバシー技術って、ずっと複雑だと思ってたから、こうやってアルゴリズムで検証できるってすごいよね！しかも、ノイズのあるデータからも学習できるなんて、もっと幅広く応用が効きそう～！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ME, stat.ML, **投稿日時:** 2024-10-07 19:44


- - -

### [DiSK: Differentially Private Optimizer with Simplified Kalman Filter for Noise Reduction](http://arxiv.org/abs/2410.03883)

**DiSK: ノイズ低減のためのカマンフィルターを用いた差分プライベート最適化技術**

Xinwei Zhang, Zhiqi Bu, Borja Balle, Mingyi Hong, Meisam Razaviyayn, Vahab Mirrokni

- 差分プライバシーは個人データを保護する枠組みであり、差分プライベート最適化技術が注目されている
- 既存の技術は大規模なトレーニングで性能が低下する問題があり、それが大量のノイズ注入に起因
- DiSKという新しいフレームワークを提案し、カマンフィルターを用いてプライベート化された勾配をデノイズ
- 広範な実験でDiSKが標準のDP最適化手法を超える性能を示し、複数のベンチマークで差をつけた

わー、このDiSKって技術すごいね！大規模データでもプライバシーを保ちつつ性能アップできるなんて、今後のAIの発展に大きな影響を与えそう♪



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ML, **投稿日時:** 2024-10-04 19:30


- - -

### [Camel: Communication-Efficient and Maliciously Secure Federated Learning in the Shuffle Model of Differential Privacy](http://arxiv.org/abs/2410.03407)

**Camel: 差分プライバシーのシャッフルモデルにおける通信効率の高い悪意あるセキュア連合学習**

Shuangqing Xu, Yifeng Zheng, Zhongyun Hua

- 連合学習はクライアントのプライベートデータを公開せずにモデルを学習するパラダイム
- LDPメカニズムでプライバシー保証を提供するが、ノイズが多くモデルの有用性が低下
- シャッフルモデルを用いてプライバシー増幅し、より良いプライバシー-ユーティリティのトレードオフを実現
- Camelは通信効率とセキュリティを最適化し、RDPを用いてプライバシー損失を厳しく評価

連合学習って面白そうだよね。大人数で協力して賢いモデルを育てるなんて、未来の学校みたいでワクワクする！Camelの方法で、もっと安全で効率的になっていくのかなぁ。

**Comment:** Accepted by CCS'2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-04 13:13
