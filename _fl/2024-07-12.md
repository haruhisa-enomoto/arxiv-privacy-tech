---
title: 連合学習 (2024-07-12 ~ 2024-07-18)
date: 2024-07-12
---

連合学習に関する論文まとめ (2024-07-12 ~ 2024-07-18)


- - -

### [Harvesting Private Medical Images in Federated Learning Systems with Crafted Models](http://arxiv.org/abs/2407.09972)

**連合学習システムにおけるクラフトモデルを用いたプライベート医療画像の収集**

Shanghao Shi, Md Shahedul Haque, Abhijeet Parida, Marius George Linguraru, Y. Thomas Hou, Syed Muhammad Anwar, Wenjing Lou

- MediLeak攻撃を提案し、悪意のあるサーバーがクライアントからモデル更新を通じて高精度な患者画像を復元する方法を示す
- サーバーは元のモデルにクラフトモジュールを追加し、連合学習の過程でクライアントに配布してローカルトレーニングを実行させる
- クラフトモジュールのパラメーター更新を基に、サーバーがプライベートデータを解析・復元する技術を実装
- MedMNISTとCOVIDx CXR-4データセットで検証し、高い復元率と定量スコアを達成、患者画像の病気分類精度も元のデータと遜色ない

連合学習の裏に潜む危険性が明らかにされるとか、本当にびっくりだよね。最先端技術を悪用するアイデアにはドキドキしちゃうけど、対策も必要だね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-07-13 18:31


- - -

### [Partner in Crime: Boosting Targeted Poisoning Attacks against Federated Learning](http://arxiv.org/abs/2407.09958)

**共犯関係: 連合学習に対するターゲット型ポイズニング攻撃の強化**

Shihua Sun, Shridatt Sugrim, Angelos Stavrou, Haining Wang

- 連合学習（FL）はターゲット型ポイズニング攻撃に対して脆弱である
- BoTPAはFLトレーニング前にデータラベルを偽装することで攻撃を強化
- BoTPAは複数の攻撃に対してその効果と適合性を評価
- BoTPAは様々な防御方法に対して攻撃成功率の大幅な向上を達成

FLへの攻撃方法ってこんなに工夫されているんだね！BoTPAの強化策は未来の研究にすごく活かせそう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-07-13 17:59


- - -

### [Enhancing Semantic Segmentation with Adaptive Focal Loss: A Novel Approach](http://arxiv.org/abs/2407.09828)

**適応焦点損失による意味セグメンテーションの強化: 新たなアプローチ**

Md Rakibul Islam, Riad Hassan, Abdullah Nazib, Kien Nguyen, Clinton Fookes, Md Zahidul Islam

- 小さく不規則な物体のセグメンテーション効果が低下する問題がある
- SmoothnessとVolume情報を取り入れた損失関数で改善を試みる
- 適応焦点損失(A-FL)はクラス不均衡を軽減し困難な例に重点を置く
- ResNet50-encoded U-NetでA-FLを評価し、一般的な手法を上回る成果を達成

この研究、医療画像の精度がすごく向上しそう！新しい診断工具の発展に繋がるって、未来が楽しみ♡

**Comment:** 15 pages, 4 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.AI, cs.CV, **投稿日時:** 2024-07-13 09:41


- - -

### [Private Heterogeneous Federated Learning Without a Trusted Server Revisited: Error-Optimal and Communication-Efficient Algorithms for Convex Losses](http://arxiv.org/abs/2407.09690)

**信頼できるサーバーなしでのプライベート異種連合学習再訪：凸損失に対する誤差最適・通信効率のアルゴリズム**

Changyu Gao, Andrew Lowy, Xingyu Zhou, Stephen J. Wright

- プライバシー保護のため、各シロ（例：病院）は患者データをサーバーや他のシロから守る必要がある
- ISRL-DPは各シロのデータを差分プライバシーで守り、データ漏洩を防ぐ
- 先行研究は同質データ（i.i.d.）での最適リスク境界を示していたが、異質データ（非i.i.d.）でも最適リスクが達成可能と確認
- 新アルゴリズムは、通信ラウンドを削減しつつ、滑らかな損失関数に対して最適リスクと一致する通信複雑性を達成

この研究、めっちゃ興味深いね！プライバシー守りながら効率的にデータ使う方法が現実的になりそうだよね。未来の医療とかにすごく役立ちそう！

**Comment:** The 41st International Conference on Machine Learning (ICML 2024)

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, math.OC, **投稿日時:** 2024-07-12 21:20


- - -

### [BoBa: Boosting Backdoor Detection through Data Distribution Inference in Federated Learning](http://arxiv.org/abs/2407.09658)

**BoBa: 連合学習におけるデータ分布推論を利用したバックドア検出の強化**

Ning Wang, Shanghao Shi, Yang Xiao, Yimin Chen, Y. Thomas Hou, Wenjing Lou

- 連合学習は分散性により中毒攻撃に脆い
- 非IIDデータはバックドア検出が困難であり、以前の手法は効果が低い
- 提案されたBoBaは、データ分布推論を用いてクラスタリングと投票システムに基づく検出を行う
- BoBaは、重複クラスタリングを用いて検出の堅牢性を向上し、攻撃成功率を0.001以下に抑えつつ高精度を維持

バックドア攻撃をした犯人も見つけられるかもね！次世代の連合学習の基礎になりそう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-07-12 19:38


- - -

### [Novel clustered federated learning based on local loss](http://arxiv.org/abs/2407.09360)

**局所損失に基づく新しいクラスタ化連合学習**

Endong Gu, Yongxin Chen, Hao Wen, Xingju Cai, Deren Han

- LCFLは、連合学習におけるクライアント間のデータ分布評価のための新しい指標
- プライバシー懸念に対応し、非凸モデルへの適用性を向上させる
- クライアントのデータ分布の事前知識を必要としない
- 数値実験で、複数のベンチマークにおいて優れた性能を示す

新しいアプローチって感じでワクワクするね。実際に使われるようになるといいなー！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, math.OC, **投稿日時:** 2024-07-12 15:37


- - -

### [Provable Privacy Advantages of Decentralized Federated Learning via Distributed Optimization](http://arxiv.org/abs/2407.09324)

**分散最適化を介した分散型連合学習の証明可能なプライバシー利点**

Wenrui Yu, Qiongxiu Li, Milan Lopuhaä-Zwakenberg, Mads Græsbøll Christensen, Richard Heusdens

- 分散型FLは、理論的にも実証的にも中央集権型よりプライバシー保護が優れていると証明
- iterativelyなプロセスによるプライバシー損失の定量化が課題であるが、情報理論ベースの解析を実施
- パッシブアドバサリモデルを含む複数の脅威シナリオでのプライバシー漏洩の境界を確立
- 深層ニューラルネットワークでは、分散型FLが中央集権型よりプライバシーリスクが低いことを示す事例研究を実施

分散型FLについてのプライバシー分析って新鮮だし、応用の幅が広がりそう！深層ニューラルネットにも対応してるのが特に楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.IT, math.IT, **投稿日時:** 2024-07-12 15:01


- - -

### [FedVAE: Trajectory privacy preserving based on Federated Variational AutoEncoder](http://arxiv.org/abs/2407.09239)

**FedVAE: 連合変分オートエンコーダを用いた軌道プライバシー保護**

Yuchen Jiang, Ying Wu, Shiyao Zhang, James J. Q. Yu

- 軌道データはITSなどの交通システムで重要であり、LBSが個人化サービスを提供するために活用
- 現在のプライバシー保護方法（Kアノニミティ、差分プライバシー）にはデータ特徴への影響や現実的でない軌道生成などの課題がある
- 提案するFedVAEは、軌道データの構造を保ちつつプライバシーを守る新しいデータセットを生成する
- FedVAEは連合学習を活用してユーザーデータをローカルに保持し、従来の方法よりも優れた性能を示した

新しい手法で実際のデータ構造を保ちつつプライバシーを守れるなんて、画期的だね。連合学習を使うことで個人情報を外部に出さないっていうのもいいなぁ。

**Comment:** 2023 IEEE 98th Vehicular Technology Conference

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.AI, **投稿日時:** 2024-07-12 13:10


- - -

### [PriRoAgg: Achieving Robust Model Aggregation with Minimum Privacy Leakage for Federated Learning](http://arxiv.org/abs/2407.08954)

**PriRoAgg:連合学習における最小プライバシー漏洩と堅牢なモデル集約の実現**

Sizai Hou, Songze Li, Tayyebeh Jahani-Nezhad, Giuseppe Caire

- 連合学習はユーザープライバシーを保護しつつ分散データを活用するが、プライバシーと堅牢性の課題がある
- 既存の解決策は簡単な有効性チェックに依存しており、高度な攻撃への対策が不十分
- より複雑な堅牢集約アルゴリズムでは、一部のプライバシー漏洩が発生する
- PriRoAggは集計されたプライバシー概念を導入し、ゼロ知識証明を用いて堅牢な集約を実現

データの安全性を保ちながら堅牢なモデル構築って興味深いな～。これ、具体的にどのくらいの攻撃に耐えられるのか知りたいよね！



**トピック:** [連合学習](../../fl), [ゼロ知識証明](../../zkp), **カテゴリ:** cs.CR, **投稿日時:** 2024-07-12 03:18


- - -

### [Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses](http://arxiv.org/abs/2407.08935)

**連合グラフ学習における分散バックドア攻撃と認証防御**

Yuxin Yang, Qiang Li, Jinyuan Jia, Yuan Hong, Binghui Wang

- 連合グラフ学習(FedGL)は多様なソースからグラフデータを学習するFLの新しいフレームワークである
- 本研究は、FedGLに対する効果的でステルス性があり永続的なバックドア攻撃を提案
- 提案された攻撃はサブグラフをトリガーとして使用し、適応的なトリガー生成器を設計
- 本研究ではまた、攻撃に対する認証防御を開発し、複数のサブグラフへの分割と過半数投票を活用 

連合学習のセキュリティ強化って今後ますます重要になりそう！新しい防御手法がどれだけ実用的かも気になるね。

**Comment:** This paper is accepted to CCS2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-07-12 02:43
