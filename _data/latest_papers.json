[
  {
    "url": "http://arxiv.org/abs/2412.18557",
    "title": "FedVCK: Non-IID Robust and Communication-Efficient Federated Learning via Valuable Condensed Knowledge for Medical Image Analysis",
    "japanese_title": "FedVCK: 医学画像解析のための貴重な凝縮知識を活用した非独立同分布に強く通信効率の良い連合学習",
    "authors": [
      "Guochen Yan",
      "Luyuan Xie",
      "Xinyi Gao",
      "Wentao Zhang",
      "Qingni Shen",
      "Yuejian Fang",
      "Zhonghai Wu"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "Accepted by AAAI 2025",
    "summary": "- 医療機関間の連携においてデータは非独立同分布であり、クライアントドリフトや成績低下を招く\n- 提案するFedVCKはモデルが導く最も必要な知識を選び、通信コストを抑えつつ非IID問題を効果的に解決\n- クライアント側で知識を凝縮した小さなデータセットを作成し、不要な通信を最小限に抑える\n- サーバー側での関係的教師付きコントラスト学習により、モデル更新のための監視信号を強化\n\n貴重な知識を凝縮することで通信頻度を抑えつつ、性能向上を目指すアイデアがすごいね！医療現場でのデータ共有のハードルをうまくクリアしてるのが興味深いなぁ。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-12-24T17:20:43+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18524",
    "title": "HTR-JAND: Handwritten Text Recognition with Joint Attention Network and Knowledge Distillation",
    "japanese_title": "HTR-JAND: 手書き文字認識における共同注意ネットワークと知識蒸留",
    "authors": [
      "Mohammed Hamdan",
      "Abderrahmane Rahiche",
      "Mohamed Cheriet"
    ],
    "categories": [
      "cs.CV"
    ],
    "comment": "",
    "summary": "- 手書き文字認識（HTR）は、歴史的文書の多様な書式や劣化した品質に対応するのが難しい。\n- HTR-JANDは、特徴抽出と知識蒸留を組み合わせる効率的なHTRフレームワークを提案。\n- マルチヘッド自己注意とプロクシマ注意が結合した注意メカニズムで強力なシーケンスモデリングを実現。\n- HTR-JANDフレームワークで、モデル圧縮しつつ認識精度を保ち、新たなCERを達成。\n\n手書き文字認識って歴史的文書には結構難しそうだけど、技術進化ってすごいよね！この新しいアーキテクチャで効率性も精度もアップするなんて、未来の研究が楽しみだな！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-12-24T16:08:24+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18515",
    "title": "Subsampling, aligning, and averaging to find circular coordinates in recurrent time series",
    "japanese_title": "再帰的時系列における円形座標を見つけるための部分サンプリング、整列、平均化",
    "authors": [
      "Andrew J. Blumberg",
      "Mathieu Carrière",
      "Jun Hou Fung",
      "Michael A. Mandell"
    ],
    "categories": [
      "stat.ML",
      "cs.CG",
      "cs.LG",
      "math.AT"
    ],
    "comment": "",
    "summary": "- データの再帰性に基づく円形座標を見つける新アルゴリズムを提案\n- 不均一なサンプリング密度の補正技術を導入し、座標のロバスト性を向上\n- 部分サンプルの整列と平均化により、他の方法より効率的な手法を提供\n- 合成データとニューロン活動の記録を使い技術を検証し、特定の行動に対応する脳状態をモデル化\n\nこの研究、めちゃくちゃ面白そう！脳の状態が特定の行動にどうつながっているのか、C. elegansを通じて見える化しちゃうのがすごいよね。再帰データでの新手法が他の分野でも活用できるかも？！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-12-24T15:52:51+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18513",
    "title": "FedGIG: Graph Inversion from Gradient in Federated Learning",
    "japanese_title": "FedGIG: 連合学習における勾配からのグラフ逆推論",
    "authors": [
      "Tianzhe Xiao",
      "Yichen Li",
      "Yining Qi",
      "Haozhao Wang",
      "Ruixuan Li"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "comment": "",
    "summary": "- 連合学習は勾配逆推論攻撃に脆弱で、プライベートデータが漏れる可能性がある\n- 従来の手法は画像やテキスト向けで、グラフデータには直接適用できない\n- FedGIGはグラフ構造データに特化した新しい逆推論手法である\n- テストではFedGIGが既存の手法よりも高い精度を持つことを確認した\n\n連合学習でのグラフデータのプライバシーを守るための技術なんて新鮮！グラフ構造特有のデータ扱いに特化しているところが特に興味深いなぁ。どんな応用ができるのかワクワクするね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-12-24T15:52:21+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18507",
    "title": "An Empirical Analysis of Federated Learning Models Subject to Label-Flipping Adversarial Attack",
    "japanese_title": "ラベルフリップ攻撃を受ける連合学習モデルの実証的分析",
    "authors": [
      "Kunal Bhatnagar",
      "Sagana Chattanathan",
      "Angela Dang",
      "Bhargav Eranki",
      "Ronnit Rana",
      "Charan Sridhar",
      "Siddharth Vedam",
      "Angie Yao",
      "Mark Stamp"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合学習モデルに対するラベルフリップ攻撃を実証的に分析\n- MLR、SVC、MLP、CNN、RNN、ランダムフォレスト、XGBoost、LSTMを用いて実験\n- 10から100の連合クライアント、ラベルの変更率10%から100%で攻撃をシミュレート\n- モデルによって対抗能力が異なり実用的な影響を考察\n\nラベルフリップ攻撃がどのモデルにどんな影響を与えるのか、リアルに分析しているのが面白いね。同じアルゴリズムでもこれだけ違いがあるのなら、攻撃対策もさらに必要だなって思う！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-12-24T15:47:25+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18460",
    "title": "GeFL: Model-Agnostic Federated Learning with Generative Models",
    "japanese_title": "GeFL: ジェネレーティブモデルを用いたモデルアグノスティックな連合学習",
    "authors": [
      "Honggu Kang",
      "Seohyeon Cha",
      "Joonhyuk Kang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "comment": "20 pages",
    "summary": "- 連合学習はユーザープライバシーを守る分散学習の有望な手法\n- 大規模モデルは一部のユーザーには負担で、異なる計算能力のために異種モデルが必要\n- ジェネレーティブモデルを用いるGeFLは異種モデル間の知識統合を図る\n- GeFL-Fは特徴生成モデルでプライバシーとスケーラビリティを改善する\n\n連合学習って未来的だよね！いろんな能力のデバイスが一緒に学習できるって、まるでチームプレイみたいでおもしろいなぁ。技術がもっと進むと、セキュリティもさらに向上して安心かな。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-12-24T14:39:47+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18426",
    "title": "GUI Testing Arena: A Unified Benchmark for Advancing Autonomous GUI Testing Agent",
    "japanese_title": "GUIテストアリーナ: 自律的GUIテストエージェントを進化させるための統一ベンチマーク",
    "authors": [
      "Kangjia Zhao",
      "Jiahui Song",
      "Leigang Sha",
      "Haozhan Shen",
      "Zhi Chen",
      "Tiancheng Zhao",
      "Xiubo Liang",
      "Jianwei Yin"
    ],
    "categories": [
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 現状のGUIエージェント研究は自動化に焦点を当て、様々なGUIシナリオで制限がある\n- GUI自動テスト環境GTArenaを提案し、一貫した操作を可能にする標準化された環境を提供\n- テストを3つのサブタスクに分け、実際のアプリや合成データを用いて包括的評価を実施\n- 現存の先進的モデルでも全サブタスクで高性能を発揮できず、実用性に大きなギャップがある\n\n新しいGUIエージェントの開発に向けての基準ができる感じがするよね！特に、今後の技術の進化がどこに向かうのか見える指針になるのがワクワクする♪",
    "topics": [
      "合成データ"
    ],
    "published": "2024-12-24T13:41:47+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18355",
    "title": "Addressing Spatial-Temporal Data Heterogeneity in Federated Continual Learning via Tail Anchor",
    "japanese_title": "連合継続学習における時空間データの不均一性への対応",
    "authors": [
      "Hao Yu",
      "Xin Yang",
      "Le Zhang",
      "Hanlin Gu",
      "Tianrui Li",
      "Lixin Fan",
      "Qiang Yang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合継続学習は、各クライアントがタスクストリームから知識を継続的に更新する手法\n- クライアント間の空間データの不均一性とタスク間の時間データの不均一性が課題\n- Federated Tail Anchor (FedTA)を提案し、モデルのパラメータと出力の忘却を克服\n- 入力強化や選択的入力知識融合などを含むFedTAが、既存手法より優れた性能を実証\n\n連合学習の課題を解決する新しい手法が提案されてて面白そう！時空間の不均一性をどう克服するのかっていう技術が、実用に向けた大きな一歩になりそうだね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-12-24T11:35:40+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18232",
    "title": "Efficient Long Context Language Model Retrieval with Compression",
    "japanese_title": "効率的な長文コンテキスト言語モデルの圧縮による情報検索",
    "authors": [
      "Minju Seo",
      "Jinheon Baek",
      "Seongyun Lee",
      "Sung Ju Hwang"
    ],
    "categories": [
      "cs.IR"
    ],
    "comment": "",
    "summary": "- 長文コンテキスト言語モデル（LCLM）は、多量の情報を一度に処理し、伝統的な検索手法を超える可能性を持つ\n- 多数のパッセージを処理するには計算コストが高く、推論時も時間がかかる\n- パッセージを圧縮する新手法を提案し、検索性能を最大化しつつ長さを削減\n- 9つのデータセット実験で、圧縮サイズを1.91倍にしながら検索性能を6%向上\n\nデータを圧縮しても情報がしっかり取り出せるってすごいね！これからは、もっと早く情報が見つかるようになるかな？圧縮の技術がこんなに効くとは思わなかった！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-12-24T07:30:55+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18169",
    "title": "KunServe: Elastic and Efficient Large Language Model Serving with Parameter-centric Memory Management",
    "japanese_title": "KunServe: パラメータ中心メモリ管理による弾性で効率的な大規模言語モデルのサービス提供",
    "authors": [
      "Rongxin Cheng",
      "Yifan Peng",
      "Yuxin Lai",
      "Xingda Wei",
      "Rong Chen",
      "Haibo Chen"
    ],
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 大規模言語モデルの状態保持は、高負荷時にGPUメモリを圧迫し、遅延を引き起こす\n- 既存のKVCache中心のアプローチは、リクエストの性能とのトレードオフがあり、SLOの違反を招く\n- パラメータを選択的に削除し、リクエスト用のメモリを確保する方法を提案\n- 新しいリモートアテンションメカニズムで、他のGPUからメモリを借りることで高効率なサービスを実現\n\nこのアプローチは、メモリ管理を効果的にしながらも、リクエストの処理をスムーズにするなんて、すごいね！これからの多様なリクエストに対しても強力な武器になりそうだなぁ。",
    "topics": [
      "TEE"
    ],
    "published": "2024-12-24T05:07:46+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18111",
    "title": "AIGT: AI Generative Table Based on Prompt",
    "japanese_title": "AIGT: プロンプトに基づくAI生成表",
    "authors": [
      "Mingming Zhang",
      "Zhiqing Xiao",
      "Guoshan Lu",
      "Sai Wu",
      "Weiqiang Wang",
      "Xing Fu",
      "Can Yi",
      "Junbo Zhao"
    ],
    "categories": [
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 企業データ資産の80%以上を占める表形式データは重要で、プライバシーの懸念が高まっている。\n- 大規模言語モデル（LLMs）は高次元データの課題を克服しつつ、リアルな合成データ生成に有効。\n- 新たなAIGTアプローチは、テーブルのメタデータ情報をプロンプトとして利用し、超高品質なデータを生成。\n- 長トークン分割アルゴリズムにより、LLMsのトークン制約を克服し、様々なスケールのテーブルをモデル化。\n\n合成データ生成の最先端を行ってる感じでワクワクしちゃう！プライバシー守りながら分析できるのって、未来のデータサイエンスの革命になりそうだよね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-12-24T02:51:06+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2412.18086",
    "title": "Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner",
    "japanese_title": "コンテキスト学習による交通シナリオ生成でより良いモーションプランナーを学習",
    "authors": [
      "Aizierjiang Aiersilan"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.GR",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 自動運転のモーションプランニングでは、希少なシナリオの対応が課題。\n- 手動でのシナリオ作成はコストが高く、効率的でない。\n- 大規模言語モデルを用いてテキストからシナリオを生成する方法を提案。\n- 合成データを使うことで、モーションプランナーの性能が向上することを実証。\n\nわたし、この研究めっちゃおもしろいと思った！合成データでモーションプランナーがもっと安全になったら、未来の交通ってもっと平和でスムーズになりそうだね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-12-24T01:52:19+00:00"
  }
]