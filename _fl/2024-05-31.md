---
title: 連合学習 (2024-05-31 ~ 2024-06-06)
date: 2024-05-31
---

連合学習に関する論文まとめ (2024-05-31 ~ 2024-06-06)


- - -

### [ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning](http://arxiv.org/abs/2405.20975)

**ACE: 連合学習における貢献評価方法へのモデルポイズニング攻撃**

Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bo Li, Radha Poovendran

- 連合学習（FL）は、クライアントがローカルデータを共有せずにグローバルモデルを共同で訓練する手法
- ACE攻撃は、悪意のあるクライアントが自身の貢献を高く評価させるための手法
- 理論的および実証的評価により、ACEが貢献評価方法を効果的に欺くことを示す
- 提案された対策はACEへの効果が不十分であり、新たな防御策の必要性を強調

悪意のあるクライアントがシステムを欺く手法が存在するなんて驚きだよね！これからもっと強力な防御策が開発されるといいな。

**Comment:** To appear in the 33rd USENIX Security Symposium, 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, cs.LG, **投稿日時:** 2024-05-31 16:21


- - -

### [Sheaf HyperNetworks for Personalized Federated Learning](http://arxiv.org/abs/2405.20882)

**連合学習のための層ハイパーネットワーク**

Bao Nguyen, Lorenzo Sani, Xinchi Qiu, Pietro Liò, Nicholas D. Lane

- GHNsはGNNsとHNsを組み合わせたが、過剰平滑化や異種性などの問題がある
- PFLにはGHNsが直接適用できず、あらかじめクライアント関係グラフがない場合が多い
- PFLの文脈で限界を克服するため、セルラー層理論とHNsを組み合わせたSHNsを提案
- SHNsは複雑な非IIDシナリオで精度が最大2.7%、平均二乗誤差が最大5.3%改善

新しいアーキテクチャがどれだけ性能を引き上げるのかワクワクするね！応用先も広くて、交通予測や天気予報にも使えるなら未来が楽しみ！

**Comment:** 25 pages, 12 figures, 7 tables, pre-print under review

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-05-31 14:55


- - -

### [BackdoorIndicator: Leveraging OOD Data for Proactive Backdoor Detection in Federated Learning](http://arxiv.org/abs/2405.20862)

**BackdoorIndicator: 連合学習におけるバックドア検出のためのOODデータ活用**

Songze Li, Yanbo Dai

- 連合学習システムでは、悪意あるクライアントが毒されたモデルをアップロードしバックドアを植え付ける可能性がある
- 既存のバックドア防御はシステムや攻撃者設定によって性能が不安定である
- BackdoorIndicatorは、サーバがOODデータを用いてバックドアの存在を正確に検出する新たな検出メカニズムを提案する
- 一連の実証実験を通じて、BackdoorIndicatorは既存の防御策に比べ一貫した優れた性能と実用性を示した

バックドア検出のソリューションなんてめっちゃかっこいいじゃん！セキュリティと機械学習両方好きな人にはすごく興味深い内容だね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-05-31 14:44


- - -

### [Pursuing Overall Welfare in Federated Learning through Sequential Decision Making](http://arxiv.org/abs/2405.20821)

**連合学習における逐次意思決定による全体的福祉の追求**

Seok-Ju Hahn, Gi-Soo Kim, Junghye Lee

- 単一のグローバルモデルでは全クライアントに対して均等に性能を提供できない
- クライアントごとの公平性を達成するため、適応的な集約方式の導入が必要
- 既存の公平性を考慮した集約戦略はオンライン凸最適化フレームワークで統一できる
- 細分化された新手法AAggFFは既存方法よりもクライアントレベルの公平性が向上

連合学習でクライアントごとの公平性をめちゃ考えてるね。新しいAAggFFがどれだけ実用的か、コード見て試したくなっちゃう♪

**Comment:** Accepted at ICML 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, stat.ML, **投稿日時:** 2024-05-31 14:15


- - -

### [Share Your Secrets for Privacy! Confidential Forecasting with Vertical Federated Learning](http://arxiv.org/abs/2405.20761)

**秘密を共有してプライバシーを守ろう！垂直連合学習での機密予測**

Aditya Shankar, Lydia Y. Chen, Jérémie Decouchant, Dimitra Gkorou, Rihan Hai

- 垂直連合学習は、予知保全と機械制御などの産業用時系列予測に有望
- データプライバシーと小規模・ノイズデータでの過学習が課題
- 秘密共有と秘密計算を用いたサーバーレス予測を提案
- 提案フレームワークは中央集権的手法と比較して予測精度が向上し、23.81%の精度向上を達成

データプライバシーを保ちながら予測精度も上げるなんて、すごく興味深いよね！セキュリティに煩わされずに産業がもっと効率的になるかも。

**Comment:** Submitted to the 27TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE   (ECAI 2024)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-05-31 12:27


- - -

### [GANcrop: A Contrastive Defense Against Backdoor Attacks in Federated Learning](http://arxiv.org/abs/2405.20727)

**GANcrop: 連合学習におけるバックドア攻撃に対するコントラスト防御**

Xiaoyun Gan, Shanyu Gan, Taizhi Su, Peng Liu

- 連合学習はデータプライバシー保護のために注目されているが、バックドア攻撃の機会も提供する
- GANcropはコントラスト学習を用いて悪意あるモデルと善良なモデルの違いを探る新たな防御機構を提案
- GANを使用してバックドアトリガーを回収し、ターゲットを絞った緩和戦略を実施する
- 実験結果では、特に非独立同分布（non-IID）シナリオで、バックドア攻撃から効果的に保護しつつ、高いモデル精度を維持することが示された

連合学習のバックドア攻撃を防ぐ新手法って、めちゃ楽しそう！GANを使ってうまく対処してるってみたいだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, cs.DC, **投稿日時:** 2024-05-31 09:33


- - -

### [GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search](http://arxiv.org/abs/2405.20725)

**GI-NAS: 適応的ニューラルアーキテクチャ検索による勾配逆転攻撃の強化**

Wenbo Yu, Hao Fang, Bin Chen, Xiaohang Sui, Chuan Chen, Hao Wu, Shu-Tao Xia, Ke Xu

- 連合学習システムで勾配を逆転し、ローカルクライアントの機微データを再構築する手法
- 多くの手法は明示的な事前知識（例: 事前訓練済み生成モデル）に依存しているが、これは現実シナリオでは入手困難
- 提案手法GI-NASはニューラルアーキテクチャ検索を通じて暗黙的な事前知識を活用し、ネットワークを自動検索
- 高解像度画像や大きなバッチサイズ、先進的な防御戦略など、より実用的な設定でも優れた攻撃性能を示した

適応的にニューラルアーキテクチャを探索することで、従来の手法では難しかったシナリオでも成功するって、めっちゃ興味深い！今後のプライバシー技術にとって重要なステップになりそうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.AI, cs.CV, **投稿日時:** 2024-05-31 09:29


- - -

### [Prune at the Clients, Not the Server: Accelerated Sparse Training in Federated Learning](http://arxiv.org/abs/2405.20623)

**クライアントで剪定を行う: 連合学習における加速スパーストレーニング**

Georg Meinhardt, Kai Yi, Laurent Condat, Peter Richtárik

- 連合学習（FL）は複数のクライアントがローカルデータを保持しながら共有モデルを訓練する方式
- クライアントのリソース制限と通信コストが大規模モデルの訓練において主要な問題
- サーバー側でのスパーストレーニングと加速は失敗し、クライアント側で適切に実行する新手法を提案
- Sparse-ProxSkipは、非凸設定でのスパーストレーニングと加速を組み合わせ、実験でも良好な性能を示す

クライアント側で剪定を行うとか、新しい発想だね！これで連合学習の効率がもっと上がるかも。試してみたくなるね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, math.OC, **投稿日時:** 2024-05-31 05:21


- - -

### [Selective Knowledge Sharing for Personalized Federated Learning Under Capacity Heterogeneity](http://arxiv.org/abs/2405.20589)

**キャパシティ不均一性におけるパーソナライズされた連合学習のための選択的知識共有**

Zheng Wang, Zheng Wang, Zhaopeng Peng, Zihui Wang, Cheng Wang

- 連合学習は低キャパシティデバイスからのプライベートデータと計算力を利用可能
- クライアント特有のデータに基づくモデルのパーソナライズが不十分で、効率に課題
- Pa3dFLはレイヤーを一般パラメータと個別パラメータに分けて、効率的な知識の共有を実現
- 実験結果では、Pa3dFLがベースライン法を性能面で一貫して上回り、通信・計算効率も良好

Pa3dFL、すごく面白いね！低キャパシティデバイスの活用が進むと、もっと多様なデバイスでの学習ができるかもね。今後の連合学習がどう発展するか楽しみだな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-05-31 02:59
