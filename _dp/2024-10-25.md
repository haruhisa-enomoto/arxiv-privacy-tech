---
title: 差分プライバシー (2024-10-25 ~ 2024-10-31)
date: 2024-10-25
---

差分プライバシーに関する論文まとめ (2024-10-25 ~ 2024-10-31)


- - -

### [QuACK: A Multipurpose Queuing Algorithm for Cooperative -Armed Bandits](http://arxiv.org/abs/2410.23867)

**QuACK: 協力的なk-アームドバンディットのための多目的キューイングアルゴリズム**

Benjamin Howson, Sarah Filippi, Ciara Pike-Burke

- 複数のエージェントが協力して最適な行動を見つける問題を研究
- 単一エージェントアルゴリズムを任意に多エージェント設定に拡張可能
- 単一プレイヤーのアルゴリズムの後悔保証を多エージェントにも適用可能
- 提案手法が特化型アルゴリズムを超える性能を実証

この論文、めっちゃ面白そう！マルチエージェントで協力しちゃうところが未来っぽいよね。どのアルゴリズムにも応用できるって、可能性がめちゃ広がるじゃん！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-31 12:20


- - -

### [Private Synthetic Text Generation with Diffusion Models](http://arxiv.org/abs/2410.22971)

**拡散モデルを用いたプライベートな合成テキスト生成**

Sebastian Ochs, Ivan Habernal

- 拡散モデルは、合成テキスト生成で自己回帰型LLMs並みの性能を持つ
- 差分プライバシーを活用した合成データ生成には十分な証拠がまだない
- 既存のLLMsによる合成テキスト生成は差分プライバシー保証を破る可能性がある
- プライバシー環境下では、オープンソースLLMsが拡散モデルより優れていると判明

拡散モデルって本当すごいのかもって思ったけど、意外とLLMsの方が強かったんだね！オープンソースで、いっぱい実験してくれるのありがたいから、もっと研究進むといいな〜。



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.CL, **投稿日時:** 2024-10-30 12:38


- - -

### [Exactly Minimax-Optimal Locally Differentially Private Sampling](http://arxiv.org/abs/2410.22699)

**ローカル差分プライバシーにおけるサンプリング問題の厳密なミニマックス最適化**

Hyun-Young Park, Shahab Asoodeh, Si-Hyeon Lee

- ローカル差分プライバシーの下でのサンプリング問題は生成モデルへの応用が期待される
- f-ダイバージェンスを用いてプライバシー-ユーティリティトレードオフ（PUT）をミニマックス的に定義
- 有限および連続データ空間におけるPUTを正確に特徴付け、すべてのf-ダイバージェンスに対して最適なサンプリングメカニズムを提案
- 数値実験により、理論的および実証的なユーティリティの面で提案手法がベースラインを上回ることを示した

プライバシーを保ちながらも、実用的な性能を最大限引き出そうとするアプローチが興味深いね！こんな技術、関係する分野でどんなふうに花開くのかな？ワクワクするね！

**Comment:** 32 pages and 7 figures. Accepted by NeurIPS 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-30 05:13


- - -

### [Calibrating Practical Privacy Risks for Differentially Private Machine Learning](http://arxiv.org/abs/2410.22673)

**差分プライバシー機械学習における実用的プライバシーリスクの調整**

Yuechun Gu, Keke Chen

- 差分プライバシーの理論的指標$\epsilon$は、モデルやデータセットによって実用的解釈が複雑である。
- LiRA攻撃成功率(ASR)は、$\epsilon$設定が同じでもデータセットやモデルにより変動し実世界のリスク指標となる。
- プライバシーに敏感な特徴を抑えることでASRを低下させ、データ有用性を損なわずに柔軟なプライバシー設定が可能に。
- SHAPとLIMEを使い特徴感度を評価し、特徴をマスクする戦略がデータセットのプライバシーリスクを軽減。

プライバシーリスクをこんなにしっかり考えてるなんて、すごいなぁ。データの便利さと安全性を両立させる方法が、未来の技術の鍵かもね！高校のレポートにも使える知識かもしれないから、詳しく見てみたいな。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-30 03:52


- - -

### [FT-PrivacyScore: Personalized Privacy Scoring Service for Machine Learning Participation](http://arxiv.org/abs/2410.22651)

**FT-PrivacyScore: 機械学習参加のための個別化プライバシースコアサービス**

Yuechun Gu, Jiajie He, Keke Chen

- プライバシー損失を定量化する手法は精度に影響を与える
- 多くの業界や研究では制御されたデータアクセスが主流
- 個別のプライバシーリスクを事前評価する定量的手段がない
- FT-PrivacyScoreで効率的にプライバシーリスクを推定可能

プライバシーを守りつつ機械学習に参加できるなんてすごいね！もしこれがもっと広まったら、みんなのデータ活用がもっと安全に行えそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-30 02:41


- - -

### [Privacy-Preserving Dynamic Assortment Selection](http://arxiv.org/abs/2410.22488)

**プライバシー保護の動的アソートメント選択**

Young Hyun Cho, Will Wei Sun

- プライバシー保護の必要性が増大する中、MNLバンディットモデルを用いた新たなフレームワークを提案。
- 摂動されたアッパーコンフィデンスバウンド法を用いて、ユーザーの効用推定にノイズを加え探索と活用のバランスを確保。
- 提案手法は動的環境に適した共同差分プライバシーを満たし、推論攻撃のリスクを効果的に軽減。
- 提案手法の理論的な後悔境界を導出し、Expediaホテルデータセットを使用したシミュレーションで性能向上を実証。

この研究、めっちゃおもしろい！プライバシーを守りながらも個人に最適なレコメンデーションとか、未来のサービスって感じでワクワクするよね。実用化されたら旅行とかもっと楽しくなりそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ML, cs.AI, cs.CR, cs.LG, **投稿日時:** 2024-10-29 19:28


- - -

### [Auditing -Differential Privacy in One Run](http://arxiv.org/abs/2410.22235)

**1回の実行で行う$f$-差分プライバシーの監査**

Saeed Mahloujifar, Luca Melis, Kamalika Chaudhuri

- 経験的監査はプライバシー保持アルゴリズムの欠陥を見つける手段だが、計算効率が低い
- 提案した監査手順は効率的であり、画期的な分析によりプライバシーを効果的に評価可能
- 1回の実行だけでターゲットメカニズムのプライバシーを監査できるのが特長
- 提案手法は従来の差分プライバシーパラメータを超える精度の高いプライバシー推定を実現

プライバシーを守る方法っていつも計算が大変だけど、この論文は1回で済むのがすごいね！これならAIの活用がもっと安心してできるかも。🖥️🔒



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-29 17:02


- - -

### [Differentially Private Learned Indexes](http://arxiv.org/abs/2410.21164)

**差分プライバシーを備えた学習インデックス**

Jianzhang Du, Tilak Mudgal, Rutvi Rahul Gadre, Yukui Luo, Chenghong Wang

- 検索効率化のためのインデックスは暗号化データベースでは漏洩リスクが高い。
- 差分プライバシーでノイズを加える方法はプライバシーを守れるが、ストレージコストが大きい。
- 学習インデックス技術を利用し、コンパクトな差分プライバシーインデックスを構築する提案。
- 提案手法は鍵空間のサイズに対するインデックスサイズを大幅に削減できる。

データベース内の検索にもプライバシーが大事だよね！そのうえで省スペースな保護方法を考えたなんて、実用化が楽しみ〜。この技術が広まれば、もっと安全なデータ処理が進みそう！



**トピック:** [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.DB, cs.CR, cs.LG, **投稿日時:** 2024-10-28 16:04


- - -

### [Privacy-Enhanced Adaptive Authentication: User Profiling with Privacy Guarantees](http://arxiv.org/abs/2410.20555)

**プライバシー強化型適応認証: プライバシー保証を伴うユーザープロファイリング**

Yaser Baseri, Abdelhakim Senhaji Hafid, Dimitrios Makrakis

- ユーザープロファイリングは適応リスク認証に不可欠だが、プライバシーの懸念が大きい。
- 新たな認証プロトコルはOPRFと差分プライバシーを用いてユーザーのプライバシーを強化。
- 暗号技術がデータの機密性や整合性を確保し、差分プライバシーでデータ点の影響を低減。
- プロトコルの計算・通信負荷は現実的で、GDPRなどの法律とも整合性がある。

ユーザーのプライバシーを守りつつ認証プロセスを強化する技術って、未来的でかっこいいよね！プライバシーの問題を配慮することで、企業の信頼性がぐっと高まりそう～。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-27 19:11


- - -

### [FL-DABE-BC: A Privacy-Enhanced, Decentralized Authentication, and Secure Communication for Federated Learning Framework with Decentralized Attribute-Based Encryption and Blockchain for IoT Scenarios](http://arxiv.org/abs/2410.20259)

**FL-DABE-BC: IoTシナリオのためのプライバシー強化、分散型認証、および安全な通信を備えた連合学習フレームワーク**

Sathwik Narkedimilli, Amballa Venkata Sriram, Satvik Raghav

- 連合学習でIoTデバイスのデータを安全に扱うために分散属性ベースの暗号化とブロックチェーンを利用
- ホモモルフィック暗号化で暗号化されたデータ上の計算を許可し、秘密計算で協力的計算のプライバシーを確保
- ローカルモデルの重みは暗号化され、フォグ層に送信して差分プライバシーで中央サーバーでの漏洩を防ぐ
- このシステムは分散IoTデバイスにおける効率的なモデル訓練とリアルタイム分析を可能にする

IoTデバイスに直接分散型認証と暗号化ができるのすごいね！この技術でデータ漏洩のリスクが減ると嬉しいな。セキュリティとプライバシーの同時実現、ワクワクしちゃう！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-26 19:30


- - -

### [Privacy without Noisy Gradients: Slicing Mechanism for Generative Model Training](http://arxiv.org/abs/2410.19941)

**ノイズのない勾配でプライバシーを守る：生成モデル訓練のためのスライス機構**

Kristjan Greenewald, Yuancheng Yu, Hao Wang, Kai Xu

- 差分プライバシーで生成モデルを訓練する際のノイズ注入がハイパーパラメータ調整の障害に
- スライスプライバシー機構で低次元に圧縮、ノイズを加えて強力なプライバシー保証を提供 
- スムーズスライス$f$-発散を導入、統計的一貫性を持ち、敵対的訓練が不要
- 数値実験で高品質な合成データを生成し、柔軟なモデル調整が可能に

プライバシーを守りつつも、ノイズに頼らないでデータ生成ができるのって、すっごく効率的かも！これからのデータサイエンスに革命を起こしそうで、ワクワクしちゃうね！

**Comment:** accepted to Neurips 2024

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-25 19:32


- - -

### [Noise-Aware Differentially Private Variational Inference](http://arxiv.org/abs/2410.19371)

**ノイズ認識差分プライバシー変分推論**

Talal Alrawajfeh, Joonas Jälkö, Antti Honkela

- 差分プライバシーは統計的推論のプライバシーを保護するが、結果にバイアスをもたらしやすい
- 既存のノイズ認識手法は単純な確率モデルに限られ、高次元モデルには適用困難
- 提案手法は高次元および非共役モデルにも適用可能なノイズ認識ベイズ推論法
- 高次元ベイズ線形回帰とUCI Adultデータセット上での予測確率の正確さを実証

ベイズ推論を使ったノイズ対応の手法ってすごく未来っぽい！これが実用化されれば、高次元のモデルでも信頼性のある結果が出せそうで、ワクワクするよね！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ML, cs.CR, cs.LG, **投稿日時:** 2024-10-25 08:18
