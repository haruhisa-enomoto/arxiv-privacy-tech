[
  {
    "url": "http://arxiv.org/abs/2410.02749",
    "title": "Training Language Models on Synthetic Edit Sequences Improves Code Synthesis",
    "japanese_title": "合成編集シーケンスを用いた言語モデルの訓練によるコード合成の改善",
    "authors": [
      "Ulyana Piterbarg",
      "Lerrel Pinto",
      "Rob Fergus"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "comment": "",
    "summary": "- ソフトウェアエンジニアは既存のプログラムを編集するが、大規模言語モデル（LLM）は一度に合成する\n- 高品質の編集データは入手困難であり、その不足を補うためにLintSeqという合成データ生成アルゴリズムを開発\n- LintSeqはコードを編集シーケンスとしてテキスト出力し、命令+プログラムペアを編集シーケンスに変換する\n- 合成編集シーケンスで微調整した小型LLMは、GPT-4に匹敵し、特にHumanEvalでは+20%性能向上を示す\n\n合成データでトレーニングすると、既存のモデルよりもパフォーマンスが向上するみたい！将来はもっと小型のデバイスで、高度なコード生成ができるかもね。すごく楽しみ！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-03T17:57:22+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02733",
    "title": "Data Similarity-Based One-Shot Clustering for Multi-Task Hierarchical Federated Learning",
    "japanese_title": "データ類似性に基づくマルチタスク階層型連合学習のためのワンショットクラスタリング",
    "authors": [
      "Abdulmoneam Ali",
      "Ahmed Arafa"
    ],
    "categories": [
      "cs.LG",
      "cs.IT",
      "cs.NI",
      "eess.SP",
      "math.IT"
    ],
    "comment": "To appear in Asilomar 2024",
    "summary": "- 無秩序なタスクに対応するため、同一タスクのユーザをクラスタリングして共同学習を可能にする\n- ユーザ間のデータ類似性に基づくワンショットクラスタリングアルゴリズムを提案\n- プライバシーの懸念、通信負荷、事前知識不要などの課題を克服\n- CIFAR-10やFashion MNISTでの実験により、精度や分散削減でベースラインを上回る性能を示す\n\nこの研究おもしろそう〜！いろんなタスクを一斉に効率的に学習できるって、まるでチームプレーみたいでワクワクするね。技術もプライバシー守りつつ進化してて、みんなが協力して良い結果を出せる時代が来るといいな！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-03T17:51:21+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02666",
    "title": "AlphaIntegrator: Transformer Action Search for Symbolic Integration Proofs",
    "japanese_title": "AlphaIntegrator: シンボリック積分証明のためのトランスフォーマー行動探索",
    "authors": [
      "Mert Ünsal",
      "Timon Gehr",
      "Martin Vechev"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "comment": "",
    "summary": "- 数学的積分をステップごとに行う学習ベースのシステムを初めて提案\n- GPTトランスフォーマーモデルで、積分ルールを導くポリシー学習を実現\n- 準同型暗号的な正しい動作と合成データ上での強力な一般化を達成\n- 標準的なLLMの微調整では解決困難、新たな創造的手法の重要性を指摘\n\n新しい積分のアイデア超おもしろそう！知識とシンボリックな推論の組み合わせで、新しい数学の可能性が広がるかもね。こういう革新が、いろんな学問で役立ちそうな気がする！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-03T16:50:30+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02637",
    "title": "Plots Unlock Time-Series Understanding in Multimodal Models",
    "japanese_title": "プロットが時系列理解をマルチモーダルモデルで解き明かす",
    "authors": [
      "Mayank Daswani",
      "Mathias M. J. Bellaiche",
      "Marc Wilson",
      "Desislav Ivanov",
      "Mikhail Papkov",
      "Eva Schnider",
      "Jing Tang",
      "Kay Lamerigts",
      "Gabriela Botea",
      "Michael A. Sanchez",
      "Yojan Patel",
      "Shruthi Prabhakara",
      "Shravya Shetty",
      "Umesh Telang"
    ],
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "comment": "49 pages",
    "summary": "- マルチモーダルモデルはテキスト以外のデータも扱えるが、時系列データ解析では未活用\n- 視覚化で時系列データを「見る」手法を提案し、モデルの再トレーニングを不要に\n- 時系列データを視覚化することで最大90%のモデルAPIコスト削減を実現\n- プロットの使用でゼロショットタスクで120%、実世界タスクで150%の性能向上を確認\n\nマルチモーダルモデルって視覚的な認識力も持ってるのね！時系列データをプロットにすると解析がすごく効率的になるんだ。これ、将来的には医療やフィンテック分野で大活躍な予感！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-03T16:23:13+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02547",
    "title": "Personalized Quantum Federated Learning for Privacy Image Classification",
    "japanese_title": "プライバシー画像分類のための個別量子連合学習",
    "authors": [
      "Jinjing Shi",
      "Tian Chen",
      "Shichao Zhang",
      "Xuelong Li"
    ],
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 量子連合学習はプライバシー画像分類を改善するが、クライアントモデルの個別性に欠ける課題がある\n- 個別量子連合学習アルゴリズムを提案し、不均衡な画像分布でもクライアントモデルの個別性を強化\n- 提案手法は、FashionMNISTデータセットで非個別モデルより7%高い精度でサーバーとクライアントで性能を向上\n- 追加訓練なしにモデルとデータのプライバシーを守り、量子技術の普及と効果的な分散機械学習を促進\n\n量子技術を使った連合学習で、個別性をちゃんと考慮しているのが新しいよね！これからどんどんセキュリティや効率が良くなる未来を考えるとワクワクしちゃう。みんなにとって便利な技術になるといいなって思うな。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-03T14:53:04+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02496",
    "title": "Efficient learning of differential network in multi-source non-paranormal graphical models",
    "japanese_title": "複数ソース非正規分布グラフモデルにおける差分ネットワークの効率的学習",
    "authors": [
      "Mojtaba Nikahd",
      "Seyed Abolfazl Motahari"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 非正規分布グラフモデル間の差分ネットワークを学習し、ラッソペナルティを最適化\n- 計算の複雑さが低く、特に差分ネットワークがスパースな場合に効率的\n- 合成データでのシミュレーションにおいて、スピードと精度の面で既存手法を上回る\n- 複数のソースからデータを組み合わせることで、実世界での差分ネットワーク推定が効果的\n\n非正規分布のモデル間でどのように情報を効率的に学習するかって本当に興味深いよね！この手法が実際の医療研究で活かされる未来が楽しみ！新しいものが見つかるかも。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-03T13:59:38+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02486",
    "title": "Encryption-Friendly LLM Architecture",
    "japanese_title": "暗号化に優しいLLMアーキテクチャ",
    "authors": [
      "Donghwan Rho",
      "Taeseong Kim",
      "Minje Park",
      "Jung Woo Kim",
      "Hyunsik Chae",
      "Jung Hee Cheon",
      "Ernest K. Ryu"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "comment": "27 pages",
    "summary": "- 大規模言語モデルは個別応答を提供するが、プライバシーが大きな課題である\n- 準同型暗号は暗号状態で計算可能にし、プライバシー保護に寄与\n- 変換器の計算負荷が課題、そこで変換器アーキテクチャを改良\n- 新手法でチューニングや推論速度が向上、結果は平文モデルと同等\n\nこれからプライバシーを大事にしつつ、パーソナライズされたサービスができるって素敵だよね！機械学習の未来がもっと楽しくなるかも！",
    "topics": [
      "準同型暗号"
    ],
    "published": "2024-10-03T13:48:35+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02450",
    "title": "Personalized Federated Learning for Generative AI-Assisted Semantic Communications",
    "japanese_title": "ジェネレーティブAI支援による意味通信のための個別化連合学習",
    "authors": [
      "Yubo Peng",
      "Feibo Jiang",
      "Li Dong",
      "Kezhi Wang",
      "Kun Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.IT",
      "math.IT"
    ],
    "comment": "",
    "summary": "- セマンティック通信は意味情報のみを送信し、モバイルユーザーによるスペクトル資源の利用を効率化\n- 新たに提案されたGSCモデルは、ジェネレーティブAIを活用した通信改善を目指す\n- 個別化連合学習を導入し、プライバシーを保ちながらモバイルユーザーの多様な要求に対応\n- 特にPLDとAGPを用いて通信エネルギーを削減し、モデルの効率化と効果を実現\n\nこれってすごく面白そう！モバイル通信がより効率的になれば、もっとスムーズに情報交換できるよね。未来の通信技術がどう発展するか、目が離せない！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-03T12:52:36+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02443",
    "title": "Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration",
    "japanese_title": "Clinnova連合学習概念実証: 国境を越えたコラボレーションからの主要な教訓",
    "authors": [
      "Julia Alekseenko",
      "Bram Stieltjes",
      "Michael Bach",
      "Melanie Boerries",
      "Oliver Opitz",
      "Alexandros Karargyris",
      "Nicolas Padoy"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- フランス、ドイツ、スイス、ルクセンブルクが連携し、データの連合化と標準化により精密医療を促進\n- AIとデータサイエンスを駆使して、医療成果と効率を向上させるヨーロッパの統一基準を構築\n- 統合され連携されたアルゴリズムで個別化医療を推進し、MS患者のデジタルバイオマーカーを検証\n- MSセグメンテーションでの国境を超えた連合学習の概念実証において技術的、倫理的な課題が浮き彫りに\n\n異文化が交わる連携って、とっても力強いね！課題も多そうだけど、それを超えるデータ活用が未来の医療をどう変えるか楽しみだな。それに、欧州の巨匠たちがどんなAIを作るのか、ワクワクしちゃうね！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-03T12:40:52+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02312",
    "title": "Federated Reinforcement Learning to Optimize Teleoperated Driving Networks",
    "japanese_title": "連合強化学習による遠隔操作運転ネットワークの最適化",
    "authors": [
      "Filippo Bragato",
      "Marco Giordani",
      "Michele Zorzi"
    ],
    "categories": [
      "cs.NI"
    ],
    "comment": "This paper has been accepted for publication at IEEE Global   Communications Conference (GLOBECOM), 2024",
    "summary": "- 第6世代(6G)技術は信頼性と低遅延が重要で、特に遠隔操作運転で要求される。\n- 学習強化を用いて、ネットワーク条件に応じたTDアプリの動的設定を提案。\n- 複数のRLアルゴリズムを使用し、連合学習で収束時間や公平性を向上。\n- Q-ラーニングが少数パラメータで最適なPQoSを提供し、平均報酬や計算コストが良好。\n\n最適化のために連合学習を活用するの面白そう！未来の遠隔操作技術が更に進化しそうでワクワクする。QoSとQoEのトレードオフを解決するための詳細なアプローチが気になるね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-03T08:51:32+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02260",
    "title": "FedScalar: A Communication efficient Federated Learning",
    "japanese_title": "FedScalar: 通信効率の良い連合学習",
    "authors": [
      "M. Rostami",
      "S. S. Kia"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合学習はプライバシーを守るが、大規模問題では通信コストが課題\n- FedScalarはエージェント間通信をスカラーで行い通信効率を向上\n- 提案手法は非凸損失関数で$O(1/\\sqrt{K})$の収束率を実現\n- ランダムベクトルの分布調整で集約ステップの分散を低減可能\n\nめっちゃ面白そう！FedScalarが連合学習の通信の問題をすっごく効率的にしてくれるんだ。数学的にもしっかり証明してるから、実生活にもすぐ役立ちそうだよね。どんな応用ができるのか楽しみ〜！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-03T07:06:49+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02250",
    "title": "Probabilistic road classification in historical maps using synthetic data and deep learning",
    "japanese_title": "合成データとディープラーニングを活用した歴史的地図における確率的道路分類",
    "authors": [
      "Dominik J. Mühlematter",
      "Sebastian Schweizer",
      "Chenjing Jiao",
      "Xue Xia",
      "Magnus Heitzler",
      "Lorenz Hurni"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 歴史的地図から道路ネットワークをデジタル化するのはコストが高く時間がかかる\n- 提案された新しいフレームワークは、ラベルなしでの道路幾何学の抽出と分類を実現\n- 合成データを用いて、道路クラスのピクセル単位の確率を予測するディープラーニングを実施\n- スイスのSiegfried地図で94%以上の正確度を達成し、都市計画に有用\n\n地図って時代を超えていろんな情報を教えてくれるね！技術が発展して、昔の地図からも効率的にデータが引き出せるようになってくると、都市計画とかにももっと活かせそうでワクワクするね！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-03T06:43:09+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02246",
    "title": "PFGuard: A Generative Framework with Privacy and Fairness Safeguards",
    "japanese_title": "PFGuard: プライバシーと公平性を確保した生成フレームワーク",
    "authors": [
      "Soyeon Kim",
      "Yuji Roh",
      "Geon Heo",
      "Steven Euijong Whang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 生成モデルは信頼性のためにプライバシーと公平性の両方を確保する必要がある\n- プライバシーと公平性技術を単純に組み合わせても、対立が発生し十分でないことがある\n- PFGuardは、複数の教師モデルのアンサンブルを使用しプライバシーと公平性の対立を解決\n- 高次元データにおいて合成データを生成しつつ、公平性収束と厳密なDP保証を提供する\n\nPFGuardってすごいよね！データのプライバシーと公平性を同時に守る方法を見つけたなんて、考えただけでワクワクしちゃう！これでAIの信頼性がさらにアップするかもね！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-03T06:37:16+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02191",
    "title": "A Survey on Point-of-Interest Recommendation: Models, Architectures, and Security",
    "japanese_title": "地点推薦に関する調査：モデル、アーキテクチャ、セキュリティ",
    "authors": [
      "Qianru Zhang",
      "Peng Yang",
      "Junliang Yu",
      "Haixin Wang",
      "Xingwei He",
      "Siu-Ming Yiu",
      "Hongzhi Yin"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "comment": "20 pages",
    "summary": "- スマートフォンと位置情報型ソーシャルネットワークの普及により、地点推薦システムにとっての機会が拡大。\n- 伝統的なアプローチではなく、新しいモデルやセキュリティを考慮した最新の地点推薦システムを包括的にレビュー。\n- 地点推薦の進化として、集中的から分散型・連合学習システムへ移行し、プライバシーと拡張性が向上。\n- セキュリティの重要性が増しており、潜在的な脆弱性とプライバシー保護の方法を検討。\n\n最新技術の進化を詳しく知ることで、新しい方向性を見つけられるのは面白いよね。セキュリティとプライバシーがどんどん大事になっていくのも納得だし、自分に合ったおすすめができる時代ってワクワクするよね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-03T04:11:42+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02145",
    "title": "Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes",
    "japanese_title": "勾配を使わないカッティングプレーンによる深層ニューラルネットワークのアクティブラーニング",
    "authors": [
      "Erica Zhang",
      "Fangzhao Zhang",
      "Mert Pilanci"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "comment": "",
    "summary": "- アクティブラーニングは機械学習のサンプル複雑性を向上させる方法の一つ\n- 本研究ではReLUネットワークにおける勾配不要のカッティングプレーン法を提案\n- 非線形な決定境界を持つ深層ニューラルネットへの拡張が初めて示された\n- 提案手法は収束保証を達成し、既存手法と比較して有効性を実験で実証\n\n勾配を使わなくてもカッティングプレーン法って深層ニューラルネットワークでも使えるんだね！それに、収束保証までつけたアクティブラーニングの手法ってちょっとすごい気がするよ。新しい可能性を感じるなぁ。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-03T02:11:35+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02079",
    "title": "Deep Generative Modeling for Identification of Noisy, Non-Stationary Dynamical Systems",
    "japanese_title": "ノイズと非定常な動的システムの識別のための深層生成モデリング",
    "authors": [
      "Doris Voina",
      "Steven Brunton",
      "J. Nathan Kutz"
    ],
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "comment": "19 pages + 7 figures + Supplementary Materials (and supplementary   figures)",
    "summary": "- 時間変化する測定データの差分方程式復元は難しい課題\n- 提案手法は動的SINDyで、時変係数の疎ODAモデル化を行う\n- variational inferenceを用い、不確実性を評価しながら自律動的モデル化\n- 合成データとC. elegansのニューロン活動データで手法を検証\n\nこの研究すっごく面白いね！ノンステーショナリティにも対応できるなら、もっと広い分野で活用されそう！データ生かしていく未来が楽しみだね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-02T23:00:00+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02056",
    "title": "Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data",
    "japanese_title": "Synthio: 合成データによる小規模音声分類データセットの拡張",
    "authors": [
      "Sreyan Ghosh",
      "Sonal Kumar",
      "Zhifeng Kong",
      "Rafael Valle",
      "Bryan Catanzaro",
      "Dinesh Manocha"
    ],
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "comment": "Code and Checkpoints will be soon available here:   https://github.com/Sreyan88/Synthio",
    "summary": "- 小規模データセットの音声分類精度向上を目指し、合成データで拡張\n- 従来の人工変換手法は、多様性を表現し切れない問題がある\n- T2A拡散モデルでの合成音声生成により、多様性と一貫性を両立\n- 提案手法はベースラインを0.1%-39%上回る成果を示した\n\n合成音声データで音声分類の精度を上げるなんてすごい！テキストから音声を生成する技術がここまで進化しているとはね。どんな音声が生成されるのか試してみたいな。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-10-02T22:05:36+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02042",
    "title": "EAB-FL: Exacerbating Algorithmic Bias through Model Poisoning Attacks in Federated Learning",
    "japanese_title": "EAB-FL: 連合学習におけるモデル改ざん攻撃によるアルゴリズムバイアスの悪化",
    "authors": [
      "Syed Irfan Ali Meerza",
      "Jian Liu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "comment": "",
    "summary": "- 連合学習はプライバシーを保ちながらモデルを共同訓練する技術\n- 異なるデータと参加者により、モデルに人種や性別のバイアスが生じる\n- 一部の悪意ある参加者による攻撃が、バイアスやモデル精度を低下させる可能性\n- 提案されたEAB-FL攻撃が公平性を悪化させつつ、モデルの有用性を保持することを実証\n\n攻撃によって公平性が揺らぐって、なんだか怖いよね。でも、これを理解して対策を考えることが、公平な社会を作るのに役立ちそう！もっと安全で公平な技術が広まればいいなって思ったよ。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-02T21:22:48+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.02006",
    "title": "Addressing Data Heterogeneity in Federated Learning with Adaptive Normalization-Free Feature Recalibration",
    "japanese_title": "連合学習におけるデータの不均一性を適応的な正規化不要の特徴再調整で解決",
    "authors": [
      "Vasilis Siomos",
      "Sergio Naval-Marimont",
      "Jonathan Passerat-Palmbach",
      "Giacomo Tarroni"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "comment": "10 pages",
    "summary": "- 連合学習は分散協調訓練手法でデータオーナーシップを保持しつつ性能向上を図る。\n- クライアント間の統計的異質性がシステム性能を低下させる課題を解決するためにANFRを提案。\n- ANFRは重み標準化とチャンネルアテンションを組み合わせ、クライアント間での不一致を抑制。\n- 差分プライバシー下でも強力なプライバシー保証を維持しつつ性能を犠牲にしない。\n\n新しい手法を提案することで、連合学習をもっと効率的にできるんだね。特に異質性っていう難しい問題を解決しつつプライバシーを守れるっていうのが魅力的。もっと色んな現場で応用されるとすごく面白そう！",
    "topics": [
      "連合学習",
      "差分プライバシー"
    ],
    "published": "2024-10-02T20:16:56+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.01948",
    "title": "Differentially Private Parameter-Efficient Fine-tuning for Large ASR Models",
    "japanese_title": "大型ASRモデルのための差分プライバシーによるパラメーター効率良好な微調整",
    "authors": [
      "Hongbin Liu",
      "Lun Wang",
      "Om Thakkar",
      "Abhradeep Thakurta",
      "Arun Narayanan"
    ],
    "categories": [
      "cs.CR"
    ],
    "comment": "",
    "summary": "- 大型ASRモデルは差分プライバシーを用いることでプライバシー漏れを軽減できる。\n- 従来の差分プライバシー訓練は計算コストが高く、モデル性能に悪影響を及ぼす可能性がある。\n- 差分プライバシーを考慮したパラメーター効率良好な微調整で計算と性能のコストを削減。\n- 微調整で新しい性能基準を達成し、(10, 3.52e-6)-DPを維持しながら優れた結果を報告。\n\n大規模モデルで安全性と効率性の両立ができるなんて素敵じゃない？機械学習の未来がますます楽しみだよね！プライバシーを守りつつ、高性能も実現する技術がさらに進化しそうでワクワクする。",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-10-02T18:49:15+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2410.01922",
    "title": "NTK-DFL: Enhancing Decentralized Federated Learning in Heterogeneous Settings via Neural Tangent Kernel",
    "japanese_title": "NTK-DFL: ニューラルタンジェントカーネルによる異種環境での分散型連合学習の向上",
    "authors": [
      "Gabriel Thompson",
      "Kai Yue",
      "Chau-Wai Wong",
      "Huaiyu Dai"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 分散型連合学習(DFL)は中央サーバーや生データ交換なしでモデルをトレーニングするフレームワーク。\n- 統計的異質性が課題だが、NTKアプローチを用いることで効率的な収束とデータ異質性の克服を実現。\n- NTKを利用し、分散設定でのクライアントモデルを強化し、モデル平均化とシナジーを導入。\n- 提案手法はモデル認識力を向上させ、通信ラウンドが4.6分の1で目標を達成し正確性を向上。\n\n分散型でもNTKを活用すれば精度や効率がぐんとアップするなんてワクワクだね！通信が少なくても済むのは、特に多様な環境で協力が必要な状況にぴったりかも。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-10-02T18:19:28+00:00"
  }
]