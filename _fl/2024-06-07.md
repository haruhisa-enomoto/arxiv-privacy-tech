---
title: 連合学習 (2024-06-07 ~ 2024-06-13)
date: 2024-06-07
---

連合学習に関する論文まとめ (2024-06-07 ~ 2024-06-13)


- - -

### [FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation](http://arxiv.org/abs/2406.09547)

**FLea: プライバシー保護型特徴増強による連合学習のデータ不足とラベル偏りへの対処**

Tong Xia, Abhirup Ghosh, Xinchi Qiu, Cecilia Mascolo

- 連合学習では多数のエッジデバイスのデータを活用するが、データ不足とラベル偏りがモデル性能を阻害
- FLeaはグローバル特徴バッファを導入し、複数のクライアントのデータを共有し局所訓練を支援
- ローカルとグローバルの活性化ミックスアップを用いた特徴増強により、訓練サンプル数を増加させ局所オーバーフィッティングを軽減
- 中間活性化と元データの相関を最小化する難読化手法を採用し、共有特徴のプライバシーを強化

データ不足やラベルの不均衡にこんな風に対処するのめっちゃ面白そう！プライバシーもちゃんと考慮してるのが未来っぽいよね。

**Comment:** This paper has been accepted by KDD 2024. arXiv admin note: text   overlap with arXiv:2312.02327

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-13 19:28


- - -

### [EncCluster: Scalable Functional Encryption in Federated Learning through Weight Clustering and Probabilistic Filters](http://arxiv.org/abs/2406.09152)

**EncCluster: 重みクラスタリングと確率フィルタによる連合学習のスケーラブルな機能暗号化**

Vasileios Tsouvalas, Samaneh Mohammadi, Ali Balador, Tanir Ozcelebi, Francesco Flammini, Nirvana Meratnia

- 連合学習は地方分散型デバイス間でモデルを訓練し、ローカルモデル更新のみを集約サーバに送信
- 通常の連合学習は推論攻撃のリスクがある
- EncClusterは重みクラスタリングと確率フィルタを統合し、性能に影響なく強力なプライバシー保証を提供
- EncClusterは通信コストを従来の方法よりも大幅に削減し、暗号化速度を4倍超に向上させる

具体的な手法は難しそうだけど、プライバシーを守りながら効率も良くなるなんてすごいね！未来の連合学習の標準になりそう♡

**Comment:** 21 pages, 4 figures

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DC, cs.LG, **投稿日時:** 2024-06-13 14:16


- - -

### [Nonconvex Federated Learning on Compact Smooth Submanifolds With Heterogeneous Data](http://arxiv.org/abs/2406.08465)

**異種データを扱うコンパクトな滑らかな部分多様体上の非凸分散学習**

Jiaojiao Zhang, Jiang Hu, Anthony Man-Cho So, Mikael Johansson

- 連合学習において非凸最適化問題と多様体最適化を扱う新手法を提案
- 確率的リーマン勾配と多様体射影演算子を用いて計算効率を向上
- 局所的更新を利用し通信効率を改善し、クライアントドリフトを回避
- 提案アルゴリズムは既存の方法より計算および通信オーバーヘッドが小さいことを示す

理論もしっかりしているし、実験でも良い結果が出ているなんて、これからの連合学習の標準になるかもね。異種データを扱うっていう点も現実的にすごく役立ちそう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-12 17:53


- - -

### [A deep cut into Split Federated Self-supervised Learning](http://arxiv.org/abs/2406.08267)

**分割連合自己教師付き学習の深堀り**

Marcin Przewięźlikowski, Marcin Osial, Bartosz Zieliński, Marek Śmieja

- 最先端手法のMocoSFLは初期層にネットワーク分割を最適化するが、クライアントデータの保護が低下し通信オーバーヘッドが増加
- 分割の深さが分散学習におけるプライバシーと通信効率の維持に重要であることを示す
- MocoSFLは最小限の通信オーバーヘッドでは品質が劇的に劣化することが判明
- オンラインとモメンタムクライアントモデルを揃えるMonAcoSFLを導入し、精度を向上させつつ通信オーバーヘッドを大幅に削減

新しい手法MonAcoSFLで本当に連合学習の実用性が上がるのか注目だね！特に通信効率が改善されると、もっと広い環境で応用できそうでわくわくする。

**Comment:** Accepted to European Conference on Machine Learning (ECML) 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-06-12 14:35


- - -

### [Figuratively Speaking: Authorship Attribution via Multi-Task Figurative Language Modeling](http://arxiv.org/abs/2406.08218)

**比喩的表現による著者識別: マルチタスク比喩言語モデル**

Gregorios A Katsios, Ning Sa, Tomek Strzalkowski

- 比喩言語（FL）の特徴の識別は、著者の意図する意味とそのニュアンスを理解するために重要
- 複数のFL形式を組み合わせた使用が、単一の構成よりも作家のスタイルを正確に反映
- FL特徴が著者識別（AA）に重要な役割を果たすと仮定し、AAに基づくFL使用の最初の計算研究を実施
- マルチタスク比喩言語モデル（MFLM）を提案し、いくつかのデータセットでAAのパフォーマンスを改善

比喩言語で著者が特定できるなんて面白そう！たくさんのスタイルがモデルで検出されるなんて、スゴイね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, **投稿日時:** 2024-06-12 13:49


- - -

### [A Federated Online Restless Bandit Framework for Cooperative Resource Allocation](http://arxiv.org/abs/2406.07992)

**連合オンラインレストレスバンディットフレームワークによる協調リソース配分**

Jingwen Tong, Xinran Li, Liqun Fu, Jun Zhang, Khaled B. Letaief

- 既存の研究はMarkov報酬プロセス(MRP)の既知の指数の前提によるものが多い
- MRPsの未知のシステムダイナミクス問題を解決するための学習ベースの効率的な解決策は未解決
- フェデレーテッドThompsonサンプリング有効Whittle指数(FedTSWI)アルゴリズムを提案
- 提案アルゴリズムは速い収束率と高性能を達成し、エージェント数が多いほどサンプル複雑性が低下

協調的な学習でシステムダイナミクスを効率よく学ぶって未来っぽくてワクワクしちゃうね。リソース配分って難しいけど、この方法ならうまくいきそうな予感！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, eess.SP, **投稿日時:** 2024-06-12 08:34


- - -

### [IMFL-AIGC: Incentive Mechanism Design for Federated Learning Empowered by Artificial Intelligence Generated Content](http://arxiv.org/abs/2406.08526)

**IMFL-AIGC: 連合学習を強化する人工知能生成コンテンツのためのインセンティブ機構設計**

Guangjing Huang, Qiong Wu, Jingyi Li, Xu Chen

- 連合学習は、クライアントがデータを共有せずに協力してモデルを訓練できる画期的な枠組み
- データ品質の異質性を軽減するため、人工知能生成コンテンツ（AIGC）が新たなデータ合成技術として利用可能
- AIGCを取り入れた連合学習の費用（計算やデータ合成のコスト）が参加の阻害要因となる
- 提案されたデータ品質評価法とインセンティブ機構により、トレーニングの精度向上とコスト削減が実現

連合学習とAI生成データを組み合わせた新しいアプローチだね！これが実現すれば、もっと効率的にモデルを訓練できる未来が楽しみだな～。

**Comment:** The paper has been accepted by IEEE Transactions on Mobile Computing

**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.AI, cs.DC, cs.GT, **投稿日時:** 2024-06-12 07:47


- - -

### [FDLoRA: Personalized Federated Learning of Large Language Model via Dual LoRA Tuning](http://arxiv.org/abs/2406.07925)

**FDLoRA: デュアルLoRAチューニングによる大規模言語モデルの個別連合学習**

Jiaxing QI, Zhongzhi Luan, Shaohan Huang, Carol Fung, Hailong Yang, Depei Qian

- 大規模言語モデル（LLM）の訓練は多大な計算リソースと豊富なラベル付きデータを必要とし、個別ユーザー向けのLLM訓練が困難。
- 連合学習（FL）を導入して分散プライベートデータ上で協調訓練を行うことが提案されているが、データやシステムの異質性、モデルサイズの課題により低効率。
- 新たな個別連合学習（PFL）フレームワーク「FDLoRA」は、クライアント単位でパーソナライズとグローバル知識をキャプチャするデュアルLoRAモジュールをセット。
- 自適応融合アプローチを採用し、計算コストと通信コストを抑えつつ、クライアントのパフォーマンス向上を実現。

この論文は、個別のデータで効率的に連合学習を実行し、大規模言語モデルの訓練を最適化する新戦略を提案しているところが面白いと思う。このアプローチで、将来的にいろいろなアプリがさらに賢くなりそうでワクワクするよね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-06-12 06:44


- - -

### [Aggregation Design for Personalized Federated Multi-Modal Learning over Wireless Networks](http://arxiv.org/abs/2406.07915)

**ワイヤレスネットワークにおけるパーソナライズド連合マルチモーダル学習のための集約設計**

Benshun Yin, Zhiyong Chen, Meixia Tao

- パーソナライズド連合マルチモーダル学習（FMML）で異なるモダリティの情報が統合され、学習性能が向上する
- パラメータスケジューリングスキームを開発し、非独立・非同分布（non-IID）データとモダリティヘテロジニティを考慮
- 学習ベースのアプローチを用いて、異なるデバイスのモダリティごとのパラメータの集約係数を得る
- 提案アルゴリズムがFMMLのパーソナライズド性能を効果的に向上させることを実験結果で示す

ネットワーク環境が違っても個別に最適化できる学習法ってすごく面白そう！どんなデバイスでも効果が出るなんて未来感あるよね。

**Comment:** accepted by IEEE Communications Letters

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.IT, eess.SP, math.IT, **投稿日時:** 2024-06-12 06:35


- - -

### [Regularizing and Aggregating Clients with Class Distribution for Personalized Federated Learning](http://arxiv.org/abs/2406.07800)

**クラス分布によるクライアントの正則化と集約を用いた個別化連合学習**

Gyuejeong Lee, Daeyoung Choi

- 個別化連合学習(PFL)は異なるデータ分布を持つクライアントに対してカスタマイズされたモデルを提供
- 高い計算コストや通信コストが既存のPFL方法の実用性を制限している
- 提案手法cwFedAVGは、クラスごとに連合平均化（FedAVG）を行い、サーバーでクラスごとのグローバルモデルを作成
- WDRにより推定精度を向上させ、cwFedAVGは他のPFL手法と比較して性能が優れ、計算効率も高い

新しいPFL手法で計算コストがグッと下がるのはマジ嬉しい！クラスごとにモデルを特化させるなんて新鮮で面白そうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-12 01:32


- - -

### [Automated Question Generation for Science Tests in Arabic Language Using NLP Techniques](http://arxiv.org/abs/2406.08520)

**自然言語処理技術を用いたアラビア語理科試験の自動問題生成**

Mohammad Tami, Huthaifa I. Ashqar, Mohammed Elhenawy

- 教育評価のための自動質問生成は教育技術分野で重要
- 最近の研究はアラビア語での評価質問生成に挑戦も、文解析の誤りや名前認識の問題などが影響
- 3つの段階（キーワード抽出、質問生成、ランキング）で構築されたシステムを提案
- 提案された方法は精度83.50%、再現率78.68%、F1スコア80.95%を達成し、人間評価で84%の平均評価

実際にアラビア語での質問生成って本当に難しいんだね。でも、この研究が後々もっと広がって、他の言語にも活きそうで超ワクワクする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.CY, **投稿日時:** 2024-06-11 20:27


- - -

### [Minimizing Energy Costs in Deep Learning Model Training: The Gaussian Sampling Approach](http://arxiv.org/abs/2406.07332)

**ディープラーニングモデル訓練におけるエネルギーコスト削減：ガウスサンプリングアプローチ**

Challapalli Phanindra Revanth, Sumohana S. Channappayya, C Krishna Mohan

- 逆伝搬法による損失勾配の計算は多くのエネルギーを消費
- GradSampと呼ばれる方法で、ガウス分布から勾配更新をサンプリング
- ガウス「ノイズ」でモデルパラメータを周期的またはランダムに更新
- 画像分類などのさまざまなタスクで、エネルギー削減と性能維持を実証

新しい勾配更新方法が省エネに繋がるなんて、環境にも優しいね！実験で効果が見られたから、実用化も期待できそうだね～。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-06-11 15:01


- - -

### [Optimal Federated Learning for Nonparametric Regression with Heterogeneous Distributed Differential Privacy Constraints](http://arxiv.org/abs/2406.06755)

**異質な分散差分プライバシー制約を持つ非パラメトリック回帰のための最適な連合学習**

T. Tony Cai, Abhinav Chakraborty, Lasse Vuursteen

- サーバごとに異なる差分プライバシー制約とサンプルサイズの非均質な環境での連合学習を研究
- ベゾフ空間の上での最適収束率を確立し、グローバルおよびポイントワイズ推定を検討
- 分散プライバシー保護推定量を提案し、そのリスク特性を調査
- プライバシーバジェットとデータ分散による損失間のトレードオフを解析

異なるサーバでプライバシーを保持しながら最適な推定を行う方法、めっちゃ興味深い！特にポイントワイズ推定とグローバル推定の違いがどうなるのか知りたいな。

**Comment:** 49 pages total, consisting of an article (24 pages) and a supplement   (25 pages)

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** math.ST, cs.LG, stat.ML, stat.TH, 62G08, 62C20, 68P27, 62F30,, **投稿日時:** 2024-06-10 19:34


- - -

### [Federated Nonparametric Hypothesis Testing with Differential Privacy Constraints: Optimal Rates and Adaptive Tests](http://arxiv.org/abs/2406.06749)

**差分プライバシー制約下における連合ノンパラメトリック仮説検定：最適レートと適応的テスト**

T. Tony Cai, Abhinav Chakraborty, Lasse Vuursteen

- 差分プライバシー制約下での白色雑音ドリフトモデルにおける連合ノンパラメトリック適合度検定を研究
- 最適レートを指数関数的な因子まで一致させる下界と上界を確立し、テスト問題の難しさを評価
- 共有ランダムネスにアクセスできる分散型のワンショットプロトコルが、それなしよりも優れている現象を発見
- 未知の規則性パラメータに適応し、差分プライバシー制約を維持したまま追加コストを最小限に抑えるデータ駆動型テスト手法を構築

共有ランダムネスをうまく利用することで効率が上がるなんて、すごく面白いね！これからのプライバシー保護技術がもっと進化していくのが楽しみ～！

**Comment:** 77 pages total; consisting of a main article (28 pages) and   supplement (49 pages)

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** math.ST, cs.LG, stat.ML, stat.TH, 62G10, 62C20, 68P27, 62F30, **投稿日時:** 2024-06-10 19:25


- - -

### [Decentralized Personalized Federated Learning](http://arxiv.org/abs/2406.06520)

**分散型個別化連合学習**

Salma Kharrat, Marco Canini, Samuel Horvath

- 分散型連合学習におけるデータの異質性と通信制限の課題に取り組む
- クライアントが適切な協力者を選ぶためのコラボレーショングラフを作成
- 資源効率を高め、通信オーバーヘッドを最小限に抑える新しい戦略を採用
- DPFLはさまざまなデータセットで優れた性能を示し、他の手法を上回る

データが異質でも効率的に協力できるなんてすごいね！将来への期待が高まるな〜。これは連合学習をさらに実用化するステップになるかもね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, cs.MA, math.OC, **投稿日時:** 2024-06-10 17:58


- - -

### [Optimisation of federated learning settings under statistical heterogeneity variations](http://arxiv.org/abs/2406.06340)

**統計的不均一性変動下における連合学習設定の最適化**

Basem Suleiman, Muhammad Johan Alibasa, Rizka Widyarini Purwanto, Lewis Jeffries, Ali Anaissi, Jacky Song

- 連合学習は、中央でモデルパラメータを共有することで協力して学習
- 統計的不均一性により、デバイスごとのデータ分布が独立同分布で異なる
- データ分割戦略とメトリックを提案し、異なる統計的不均一性をシミュレート
- 最適なFLモデルとパラメータを特定し、推奨ガイドラインを提供

連合学習の最適化って、けっこうデータのばらつきに左右されるんだね。うまく使えばいろんな場面で役立ちそう！

**Comment:** 27 pages, 17 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-10 15:01


- - -

### [Lurking in the shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning](http://arxiv.org/abs/2406.06207)

**影に潜む: パーソナライズド連合学習に対するステルス性バックドア攻撃の解明**

Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Yongsheng Zhu, Guangquan Xu, Jiqiang Liu, Xiangliang Zhang

- パーソナライズド連合学習（PFL）は各クライアントが個別のローカルモデルを作成できるように設計されている
- PFLの個別化プロセスがバックドア中毒効果を希釈することができ、防御機構を使用して強化可能
- 提案された\textit{PFedBA}攻撃戦略は、主学習タスクとバックドア学習タスクを巧妙に一致させる
- \textit{PFedBA}は10種の最新PFLアルゴリズム全てで高い攻撃性能を示し、6種の既存防御を突破

PFLは連合学習の次のステップみたいだけど、それでもまだまだ安全性に課題がいっぱいだね〜。\textit{PFedBA}のやり方、すごく巧妙だけどちょっと怖いかも！

**Comment:** Accepted by Usenix Security 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-06-10 12:14


- - -

### [Federated learning in food research](http://arxiv.org/abs/2406.06202)

**フードリサーチにおける連合学習**

Zuzanna Fendor, Bas H. M. van der Velden, Xinxin Wang, Andrea Jr. Carnoli, Osman Mutlu, Ali Hürriyetoğlu

- フードリサーチはデータ共有の障害（データ所有、プライバシー、規制）により制約されやすい
- データ共有の障害を軽減するために、ローカルデータを使いモデルをトレーニングする連合学習が提案されている
- 水とミルクの品質評価、サイバーセキュリティ、農薬リスク分析、雑草検出、不正検出の例が含まれる
- 知識ギャップとして縦型/転送連合学習と分散アーキテクチャの不足が指摘されている

フードリサーチに連合学習を取り入れることで、より多くのデータを活用できる可能性が熱いね！技術の進展が楽しみだなぁ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-06-10 11:58


- - -

### [Fed-Sophia: A Communication-Efficient Second-Order Federated Learning Algorithm](http://arxiv.org/abs/2406.06655)

**Fed-Sophia: 通信効率の高い二次連合学習アルゴリズム**

Ahmed Elbakary, Chaouki Ben Issaid, Mohammad Shehab, Karim Seddik, Tamer ElBatt, Mehdi Bennis

- 連合学習は複数のデバイスがパラメータサーバーを介して局所更新を共有し学習する方法
- 二次導関数情報は収束を早めるために重要であるが、それを活用する新たな方法を提案
- 提案手法であるFed-Sophiaは、勾配の加重移動平均とクリッピング操作を組み合わせる
- 提案手法は、数値評価において従来の一次および二次手法と比較して優越性、堅牢性、スケーラビリティを示す

二次導関数の力ってやっぱりすごいんだね！この方法で連合学習がもっと速くなるのかもね。

**Comment:** ICC 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-06-10 09:57


- - -

### [Comments on "Federated Learning with Differential Privacy: Algorithms and Performance Analysis"](http://arxiv.org/abs/2406.05858)

**「連合学習と差分プライバシー：アルゴリズムとパフォーマンス分析」に関するコメント**

Mahtab Talaei, Iman Izadi

- Weiらの論文における連合学習の差分プライバシーアルゴリズムの収束性能が対象
- 提案された差分プライバシーアルゴリズムはNoising before Model Aggregation FL (NbAFL)と呼ばれる
- 元の論文のNbAFLの収束上限（定理2）が誤っていると指摘
- 正しい収束上限をこのコメントで提示することが目的

収束性能の上限が修正されて正確になったみたい。これでNbAFLがもっと効果的に使えるようになるから、注目されそうだね！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.DC, cs.CR, cs.PF, **投稿日時:** 2024-06-09 17:03


- - -

### [Blockchain Integrated Federated Learning in Edge-Fog-Cloud Systems for IoT based Healthcare Applications A Survey](http://arxiv.org/abs/2406.05517)

**IoTベースのヘルスケアアプリケーションにおけるエッジ-フォグ-クラウドシステムに統合されたブロックチェーン連合学習の調査**

Shinu M. Rajagopal, Supriya M., Rajkumar Buyya

- IoTアプリケーションは大量のデータを生成するが、データのサイロ化とユーザープライバシー法が利用を制約する
- 連合学習は分散型パラダイムであり、プライバシーを保ちながらの共同学習を可能にする理想的な手法である
- 暗号技術を使用することで、IoTシステムはデータを安全に保管・送信し、一貫性を保証できる
- ヘルスケアのような機密データの処理における連合学習とブロックチェーンの統合は特に有益である

連合学習とブロックチェーンがヘルスケアデータの処理でどう役立つか、とっても面白そう！エッジ-フォグ-クラウドの説明も知りたいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-08 16:36


- - -

### [PTF-FSR: A Parameter Transmission-Free Federated Sequential Recommender System](http://arxiv.org/abs/2406.05387)

**PTF-FSR: パラメータ送信不要な連合逐次推薦システム**

Wei Yuan, Chaoqun Yang, Liang Qu, Quoc Viet Hung Nguyen, Guanhua Ye, Hongzhi Yin

- 従来の連合逐次推薦システムは共有モデルの必要性があり、知的財産の懸念がある
- 高い通信コストが問題で、大規模言語モデルの時代には適用困難
- PTF-FSRはモデルとデータのプライバシーを保護し、複雑で大規模なモデルに対応可能
- 実験結果は、PTF-FSRの有効性と汎用性を示し、多様なデータセットとモデルで検証

モデルの知的財産を守りつつ、プライバシー保護も実現できるなんて新しいアプローチだね！これで連合学習がもっと広まるかも、早く試してみたい！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.IR, **投稿日時:** 2024-06-08 07:45


- - -

### [Federated LoRA with Sparse Communication](http://arxiv.org/abs/2406.05233)

**スパース通信を用いた連合LoRA**

Kevin Kuo, Arian Raje, Kousik Rajesh, Virginia Smith

- LoRAは通信制約のある機械学習設定での微調整に自然な方法である
- 中央集権型MLの手法でのLoRAの効率改善は連合設定では効果が低い
- 代わりに、通信中にスパース化を適用するFLASCを提案し、局所的微調整を可能にした
- 4つの連合学習タスクで、通信量を10倍削減しつつLoRAの性能を維持することを実証

この論文、連合学習での通信効率ってめっちゃ重要なんだね！性能維持しつつ通信量減らせるなんて、未来のネットワーク環境でも大活躍しそう♡

**Comment:** 12 pages (excluding references), 8 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-07 19:42


- - -

### [FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models](http://arxiv.org/abs/2406.04845)

**FedLLM-Bench: 連合学習で大規模言語モデルを評価するための現実的なベンチマーク**

Rui Ye, Rui Ge, Xinyu Zhu, Jingyi Chai, Yaxin Du, Yang Liu, Yanfeng Wang, Siheng Chen

- 現在の連合学習のデータセットとベンチマークは人工的であり、現実的なシナリオを捉えられていない
- FedLLM-Benchは8つのトレーニング方法、4つのトレーニングデータセット、6つの評価指標を含む
- 提案されたデータセットは多言語や質、量、指示、長さなどの多様性を含んでいる
- FedLLM-Benchは実験を通じて現実的な洞察を提供し、連合学習コミュニティに利益をもたらす

この論文、おもしろそう！連合学習で色々なシナリオを再現できるなんて、これからの研究に役立ちそうだよね！

**Comment:** 22 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.AI, cs.DC, cs.LG, cs.MA, **投稿日時:** 2024-06-07 11:19


- - -

### [When Swarm Learning meets energy series data: A decentralized collaborative learning design based on blockchain](http://arxiv.org/abs/2406.04743)

**スウォームラーニングがエネルギー時系列データと出会うとき: ブロックチェーンに基づく分散協調学習設計**

Lei Xu, Yulong Chen, Yuntian Chen, Longfeng Nie, Xuetao Wei, Liang Xue, Dongxiao Zhang

- 機械学習モデルは、将来のエネルギー生産や消費を予測し、既存のデータから未知の重要変数を推測する能力を持つ。
- エネルギーセクターにおける法的・政策的制約により、データは機密扱いとなり、多様なソースからの利用に技術的な課題が生じる。
- スウォームラーニング（SL）を採用し、中央サーバーをブロックチェーンベースの分散ネットワークに置き換えることで、連合学習（FL）の中央集権型アーキテクチャに内在するセキュリティとプライバシーの問題に対処する。
- 提案されたフレームワークは三つの実世界のエネルギーモデリングシナリオで優れた性能を示し、中央集権型学習およびFL手法に比べてデータセキュリティとプライバシーを強調している。

ブロックチェーンと機械学習が組み合わさって、エネルギー業界の未来が変わるかも！これ、データセキュリティが超強化されるってことだよね？面白くなりそう❤



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, stat.AP, **投稿日時:** 2024-06-07 08:42


- - -

### [Federated Representation Learning in the Under-Parameterized Regime](http://arxiv.org/abs/2406.04596)

**低次元パラメータ領域における連合表現学習**

Renpu Liu, Cong Shen, Jing Yang

- 連合表現学習（FRL）は、共通の表現を学習しつつ個別のヘッドを保持するフレームワーク
- 従来の研究は過剰パラメータ領域に集中していたが、この研究は低次元パラメータ領域を探求
- 新しいアルゴリズムFLUTEを提案し、サンプル複雑性と収束率を理論的に特徴付けた
- 実験結果は、FLUTEが最新のFRLソリューションを両方の合成および実世界のタスクで上回ることを示している

新しいアルゴリズムFLUTEめっちゃ気になる！これが実際に現場でどう使われるか、将来の応用も楽しみだよね。

**Comment:** This work has been accepted to ICML 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-06-07 03:00
