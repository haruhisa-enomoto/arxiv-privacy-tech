---
title: 差分プライバシー (2024-09-20 ~ 2024-09-26)
date: 2024-09-20
---

差分プライバシーに関する論文まとめ (2024-09-20 ~ 2024-09-26)


- - -

### [Slowly Scaling Per-Record Differential Privacy](http://arxiv.org/abs/2409.18118)

**ゆっくりとスケーリングするレコードごとの差分プライバシー**

Brian Finley, Anthony M Caruso, Justin C Doty, Ashwin Machanavajjhala, Mikaela R Meyer, David Pujol, William Sexton, Zachary Terner

- 多くの外れ値を含むデータの統計を公開するための形式的なプライバシーメカニズムを開発
- レコードの影響が大きいほどプライバシー損失が大きくなるが、新しいメカニズムはその低下を対数関数的に抑制
- 例えば給与データのような無限に拡張可能なデータも、影響力の大きいレコードに対して意味のあるプライバシー保護を提供
- 提案したメカニズムの実用性を実証実験で評価し、その有用性を確認

めっちゃ面白そう！経済データみたいな複雑なデータもこれで安心して使えそうだね。ログ関数的に抑えるってすごい未来が広がりそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, stat.ME, **投稿日時:** 2024-09-26 17:56


- - -

### [Fully Dynamic Graph Algorithms with Edge Differential Privacy](http://arxiv.org/abs/2409.17623)

**エッジ差分プライバシーを考慮した完全動的グラフアルゴリズム**

Sofya Raskhodnikova, Teresa Anna Steiner

- エッジの追加と削除が連続的に行われる完全動的な環境での差分プライベートアルゴリズムを研究
- 三角形の数、連結成分の数、最大マッチングのサイズ、次数ヒストグラムなどの基本グラフ統計に対応
- イベントレベルとアイテムレベルの2種類のエッジ差分プライバシーを研究し、それぞれの誤差に上限と下限を設定
- アイテムレベルプライバシーにおけるアルゴリズムの誤差が下限に一致する問題もいくつか存在

この研究、すごく興味深いよね！特に、エッジ差分プライバシーを使った完全動的アルゴリズムが新しい道を切り開いている感じがするよ～

**Comment:** 30 pages, 3 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, cs.CR, **投稿日時:** 2024-09-26 08:17


- - -

### [KIPPS: Knowledge infusion in Privacy Preserving Synthetic Data Generation](http://arxiv.org/abs/2409.17315)

**KIPPS: プライバシー保護型合成データ生成における知識注入**

Anantaa Kotal, Anupam Joshi

- 差分プライバシー技術の統合により、合成データのプライバシーが保証される
- 生成モデルはサイバーセキュリティやヘルスケアなどの重要な領域でのデータ生成に課題がある
- トレーニングデータセットが限定的で多様性がない場合、繰り返し生成される敏感な特徴がプライバシーリスク
- 新しいKIPPSモデルは知識グラフからドメインと規制知識を注入し、現実的でドメイン準拠の合成データ生成を実現

この研究、実際のサイバーセキュリティやヘルスケアデータで試してるんだね。だから、個人情報保護とデータ品質のバランスがとれたデータがどれくらい作れるか、期待しちゃう！



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-09-25 19:50


- - -

### [Immersion and Invariance-based Coding for Privacy-Preserving Federated Learning](http://arxiv.org/abs/2409.17201)

**プライバシー保護連合学習のためのイマージョン・不変性に基づくコーディング**

Haleh Hayati, Carlos Murguia, Nathan van de Wouw

- 連合学習（FL）は、プライバシーを保護しながら分散学習を行う方法である
- FLでは、クライアントがデータを共有せずにデバイス上でモデルを訓練するが、モデル更新から情報が漏れる可能性がある
- 本研究では、差分プライバシーと制御理論のシステムイマージョンツールを組み合わせたFLフレームワークを提案
- 提案フレームワークは、元のアルゴリズムのパラメータが符号化パラメータに収束するように設計され、サーバでデコード可能である

差分プライバシーも制御理論も使ってプライバシーと精度を両立できるアイデアがワクワクするね！連合学習がますます安心して使えるようになるかも～✨



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-09-25 15:04


- - -

### [Cycle Counting under Local Differential Privacy for Degeneracy-bounded Graphs](http://arxiv.org/abs/2409.16688)

**局所差分プライバシーを用いた縮退制約グラフでのサイクルカウント**

Quentin Hillebrand, Vorapong Suppakitpaisarn, Tetsuo Shibuya

- 局所差分プライバシー下で縮退制約されたグラフのサイクル数を数えるアルゴリズムを提案
- これまでの研究は三角形数のカウントに注力し、既存手法のエラーは\(\Omega(n^{1.5})\)
- 提案アルゴリズムは新しい誤差の形式であり、特に\(\delta\)や\(d_{\max}\)に基づく計算を行う
- ソーシャルネットワークのような実際のグラフでより低いエラー率を実現し、その他サイクル長でも応用可能

提案アルゴリズムが既存の問題点を大きく改善しているところが注目どころだよね。どんな応用が可能か考えるとワクワクしちゃう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DS, **投稿日時:** 2024-09-25 07:23


- - -

### [Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learning](http://arxiv.org/abs/2409.13440)

**微分プライベートなマルチモーダルラプラシアン脱落 (DP-MLD) を用いたEEG代表学習**

Xiaowen Fu, Bingxin Wang, Xinzhou Guo, Guoqing Liu, Yang Xiang

- 疾病検出で有望なマルチモーダルEEG学習と、法的・倫理的懸念に対処するプライバシー保護が重要
- 微分プライバシー (DP) は解釈が明確で実装が容易なため広く採用されるが、マルチモーダルEEGデータにはあまり適用されていない
- 提案手法(DP-MLD)はEEGデータを言語モデルでテキストとして処理し、他のモーダルデータをビジョントランスフォーマーで画像として処理する新しい代表学習モデル
- 実験では、パーキンソン病の歩行不自由症(Freezing of Gait: FoG)に関するデータセットで約4%の分類精度向上と最新の性能を達成

すごく面白そう！プライバシーを守りながら精度も上げるって、まさに未来って感じだよね。これからもっと応用が広がりそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** eess.SP, cs.AI, cs.CR, cs.LG, **投稿日時:** 2024-09-20 12:08


- - -

### [CorBin-FL: A Differentially Private Federated Learning Mechanism using Common Randomness](http://arxiv.org/abs/2409.13133)

**CorBin-FL: 共通ランダム性を利用した差分プライバシー連合学習メカニズム**

Hojat Allah Salehi, Md Jueal Mia, S. Sandeep Pradhan, M. Hadi Amini, Farhad Shirani

- 連合学習は複数のクライアントの協調による分散学習を可能にするが、プライバシー、通信効率、モデル精度のバランスを取るのが課題
- CorBin-FLは相関バイナリ確率量子化を使用し、差分プライバシーを確保しつつ、全体のモデル精度を維持するメカニズム
- この方法は、個々のプライバシーを侵害せずにローカルモデルの更新を相関量子化するために秘密計算技術を使用
- AugCorBin-FLはユーザーレベルおよびサンプルレベルの中央差分プライバシーも達成し、理論的にプライバシーと精度のトレードオフを最適化

連合学習のプライバシー保護がこんなに進化してるなんてビックリ！私たちのデータがより安全に使われる世の中になるのが楽しみだな。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.IT, math.IT, **投稿日時:** 2024-09-20 00:23
