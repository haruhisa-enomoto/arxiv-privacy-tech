---
title: 差分プライバシー (2024-12-27 ~ 2025-01-02)
date: 2024-12-27
---

差分プライバシーに関する論文まとめ (2024-12-27 ~ 2025-01-02)


- - -

### [A Tale of Two Imperatives: Privacy and Explainability](http://arxiv.org/abs/2412.20798)

**2つの命令: プライバシーと説明可能性の物語**

Supriya Manna, Niladri Sett

- 深層学習の普及が、プライバシーと説明可能性の両方を満たす枠組みを要請
- プライバシーには差分プライバシーを採用し、強力な定量的保証を提供
- 説明可能性には、モデル訓練と独立したポストホック説明が選ばれる
- 両者を高リスクな用途で効果的に統合する方法と産業ソフトウェアの例を提示

プライバシーと説明可能性の両立を実際の例で示すのがステキ！どの業界でも応用効きそうで楽しみだね。

**Comment:** Work in progress

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.CV, **投稿日時:** 2024-12-30 08:43


- - -

### [SafeSynthDP: Leveraging Large Language Models for Privacy-Preserving Synthetic Data Generation Using Differential Privacy](http://arxiv.org/abs/2412.20641)

**SafeSynthDP: 差分プライバシーを用いたプライバシー保護型合成データ生成のための大規模言語モデル活用**

Md Mahadi Hasan Nahid, Sadid Bin Hasan

- 機械学習モデルは個人情報を含むデータに依存し、プライバシー問題を引き起こす
- 大規模言語モデルを用いて差分プライバシー付きの合成データセットを生成する手法を提案
- ラプラスやガウス分布によるノイズ注入でデータのプライバシー保持を確保
- 実験では、差分プライバシー機構を組み込んだ合成データがプライバシーとデータ利用性のバランスを実現

大規模言語モデルがプライバシーを守りながらデータを生成できるなんてかっこいい！これが普及すれば、安心して研究や開発ができそうだよね。未来の技術がどんどん進化していくのが楽しみ！

**Comment:** 15 pages, 1 figure, 5 tables

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-12-30 01:10


- - -

### [Sub-optimal Learning in Meta-Classifier Attacks: A Study of Membership Inference on Differentially Private Location Aggregates](http://arxiv.org/abs/2412.20456)

**メタ分類器攻撃における最適でない学習：差分プライバシーによる位置情報集計に対するメンバーシップ推論の研究**

Yuhan Liu, Florent Guepin, Igor Shilov, Yves-Alexandre De Montjoye

- 差分プライバシーを用いた位置情報の集計でも、プライバシーリスクが過小評価される可能性がある。
- 新たに1つの閾値攻撃と2つの閾値攻撃の2つのメトリック基準のMIAsを提案し、異なるデータ分布での効果を調査。
- MLPベースの攻撃はラプラスノイズ下で最適でなく、プライバシーリスクを過小評価することがわかった。
- 差分プライバシー付きデータ集合全般にも応用可能であり、合成データ生成や事前学習が複雑なルール学習を促進可能。

位置情報だけでなく、他のデータにも使えるって面白そう！実際のプライバシーリスクがもっと正確にわかったら、安心感が増すかもね。あと、合成データとか事前学習で進化したMLPがどんな結果をもたらすのか、未来が楽しみだね。



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-12-29 12:51
