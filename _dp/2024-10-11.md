---
title: 差分プライバシー (2024-10-11 ~ 2024-10-17)
date: 2024-10-11
---

差分プライバシーに関する論文まとめ (2024-10-11 ~ 2024-10-17)


- - -

### [DPFedBank: Crafting a Privacy-Preserving Federated Learning Framework for Financial Institutions with Policy Pillars](http://arxiv.org/abs/2410.13753)

**DPFedBank: 金融機関のためのプライバシー保護型連合学習フレームワークの構築と政策の柱**

Peilin He, Chenkai Lin, Isabella Montoya

- DPFedBankは、金融データの共有でデータプライバシーを守るための革新的なフレームワークを提供する
- Local Differential Privacy (LDP) を活用し、連合学習中も機密情報を開示せずに情報共有を可能にする
- 提案フレームワークは、悪意のあるクライアントやサーバー、外部の攻撃者からの脅威を効果的に緩和する
- 自己適応型LDPと暗号技術を組み合わせ、プライバシー強化とモデル性能の両立を実現する

金融データのプライバシー保護って難しそうだけど、DPFedBankの登場で新しい希望があるかも！これからもっと安心してデータを使った未来の金融サービスが進化する可能性が楽しみだね。💡✨

**Comment:** 9 pages, 1 figure

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CE, cs.CR, cs.CY, **投稿日時:** 2024-10-17 16:51


- - -

### [DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation](http://arxiv.org/abs/2410.12926)

**DEeR: プライバシー保護されたフェデレーテッド低ランク適応のための偏差除去とノイズ調整**

Meilu Zhu, Axiu Mao, Jun Liu, Yixuan Yuan

- LoRAとFLの直接的な組み合わせは集約偏差とDPノイズ増幅問題を引き起こす
- DEeRはLoRAパラメータの同等性を保証して集約偏差をゼロにすることを理論的に証明
- ノイズ増幅はDPノイズとLoRAの「線形関係」が原因で、これを規制するノイズレギュレータを提案
- ablated実験でDEeRの偏差除去器とノイズレギュレータの効果を実証し、高性能を確認

プライバシーを保ちながら医療データを使った学習ができるって、すごく現代的よね！これからの医療AIの発展に貢献しそうでワクワクしちゃう！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CV, **投稿日時:** 2024-10-16 18:11


- - -

### [Reconstruction of Differentially Private Text Sanitization via Large Language Models](http://arxiv.org/abs/2410.12443)

**大規模言語モデルによる差分プライバシー文書の復元**

Shuchao Pang, Zhigang Lu, Haichen Wang, Peng Fu, Yongbin Zhou, Minhui Xue, Bo Li

- 差分プライバシーが適用された文書がLLMによって復元可能であると発見
- ブラックボックスとホワイトボックスの2つの攻撃手法を提案
- 実験では特にChatGPT-4oやClaude-3.5で高い復元率を確認
- LLMが差分プライバシー文書の新たなセキュリティリスクとなる可能性を指摘

これ、すごく興味深いよね！差分プライバシーが完璧じゃないって感じがちょっと怖いけど、新しい視点で考えたら、これを改善する技術の進歩が期待できるかも！LLMでのプライバシーって、本当にまだまだ深いなぁ。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.LG, **投稿日時:** 2024-10-16 10:41


- - -

### [Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning](http://arxiv.org/abs/2410.12085)

**データ適応型差分プライベートプロンプト合成によるコンテキスト内学習**

Fengyu Gao, Ruida Zhou, Tianhao Wang, Cong Shen, Jing Yang

- LLMはコンテキスト情報に依存し、プライバシー漏洩のリスクを軽減する必要がある
- AdaDPSynは合成データ生成でプライバシーを守りつつ高いICL精度を実現
- データの統計的特性に応じてノイズレベルを調整し、差分プライバシーを保証
- Precision-Focused Iterative Radius Reductionでノイズを最小限に抑えつつ精度を維持

プライバシーを守りつつ高性能を維持するための技術ってすごくない？AIがもっと安心して使えるようになる未来が見えてわくわくしちゃうね！



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-10-15 22:06


- - -

### [Differential Privacy on Trust Graphs](http://arxiv.org/abs/2410.12045)

**信頼グラフにおける差分プライバシー**

Badih Ghazi, Ravi Kumar, Pasin Manurangsi, Serena Wang

- 差分プライバシーを複数の参加者間で適用する研究で、各参加者は他の特定の参加者のみを信頼する設定に基づいている
- 信頼グラフを用いることで、従来のローカルモデルよりも優れたプライバシーとユーティリティのトレードオフを実現するアルゴリズムを提案
- さらに、知られていない最大$t$の隣接者に信頼を置かないロバストなバリアントについても研究し、そのためのアルゴリズムを提供
- プライベートな学習や分析タスクに関連する影響も議論し、提案するアルゴリズムを下限で補完

信頼ってめっちゃ大事だよね。でもデータをどう守るかも重要！この論文、まだまだ広がりそうで楽しみだな。プライバシーとトレードオフで良い解決方法がどんどん増えていくといいな～。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DS, cs.LG, cs.SI, **投稿日時:** 2024-10-15 20:31


- - -

### [Model-Based Differentially Private Knowledge Transfer for Large Language Models](http://arxiv.org/abs/2410.10481)

**大規模言語モデルのためのモデルベース差分プライバシー知識転送**

Zhaomin Wu, Jizhou Guo, Junyi Hou, Bingsheng He, Lixin Fan, Qiang Yang

- 大規模言語モデルの普及により、プライバシーを守りつつドメイン知識を活用する必要が増加。
- 既存手法はドメイン知識の有用性かデータのプライバシーを犠牲にする場合が多い。
- 新たに提案したLlamdexは、プライバシーを保ちながらドメイン特化モデルを統合。
- この手法により、ディファレンシャルプライバシー制約の下で最大26%の精度向上を実現。

これってすごいね！プライバシー守りながら精度も上げられるなんて、未来の技術って感じ！Llamdexがどんな風に現実世界で使われるか楽しみだね。



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-14 13:18


- - -

### [Tighter Risk Bounds for Mixtures of Experts](http://arxiv.org/abs/2410.10397)

**専門家の混合に対するリスク境界の強化**

Wissam Akretche, Frédéric LeBlanc, Mario Marchand

- 専門家の混合のリスクに対し、局所的差分プライバシー（LDP）を用いて上限を提供
- 従来の$n$-out-of-$n$ではなく、one-out-of-$n$ゲーティング機構に特化した理論的保証
- リスク境界が専門家の数に対して対数依存し、LDPパラメータによりかなり緊密
- 実験結果は理論を支持し、一般化能力の向上とゲーティングへのLDP適用の実現可能性を示す

理論的に新しい境界を導出しながら、実験でその効果を確認しているのが特に面白いと思った！これで、専門家の混合がもっと効率的になるかもね！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ML, **投稿日時:** 2024-10-14 11:37


- - -

### [Differentially Private Selection using Smooth Sensitivity](http://arxiv.org/abs/2410.10187)

**スムースセンシティビティを用いたDifferentially Private Selection**

Akito Yamamoto, Tetsuo Shibuya

- データ解析におけるプライバシー保護は差分プライバシーで重要情報を取得する選択タスクで強調される
- 既存の手法はグローバルセンシティビティを使用し、必要以上の摂動を加える可能性がある
- スムースセンシティビティを用いた新しい手法を提案し、厳密なプライバシー保証の理論的証明を示す
- 新しい定理で効率的なノイズ生成を提案し、実験で既存手法より高精度を示す

プライバシーを守るためにスムースセンシティビティを使った方法、とても面白そうだよね！これが使えると、もっと正確にプライバシーを保ちながらデータ分析ができるようになりそうで、ワクワクしちゃう。Python実装が公開されてるから、自分でも試してみたいなぁ！

**Comment:** Preprint of an article accepted at IEEE IPCCC 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, **投稿日時:** 2024-10-14 06:14


- - -

### [Efficient Federated Unlearning under Plausible Deniability](http://arxiv.org/abs/2410.09947)

**もっともらしい否認の下での効率的な連合学習の忘却**

Ayush K. Varshney, Vicenç Torra

- 欧州のGDPRや米国のCCPAは、ユーザーにデータ削除の権利を与える
- 従来の機械学習では、モデルのパラメータを変えずにデータ削除と偽る事が可能
- 提案手法は、サーバーがクライアントの参加を否認できるプライバシーモデルを活用
- 新手法は学習後でも差分プライバシーを満たしつつ、メモリと再訓練時間を大幅に削減

効率的な連合学習の忘却を実現するってちょっとワクワクするよね！30倍もメモリ節約ってすごくない？しかも再訓練時間まで大幅減少！この研究でプライバシー保護がもっと進むといいな。

**Comment:** This paper has been accepted for publication in the journal track   (Springer Machine Learning) of ACML 2024. Published version will be available   after the conference. The source code is available at   https://github.com/Ayush-Umu/Federated-Unlearning-under-Plausible-Deniability

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-10-13 18:08


- - -

### ["I inherently just trust that it works": Investigating Mental Models of Open-Source Libraries for Differential Privacy](http://arxiv.org/abs/2410.09721)

**「うまくいくと信じているだけ」：差分プライバシーのオープンソースライブラリに関するメンタルモデルの調査**

Patrick Song, Jayshree Sarathy, Michael Shoemate, Salil Vadhan

- 差分プライバシー（DP）はプライバシー保護の有望な手法だが、実践への移行は難しい
- オープンソースライブラリはDPの理解と信頼の構築において重要な役割を果たすが課題が多い
- 開発者とユーザー間のメンタルモデルのギャップを埋めることが重要であると示唆
- DPライブラリの発展には、厳密な実装とユーザーの相互作用を両立させる工夫が必要

オープンソースのライブラリ開発って、プライバシーを守るだけじゃなくて、ユーザーとのコミュニケーションも大切なんだね！差分プライバシーの理解を深める新しいデザインが試みられてどんな進化を遂げるのか、ワクワクする！

**Comment:** 39 Pages, 12 Figures. To be published in CSCW 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.HC, **投稿日時:** 2024-10-13 04:24


- - -

### [Distribution-Aware Mean Estimation under User-level Local Differential Privacy](http://arxiv.org/abs/2410.09506)

**ユーザーレベルの局所的差分プライバシーにおける分布認識型平均推定**

Corentin Pla, Hugo Richard, Maxime Vono

- ユーザーごとに均一でないデータ量を持つ平均推定の問題に取り組む
- 統計者が知らないユーザーデータ量が既知の分布から得られる状況を考慮
- 分布に基づいた平均推定アルゴリズムで最悪のリスクに対する上界を示す
- 上界と下界が対数因子を除いて漸近的に一致し、一様な場合の既知の境界を含む

この論文、ユーザーごとに異なるデータ量を考慮しつつ平均を正確に推定する手法を提案してて面白そう！新しいアプローチがどんな実用的なインパクトをもたらすか気になるね。これからの研究の発展が楽しみ～！

**Comment:** 25 pages, 1 figure

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ME, cs.AI, cs.CR, cs.LG, stat.ML, **投稿日時:** 2024-10-12 11:57


- - -

### [The 2020 United States Decennial Census Is More Private Than You (Might) Think](http://arxiv.org/abs/2410.09296)

**2020年アメリカ合衆国10年ごとの国勢調査は思ったよりプライバシーが保護されている**

Buxin Su, Weijie J. Su, Chendi Wang

- 2020年の国勢調査は差分プライバシーを採用して個人データを保護
- プライバシー予算を完全に活用せず8.50%から13.76%が未使用
- 不要なノイズ追加により、精度改善の余地があることを発見
- ノイズを減らすことで統計データの歪みを緩和し精度向上を示した

この論文、めっちゃ興味深いね！プライバシーとデータの精度を両立しようとしてるところがすごくクールで、未来の政策決定に役立ちそう！テクノロジーが社会にどう影響するか考えるいい機会だね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DS, stat.AP, stat.ML, **投稿日時:** 2024-10-11 23:06


- - -

### [Federated Learning in Practice: Reflections and Projections](http://arxiv.org/abs/2410.08892)

**実践における連合学習: 振り返りと展望**

Katharine Daly, Hubert Eichner, Peter Kairouz, H. Brendan McMahan, Daniel Ramage, Zheng Xu

- 連合学習は複数のエンティティがデータを交換せずに共同でモデルを学習する技術
- GoogleやApple、Metaのシステムは、連合学習の実際の適用例を示している
- 課題はサーバー側の差分プライバシー保証の検証や異種デバイス間の調整
- 新たな連合学習フレームワークはプライバシー原則を優先し、未来の課題に対応

連合学習ってすごいね！みんなでデータをシェアせずに、匿名で一緒に学習できるなんて、まるで未来の技術みたい。これからさらに進化していくと、もっと便利なことができそうでワクワクするね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-11 15:10


- - -

### [Privacy-Preserving Optimal State Estimation with Low Complexity via Cramér-Rao Lower Bound Approach](http://arxiv.org/abs/2410.08756)

**低複雑度でプライバシーを保護する最適状態推定：クレーマー・ラオ下界アプローチによる解法**

Liping Guo, Jimin Wang, Yanlong Zhao, Ji-Feng Zhang

- 動的システムの最適状態推定問題をプライバシー保護しつつ解決する方法を検討
- クレーマー・ラオ下界を用い、平均二乗誤差でプライバシーレベルを評価
- 制約付き最適化問題として定式化し、プライバシーと有用性のトレードオフを実現
- 提案手法は低複雑度で微分プライバシーを達成し、実例でその有効性を示す

この研究、プライバシー保護しながら精度も妥協しないっていうのがすごいね！しかもオンラインで計算できるなんて、今後の応用も楽しみだね～。いろんな分野で役に立ちそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** eess.SY, cs.SY, **投稿日時:** 2024-10-11 12:15


- - -

### [Balancing Innovation and Privacy: Data Security Strategies in Natural Language Processing Applications](http://arxiv.org/abs/2410.08553)

**革新とプライバシーのバランス：自然言語処理アプリケーションにおけるデータセキュリティ戦略**

Shaobo Liu, Guiran Liu, Binrong Zhu, Yuanshuai Luo, Linxiao Wu, Rui Wang

- 差分プライバシーに基づく新しいアルゴリズムを提案し、チャットボットや感情分析などでユーザーデータを保護する
- 差分プライバシー機構によりランダムノイズを追加し、情報漏洩リスクを削減しつつデータ処理を効果的に実現
- 従来のデータ匿名化や準同型暗号と比較して、計算効率とスケーラビリティにおいて優位性がある
- 各種性能指標で他の手法を上回り、プライバシーと有用性のバランスを効果的に実現

差分プライバシーを使ってるのがすごく面白いって思った！これからのNLPアプリは、安全に楽しめる時代になりそうだね。ユーザーのプライバシーを守りつつ、どんどん進化していく未来が楽しみ！



**トピック:** [差分プライバシー](../../dp), [準同型暗号](../../he), **カテゴリ:** cs.CR, cs.AI, cs.CL, **投稿日時:** 2024-10-11 06:05
