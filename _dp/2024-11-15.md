---
title: 差分プライバシー (2024-11-15 ~ 2024-11-21)
date: 2024-11-15
---

差分プライバシーに関する論文まとめ (2024-11-15 ~ 2024-11-21)


- - -

### [No-regret Exploration in Shuffle Private Reinforcement Learning](http://arxiv.org/abs/2411.11647)

**プライバシー強化型強化学習における後悔のない探索**

Shaojie Bai, Mohammad Sadegh Talebi, Chengcheng Zhao, Peng Cheng, Jiming Chen

- 差分プライバシーがエピソディック強化学習に導入され、ユーザープライバシー問題に対応
- 中央モデルとローカルモデルの信頼モデルが存在し、それぞれに課題がある
- 新たにシャッフルモデルを用いて、中央モデルより強くローカルモデルより低コストでデータを保護
- シュッフルプライバタイザーを用い、最適な後悔境界を達成しつつプライバシーコストを削減

プライバシーを守りながらもパフォーマンスが良くなるって、すごく良さそう！今後の色んな場面でこの技術が活躍しそうだね。ますます安心してデジタルサービスを使えるようになるかも！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-11-18 15:24


- - -

### [Preempting Text Sanitization Utility in Resource-Constrained Privacy-Preserving LLM Interactions](http://arxiv.org/abs/2411.11521)

**リソースが限られた環境でのプライバシー保持LLM対話におけるテキスト洗浄の利用価値の先取り**

Robin Carpentier, Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Dali Kaafar

- オンラインLLMの利用が増加し、第三者がユーザ情報を収集するプライバシー問題が存在する
- ユーザのプロンプトを洗浄するテクニックが提案されているが、性能に悪影響を与える
- 洗浄が経済的損失や計算資源の無駄を招くため、問題となる
- ユーザ側でSLMを使い、送信前に洗浄の影響を見積もるアーキテクチャを提案

大きなLLMを使うだけでなく、ユーザ側で小さいモデルも活用するなんて新しいよね。プライバシー問題を解決しつつ資源の無駄を防ぐ方法がどんどん進化してて面白い！これからの研究でより安全で効率的な技術が広がることを期待したいな。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-11-18 12:31


- - -

### [Efficient Federated Unlearning with Adaptive Differential Privacy Preservation](http://arxiv.org/abs/2411.11044)

**適応型差分プライバシーによる効率的な連合型アンラーニング**

Yu Jiang, Xindi Tong, Ziyao Liu, Huanyi Ye, Chee Wei Tan, Kwok-Yan Lam

- 連合型アンラーニングは「忘れられる権利」を実現し、特定クライアントデータの影響を消去する。
- 最もシンプルな方法はモデルを再構築することだが、リソースが多く必要である。
- 提案手法FedADPは適応型差分プライバシーを使用し、効率とプライバシーを両立する。
- FedADPの実証実験は、アンラーニングの効率性とプライバシー保護のトレードオフを管理する。

「忘れられる権利」とか、めちゃくちゃ大事だよね！自分のデータとかコントロールできるのすごい。FedADPみたいな技術がもっと普及して、安全な未来が待ってるって考えるとワクワクする！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-11-17 11:45


- - -

### [To Shuffle or not to Shuffle: Auditing DP-SGD with Shuffling](http://arxiv.org/abs/2411.10614)

**シャッフルするかしないか: シャッフルを伴うDP-SGDの監査**

Meenatchi Sundaram Muthu Selva Annamalai, Borja Balle, Emiliano De Cristofaro, Jamie Hayes

- DP-SGDは訓練データをバッチで処理し、ポアソン部分サンプリングを用いる手法である
- コンピュータの互換性のため、部分サンプリングをシャッフルに置き換えることが一般化
- シャッフルによるDP保証は不明であり、過大評価されたプライバシー保証を指摘
- バッチサイズなどのパラメータがプライバシー漏洩に影響することを確認

この研究、めっちゃ重要そうじゃない？だって、みんなが使ってるシャッフルが本当にいいのか、疑問視してて、ちゃんと新しい監査手法で確認しているのカッコイイ！これからのプライバシー保護、しっかり進化させてくれそう。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-11-15 22:34
