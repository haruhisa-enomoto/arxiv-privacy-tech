---
title: 差分プライバシー (2024-04-26 ~ 2024-05-02)
date: 2024-04-26
---

差分プライバシーに関する論文まとめ (2024-04-26 ~ 2024-05-02)


- - -

### [Navigating Heterogeneity and Privacy in One-Shot Federated Learning with Diffusion Models](http://arxiv.org/abs/2405.01494)

**一発合成学習における異質性とプライバシーの調査：拡散モデルの使用**

Matias Mendieta, Guangyu Sun, Chen Chen

- 一発合成学習は通信ラウンドを削減し、効率を向上させ、盗聴攻撃からのセキュリティを強化するが、データの異質性の問題が残る
- 拡散モデルが一発合成学習においてデータ異質性に対処し、全体のパフォーマンスを向上させるのに有効であることを示す
- FedDiffという拡散モデルアプローチを差分プライバシーの下で他の一発合成学習手法と比較し、その有用性を調査
- 差分プライバシー設定下で生成されたサンプルの品質を改善するために、実際的なフーリエ振幅フィルタリング法を提案し、グローバルモデルトレーニングでの生成データの効果を向上



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CV, cs.CR, cs.LG, **投稿日時:** 2024-05-02 17:26


- - -

### [Privacy-Enhanced Database Synthesis for Benchmark Publishing](http://arxiv.org/abs/2405.01312)

**プライバシー保護付きデータベース合成によるベンチマークパブリッシング**

Yongrui Zhong, Yunqing Ge, Jianbin Qin, Shuyuan Zheng, Bo Tang, Yu-Xuan Qiu, Rui Mao, Ye Yuan, Makoto Onizuka, Chuan Xiao

- 実際のユーザーデータを取り入れたデータベース作成により、ビジネス環境をより正確に反映させる動きが増えている
- プライバシーの問題から直接データの共有は避けられがちであり、プライバシー保護を優先した合成データベースの作成が重要視されている
- PrivBenchという新しい合成フレームワークを導入し、プライバシーを保持しつつ高品質なデータ生成を支援する
- PrivBenchは差分プライバシーを利用し、クエリ性能がオリジナルのデータに近いプライバシー保護データベースを生成することに成功している



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DB, cs.CR, **投稿日時:** 2024-05-02 14:20


- - -

### [The Privacy Power of Correlated Noise in Decentralized Learning](http://arxiv.org/abs/2405.01031)

**分散学習における相関ノイズのプライバシー保護効果**

Youssef Allouah, Anastasia Koloskova, Aymane El Firdoussi, Martin Jaggi, Rachid Guerraoui

- 分散学習を用いることで中央集権を避けつつ、大量の分散データとリソースをスケーラブルに利用可能
- 分散SGDに差分プライバシーを統合した新型手法「Decor」を提案し、局所モデルの保護に相関ガウスノイズを注入
- Decorは任意の接続グラフに対して中心差分プライバシーの最適なプライバシーと効用のトレードオフに匹敵
- 通信対の秘密共有を前提とした新しいローカル差分プライバシーの緩和版（SecLDP）と、それに対応するプライバシー計算ツールを提案

**Comment:** Accepted as conference paper at ICML 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DC, math.OC, stat.ML, **投稿日時:** 2024-05-02 06:14


- - -

### [Metric geometry of the privacy-utility tradeoff](http://arxiv.org/abs/2405.00329)

**メトリック幾何学とプライバシー・ユーティリティトレードオフ**

March Boedihardjo, Thomas Strohmer, Roman Vershynin

- 合成データはデータ共有におけるプライバシーを確保する魅力的な概念である
- メトリックプライバシーを使用し、離散的な設定を超えた差分プライバシーの一般化を効果的に実施
- データの基盤となる空間のメトリック幾何学によって、最適なプライバシー精度トレードオフを特徴づける問題を提起
- 「エントロピックスケール」という量を用いて、この問題の部分的な解決策を提供し、メトリック空間の多スケール幾何学を捉える



**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DS, math.PR, **投稿日時:** 2024-05-01 05:31


- - -

### [Differentially Private Release of Israel's National Registry of Live Births](http://arxiv.org/abs/2405.00267)

**差分プライバシーを用いたイスラエル国立出生登録簿の公開**

Shlomi Hod, Ran Canetti

- イスラエルの保健省は2014年の生誕データを差分プライバシー技術を用いて処理し、科学研究や政策立案に利用可能なデータセットをリリース
- プライバシー保護の基準として差分プライバシーを採用し、プライバシー喪失予算（\(\epsilon = 9.98\)）が設定された
- データ変換やモデル生成アルゴリズム選択等、複数のステップでプライベート選択アルゴリズムを活用
- プロジェクトの評価は差分プライバシー保証を提供するため、受入基準もおおよそのみ開示された



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.CY, cs.DS, **投稿日時:** 2024-05-01 01:20


- - -

### [Private graph colouring with limited defectiveness](http://arxiv.org/abs/2404.18692)

**プライベートグラフ彩色における限定的な欠陥性**

Aleksander B. G. Christiansen, Eva Rotenberg, Teresa Anna Steiner, Juliette Vlieghe

- 差分プライバシーは、幅広い分野で重要なプライバシー保護データ分析の問題でゴールドスタンダードである
- 本研究では、差分プライバシー設定下での頂点色付け問題を検討している
- エッジ差分プライベート化を実現するための色分けアルゴリズムは欠陥が必要で、d-欠陥性色分けとは頂点が最大d個の隣接点と色を共有できる状況を指す
- 提案されたε-差分プライベート色分けアルゴリズムは、グラフをΘ({Δ} / log n + 1 / {ε})色で最大Θ(log n)の欠陥性で色分け可能



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, **投稿日時:** 2024-04-29 13:41


- - -

### [SPECIAL: Synopsis Assisted Secure Collaborative Analytics](http://arxiv.org/abs/2404.18388)

**SPECIAL: シノプシス支援型安全協調分析**

Chenghong Wang, Lina Qiu, Johes Bater, Yukui Luo

- 従来の安全協調分析(SCA)はデータの秘匿性が高いが、データ忘却プリミティブの大きなオーバーヘッドが実用的な採用を妨げている
- SPECIALは、制御された情報漏洩を許容することでプライバシーと効率のバランスが取れた初のSCAシステムである
- 特定のプライバシーコストで個人データからプライベートシノプシス(テーブル統計)を取得し、プライバシーを損なうことなくデータを安全に処理する
- 複雑なクエリに対して80倍高速なクエリ時間と900倍以上小さなメモリ使用量を実現し、連続処理におけるプライバシー損失も大幅に削減



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DB, **投稿日時:** 2024-04-29 02:55


- - -

### [Federated Learning and Differential Privacy Techniques on Multi-hospital Population-scale Electrocardiogram Data](http://arxiv.org/abs/2405.00725)

**連合学習と差分プライバシー技術を用いた複数病院の大規模心電図データに関する研究**

Vikhyat Agrawal, Sunil Vasu Kalmady, Venkataseetharam Manoj Malipeddi, Manisimha Varma Manthena, Weijie Sun, Saiful Islam, Abram Hindle, Padma Kaul, Russell Greiner

- カナダ・アルバータの7つの病院からの1,565,849件の心電図データを使用し、連合学習と差分プライバシーを適用して多ラベル心電図分類モデルを学習
- 連合学習を用いることで、病院間で生データを共有せずにモデル訓練を共同で行い、様々な心臓病の診断に有効な心電図分類モデルを構築
- 実装された連合学習モデルは、全ての病院のデータを集約して訓練したモデルと比較して同等の性能を示す
- 差分プライバシーを使用することで、モデルの性能とデータプライバシーのトレードオフを示し、訓練データが限られている病院にとってもメリットがあることを示唆

**Comment:** Accepted for ICMHI 2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** eess.SP, cs.CR, cs.LG, **投稿日時:** 2024-04-26 19:29


- - -

### [Evaluations of Machine Learning Privacy Defenses are Misleading](http://arxiv.org/abs/2404.17399)

**機械学習のプライバシー防御評価は誤解を招く**

Michael Aerni, Jie Zhang, Florian Tramèr

- 実証的な機械学習プライバシー防御は、高い効用を達成し現実的な敵に抵抗するため、差分プライバシーの証明可能な保証を放棄している
- 会員推定攻撃に基づく既存の実証的プライバシー評価に重大な欠陥があり、誤解を招く結論につながる
- これらの評価は、最も脆弱なサンプルのプライバシー漏洩を特定できず、弱い攻撃を使用し、実用的な差分プライバシー基準との比較を避けている
- 5つのケーススタディから、以前の評価はプライバシー漏洩を大幅に過小評価しており、私たちのより強力な評価では実証的防御は高効用なDP-SGD基準と競合しないことがわかった



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-04-26 13:21
