[
  {
    "url": "http://arxiv.org/abs/2405.01511",
    "title": "D2PO: Discriminator-Guided DPO with Response Evaluation Models",
    "japanese_title": "D2PO: DiscriminatorによるDPOと応答評価モデル",
    "authors": [
      "Prasann Singhal",
      "Nathan Lambert",
      "Scott Niekum",
      "Tanya Goyal",
      "Greg Durrett"
    ],
    "categories": [
      "cs.CL"
    ],
    "comment": "20 pages, 12 figures",
    "summary": "- D2POは、学習中に継続的に好みのデータを収集するオンライン設定にて、従来のDPOを拡張した新しいアプローチ\n- D2POは、ポリシーだけでなく、合成データをさらにラベル付けするための差別的応答評価モデルの訓練にも好みのデータを使用\n- リアルなチャット環境を含む様々なタスクにわたってD2POを検討し、同じデータ予算での出力品質がDPOよりも高く、効率も向上\n- 効果的なシルバーラベリングの条件を明らかにし、ポリシーモデルとは別のディスクリミネーターを保持することが効果的",
    "topics": [
      "合成データ"
    ],
    "published": "2024-05-02T17:44:41+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01494",
    "title": "Navigating Heterogeneity and Privacy in One-Shot Federated Learning with Diffusion Models",
    "japanese_title": "一発合成学習における異質性とプライバシーの調査：拡散モデルの使用",
    "authors": [
      "Matias Mendieta",
      "Guangyu Sun",
      "Chen Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.CR",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 一発合成学習は通信ラウンドを削減し、効率を向上させ、盗聴攻撃からのセキュリティを強化するが、データの異質性の問題が残る\n- 拡散モデルが一発合成学習においてデータ異質性に対処し、全体のパフォーマンスを向上させるのに有効であることを示す\n- FedDiffという拡散モデルアプローチを差分プライバシーの下で他の一発合成学習手法と比較し、その有用性を調査\n- 差分プライバシー設定下で生成されたサンプルの品質を改善するために、実際的なフーリエ振幅フィルタリング法を提案し、グローバルモデルトレーニングでの生成データの効果を向上",
    "topics": [
      "連合学習",
      "差分プライバシー"
    ],
    "published": "2024-05-02T17:26:52+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01462",
    "title": "Uncertainty for Active Learning on Graphs",
    "japanese_title": "グラフ上のアクティブラーニングにおける不確実性",
    "authors": [
      "Dominik Fuchsgruber",
      "Tom Wollschläger",
      "Bertrand Charpentier",
      "Antonio Oroz",
      "Stephan Günnemann"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- アクティブラーニング戦略の一つである不確実性サンプリングは、データ点の不確実性が最も高いもののラベルを反復的に取得することで機械学習モデルのデータ効率を向上させることを目指している\n- この戦略は独立データに対して有効であるが、グラフに対する適用可能性は十分に探究されていない\n- 論文ではノード分類のための不確実性サンプリングに関する最初の包括的研究を提案し、異なるアクティブラーニング戦略と比べてその性能差を明らかにした\n- 実データと合成データにおいて、他の不確実性推定手法よりも優れた結果を示す近似的アプローチを設計し、実証した",
    "topics": [
      "合成データ"
    ],
    "published": "2024-05-02T16:50:47+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01312",
    "title": "Privacy-Enhanced Database Synthesis for Benchmark Publishing",
    "japanese_title": "プライバシー保護付きデータベース合成によるベンチマークパブリッシング",
    "authors": [
      "Yongrui Zhong",
      "Yunqing Ge",
      "Jianbin Qin",
      "Shuyuan Zheng",
      "Bo Tang",
      "Yu-Xuan Qiu",
      "Rui Mao",
      "Ye Yuan",
      "Makoto Onizuka",
      "Chuan Xiao"
    ],
    "categories": [
      "cs.DB",
      "cs.CR"
    ],
    "comment": "",
    "summary": "- 実際のユーザーデータを取り入れたデータベース作成により、ビジネス環境をより正確に反映させる動きが増えている\n- プライバシーの問題から直接データの共有は避けられがちであり、プライバシー保護を優先した合成データベースの作成が重要視されている\n- PrivBenchという新しい合成フレームワークを導入し、プライバシーを保持しつつ高品質なデータ生成を支援する\n- PrivBenchは差分プライバシーを利用し、クエリ性能がオリジナルのデータに近いプライバシー保護データベースを生成することに成功している",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-05-02T14:20:24+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01189",
    "title": "Gradient-Congruity Guided Federated Sparse Training",
    "japanese_title": "連合学習をガイドする勾配合同性によるスパース訓練",
    "authors": [
      "Chris Xing Tian",
      "Yibing Liu",
      "Haoliang Li",
      "Ray C. C. Cheung",
      "Shiqi Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 連合学習(FL)は、データプライバシーを保持しつつエッジデバイス上でAIと機械学習モデルのデプロイを促進するが、計算と通信コストが高い問題がある\n- 異種データや分布外データによって一般化性能が低下する問題を指摘\n- 勾配合同性に基づく動的なスパース訓練を連合学習フレームワークに統合してこれらの問題に対処する新しい手法、FedSGCを提案\n- FedSGCは計算と通信のオーバーヘッドを大幅に削減し、同時に一般化能力を向上させることが示された",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-02T11:29:48+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01147",
    "title": "Why Tabular Foundation Models Should Be a Research Priority",
    "japanese_title": "タブラーファンデーションモデルを研究の優先事項にすべき理由",
    "authors": [
      "Boris van Breugel",
      "Mihaela van der Schaar"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "Accepted at International Conference on Machine Learning (ICML 2024)",
    "summary": "- 近年のテキストや画像のファンデーションモデルは非常に印象的であり、研究リソースの増大を引き寄せている\n- 本論文では、ML研究コミュニティの優先順位をタブラーデータへ僅かにシフトすることを目指している\n- 多くの分野で主要なモダリティであるタブラーデータは、研究においてほとんど注意を払われず、規模とパワーで大きく遅れをとっている\n- 大規模タブラーモデル(LTM)の開発を開始する時が来ており、これが科学とMLのタブラーデータの使用方法を革命的に変える可能性がある",
    "topics": [
      "合成データ"
    ],
    "published": "2024-05-02T10:05:16+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01144",
    "title": "Boosting Communication Efficiency of Federated Learning's Secure Aggregation",
    "japanese_title": "連合学習におけるセキュア集約の通信効率の向上",
    "authors": [
      "Niousha Nazemi",
      "Omid Tavallaie",
      "Shuaijun Chen",
      "Albert Y. Zomaya",
      "Ralph Holz"
    ],
    "categories": [
      "cs.CR"
    ],
    "comment": "2 pages, 4 figures, The 54th Annual IEEE/IFIP International   Conference on Dependable Systems and Networks",
    "summary": "- 連合学習（FL）は、クライアントデバイスがローカルでモデルを訓練し、サーバーがこれを集約してグローバルモデルを生成する分散型機械学習アプローチである\n- FLは、サーバーが訓練されたモデルから機密クライアントデータを推測可能なモデル反転攻撃に対して脆弱\n- グーグルの安全集約プロトコル（SecAgg）は通信と計算に多大なオーバーヘッドを要するものの、プライバシーを保護するためにクライアント毎に共有秘密と個別要素を用いて訓練モデルをマスキングする\n- 新たに提案された通信効率の良い安全集約プロトコル（CESA）は、クライアントごとに2つの共有秘密を使用することでオーバーヘッドを大幅に削減し、SecAggと比較して通信コストを大幅に低下させる",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-02T10:00:16+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01142",
    "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data",
    "japanese_title": "異質データにおける逐次連合学習の鋭敏な境界",
    "authors": [
      "Yipeng Li",
      "Xinchen Lyu"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "arXiv admin note: text overlap with arXiv:2311.03154",
    "summary": "- 異質データに対する逐次連合学習 (SFL) の収束理論が未整備であることに対処するため、上限と下限を含む厳密な収束保証を確立\n- 強凸、一般凸、非凸目的関数に対して上限境界を導出し、強凸および一般凸目的関数については対応する下限も構築\n- 異質度が比較的高い状況では、逐次連合学習が並列連合学習 (PFL) よりも優れていることを示す\n- 二次関数と実データセットに関する実験結果が、直感に反する比較結果を検証",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-02T09:58:49+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01108",
    "title": "Federated Learning with Heterogeneous Data Handling for Robust Vehicular Object Detection",
    "japanese_title": "連合学習を用いた異種データ処理による堅牢な車両物体検出",
    "authors": [
      "Ahmad Khalil",
      "Tizian Dege",
      "Pegah Golchin",
      "Rostyslav Olshevskyi",
      "Antonio Fernandez Anta",
      "Tobias Meuser"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 連合学習（FL）は車両ネットワーク内でモデル訓練を効率的に行いながら生データの完全性を保持\n- 新たな連合学習手法FedProx+LAは、FedProxとFedLAを基に車両向けのデータ異質性に対応\n- 連続的なオンライン物体検出モデル訓練を通じて、FedProx+LAは従来手法に比べ優れた収束率を示す\n- ラベル分布が非常に異質な場合にFedProx+LAは検出性能を大幅に向上させ、FedLAの性能も上回る",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-02T09:14:59+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01073",
    "title": "Poisoning Attacks on Federated Learning for Autonomous Driving",
    "japanese_title": "連合学習における自動運転用の毒入れ攻撃",
    "authors": [
      "Sonakshi Garg",
      "Hugo Jönsson",
      "Gustav Kalander",
      "Axel Nilsson",
      "Bhhaanu Pirange",
      "Viktor Valadi",
      "Johan Östman"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "comment": "Accepted to SCAI2024",
    "summary": "- 連合学習（FL）は自動運転内でモデルを共同で訓練しながらデータの秘密を保持する分散学習パラダイムである\n- 本研究では自動運転に特化した2つの新規毒入れ攻撃、FLStealthとOff-Track Attack（OTA）を導入\n- FLStealthはグローバルモデルの性能を低下させる目的の非対象攻撃で、OTAは特定のトリガーに反応してモデルの振る舞いを変える目的の対象攻撃\n- 車両の軌道予測タスクに関する実験で攻撃の有効性を示し、OTAに対する一般的な防御戦略が不十分であることを強調",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-02T08:06:10+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.01031",
    "title": "The Privacy Power of Correlated Noise in Decentralized Learning",
    "japanese_title": "分散学習における相関ノイズのプライバシー保護効果",
    "authors": [
      "Youssef Allouah",
      "Anastasia Koloskova",
      "Aymane El Firdoussi",
      "Martin Jaggi",
      "Rachid Guerraoui"
    ],
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DC",
      "math.OC",
      "stat.ML"
    ],
    "comment": "Accepted as conference paper at ICML 2024",
    "summary": "- 分散学習を用いることで中央集権を避けつつ、大量の分散データとリソースをスケーラブルに利用可能\n- 分散SGDに差分プライバシーを統合した新型手法「Decor」を提案し、局所モデルの保護に相関ガウスノイズを注入\n- Decorは任意の接続グラフに対して中心差分プライバシーの最適なプライバシーと効用のトレードオフに匹敵\n- 通信対の秘密共有を前提とした新しいローカル差分プライバシーの緩和版（SecLDP）と、それに対応するプライバシー計算ツールを提案",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-05-02T06:14:56+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.00965",
    "title": "Robust Decentralized Learning with Local Updates and Gradient Tracking",
    "japanese_title": "ロバストな分散学習：ローカルアップデートと勾配追跡を利用",
    "authors": [
      "Sajjad Ghiasvand",
      "Amirhossein Reisizadeh",
      "Mahnoosh Alizadeh",
      "Ramtin Pedarsani"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "comment": "",
    "summary": "- 分散学習におけるデータの異質性と敵対的堅牢性の問題を取り扱う\n- ローカルアップデートと勾配追跡の二つの重要なモジュールを使用する分散最小最適化法を提案\n- 提案されたアルゴリズム「Dec-FedTrack」は非凸-強凹の最小最適化問題でも収束することを証明\n- 理論的な結果を裏付ける数値実験も行われた",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-02T03:03:34+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.00955",
    "title": "Recovering Labels from Local Updates in Federated Learning",
    "japanese_title": "連合学習におけるローカル更新からのラベル回復",
    "authors": [
      "Huancheng Chen",
      "Haris Vikalo"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "comment": "",
    "summary": "- 連合学習において、勾配反転攻撃がクライアントのデータ復元を試みる中で、モデル更新情報からラベル回復が鍵とされる\n- RLU（Recovering Labels from Local Updates）方式は未訓練モデルに対して高い正確さを示し、現実的な環境でも効果を発揮\n- RLUは、トレーニングデータのラベルと結果としての出力層の更新との間の相関関係分析を基に最小二乗問題を解いてラベルを推定する\n- 複数のデータセットとアーキテクチャでの実験結果から、RLUは既存の方法よりも一貫して優れた性能を示し、勾配反転攻撃における画像再構成の質を向上させた",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-02T02:33:15+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.00909",
    "title": "Quantum Federated Learning Experiments in the Cloud with Data Encoding",
    "japanese_title": "量子連合学習をクラウドで実験したデータエンコーディング",
    "authors": [
      "Shiva Raj Pokhrel",
      "Naman Yash",
      "Jonathan Kua",
      "Gang Li",
      "Lei Pan"
    ],
    "categories": [
      "cs.LG",
      "cs.ET",
      "quant-ph"
    ],
    "comment": "SIGCOMM 2024, Quantum Computing, Federated Learning, Qiskit",
    "summary": "- 量子連合学習は、量子ネットワーク上で連合学習を実行し、ローカルデータのプライバシーを保つために開発されている\n- クラウドプラットフォーム上でのQFLの展開における課題が探求されている\n- 提案されたデータエンコーディングを使用したQFLは、ゲノムデータセットを用いた量子シミュレータ上での実証実験を通じて、有望な結果を示している\n- 実験と成果はGitHubでオープンソースとして公開されている",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-01T23:41:14+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.00885",
    "title": "WHALE-FL: Wireless and Heterogeneity Aware Latency Efficient Federated Learning over Mobile Devices via Adaptive Subnetwork Scheduling",
    "japanese_title": "モバイルデバイス上での適応的サブネットワークスケジューリングを利用した連合学習の遅延効率向上手法、WHALE-FL",
    "authors": [
      "Huai-an Su",
      "Jiaxiang Geng",
      "Liang Li",
      "Xiaoqi Qin",
      "Yanzhao Hou",
      "Xin Fu",
      "Miao Pan"
    ],
    "categories": [
      "cs.LG",
      "cs.NI",
      "eess.IV"
    ],
    "comment": "",
    "summary": "- 連合学習はモバイルデバイス間での異種性による計算能力と通信能力の違いにより展開が困難\n- 従来の固定サイズのサブネットワーク割り当てはデバイスの動的な変化や学習進行状況への対応が不十分\n- WHALE-FLはデバイスの計算・通信能力と連合学習の進行状態に応じたサブネットワークサイズの動的選択を可能にする新しいユーティリティ機能を導入\n- WHALE-FLは学習精度を犠牲にすることなく、連合学習の遅延を効果的に短縮",
    "topics": [
      "連合学習"
    ],
    "published": "2024-05-01T22:01:40+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.00794",
    "title": "Coherent 3D Portrait Video Reconstruction via Triplane Fusion",
    "japanese_title": "3Dポートレート動画再構築のためのTriplane Fusionによる新手法",
    "authors": [
      "Shengze Wang",
      "Xueting Li",
      "Chao Liu",
      "Matthew Chan",
      "Michael Stengel",
      "Josef Spjut",
      "Henry Fuchs",
      "Shalini De Mello",
      "Koki Nagano"
    ],
    "categories": [
      "cs.CV"
    ],
    "comment": "",
    "summary": "- 一枚の画像からの3Dポートレート再構築はあるが、フレームごとの再構築は時間的な一貫性が欠け、ユーザーの外観が失われる問題が存在\n- 自己再現手法は3Dポートレートの一貫性を維持できるが、フレームごとの細かい表情や照明を正確に再現することは困難\n- この研究では、個々の3Dモデルを補足するフレーム情報と融合し、時間的に安定で正確な3D動画を生成する新しい融合ベースの手法を提案\n- 提案手法は、表情条件付き3D GANで生成された合成データを使用して訓練され、スタジオ内及び野外データセットにおいて3D再構築の精度と時間的一貫性で最先端の成果を実現",
    "topics": [
      "合成データ"
    ],
    "published": "2024-05-01T18:08:51+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.00742",
    "title": "Federated Graph Learning for EV Charging Demand Forecasting with Personalization Against Cyberattacks",
    "japanese_title": "連合グラフ学習を用いたEV充電需要予測の個人化とサイバー攻撃対策",
    "authors": [
      "Yi Li",
      "Renyou Xie",
      "Chaojie Li",
      "Yi Wang",
      "Zhaoyang Dong"
    ],
    "categories": [
      "cs.CR",
      "cs.LG",
      "stat.ML"
    ],
    "comment": "11 pages,4 figures",
    "summary": "- 電気自動車の充電需要予測におけるサイバーセキュリティリスクの軽減は、複数の充電施設の安全な運用、電力網の安定、インフラ拡張のコスト削減に重要\n- 新たに提案された連合グラフ学習手法は、複数の充電ステーションの空間的相関を捉えつつ、予測モデルのトレーニングを協調することで汎用性と耐攻撃性を向上\n- グラフニューラルネットワークを用いて、異なる充電ステーション間の地理的相関を連合形式で特徴付けることで、モデルのパフォーマンスを高める\n- 各クライアントの個別のモデルを集約するグローバルアテンションメカニズムを活用したメッセージパッシングとクレジットベースの機能が導入され、データの異質性とサイバー攻撃のリスクに対処",
    "topics": [
      "連合学習"
    ],
    "published": "2024-04-30T05:17:46+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.00725",
    "title": "Federated Learning and Differential Privacy Techniques on Multi-hospital Population-scale Electrocardiogram Data",
    "japanese_title": "連合学習と差分プライバシー技術を用いた複数病院の大規模心電図データに関する研究",
    "authors": [
      "Vikhyat Agrawal",
      "Sunil Vasu Kalmady",
      "Venkataseetharam Manoj Malipeddi",
      "Manisimha Varma Manthena",
      "Weijie Sun",
      "Saiful Islam",
      "Abram Hindle",
      "Padma Kaul",
      "Russell Greiner"
    ],
    "categories": [
      "eess.SP",
      "cs.CR",
      "cs.LG"
    ],
    "comment": "Accepted for ICMHI 2024",
    "summary": "- カナダ・アルバータの7つの病院からの1,565,849件の心電図データを使用し、連合学習と差分プライバシーを適用して多ラベル心電図分類モデルを学習\n- 連合学習を用いることで、病院間で生データを共有せずにモデル訓練を共同で行い、様々な心臓病の診断に有効な心電図分類モデルを構築\n- 実装された連合学習モデルは、全ての病院のデータを集約して訓練したモデルと比較して同等の性能を示す\n- 差分プライバシーを使用することで、モデルの性能とデータプライバシーのトレードオフを示し、訓練データが限られている病院にとってもメリットがあることを示唆",
    "topics": [
      "連合学習",
      "差分プライバシー"
    ],
    "published": "2024-04-26T19:29:48+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2405.00719",
    "title": "EEG-Deformer: A Dense Convolutional Transformer for Brain-computer Interfaces",
    "japanese_title": "EEG-Deformer: 脳コンピュータインターフェースのための密な畳み込みトランスフォーマー",
    "authors": [
      "Yi Ding",
      "Yong Li",
      "Hao Sun",
      "Rui Liu",
      "Chengxuan Tong",
      "Cuntai Guan"
    ],
    "categories": [
      "eess.SP",
      "cs.LG",
      "q-bio.NC"
    ],
    "comment": "10 pages, 9 figures. This work has been submitted to the IEEE for   possible publication. Copyright may be transferred without notice, after   which this version may no longer be accessible",
    "summary": "- EEG信号の時間的ダイナミクスを学習することが課題だが、脳活動のデコードには不可欠である\n- EEG-Deformerは、粗大な時間的ダイナミクスを効果的に識別する階層的粗大細密トランスフォーマー(Hierarchical Coarse-to-Fine Transformer, HCT)と、多レベルの純化された時間情報を利用する密情報浄化モジュール(Dense Information Purification, DIP)を組み込んだ\n- 3つの認知タスクに関する広範な実験を通じて、提案されたEEG-Deformerの一般化能力が確認され、既存の最先端手法を上回るか、それに匹敵するパフォーマンスを示した\n- EEG-Deformerは、対応する認知タスクに対し神経生理学的に意味のある脳領域から学習していることが視覚化結果から示された",
    "topics": [
      "連合転移学習"
    ],
    "published": "2024-04-25T18:00:46+00:00"
  }
]