---
title: 連合学習 (2024-10-04 ~ 2024-10-10)
date: 2024-10-04
---

連合学習に関する論文まとめ (2024-10-04 ~ 2024-10-10)


- - -

### [FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein Estimator](http://arxiv.org/abs/2410.03499)

**FedStein: ジェームズ・スタイン推定器を用いたマルチドメイン連合学習の向上**

Sunny Gupta, Nikita Jangid, Amit Sethi

- 連合学習は、非独立同分布データの扱いで性能と収束性の課題がある
- 本研究は、異なる特徴分布を持つ複数ドメインの連合学習というあまり探索されていない問題に焦点を当てた
- 提案手法FedSteinは、クライアント間でバッチ正規化統計のジェームズ・スタイン推定値のみを共有する
- FedSteinは既存手法を超え、特定ドメインで14%以上の精度向上を達成

FedSteinって面白そう！新しい連合学習の方向性を切り開くかな？データの特徴が違ってもバッチ正規化だけ共有するアイデアが新鮮だし、精度も上がってるなんてすごい！私たちも試してみたいね。

**Comment:** 12 pages, 2 figures. Accepted at International Workshop on Federated   Foundation Models In Conjunction with NeurIPS 2024 (FL@FM-NeurIPS'24)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, cs.DC, I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;
  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10, **投稿日時:** 2024-10-04 15:13


- - -

### [Collaborative and Efficient Personalization with Mixtures of Adaptors](http://arxiv.org/abs/2410.03497)

**協力的かつ効率的なパーソナライズとアダプタの組み合わせ**

Abdulla Jasem Almansoori, Samuel Horváth, Martin Takáč

- 非独立同分布データは現実世界の連合学習でよく見られる問題である
- 提案するフレームワーク「FLoRAL」は各クライアントがパラメータを効率的に学習しタスクに適応
- アダプタのフェデレーションによりメモリ効率が向上し、効率的な協力学習が可能
- 実験でフルモデルのクラスタリングを超える性能を発揮し、有用性と堅牢性を実証

この研究って、みんなで協力してデータをシェアしながらも、それぞれに合った学び方ができるってのが面白いな！未来のアプリとかで個人にぴったりなサービスとか提供できたら楽しそうじゃない？

**Comment:** 36 pages, 10 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-04 15:11


- - -

### [Camel: Communication-Efficient and Maliciously Secure Federated Learning in the Shuffle Model of Differential Privacy](http://arxiv.org/abs/2410.03407)

**Camel: 差分プライバシーのシャッフルモデルにおける通信効率の高い悪意あるセキュア連合学習**

Shuangqing Xu, Yifeng Zheng, Zhongyun Hua

- 連合学習はクライアントのプライベートデータを公開せずにモデルを学習するパラダイム
- LDPメカニズムでプライバシー保証を提供するが、ノイズが多くモデルの有用性が低下
- シャッフルモデルを用いてプライバシー増幅し、より良いプライバシー-ユーティリティのトレードオフを実現
- Camelは通信効率とセキュリティを最適化し、RDPを用いてプライバシー損失を厳しく評価

連合学習って面白そうだよね。大人数で協力して賢いモデルを育てるなんて、未来の学校みたいでワクワクする！Camelの方法で、もっと安全で効率的になっていくのかなぁ。

**Comment:** Accepted by CCS'2024

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-04 13:13


- - -

### [Influence-oriented Personalized Federated Learning](http://arxiv.org/abs/2410.03315)

**影響指向の個別連合学習**

Yue Tan, Guodong Long, Jing Jiang, Chengqi Zhang

- 従来の連合学習は固定加重に頼り、データの不均一性に対応できない
- 提案するFedC^2Iは、クライアントとクラスの影響を定量化し適応的なパラメータ集約を実現
- 影響ベクトルと影響マトリクスを用いてクライアント間の影響をモデル化
- 非IID設定下で実験し、FedC^2Iが従来手法よりも優れていると評価

この論文、データのバラバラな状態での連合学習をもっと効果的にする方法なんだね！個々に合わせた学習を実現してくれるって、なんか未来の勉強スタイルみたいでワクワクする～！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-10-04 11:00


- - -

### [BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated Learning](http://arxiv.org/abs/2410.03281)

**BN-SCAFFOLD: 連合学習におけるバッチ正規化統計のドリフト制御**

Gonzalo Iñaki Quintana, Laurence Vancamberg, Vincent Jugnon, Mathilde Mougeot, Agnès Desolneux

- 連合学習は分散型で機械学習モデルを訓練する新しいパラダイム
- バッチ正規化は深層ニューラルネットワークで普及しているが、バラつきが問題に
- FedTANはバッチ正規化の統計を集約して対応するが通信コストが高い
- 新アルゴリズムBN-SCAFFOLDは通信効率を上げつつ性能でFedTANと同等

BN-SCAFFOLDって、通信コストを下げつつ性能を上げるなんてかっこいい！深層学習の訓練がもっと効率的になって、色んな新しい技術がでてきそうでワクワクしちゃう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-04 09:53


- - -

### [FedMAC: Tackling Partial-Modality Missing in Federated Learning with Cross-Modal Aggregation and Contrastive Regularization](http://arxiv.org/abs/2410.03070)

**FedMAC: 連合学習における部分モダリティ欠損へのクロスモーダル集約とコントラスト正則化による対処**

Manh Duong Nguyen, Trung Thanh Nguyen, Huy Hieu Pham, Trong Nghia Hoang, Phi Le Nguyen, Thanh Trung Huynh

- 連合学習は分散データで機械学習モデルを訓練し、クライアントのデータプライバシーを守る技術
- クライアント間でデータのモダリティが欠損する場合があり、データ分布の不均一さが課題となる
- 既存研究は完全なモダリティ欠損に対処するが、部分的なモダリティ欠損には効果的でない
- 提案手法FedMACは、統計的に不均一なクライアント構成でも26%の性能向上を達成

FedMAC、すごくイケてる名前だね！部分的にデータが欠けてても、ちゃんと結果が出る技術って便利そう！次のデジタル時代を支える技術になりそうだね。

**Comment:** The 22nd International Symposium on Network Computing and   Applications (NCA 2024)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.MM, **投稿日時:** 2024-10-04 01:24


- - -

### [FedCert: Federated Accuracy Certification](http://arxiv.org/abs/2410.03067)

**FedCert: 連合学習の精度認証**

Minh Hieu Nguyen, Huu Tien Nguyen, Trung Thanh Nguyen, Manh Duong Nguyen, Trong Nghia Hoang, Truong Thao Nguyen, Phi Le Nguyen

- 連合学習はデータをクライアントに保持することでプライバシーを守るが、データの改変に対するロバスト性評価が課題
- FedCertは各クライアントの認定精度とクラス分布を基にグローバルモデルの認定精度を近似する新手法を提案
- 非独立同分布なデータに対し、認定精度を安定させるためのクライアントグループ化アルゴリズムを導入
- CIFAR-10とCIFAR-100データセットでの実験で、FedCertが従来手法よりも一貫して推定誤差を減少させることを確認

FedCert、面白そう！連合学習の新しい可能性を探ってるって感じでワクワクするね。実際のデータで有効性が確認されたってすごく重要だし、これからの研究でどんな進展があるのか楽しみ！

**Comment:** The 22nd International Symposium on Network Computing and   Applications (NCA 2024)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-10-04 01:19
