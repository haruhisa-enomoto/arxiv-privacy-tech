---
title: 差分プライバシー (2024-08-09 ~ 2024-08-15)
date: 2024-08-09
---

差分プライバシーに関する論文まとめ (2024-08-09 ~ 2024-08-15)


- - -

### [Deep Learning with Data Privacy via Residual Perturbation](http://arxiv.org/abs/2408.05723)

**残差摂動によるデータプライバシーを伴う深層学習**

Wenqi Tao, Huaming Ling, Zuoqiang Shi, Bao Wang

- ディープラーニングにおけるプライバシー保護は重要で、既存の手法はプライバシーを守るが、実用性の低下や計算過負荷の問題がある
- 本研究では、ガウスノイズをResNetの各残差写像に注入する確率微分方程式に基づいた摂動を提案
- 理論的には、この残差摂動が差分プライバシーを保証し、ディープラーニングの一般化ギャップを減少させると証明
- 経験的には、この手法が計算効率が高く、メンバーシッププライバシーを犠牲にせずに最新の差分プライバシーを用いた確率的勾配降下法よりも優れていることを示した

これめっちゃ面白そうじゃない？プライバシーを守りながらも性能を落とさない方法がどれだけ普及するか今後が楽しみ！これから色んなアプリやサービスがもっと安全に使えるようになりそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.CV, **投稿日時:** 2024-08-11 08:26


- - -

### [The Bandit Whisperer: Communication Learning for Restless Bandits](http://arxiv.org/abs/2408.05686)

**バンディットのささやき者: 静動的バンディットのためのコミュニケーション学習**

Yunfan Zhao, Tonghan Wang, Dheeraj Nagaraj, Aparna Taneja, Milind Tambe

- 連続アームバンディット(RMABs)に強化学習を適用することで、資源制約と時間的動態を持つ配分問題に対処する
- しかし、従来のRMABモデルはデータ収集プロトコルの違いや差分プライバシーによる意図的なノイズなどのデータエラーの課題を無視している
- 初のコミュニケーション学習アプローチを提案し、どのアームがコミュニケーションに関与することでデータエラーの影響を軽減するかを研究
- Qネットワークアーキテクチャを使用し、メッセージの共同効用を考慮したコミュニケーション戦略を学習することで、RMABの性能が大幅に向上することを理論的および実証的に確認

リアルタイムでデータエラーに対処できるなんて、この研究ってきっと実用的でスゴい！未来のAIがもっと賢くなりそうだね、ワクワクする！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.MA, **投稿日時:** 2024-08-11 03:39


- - -

### [Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions](http://arxiv.org/abs/2408.05212)

**大規模言語モデルにおけるプライバシー保護: 現在の脅威と解決策に関する調査**

Michele Miranda, Elena Sofia Ruzzetti, Andrea Santilli, Fabio Massimo Zanzotto, Sébastien Bratières, Emanuele Rodolà

- 大規模言語モデル（LLMs）は様々な分野で応用されているが、巨大なデータセットの使用によりプライバシー問題が顕著である
- LLMsはデータを記憶し、機密情報を露呈するリスクがあることが指摘されている
- 差分プライバシーの導入や訓練データセットの匿名化など、包括的なプライバシー保護手法を提案している
- 現在の取り組みとツール、そしてプライバシー保護のための今後の方向性について詳しくレビューしている

これ面白そう！LLMsのプライバシー問題って、たしかに今後もっと重要になりそうだし、安心して使えるAIシステムが増えるといいよね。

**Comment:** GitHub repository:   https://github.com/michele17284/Awesome-Privacy-Preserving-LLMs

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.CL, cs.LG, **投稿日時:** 2024-08-10 05:41


- - -

### [PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks](http://arxiv.org/abs/2408.05092)

**PriPHiT: 階層的な深層ニューラルネットワーク訓練におけるプライバシー保護**

Yamin Sepehri, Pedram Pad, Pascal Frossard, L. Andrea Dunbar

- 深層ニューラルネットワークの訓練はクラウドサーバー上で行われることが多く、プライバシーリスクがある
- エッジデバイスとクラウドを併用し、センシティブな内容をクラウドに送信せずに訓練を行う方法を提案
- エッジでの早期終了とノイズ追加を利用し、差分プライバシーを保証
- 多様な顔属性のデータセットで試験し、優れた性能を示した上、ホワイトボックス攻撃や再構成攻撃に対する防御を実証

クラウドに頼る技術でも、個人情報の漏えい防げるなんて期待できるよね！色んな攻撃にも耐えうるだなんて、安心して使えそう！

**Comment:** 16 pages, 16 figures, 6 tables

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CV, cs.CR, cs.DC, cs.LG, eess.IV, I.2.10; I.2.6; I.2.11; K.4.1, **投稿日時:** 2024-08-09 14:33


- - -

### [Locally Private Histograms in All Privacy Regimes](http://arxiv.org/abs/2408.04888)

**全てのプライバシーレジームにおける局所的プライバシーヒストグラム**

Clément L. Canonne, Abigail Gentle

- ヒストグラム（頻度推定）はデータ分析の基本手法であり、差分プライバシーの下で広く研究されている
- 局所モデルでのヒストグラム計算は最近の研究の焦点であり、高いプライバシー状態での最適な$\ell_\infty$エラーを達成するアルゴリズムが提案されている
- 中・低プライバシーレジーム(大きな$\varepsilon$)における研究は不明確であり、この研究ではこの領域での局所的プライバシーヒストグラムのエラー境界を解明
- 理論的知見は新しい解析方法から得られ、既存のアルゴリズムの全プライバシーレジームにおける性能と特性を実証的に比較

プライバシーの高低で性能がどう変わるのか気になるよね！エラー境界の発見とか新しい解析がどんな風に役立つのか楽しみ！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, cs.CR, cs.DM, **投稿日時:** 2024-08-09 06:22
