---
title: 連合学習 (2024-06-14 ~ 2024-06-20)
date: 2024-06-14
---

連合学習に関する論文まとめ (2024-06-14 ~ 2024-06-20)


- - -

### [Synergizing Foundation Models and Federated Learning: A Survey](http://arxiv.org/abs/2406.12844)

**基盤モデルと連合学習の融合：調査**

Shenghui Li, Fanghua Ye, Meng Fang, Jiaxu Zhao, Yun-Hin Chan, Edith C. -H. Ngai, Thiemo Voigt

- 基盤モデル（大型言語モデル、視覚トランスフォーマ、マルチモーダルモデル）が学術界と産業界に大きな影響を与えている
- 小規模モデルと比較して、基盤モデルはプレトレーニングフェーズで大量のデータを必要とする
- 一般的な基盤モデルはインターネットから収集したデータでプレトレーニング可能だが、ドメイン固有の基盤モデルは専有データが必要でプライバシーの問題が発生
- 連合学習は、異なる参加者からのデータの可用性の壁を破り、プライバシーを保護しながら分散データセットを使用した基盤モデルのカスタマイズと適応を可能にする

基盤モデルと連合学習を組み合わせることで、様々なドメインに特化した強力なモデルがプライバシーを守りながら構築できるようになるんだよね。最新技術がどのようにプライバシーとデータ利用のバランスを取るか、これからの発展が楽しみ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-18 17:58


- - -

### [Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation](http://arxiv.org/abs/2406.12815)

**医療画像における不確実性推定を伴うプライバシー保護型連合学習**

Nikolas Koutsoubis, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

- 連合学習（FL）はプライバシー保護の下で機械学習モデルの訓練を可能にする
- 患者データのプライバシー問題が大規模な訓練データセットの構築を妨げている
- 不確実性推定がFLにおいて重要であり、データの異質性が課題となる
- 現行研究の調査とともに、プライバシー向上とノイズの多い医療画像データの課題解決の方向性を提案

医療分野での連合学習の重要性が分かるね！これからの研究がどのようにプライバシーを守りつつ精度を上げていけるのかに注目したい。

**Comment:** 31 pages, 5 figures, 3 tables, Journal preprint

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, eess.IV, stat.ML, **投稿日時:** 2024-06-18 17:35


- - -

### [Federated Learning with a Single Shared Image](http://arxiv.org/abs/2406.12658)

**連合学習における単一の共有画像の利用**

Sunny Soni, Aaqib Saeed, Yuki M. Asano

- 連合学習はプライベートなトレーニングデータ共有を避け、モデルを協同で訓練する技術
- 既存のFedDFは共通の共有データセットを使用するが、これはプライバシーやストレージの問題で困難
- 本研究では、クライアント間とサーバー間で単一の共有画像のみを使用する新たな知識蒸留法を提案
- 新しい適応型データセットプルーニングアルゴリズムにより、単一画像から最も情報価値の高い切り取り範囲を選択

一枚の画像で全体の連合学習がより効果的に行えるなんて革新的だね！異なるクライアントアーキテクチャも対応できるのはすごい未来な感じ。

**Comment:** 8 Pages, 3 Figures, Appendix 4 Pages, CVPRW 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.LG, **投稿日時:** 2024-06-18 14:26


- - -

### [UIFV: Data Reconstruction Attack in Vertical Federated Learning](http://arxiv.org/abs/2406.12588)

**UIFV: 垂直連合学習におけるデータ再構築攻撃**

Jirui Yang, Peng Chen, Zhihui Lu, Qiang Duan, Yubing Bao

- 垂直連合学習（VFL）は、生データを共有せずに協調機械学習を行う手法である
- 既存のデータ再構築方法はモデルや勾配情報に依存し、VFL適用には限界がある
- 本研究では、UIFVという新しい方法を提案し、中間特徴データを用いて元データを再構築する
- 実験では、提案手法が最先端技術よりも高い攻撃精度を示し、VFLのプライバシーの脆弱性を明らかにした

データ共有なしで協力するのに、まだこんな抜け道があるなんてビックリ！UIFVのような新しい方法で、もっとプライバシーを守れる方法が必要だね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, stat.ML, **投稿日時:** 2024-06-18 13:18


- - -

### [Low-Resource Machine Translation through the Lens of Personalized Federated Learning](http://arxiv.org/abs/2406.12564)

**パーソナライズド連合学習による低リソース機械翻訳へのアプローチ**

Viktor Moskvoretskii, Nazarii Tupitsa, Chris Biemann, Samuel Horváth, Eduard Gorbunov, Irina Nikishina

- MeritFedアルゴリズムに基づく新しいアプローチを提案
- 低リソース機械翻訳のタスクに適用し、その有効性を検証
- 訓練に使用する各言語の影響を追跡できるため、MeritFedは非常に解釈可能
- ターゲットデータセットのサイズ、関連性のない言語の影響、および補助最適化パラメータの効果を分析

MeritFedって、低リソース言語の機械翻訳にも使えるんだね！異なる言語の影響を追跡できるって、かなり役立ちそう💡

**Comment:** 18 pages, 7 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.LG, **投稿日時:** 2024-06-18 12:50


- - -

### [Update Selective Parameters: Federated Machine Unlearning Based on Model Explanation](http://arxiv.org/abs/2406.12516)

**更新選択パラメータ: モデル説明に基づく連合機械学習のアンラーニング**

Heng Xu, Tianqing Zhu, Lefeng Zhang, Wanlei Zhou, Philip S. Yu

- 機械アンラーニングが必要な理由は、特定のトレーニングデータの影響をモデルから除去するため
- 現行の中央集権的なアンラーニング手法では連合学習に不向きであり、全データへのアクセスが前提となる
- 新たな手法はモデル説明に基づき、重要なチャネルのみを調整してデータの影響を削減
- 提案手法は計算コストと通信コストを削減しつつ、モデルの性能を維持することを実験で実証

この論文は連合学習の新しいアプローチだね！モデル説明を活用するアイデア、とってもクールじゃない？

**Comment:** Accepted by IEEE Transactions on Big Data

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, cs.LG, **投稿日時:** 2024-06-18 11:43


- - -

### [Federated Learning with Limited Node Labels](http://arxiv.org/abs/2406.12435)

**ラベルの限定されたノードを持つ連合学習**

Bisheng Tang, Xiaojun Chen, Shaopu Wang, Yuexin Xuan, Zhendong Zhao

- 分散グラフ構造データを扱うための手法として、サブグラフ連合学習（SFL）が注目を集めている
- SFLの一部モデルは、サブグラフ間の欠落エッジの重要性を見落とし、ローカルGNNがグローバル表現を他のパーティのGNNに渡せなくなる
- 既存のSFLモデルは多くのラベル付きデータを必要とし、実用性を制限している
- 提案する新たなSFLフレームワークFedMpaは、少量のデータでMLPモデルを訓練し、連合特徴をローカル構造に伝播

新しいSFLフレームワークが実用性を高める方法についての研究なんて面白そうだね！将来的にもっと現実の応用が増えるかもって感じだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-06-18 09:30


- - -

### [Security and Privacy of 6G Federated Learning-enabled Dynamic Spectrum Sharing](http://arxiv.org/abs/2406.12330)

**6G連合学習対応動的スペクトル共有のセキュリティとプライバシー**

Viet Vo, Thusitha Dayaratne, Blake Haydon, Xingliang Yuan, Shangqi Lai, Sharif Abuadbba, Hajime Suzuki, Carsten Rudolph

- 6G無線通信における動的スペクトル共有が重要
- 連合学習によるスペクトルセンシング技術が注目を集める
- 協調トレーニングの整合性とローカルユーザのスペクトル情報のプライバシーが未解決
- 実践的な攻撃ベクトルと防御の指針を提示

連合学習でプライバシーを保ちながら6Gの通信をより効率的にするなんて、未来のネットワークがもっと便利になりそうでワクワクする！新しいテクノロジーでどんな日常が来るのか、楽しみだね。

**Comment:** 7 pages, 5 figures. The paper is submitted to IEEE Networks for   review

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, cs.ET, cs.LG, cs.NI, **投稿日時:** 2024-06-18 06:54


- - -

### [BadSampler: Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning](http://arxiv.org/abs/2406.12222)

**BadSampler: カタストロフィックフォゲッティングの力を利用したビザンチン耐性連合学習の毒殺攻撃**

Yi Liu, Cong Wang, Xingliang Yuan

- ビザンチン耐性の連合学習における毒殺攻撃の研究がほとんど行われていない
- 本論文では、カタストロフィックフォゲッティングを利用した新たな攻撃BadSamplerを提案
- Clean-labelデータのみを使用し、モデルの一般化誤差を最大化するように訓練データを選択
- 提案手法の有効性と性能を二つの実データセットで評価し、効率的な攻撃が可能であることを示した

これ、めっちゃ興味深いね！毒殺攻撃とか、まるでスパイ映画みたいだし、連合学習がもっと強くなるかもってワクワクするね。

**Comment:** In Proceedings of the 30th ACM SIGKDD Conference on Knowledge   Discovery and Data Mining (KDD' 24), August 25-29, 2024, Barcelona, Spain

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, cs.LG, **投稿日時:** 2024-06-18 02:43


- - -

### [SFedCA: Credit Assignment-Based Active Client Selection Strategy for Spiking Federated Learning](http://arxiv.org/abs/2406.12200)

**SFedCA: スパイキング連合学習のための信用配分に基づくアクティブクライアント選択戦略**

Qiugang Zhan, Jinbo Cao, Xiurui Xie, Malu Zhang, Huajin Tang, Guisong Liu

- スパイキング連合学習は、デバイスが局所データを交換せず低消費電力で協力して学習する
- プライバシー保護機能とエネルギー効率を兼ね備え、マルチメディアデータ処理に革命をもたらす可能性
- 既存手法はクライアントの無作為選択に依存し、統計的異質性がグローバルモデルの収束や精度に影響
- SFedCAは閾値に基づきクライアントを選定し、データ分布のバランスを維持。また、通信ラウンド数を減らすことに成功

この技術で低消費電力で効率的に学習できるとか、未来のガジェットがすごくスマートになりそう！早く実用化されるといいね。

**Comment:** 9 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, cs.ET, cs.MM, cs.NE, **投稿日時:** 2024-06-18 01:56


- - -

### [P3GNN: A Privacy-Preserving Provenance Graph-Based Model for APT Detection in Software Defined Networking](http://arxiv.org/abs/2406.12003)

**P3GNN: ソフトウェア定義ネットワーキングにおけるAPT検出のためのプライバシー保護型プロベナンスグラフベースモデル**

Hedyeh Nazari, Abbas Yazdinejad, Ali Dehghantanha, Fattane Zarrinkalam, Gautam Srivastava

- SDNはネットワーク管理に進展をもたらしたが、APTやゼロデイ攻撃の脅威も増加
- 既存の対策は新しい脅威の検出や共同学習中のデータプライバシーの問題に不十分
- P3GNNは連合学習と準同型暗号を組み合わせ、データ機密性と勾配の整合性を強化
- 無監督学習で攻撃を検知し、DARPA TCE3データセットで高い精度と低い誤検知率を実現

連合学習と準同型暗号の組み合わせってすごいね！これなら新しい脅威にも対応できるから安心じゃん？



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-17 18:14


- - -

### [Feasibility of Federated Learning from Client Databases with Different Brain Diseases and MRI Modalities](http://arxiv.org/abs/2406.11636)

**クライアントデータベースから異なる脳疾患とMRIモダリティを用いた連合学習の実現可能性**

Felix Wagner, Wentian Xu, Pramit Saha, Ziyun Liang, Daniel Whitehouse, David Menon, Natalie Voets, J. Alison Noble, Konstantinos Kamnitsas

- 特定の脳疾患用のセグメンテーションモデルは固定されたMRIモダリティセットで訓練される
- 連合学習を用いて異なる脳疾患と多様なMRIモダリティで単一モデルの訓練を試みる
- 全てのクライアントデータベースのモダリティをカバーする入力チャンネルやランダムなモダリティドロップの訓練を導入
- 7つの脳MRIデータベースで評価し、新規データベースでも高いセグメンテーション性能を確認

異なる脳疾患やモダリティの組み合わせでも、連合学習が有効なんて面白そう！将来はもっと多くの病気やデータに対応できるモデルが出てきてほしいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.CV, cs.LG, I.4.9; I.4.6; I.2.11; I.4.0, **投稿日時:** 2024-06-17 15:16


- - -

### [Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs](http://arxiv.org/abs/2406.11569)

**空中連合メタ学習による事前トレーニングと個別調整: 収束と一般化のトレードオフ**

Haifeng Wen, Hong Xing, Osvaldo Simeone

- 大規模言語モデルなどのAIアプリでは、事前トレーニング後のファインチューニングが主流
- 連合学習（FL）が進み、事前トレーニングが中央集権型から分散型に移行中
- メタ学習ベースの個別FLは、基本的なパーソナライズを超え、新しいエージェントやタスクへの一般化を目指す
- 無線設定での一般化と収束のトレードオフを分析、チャンネルの欠陥が一般化を助ける一方で収束を悪化させる

無線通信を利用してAIモデルをパーソナライズするなんて、未来を感じるね。新しい技術がどんな風に役立つか楽しみ！

**Comment:** 37 pages, 7 figures, submitted for possible journal publication

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.IT, eess.SP, math.IT, **投稿日時:** 2024-06-17 14:06


- - -

### [Federated Active Learning Framework for Efficient Annotation Strategy in Skin-lesion Classification](http://arxiv.org/abs/2406.11310)

**皮膚病変分類における効率的なアノテーション戦略のための連合能動学習フレームワーク**

Zhipeng Deng, Yuqiao Yang, Kenji Suzuki

- 連合学習（FL）は複数の機関がプライベートデータを共有せずにモデルを共同で訓練できる
- 医療シナリオではデータのアノテーションに専門知識と労働力が必要であり、FLにおいて重大な問題
- 提案する連合能動学習（FedAL）フレームワークは、FLの下で定期的かつ対話的にALを実行する
- 実データセットで検証し、50%のサンプルで最先端の性能を達成、他のAL手法より優れた結果を示す

連合能動学習がどんな未来を切り開くのか気になる！これで医療データの負担が減れば、多くの人が救われそうだよね。

**Comment:** 14 pages, 3 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.LG, **投稿日時:** 2024-06-17 08:16


- - -

### [Save It All: Enabling Full Parameter Tuning for Federated Large Language Models via Cycle Black Gradient Descent](http://arxiv.org/abs/2406.11187)

**すべてを保存：Cycle Black Gradient Descentによる連合大規模言語モデルの完全なパラメータチューニングの実現**

Lin Wang, Zhichao Wang, Xiaoying Tang

- 大規模言語モデル（LLMs）の登場により、深層学習のパラダイムが革命的に変わった
- 連合学習（FL）では、LLMsの事前学習やファインチューニングが計算資源やメモリ消費、通信ボトルネックに直面する
- 提案手法FedCyBGDは、Cycle Block Gradient Descentを用いて周期的にモデルを更新し、通信や計算、メモリコストを削減する
- FedCyBGDは選択されたブロックの更新とアップロードだけで完全なパラメータ学習を可能にし、FL LLMトレーニングで最先端の性能を実現

この方法を使えば、みんなのパソコンの負担が軽くなるってことかな？本当に実用化されたら影響大きそうでワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-06-17 03:49


- - -

### [Federated Face Forgery Detection Learning with Personalized Representation](http://arxiv.org/abs/2406.11145)

**個別化表現による連合型顔偽造検出学習**

Decheng Liu, Zhan Dang, Chunlei Peng, Nannan Wang, Ruimin Hu, Xinbo Gao

- 深層生成技術は高品質な偽動画を作成でき、深刻な社会的脅威である
- 連合学習戦略により、データのプライバシーを保護しつつモデルパラメータを集約
- クライアントごとの個別化表現学習で、検出性能を向上
- 公開顔偽造検出データセットの実験で、最先端手法と比べて優れた性能を示した

個別化表現で性能向上とか新しい感じでワクワクする！実用化が進んだら、偽動画の脅威も怖くなくなるかもね。楽しみ〜。

**Comment:** The code is publicly available

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-06-17 02:20


- - -

### [Leveraging Foundation Models for Multi-modal Federated Learning with Incomplete Modality](http://arxiv.org/abs/2406.11048)

**基礎モデルを活用した不完全モダリティによるマルチモーダル連合学習**

Liwei Che, Jiaqi Wang, Xinyue Liu, Fenglong Ma

- 連合学習は分散データ環境での共同訓練をプライバシー保証と共に実現
- クライアントが複数のデータモダリティを保有する現実的なシナリオに注目
- モダリティ欠損問題を解決するためFedMVPを提案し、事前訓練モデルを利用
- モデルは現実世界の画像とテキスト分類データセットで優れた性能を示す

異なるモダリティ間でも連合学習を効率的に行えるってすごい！これが実用化されたら、もっと複雑なデータもプライバシーを守りながら分析できるようになるかもね。

**Comment:** Accepted by ECML-PKDD 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-16 19:18


- - -

### [Promoting Data and Model Privacy in Federated Learning through Quantized LoRA](http://arxiv.org/abs/2406.10976)

**量子化されたLoRAによる連合学習におけるデータおよびモデルプライバシーの促進**

JianHao Zhu, Changze Lv, Xiaohua Wang, Muling Wu, Wenhao Liu, Tianlong Li, Zixuan Ling, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang

- 通常の連合学習は異なるエッジデバイス間でデータのプライバシーを保護
- 大規模言語モデル（LLMs）の開発には多くのデータと計算リソースが必要で、それは知的財産である
- 量子化されたモデルパラメータを分配することで、データとモデルの両方のプライバシーを保護
- LoRAを使った量子化戦略により通信コストを大幅に削減し、リソース効率の良い学習を実現

この方法で通信コストを削減しながら、データとモデルのプライバシーも守れるなんてすごいよね！未来の連合学習がもっと使いやすくなりそう、楽しみだな～。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, cs.CR, **投稿日時:** 2024-06-16 15:23


- - -

### [Linkage on Security, Privacy and Fairness in Federated Learning: New Balances and New Perspectives](http://arxiv.org/abs/2406.10884)

**連合学習におけるセキュリティ、プライバシー、公平性の結びつき：新たなバランスと新しい視点**

Linlin Wang, Tianqing Zhu, Wanlei Zhou, Philip S. Yu

- モバイルデバイスや銀行システム、ヘルスケア、IoTシステムで連合学習が急速に普及中
- この研究では、プライバシー漏洩、セキュリティ脅威、公平性の相互関係を詳述
- 公平性とプライバシー、セキュリティと勾配共有のトレードオフを指摘
- 公平性がプライバシーとセキュリティ間の橋渡しとして機能し得る

プライバシーと公平性のバランスなんて難しそうだけど、めっちゃおもしろいね！未来の連合学習モデルがどんどん進化して、安全かつ公平になるといいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-06-16 10:31


- - -

### [Knowledge Distillation in Federated Learning: a Survey on Long Lasting Challenges and New Solutions](http://arxiv.org/abs/2406.10861)

**連合学習における知識蒸留：長年の課題と新たな解決策に関する調査**

Laiqiao Qin, Tianqing Zhu, Wanlei Zhou, Philip S. Yu

- 連合学習はデータをローカライズしたまま複数のクライアントがモデルを訓練する分散型プライバシー保護機械学習である
- 課題にはプライバシーリスク、データ異質性、通信のボトルネック、およびシステムの異質性が含まれる
- 知識蒸留はモデル圧縮および強化アルゴリズムとして2020年以降広く適用されている
- 知識蒸留の連合学習における適用例を包括的に調査し解決策を提示

知識蒸留が連合学習の課題をどう克服できるかを明らかにするなんて面白そう！未来の研究方向も示して、これからの進展が楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-16 09:12


- - -

### [Federated Learning Optimization: A Comparative Study of Data and Model Exchange Strategies in Dynamic Networks](http://arxiv.org/abs/2406.10798)

**連合学習最適化：動的ネットワークにおけるデータとモデル交換戦略の比較研究**

Alka Luqman, Yeow Wei Liang Brandon, Anupam Chattopadhyay

- 大規模な動的連合学習において、データとモデルのどちらを共有するべきかが重要な課題
- デバイス間での生データ、合成データ、（部分）モデル更新の交換を比較
- 基礎モデルの文脈でこれらの交換戦略の影響を詳細に調査
- 時間制限のある知識移転効率が最大で9.08%異なることが判明

効率的なデータとモデル交換ってどれがいいんだろうね？この研究で明らかになった9.08%の違い、実用的にどのくらい役立つのか気になるな～



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-16 03:46


- - -

### [Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models](http://arxiv.org/abs/2406.10630)

**連合指示調整における大規模言語モデルの新たな安全攻撃と防御**

Rui Ye, Jingyi Chai, Xiangrui Liu, Yaodong Yang, Yanfeng Wang, Siheng Chen

- 連合学習（FL）は、複数の当事者がデータを共有せずに協力して大規模言語モデル（LLM）を微調整できる
- この研究では、FedITの安全調整の脆弱性を暴露し、シンプルだが効果的な攻撃手法を提案
- 悪意のあるクライアントは自動生成された攻撃データを使い、FedITシステムの安全性を損なう
- 提案された防御法により、多くの既存のFL防御法が効果的でない中で、攻撃されたLLMの安全性を大幅に向上

安全性の調整がこんなに簡単に損なわれるのって怖いね。でも、新しい防御法がちゃんと対策できるなら、もっと安心して使えそう。楽しみだな。

**Comment:** 18 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.AI, cs.CR, cs.MA, **投稿日時:** 2024-06-15 13:24


- - -

### [Federated Neural Radiance Field for Distributed Intelligence](http://arxiv.org/abs/2406.10474)

**分散インテリジェンスのための連合ニューラルラジアンスフィールド**

Yintian Zhang, Ziyu Shao

- ARやVR応用における新規視点合成（NVS）の重要性
- Neural Radiance Field（NeRF）のNVSタスクでの性能優位性
- データプライバシーを保持しつつ異なるデータ所有者の画像を活用するFedNeRF
- 機能的多様でリソース豊富な連合学習テストベッドの構築とFedNeRFアルゴリズムの実験

FedNeRFってめっちゃおもしろそう！これで、異なる場所にあるデータでも効率的に活用できちゃうんだって。新しいAR/VR体験がさらに進化するかもね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-06-15 02:32


- - -

### [Byzantine-Robust Decentralized Federated Learning](http://arxiv.org/abs/2406.10416)

**ビザンチン耐性分散型連合学習**

Minghong Fang, Zifan Zhang, Hairi, Prashant Khanduri, Jia Liu, Songtao Lu, Yuchen Liu, Neil Gong

- 連合学習（FL）は、複数のクライアントがプライベートな訓練データを公開せずに協力して機械学習モデルを訓練する技術である
- 従来の連合学習は中央サーバーを介して調整されるが、スケーラビリティと信頼依存性の問題がある
- 分散型連合学習（DFL）はサーバーレスかつピアツーピア方式でモデルを共同訓練するが、完全に分散型であるため攻撃に弱い
- 新アルゴリズム「BALANCE」は、クライアントがローカルモデルを基準に受信モデルが悪意かどうかを判断し、防御力と収束保証を提供する

これは革新的だね！完全ピアツーピアでの連合学習、未来のAIインフラに道を開く革新かも！

**Comment:** To appear in ACM Conference on Computer and Communications Security   2024 (CCS '24)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, cs.LG, **投稿日時:** 2024-06-14 21:28


- - -

### [Federated Learning with Flexible Architectures](http://arxiv.org/abs/2406.09877)

**柔軟なアーキテクチャを用いた連合学習**

Jong-Ik Park, Carlee Joe-Wong

- 従来の連合学習はクライアントの計算および通信能力のばらつきに対応できず非効率
- FedFAはクライアントごとに異なる幅と深さのモデルをトレーニング可能にする方法を提案
- レイヤーグラフティング技術を導入し、全クライアントの貢献を統一的にグローバルモデルに統合
- スケーラブルな集約法により重みの差異を管理し、従来の手法より優れた性能およびバックドア攻撃の耐性向上

多様なデバイスに対応するための工夫が面白いね。バックドア攻撃に強いってのも、これからの普及に大事だよね!



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-06-14 09:44


- - -

### [Federated Learning driven Large Language Models for Swarm Intelligence: A Survey](http://arxiv.org/abs/2406.09831)

**連合学習による大規模言語モデルの群知能への応用：調査**

Youyang Qu

- 連合学習（FL）は大規模言語モデル（LLMs）の訓練において、データプライバシーと分散化の課題に対応
- 機械学習の文脈での「忘却の権利」に対応するため、モデルから個々のデータ貢献を安全に削除する「機械アンラーニング」に注目
- 摂動技術、モデル分解、インクリメンタル学習などの効果的なアンラーニング戦略の調査
- 最近の文献からケーススタディや実験結果を基に、実際のシナリオでの方法の有効性と効率性を評価

連合学習でデータプライバシーを守りながらモデルを訓練できるのはすごいよね！これからも倫理と技術の両立にもっと発展しそう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CL, cs.NE, **投稿日時:** 2024-06-14 08:40


- - -

### [Privacy-preserving Quantification of Non-IID Degree in Federated Learning](http://arxiv.org/abs/2406.09682)

**連合学習における非IID度のプライバシー保護定量化**

Yuping Yan, Yizhi Wang, Yingchao Yu, Yaochu Jin

- 連合学習は、生データの共有を避けつつ複数の協力者で機械学習を行う方法だが、非IIDデータセットが課題。
- 非IIDデータが精度低下や効率減少を引き起こし、実装の妨げとなっている。
- 初めて累積分布関数（CDF）を用いた非IID度の定量的定義を提案。
- 完全準同型暗号を用いて非IID度を推定し、CIFAR-100データセットで効果を検証。

新しいアプローチで連合学習がもっと効率化されそう！これでクライアント間のデータの違いも解消しやすくなるね。

**Comment:** 8 pages, 8 figures, FL@FM-IJCAI'24

**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-06-14 03:08


- - -

### [Heterogeneous Federated Learning with Convolutional and Spiking Neural Networks](http://arxiv.org/abs/2406.09680)

**畳み込みおよびスパイキングニューラルネットワークを用いた異構連合学習**

Yingchao Yu, Yuping Yan, Jisong Cai, Yaochu Jin

- 連合学習（FL）は分散データ上でモデルを訓練しながらデータのプライバシーを守る
- 現在のFLシステムは同種のモデルを前提とするが、実際には異なるAIモデルを使用することが増えてきた
- 異なるモデルを使うことで特定のタスクや要件に適応しやすく、エッジコンピューティングプラットフォームの柔軟性を高める
- CNNとSNNを組み合わせた融合フレームワークが最良の性能を示す

複数のモデルが絡むと競争抑圧が見られるんだって、面白い！これからのエッジコンピューティング技術がどう進化するのか楽しみになるね。

**Comment:** 8 pages, 5 figures, FL@FM-IJCAI'24

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-14 03:05
