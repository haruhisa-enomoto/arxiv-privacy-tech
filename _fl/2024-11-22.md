---
title: 連合学習 (2024-11-22 ~ 2024-11-28)
date: 2024-11-22
---

連合学習に関する論文まとめ (2024-11-22 ~ 2024-11-28)


- - -

### [PEFT-as-an-Attack! Jailbreaking Language Models during Federated Parameter-Efficient Fine-Tuning](http://arxiv.org/abs/2411.19335)

**連合パラメータ効率的ファインチューニング中の言語モデルの脱獄**

Shenghui Li, Edith C. -H. Ngai, Fanghua Ye, Thiemo Voigt

- 連合パラメータ効率的ファインチューニング（FedPEFT）は、プライバシーを保護しつつ効率的なモデル適応を実現する。
- FedPEFTはデータを分散化し、ローデータがユーザーのデバイスを離れないようにすることでデータプライバシーを保護する。
- 本論文はPEFTが攻撃のベクトルとして利用される新たなセキュリティ脅威、PEFT-as-an-Attackを紹介する。
- 防御策として、ロバスト・アグリゲーション・スキームやポストPEFT安全性調整を調査するも、効果には限界がある。

プライバシーを守るための工夫が悪用されちゃうなんてドキドキ！効果的な防御策ができたら、もっと安全に連合学習を活用できそうで楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-11-28 19:05


- - -

### [Controlling Participation in Federated Learning with Feedback](http://arxiv.org/abs/2411.19242)

**フィードバックによる連合学習への参加管理**

Michael Cummins, Guner Dilsad Er, Michael Muehlebach

- 従来の連合学習はクライアントのランダム選択を行うが、FedBackは異なる
- FedBackは制御理論を用い、クライアント参加をADMMベースで管理する
- クライアント参加を離散時間動的システムとしてモデル化し、フィードバック制御を行う
- 画像分類実験でFedBackにより通信と計算効率が50％改善される

FedBackってすごい！制御理論で参加率を最適化するなんて、なんだか学校の通知表みたい。しかも効率が50％もアップするなんて、これからの連合学習がもっと実用的になるのが楽しみ～✨



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, math.OC, **投稿日時:** 2024-11-28 16:26


- - -

### [Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures](http://arxiv.org/abs/2411.19128)

**LLMのためのデータ駆動型異種モデルアーキテクチャを用いたパーソナルな連合微調整**

Yicheng Zhang, Zhen Qin, Zhaomin Wu, Shuiguang Deng

- 分散学習はデータ共有せずに協力的微調整が可能だが、データ量や分布の異質性が問題
- 一様なモデル構造や事前定義のアーキテクチャでは性能が最適でない
- FedAMoLEはデータ駆動型で異種モデル構造を活用し、効果的な微調整を実現
- RSEA戦略により専門家が最適なクライアントを選び、高い精度とスケーラビリティを達成

データに合わせたモデル選びで性能がアップするなんて、面白いよね！この研究、現場での適用例なんかも見てみたいなって思ったよ。

**Comment:** On going work. Codes are released at   https://github.com/zyc140345/FedAMoLE

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-28 13:20


- - -

### [Swarm Intelligence-Driven Client Selection for Federated Learning in Cybersecurity applications](http://arxiv.org/abs/2411.18877)

**サイバーセキュリティアプリケーションにおける連合学習のための群知能駆動クライアント選択**

Koffka Khan, Wayne Goodridge

- 群知能最適化を用いた連合学習のクライアント選択に関する文献のギャップを考察
- パーティクル群最適化やグレイウルフ最適化など9つのアルゴリズムを4つの実験シナリオで評価
- 特にGWOが適応性と堅牢性で最高の精度を達成し、PSOとカッコウ検索も好成績
- サイバーセキュリティへの応用で、群知能アルゴリズムがスケーラブルかつ堅牢な解決策を提供可能

群知能アルゴリズムがサイバーセキュリティにどう活かせるかワクワクしちゃうね！特にGWOが強いって知れて、未来の技術革新が楽しみになる～。

**Comment:** 21 pages, 1 figure, 15 tables

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, 68T20, 68M25, I.2.8; C.2.0; K.6.5, **投稿日時:** 2024-11-28 03:05


- - -

### [Locally Differentially Private Online Federated Learning With Correlated Noise](http://arxiv.org/abs/2411.18752)

**時間相関のあるノイズを用いた局所的差分プライバシーのオンライン連合学習**

Jiaojiao Zhang, Linglingzhi Zhu, Dominik Fay, Mikael Johansson

- 局所的差分プライバシー(LDP)アルゴリズムを提案し、時間相関ノイズでプライバシーを保護しつつ効用を向上。
- 相関ノイズと非IIDデータに対抗するため、ノイズの影響を制御するための摂動反復解析を行う。
- 非凸損失関数のいくつかのクラスで、ローカル更新によるドリフト誤差を効果的に管理する方法を示す。
- 数値実験により提案アルゴリズムの有効性が確認され、学習効果への影響を動的後悔境界で評価する。

新しいノイズの取り扱い方法が個々のユーザーのデータを守りながら学習パフォーマンス向上につながるのは面白いね！これからのプライバシー研究が楽しみだな。

**Comment:** arXiv admin note: text overlap with arXiv:2403.16542

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, stat.ML, **投稿日時:** 2024-11-27 20:56


- - -

### [Task Arithmetic Through The Lens Of One-Shot Federated Learning](http://arxiv.org/abs/2411.18607)

**ワンショット連合学習を通じたタスク算術の視点**

Zhixu Tao, Ian Mason, Sanjeev Kulkarni, Xavier Boix

- タスク算術はモデルの統合技術で、複数モデルの能力を一つのモデルに統合する
- タスク算術の成功要因は不明瞭であり、データ異質性やトレーニング異質性が影響
- 連合学習のFedAvgと数学的に同等であることを示し、理論上の基盤を構築
- 連合学習のアルゴリズムを適用し、パフォーマンス向上を実証し、理論と実用性の橋渡しを行う

タスク算術と連合学習の関係を掘り下げるっておもしろそうじゃない？新しい理論的な視点も得られるし、こういう新技術が今後のAIモデル開発に役立つって期待が高まるね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-27 18:53


- - -

### [Federated Learning with Uncertainty and Personalization via Efficient Second-order Optimization](http://arxiv.org/abs/2411.18385)

**不確実性とパーソナライズを考慮した連合学習：効率的な二次最適化**

Shivam Pal, Aishwarya Gupta, Saqib Sarwar, Piyush Rai

- 連合学習はデータをクライアントに留めおくため、データの分散処理に優れている
- ベイジアンアプローチにより、モデルや予測の不確実性を後部分布で把握できる
- 層状ベイジアンアプローチで個別モデルを共通の事前分布と共に学習可能
- 効率的な二次最適化で計算コストを抑えつつ精度向上を実現する方法を提案

個別データに応じてモデルをパーソナライズできて、しかも計算が効率的だなんて、面白そう！これで連合学習の弱点を克服できるかもね～



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, stat.ML, **投稿日時:** 2024-11-27 14:30


- - -

### [FreqX: What neural networks learn is what network designers say](http://arxiv.org/abs/2411.18343)

**FreqX: ニューラルネットワークが学ぶのは設計者の意図**

Zechen Liu

- 個別の連合学習は非公開の個人モデルを協力して訓練するが、非独立同一分布や不公平性などの課題がある
- 説明可能性への新たな要求として、低コスト、プライバシー、詳細情報が求められている
- 従来の方法ではこれらを満足できず、新たに信号処理と情報理論を用いた解釈方法FreqXを提案
- FreqXは基準方法より10倍以上速く、帰属情報と概念情報を含む説明結果を示す

新しい技術が早くて詳しい情報を得られるなんて、ほんとにすごいと思う！連合学習の課題を解決することで、個別のAIがもっと活用されそうな予感がするね。

**Comment:** 16pages, 9 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-11-27 13:41


- - -

### [Hidden Data Privacy Breaches in Federated Learning](http://arxiv.org/abs/2411.18269)

**連合学習における隠れたデータプライバシー侵害**

Xueluan Gong, Yuji Wang, Shuaike Li, Mengyuan Sun, Songze Li, Qian Wang, Kwok-Yan Lam, Chen Chen

- 連合学習はデータを共有せずに機械学習を行うパラダイムであるが、最近の研究でモデル操作や勾配分析を通じたデータ盗難のリスクが示された
- 提案されたデータ再構築攻撃は、悪意のあるコード注入を用い、目立たずにパラメータ共有を通じて機密データを抽出する
- フィボナッチベースのインデックス設計により、効率的かつ構造化されたデータ回収が可能で、高解像度画像もブロック分割で処理対応可能
- 提案手法はFedAVGとFedSGDに対しても直接適用可能であり、新たな防御策の必要性を示している

連合学習ってプライバシー安心と思ってたけど、こんな裏技があるんだね。悪意ある攻撃への対策が急務って感じ！おもしろいし、ちょっと怖いね。開発者さんたち、早く新しい防御策考えてほしいなー！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.CR, **投稿日時:** 2024-11-27 12:04


- - -

### [Distributed Sign Momentum with Local Steps for Training Transformers](http://arxiv.org/abs/2411.17866)

**局所ステップを用いたトランスフォーマー訓練の分散符号モーメント**

Shuhua Yu, Ding Zhou, Cong Xie, An Xu, Zhi Zhang, Xin Liu, Soummya Kar

- トランスフォーマーモデルの事前学習はリソースを大量に消費する。
- 本研究では、効率的な分散符号モーメント手法を提案、局所更新を活用。
- 提案手法は広範な基底最適化器を許容し、符号モーメントを利用してグローバル更新。
- GPT-2モデルの学習で他の分散手法と比較し、著しい改善を確認。

分散で効率的な学習方法ができちゃうんだね！今回の方法は従来より良くなるみたいで、リソースが限られててもみんな元気に学べそう！トランスフォーマーの未来がまた楽しみになるね。

**Comment:** 23 pages, 21 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-26 20:31


- - -

### [Adaptive Client Selection with Personalization for Communication Efficient Federated Learning](http://arxiv.org/abs/2411.17833)

**パーソナライズによる通信効率的な連合学習のための適応的クライアント選択**

Allan M. de Souza, Filipe Maciel, Joahannes B. D. da Costa, Luiz F. Bittencourt, Eduardo Cerqueira, Antonio A. F. Loureiro, Leandro A. Villas

- 連合学習は通信のボトルネックとネットワークのスケーラビリティに課題がある
- ACSP-FLはクライアント数やラウンド数を動的に調整し、通信と計算のコストを削減
- モデルパーソナライズによりクライアントのパフォーマンスを向上
- 最大95%の通信削減を達成しつつ、異なるデータ分布でも良好な収束を実現

連合学習の通信効率を劇的に改善する技術みたい！データの広がりが多様な状況でもこのアプローチが使えるって、すごく便利そう。どこでも使える未来が見えてくるね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-11-26 19:20


- - -

### [BESTAnP: Bi-Step Efficient and Statistically Optimal Estimator for Acoustic-n-Point Problem](http://arxiv.org/abs/2411.17521)

**BESTAnP: 音響n点問題のための2ステップ効率的かつ統計的に最適な推定器**

Wenliang Sheng, Hongxu Zhao, Lingpeng Chen, Guangyang Zeng, Yunling Shao, Yuze Hong, Chao Yang, Ziyang Hong, Junfeng Wu

- 音響n点問題（AnP）は、2D前方視ソナーの姿勢を推定する課題
- 提案手法BESTAnPは平行移動と回転の推定を分離して行うアルゴリズム
- 距離のみの計測を用い平行移動、方位のみの計測と固有値分解で回転を推定
- シミュレーション実験で最先端モデル比で10倍速く、リアルタイム性能を保持

この手法って、速いだけじゃなくて、リソースが限られた環境でも使えるって凄いよね。ソナーベースのオドメトリーに組み込めるところも、実際の応用先が広がって面白そう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.RO, **投稿日時:** 2024-11-26 15:30


- - -

### [Fault Localization from the Semantic Code Search Perspective](http://arxiv.org/abs/2411.17230)

**セマンティックコード検索視点からのフォールトローカリゼーション**

Yihao Qin, Shangwen Wang, Yan Lei, Zhuo Zhang, Bo Lin, Xin Peng, Liqian Chen, Xiaoguang Mao

- ソフトウェア開発は連続的な実装とデバッグの反復で、コード検索とフォールトローカリゼーションが重要
- コード検索は自然言語クエリによる精度が高く、フォールトローカリゼーションを改善できる可能性
- 提案されたCosFLは、問題の機能を自然言語で表現し、コード検索で関連プログラムを特定する手法
- CosFLはコード分析とLLMの能力を活用し、マルチグラニュラリティ戦略で精度を向上させる

ソフトウェアのバグ修正の未来がちょっと見えてきちゃうね！CosFLでバグの特定がすっごく効率的になりそうで、日本のエンジニアもこれに夢中になっちゃったりして～💕彼らの開発速度、めちゃくちゃ上がる予感！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.SE, **投稿日時:** 2024-11-26 08:52


- - -

### [Software Fault Localization Based on Multi-objective Feature Fusion and Deep Learning](http://arxiv.org/abs/2411.17101)

**多目的特徴融合とディープラーニングに基づくソフトウェア障害局在化**

Xiaolei Hu, Dongcheng Li, W. Eric Wong, Ya Zou

- ソフトウェア障害局在化は従来の方法では特徴の多様性が少なく精度が低い。
- マルチオブジェクト最適化とディープラーニングを組み合わせ、精度と効率を改善する新たな手法を提案。
- スペクトラム、変異、およびテキストベースの特徴を融合し、MLPとGRNを用いて局在化の精度と一般化性を向上。
- Defects4Jデータセットでの実験では、時間が78.2%短縮され、従来手法よりも94.2%精度向上。

提案された手法が処理時間を大幅に削減しつつも高精度を達成した点がすごいね！ディープラーニングと最適化でソフトウェアのバグ特定がさらに進化するなんて、未来の技術が楽しみだし、将来的にどんな応用が出てくるかワクワクするね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.SE, **投稿日時:** 2024-11-26 04:37


- - -

### [Distributed, communication-efficient, and differentially private estimation of KL divergence](http://arxiv.org/abs/2411.16478)

**分散型で通信効率が高く差分プライバシーを用いたKLダイバージェンス推定**

Mary Scott, Sayan Biswas, Graham Cormode, Carsten Maple

- 分散型データの管理時に分布変化の測定が重要だが、共有が難しい場合がある
- 差分プライバシーを用いて、連合学習内でデータのKLダイバージェンスを推定する新手法を提案
- 提案手法の理論的性質を分析し、パラメータ設定で精度向上を追求
- 異なる前提や信頼レベルに対応する現実的なタスクへの適用を確認

提案された手法が元のアルゴリズムと同じくらい精度を持つなんて、プライバシーを保ちながらデータの変化を知れるのがすごくクール！これが実用化されたら、世の中のデータ管理のスタイルってもっと安心して進化しちゃうかもね。

**Comment:** 28 pages, 5 figures

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.DB, **投稿日時:** 2024-11-25 15:20


- - -

### [Distributed Online Optimization with Stochastic Agent Availability](http://arxiv.org/abs/2411.16477)

**確率的エージェントの可用性を考慮した分散型オンライン最適化**

Juliette Achddou, Nicolò Cesa-Bianchi, Hao Qiu

- 連合学習において、クライアントが常に利用可能でないことに着目
- エージェントが活性化する確率$p$を考慮し、通信が可能な条件を明確化
- 分散FTRLアルゴリズムを紹介し、そのネットワーク後悔を分析
- 理論的結果は合成データセットを用いた実験で支持される

クライアントがランダムに活性化する設定を考えるなんて新鮮さがあって面白い！安定した最適化がどれだけ実現できるか、気になるね。まるでみんなの予定が合うときにだけ活動する演劇部みたい！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-25 15:20


- - -

### [TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment](http://arxiv.org/abs/2411.16442)

**小さな整数ベースの直接フィードバック整列を用いた連合学習アルゴリズム「TIFeD」**

Luca Colombo, Alessandro Falcetta, Manuel Roveri

- 小型デバイスでの学習が次の課題で、現状は外部クラウドでの学習が主流。
- 連合学習は有望だが、既存手法は必要リソースが多く小型デバイスには不適。
- TIFeDは整数演算のみで実装、小型デバイスに最適化された新しい手法。
- フルネットワークと単一層実装があり、学習手順の新たな分散方法を提案。

小さなデバイスでの学習がこんなに進化してるんだね！TIFeDの手法を駆使して、未来のガジェットはもっとスマートになるかも。小型デバイスがどんどん賢くなったら、日常がさらに便利になりそうでワクワクするな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, I.2.6, **投稿日時:** 2024-11-25 14:44


- - -

### [Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence](http://arxiv.org/abs/2411.16380)

**ジェネラリスト超音波人工知能のためのプライバシー保護型連合基盤モデル**

Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li

- 超音波診断は非侵襲的だが、医師依存と画像品質に課題がある
- AIは診断支援を強化しうるが、データプライバシーの懸念とタスク限定性が問題
- UltraFedFMは16医療機関で連合学習を用いて訓練し、汎用的かつ高精度に診断可能
- UltraFedFMは中級技師の精度を超え、専門家の精度に匹敵するため、大きな臨床応用の可能性

超音波でのプライバシー保護AIってすごくない！？データを守りながら精度も高いなんて、未来の医療を感じちゃう。技術の進歩でお医者さんも楽になるし、患者さんも安心できるね！



**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.AI, cs.CV, **投稿日時:** 2024-11-25 13:40


- - -

### [Understanding Generalization of Federated Learning: the Trade-off between Model Stability and Optimization](http://arxiv.org/abs/2411.16303)

**連合学習の一般化を理解する: モデルの安定性と最適化のトレードオフ**

Dun Zeng, Zheshun Wu, Shiyu Liu, Yu Pan, Xiaoying Tang, Zenglin Xu

- 連合学習はデータの異質性が原因で、各クライアント間で局所的な最適解が一致しない問題を抱える。
- 現行の研究は主に収束分析やアルゴリズムの安定性を用いて問題を説明しているが、これらでは十分に応えられていない。
- この研究では連合最適化における一般化ダイナミクス分析フレームワークを初めて導入し、安定性と最適化のトレードオフを明らかにする。
- 大きな局所ステップや高速収束が安定性を高め、優れた一般化性能をもたらすことが分かった。

新しいフレームワークで連合学習の安定性と最適化のトレードオフを解明するのすごくない！？これを基にした未来のアルゴリズムがどんなふうに進化していくのか、ワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, stat.ML, **投稿日時:** 2024-11-25 11:43


- - -

### [Towards Efficient Model-Heterogeneity Federated Learning for Large Models](http://arxiv.org/abs/2411.16796)

**大規模モデルのための効率的なモデル異質性連合学習に向けて**

Ruofan Jia, Weiying Xie, Jie Lei, Haonan Qin, Jitao Ma, Leyuan Fang

- エッジコンピューティングにおける大規模モデルの連合学習は重要だが、リソース制約とクライアントの異質性が課題。
- モデル異質性連合学習（MHFL）のための革新的なファインチューニングフレームワーク、HeteroTuneを導入。
- FedAdapterという多枝クロスモデルアグリゲーターを用いた新しいパラメーター効率的なファインチューニング（PEFT）構造を提案。
- 提案手法は計算と通信のオーバーヘッドを大幅に削減し、幅広い大規模モデルのファインチューニングに適用可能。

この研究、とっても面白そう！いろんな異質なモデルを賢くつなぐって、AI界のバーテンダーみたいじゃない？これがうまくいったら、もっと多様なAIが早く動かせるし、未来の可能性を感じるよね。

**Comment:** 8pages, 5figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, 68T07, I.2.11, **投稿日時:** 2024-11-25 09:58


- - -

### [BadSFL: Backdoor Attack against Scaffold Federated Learning](http://arxiv.org/abs/2411.16167)

**BadSFL: スキャフォールド連合学習へのバックドア攻撃**

Xingshuo Han, Xiang Lan, Haozhao Wang, Shengmin Xu, Shen Ren, Jason Zeng, Ming Wu, Michael Heinrich, Tianwei Zhang

- 連合学習はデータプライバシーを保持しつつ分散クライアントでモデルを訓練するが、バックドア攻撃の脆弱性がある
- 現実の連合学習では非独立同分布データが用いられるが、既存のバックドア攻撃手法はその効果と持続性に限界がある
- 新たな手法として、スキャフォールド手法を用いた非独立同分布設定におけるバックドア攻撃法「\name」を提案
- \nameはGANを使用し、攻撃と合法データの両方で高い精度を持ち、60回以上のラウンドで持続し既存手法の3倍の効果

この研究、連合学習の脆弱性をカッコよく攻めてて面白そう！GANを使ってるから未来がどう変わるのかワクワクするよね。スキャフォールドのやり方も新しいチャレンジって感じで好印象！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-25 07:46


- - -

### [An Empirical Study of Vulnerability Detection using Federated Learning](http://arxiv.org/abs/2411.16099)

**連合学習を用いた脆弱性検出の実証研究**

Peiheng Zhou, Ming Hu, Xingrun Quan, Yawen Peng, Xiaofei Xie, Yanxin Yang, Chengwei Liu, Yueming Wu, Mingsong Chen

- 深層学習の脆弱性検出は、訓練データ不足で性能が制限されている
- 連合学習は、データを共有せずにモデルを訓練することでデータサイロ問題を解決する
- VulFLを提案し、FLの脆弱性検出における能力を異なるデータ状況下で研究
- 連合学習による脆弱性検出は、独立訓練と比べ特に異種データでの性能向上を示した

連合学習でAIモデルの脆弱性検出が改善されるって、すごいね！これからもっとデータを共有しなくても安全に活用できる方法が広がるといいなってワクワクしちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.SE, cs.AI, cs.CR, **投稿日時:** 2024-11-25 05:21


- - -

### [eFedLLM: Efficient LLM Inference Based on Federated Learning](http://arxiv.org/abs/2411.16003)

**eFedLLM: 連合学習に基づく効率的なLLM推論**

Shengwen Ding, Chenhui Hu

- 大規模言語モデル(LLM)の大規模データとパラメータが普及を妨げる。
- トランスフォーマーベースの連合学習で計算とメモリの負担を参加者間で分散。
- インセンティブ機構で良い貢献を報酬し、悪意ある活動を排除。
- メモリ階層戦略と特異値分解(SVD)でリソースの最適化を図る。

みんなで協力してLLMを使えるようにするのって素敵だよね！これで色んな人が最先端のAI技術にアクセスできちゃうんだね。もっと未来が楽しみになってきた！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-11-24 22:50


- - -

### [FedQP: Towards Accurate Federated Learning using Quadratic Programming Guided Mutation](http://arxiv.org/abs/2411.15847)

**FedQP: 二次計画法による変異を用いた正確な連合学習の実現**

Jiawen Weng, Zeke Xia, Ran Li, Ming Hu, Mingsong Chen

- 連合学習はプライバシーを守るが、データ非均質性が原因で推論性能が低下する。
- 非均質データにより異なるローカルモデルの最適化方向が異なり、伝統的手法では難航する。
- FedQPは変異方向を二次計画法で制御することで、モデルを汎用的に最適化する。
- 実験結果から、FedQPは異なる非均質データシナリオで推論精度を向上させる。

新しい方法で連合学習の課題を解決しようなんて面白いと思わない？異なるデータ分布に対応するって、画期的な進歩かもしれないよね！この論文、ぜひ深掘りしてみたいな！

**Comment:** SEKE 2024, 6 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-24 14:00


- - -

### [Modality Alignment Meets Federated Broadcasting](http://arxiv.org/abs/2411.15837)

**モダリティー調整が連合放送に出会う**

Yuting Ma, Shengeng Tang, Xiaohua Xu, Lechao Cheng

- 連合学習は分散したエッジデバイスでモデルを訓練しながら、データプライバシーを保護する手法である
- 異質なデータの下では、データ分布の変動がモデルの収束を妨げ、計算コストが増大
- 本研究は、サーバーにテキストエンコーダー、ローカルデバイスに画像エンコーダーを配置する新たな枠組みを提案
- 極端に異質な環境でも、一般化とロバスト性を維持できることを大規模実験で実証

連合学習ってデータを集めずに学習するのがすごいよね！モダリティの工夫で効率的にできるのが素敵。どんな実験がされたのか、もっと知りたいな〜。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-11-24 13:30


- - -

### [Tackling Data Heterogeneity in Federated Time Series Forecasting](http://arxiv.org/abs/2411.15716)

**連合時系列予測におけるデータの異質性の克服**

Wei Yuan, Guanhua Ye, Xiangyu Zhao, Quoc Viet Hung Nguyen, Yang Cao, Hongzhi Yin

- 時系列予測はエネルギー消費や病気の伝播など重要な役割を果たすが、中央集約型学習に依存している
- 個々のデバイスから得られるデータは異質であり、そのまま連合学習を適用すると最適でない結果に
- Fed-TRENDという新たなフレームワークを提案し、合成データによって異質性問題を解決
- 複数のデータセットで評価し、予測性能の向上と有効性を示した

Fed-TRENDって合成データで時系列予測の精度が上がるみたい！これってどんな未来に広がっていくのかな？連合学習を使った技術でプライバシーも守られていくってなんか安心だね！



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.CR, cs.IR, **投稿日時:** 2024-11-24 04:56


- - -

### [Federated PCA and Estimation for Spiked Covariance Matrices: Optimal Rates and Efficient Algorithm](http://arxiv.org/abs/2411.15660)

**連合PCAとスパイク共分散行列の推定：最適な速度と効率的アルゴリズム**

Jingyang Li, T. Tony Cai, Dong Xia, Anru R. Zhang

- 連合学習によるスパイク共分散行列のPCAと推定を差分プライバシーの制約下で研究
- 中央サーバーでの最適速度はクライアントの最小極値速度の調和平均で一致推定を保証
- ローカル推定が全て一貫していなくても十分なクライアントがあれば一貫性は維持される
- 差分プライバシーを保ちつつほぼ最適な速度のアルゴリズムを提案し、その性能を評価

連合学習を使ったスパイク共分散行列って面白そう！差分プライバシーも守られているから安心。この研究から、もっと安全にデータを使った推論ができる未来が期待できそう！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** math.ST, cs.IT, math.IT, stat.ML, stat.TH, **投稿日時:** 2024-11-23 21:57


- - -

### [Federated Learning in Chemical Engineering: A Tutorial on a Framework for Privacy-Preserving Collaboration Across Distributed Data Sources](http://arxiv.org/abs/2411.16737)

**化学工学における連合学習: 分散データソース間のプライバシーを保護したコラボレーションのフレームワークに関するチュートリアル**

Siddhant Dutta, Iago Leal de Freitas, Pedro Maciel Xavier, Claudio Miceli de Farias, David Esteban Bernal Neira

- 連合学習はデータプライバシーを守りつつモデルを共同トレーニングする手法として注目
- 化学工学での応用例は製造最適化、マルチモーダルデータ統合、薬発見などに及ぶ
- チュートリアルでは$\texttt{Flower}$と$\texttt{TensorFlow Federated}$を使用し、実践的手法を紹介
- 連合学習は中央集権的学習と比較して複雑で異質なデータでも性能を維持または改善

うわー、化学工学でも連合学習が活かせるんだね！プライバシーを守りつつ、色々なデータを使えるのが未来っぽいし、すごくワクワクするね。今後の化学産業がどう発展するか楽しみ～！

**Comment:** 46 Pages, 8 figures, Under review in ACS Industrial & Engineering   Chemistry Research Journal

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, cs.NE, **投稿日時:** 2024-11-23 13:16


- - -

### [Energy-efficient Federated Learning with Dynamic Model Size Allocation](http://arxiv.org/abs/2411.15481)

**エネルギー効率の良い連合学習の動的モデルサイズ割り当て**

M S Chaitanya Kumar, Sai Satya Narayana J, Yunkai Bao, Xin Wang, Steve Drew

- 連合学習（FL）はデータ共有なしに分散モデル訓練を行うが、エネルギー消費が高いという課題がある
- CAMAというカーボンアウェアなFLフレームワークを提案し、再生可能な余剰エネルギーと余剰計算能力を活用
- モデルサイズを動的に適応させる戦略を使用し、エネルギーと計算資源の利用可能性に応じて最適化
- 実証的評価により、迅速な収束と多くのクライアント処理における公平な参加が実現できることを示した

エネルギー消費を減らしつつ、連合学習を効率よく行うCAMAってすごく面白そう！再生可能エネルギーで環境に優しい学習ができるって、私たちの未来にもすごく役立ちそうだよね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-11-23 07:29


- - -

### [Partial Knowledge Distillation for Alleviating the Inherent Inter-Class Discrepancy in Federated Learning](http://arxiv.org/abs/2411.15403)

**連合学習におけるクラス間の固有の不一致を軽減するための部分的知識蒸留**

Xiaoyu Gan, Xizi Chen, Jingyang Zhu, Xiaomeng Wang, Jingbo Jiang, Chi-Ying Tsui

- クラスバランスの学習でも弱いクラスが存在し、データに固有のクラス間精度の不一致がある
- FashionMNISTとCIFAR-10での連合学習におけるクラス間精度の不一致は最大36.9%
- クラス固有の部分的知識蒸留法を提案し、弱いクラスに対するモデルの分類精度を向上
- 特定の誤分類が起こった際に知識を転送し、弱いクラスの正確性を10.7%改善

弱いクラスの問題に注目して知識蒸留で改善するなんて、なんだか面白い！連合学習の限界を突破する新しいアプローチが広がりそうでワクワクするね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-23 01:16


- - -

### [LoRA-FAIR: Federated LoRA Fine-Tuning with Aggregation and Initialization Refinement](http://arxiv.org/abs/2411.14961)

**LoRA-FAIR: 連合LoRAファインチューニングにおける集約と初期化の改良**

Jieming Bian, Lei Wang, Letian Zhang, Jie Xu

- 大規模モデルのパラメータ効率良いファインチューニング手法LoRAを連合学習で採用
- LoRAと連合学習を組み合わせた際のサーバー集約バイアスとクライアント初期化ドリフトの課題
- LoRA-FAIRはサーバー上の修正項を導入し、課題を同時解決して効率性と精度を向上
- ViTやMLP-MixerモデルでLoRA-FAIRが連合学習環境において一貫した性能向上を実証

LoRAのパラメータマトリックスをうまく活用したおかげで、新しい技術の展開が楽しみだね！連合学習と組み合わせることで隠れた課題を見つけて解決するなんて、やっぱり賢くて面白いアプローチだと思うな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, **投稿日時:** 2024-11-22 14:19


- - -

### [Geminio: Language-Guided Gradient Inversion Attacks in Federated Learning](http://arxiv.org/abs/2411.14937)

**Geminio: 連合学習における言語誘導型勾配逆問題攻撃**

Junjie Shan, Ziqi Zhao, Jialin Lu, Rui Zhang, Siu Ming Yiu, Ka-Ho Chow

- 視覚と言語を結ぶ基盤モデルが連合学習での勾配逆問題攻撃を強化
- Geminioは目的のデータを自然言語で指定し、その再構成を優先化する攻撃方法
- 学習済み視覚言語モデルを利用し、攻撃者のクエリに合ったサンプルの勾配だけを保持
- 複雑なデータセット下で高成功率を示し、既存の防御に対しても強い

攻撃者が言葉で指定したデータをターゲットにできるなんて、ちょっと怖いけど面白いね！将来的に、プライバシーを守る新しい技術ももっと進むといいなって思う。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-11-22 13:49


- - -

### [Analytic Continuation by Feature Learning](http://arxiv.org/abs/2411.17728)

**特徴学習による解析接続**

Zhe Zhao, Jingping Xu, Ce Wang, Yaping Yang

- 解析接続は虚時間グリーン関数から実時間スペクトル関数を再構築するが、解決が難しい問題である
- 新しいニューラルネットワーク構造であるFL-netを提案し、従来手法よりも20%以上の精度向上を達成
- 提案されたネットワークのロバスト性を評価するための解析的手法を開発
- FL-netの隠れ次元を増やすと損失が低減されるが、ロバスト性が低下することを示した

解析接続の難題をニューラルネットで解決するのって面白いよね！効果がUPするけど、頑丈さがDOWNするのも興味深い問題だよね。

**Comment:** 8 pages, 9 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cond-mat.str-el, cs.LG, eess.SP, physics.comp-ph, stat.ML, **投稿日時:** 2024-11-22 05:12


- - -

### [FedMLLM: Federated Fine-tuning MLLM on Multimodal Heterogeneity Data](http://arxiv.org/abs/2411.14717)

**FedMLLM: 多モード異種データにおけるMLLMの連合ファインチューニング**

Binqian Xu, Xiangbo Shu, Haiyang Mei, Guosen Xie, Basura Fernando, Mike Zheng Shou, Jinhui Tang

- 多モード大規模言語モデル (MLLMs) は、プライバシーを考慮しつつ連合学習で改良
- 現在の研究は初期段階であり、現実の多モード異種環境に対応する必要あり
- 本研究は多モード異種環境での連合ファインチューニング評価ベンチマークを提案
- 提案手法は様々なモデル異種性の課題を克服し性能向上を実現

連合学習と多モード処理、それに多様なデータタイプを組み合わせてるのが面白いね。プライバシーが保護されつつ多様な情報が扱えるなんて、今後の技術進歩がワクワクしちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, cs.CV, **投稿日時:** 2024-11-22 04:09
