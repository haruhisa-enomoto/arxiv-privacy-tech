---
title: 連合学習 (2024-09-20 ~ 2024-09-26)
date: 2024-09-20
---

連合学習に関する論文まとめ (2024-09-20 ~ 2024-09-26)


- - -

### [Flight: A FaaS-Based Framework for Complex and Hierarchical Federated Learning](http://arxiv.org/abs/2409.16495)

**Flight: 複雑かつ階層的な連合学習のためのFaaSベースフレームワーク**

Nathaniel Hudson, Valerie Hayot-Sasson, Yadu Babuji, Matt Baughman, J. Gregory Pauloski, Ryan Chard, Ian Foster, Kyle Chard

- Flightは、複雑な階層型多層トポロジーと非同期集約をサポート
- 制御プレーンとデータプレーンを分離し、効率向上を目指す
- Flowerと比較してFlightは2048の同時デバイスをサポートし、処理時間を短縮
- 階層型FLモデルにより通信オーバーヘッドを60%以上削減

この研究、リアルなIoT環境に適してそうだよね。2048デバイスって想像以上の規模でワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-09-24 22:49


- - -

### [Communication and Energy Efficient Federated Learning using Zero-Order Optimization Technique](http://arxiv.org/abs/2409.16456)

**ゼロ次最適化技術を用いた通信とエネルギー効率の高い連合学習**

Elissa Mhanna, Mohamad Assaad

- 連合学習（FL）はユーザーデータのプライバシーを維持しつつ共同でモデルを訓練する技術
- 通信のボトルネックとデバイスのエネルギー消費がモデル/勾配のサイズ増加で問題に
- ゼロ次最適化法を提案し、各デバイスが単一の量子化されたスカラーをアップロードすることで解決
- 非凸条件での理論的収束を証明し、通信オーバーヘッドとエネルギー消費の優位性を示した

みんなのデバイスの電池が長持ちするようになるなんてすごい！この方法、たくさんの人たちが使うともっと効率が良くなりそうだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-09-24 20:57


- - -

### [Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review](http://arxiv.org/abs/2409.16340)

**プライバシー保護を考慮した連合学習と不確実性定量による医療画像の未来保証：レビュー**

Nikolas Koutsoubis, Asim Waqas, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

- AIは、診断、予後、治療計画、監視を自動化する潜在能力を持つが、患者データのプライバシーが障壁
- 連合学習は、データを共有せずにAIモデルを共同で訓練する解決策を提供するが、まだ開発段階
- 階差情報からも依然として敏感情報が推測される可能性があり、不確実性定量が重要
- 連合学習のデータ異質性が不確実性定量を難しくし、今後の研究方向を提案

医療の未来感満載でワクワクする！プライバシー守りながらAI活用とか、SFみたいで超面白そう！

**Comment:** 21 pages, 5 figures, 4 tables, Review paper, preprint to Radiology   AI. arXiv admin note: text overlap with arXiv:2406.12815

**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.AI, cs.CV, **投稿日時:** 2024-09-24 16:55


- - -

### [Historical Trajectory Assisted Zeroth-Order Federated Optimization](http://arxiv.org/abs/2409.15955)

**履歴軌跡支援ゼロオーダー連合最適化**

Xiaoyu He, Chenlin Wu, Zike Li, Zibin Zheng

- 連合学習はクライアントが個別にモデルを訓練し、モデルの更新をアップロードする分散学習フレームワーク
- 勾配情報がない場合、ゼロオーダー情報から勾配を推定するが、従来手法は推定誤差が高い
- 本研究では、非等方サンプリング法を提案し、履歴軌跡に基づく部分空間での勾配推定を行う
- 提案手法は既存手法と同等の収束率を示し、通信やローカル計算で大きな負担を増やさない

履歴軌跡を使った勾配推定なんて面白いアイデア！今後の連合学習の精度向上に期待できそう！

**Comment:** 28 pages with theoretical proof

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-09-24 10:36


- - -

### [FedRepOpt: Gradient Re-parameterized Optimizers in Federated Learning](http://arxiv.org/abs/2409.15898)

**FedRepOpt: 連合学習における勾配再パラメータ化最適化手法**

Kin Wai Lau, Yasar Abbas Ur Rehman, Pedro Porto Buarque de Gusmão, Lai-Man Po, Lan Ma, Yuyang Xie

- 連合学習はプライバシー保護の方法であり、端末デバイス上でモデルを分散型でトレーニングする。
- 端末デバイスは計算能力とメモリに制約があり、勾配更新が制限される可能性がある。
- FedRepOptを提案し、シンプルなローカルモデルでも複雑なモデルに近い性能を発揮するようにする。
- 実験により、FedRepOpt使用モデルは性能が16.7%と11.4%、収束時間が11.7%と57.4%向上することを確認。

連合学習ってすごいね！デバイスが進化すればするほど、この技術がもっと面白くなりそう。早く実際に使われるところを見てみたいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, cs.DC, **投稿日時:** 2024-09-24 09:17


- - -

### [A Multi-Level Approach for Class Imbalance Problem in Federated Learning for Remote Industry 4.0 Applications](http://arxiv.org/abs/2409.15802)

**連合学習におけるクラス不均衡問題への多層アプローチ：リモートインダストリー4.0アプリケーション**

Razin Farhan Hussain, Mohsen Amini Salehi

- インダストリー4.0アプリケーション向けのDNNモデルは大量のデータが必要であり、データ収集と中央クラウドサーバーへの転送が費用とプライバシーの問題
- 遠隔地のオフショア油田などでは、ネットワーク接続が脆弱なため、連合フォグ環境が計算プラットフォームとして有望
- フォグシステムでのDNNモデル訓練はセキュリティ問題があり、連合学習技術が解決するが、クラス不均衡問題が性能を低下させる
- 労働者モデルの選定に動的閾値メカニズムとユーザー定義の重みを使用し、一連の実証評価でベースライン連合学習方法より性能が3-5%向上

連合学習だけでも難しいのにクラス不均衡まで考えるなんて、奥が深いね。実際にどんな風に性能が向上するのか、もっと詳しく知りたくなる！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, cs.SY, eess.SY, **投稿日時:** 2024-09-24 06:52


- - -

### [Evolving Topics in Federated Learning: Trends, and Emerging Directions for IS](http://arxiv.org/abs/2409.15773)

**連合学習における進化するトピック：トレンドと情報システム(IS)の新興方向性**

Md Raihan Uddin, Gauri Shankar, Saddam Hossain Mukta, Prabhat Kumar, Najmul Islam

- 連合学習（FL）はデータプライバシーとセキュリティを保護しつつ機械学習モデルを訓練するアプローチ
- この論文はFLに関する包括的な計算文献レビューを実施し、研究の全体像を提示
- 最も影響力のある15のトピックと分野を特定し、詳細に分析
- IS研究者のためにガイドとなる研究質問を提案し、さらなる研究の方向性を示唆

連合学習の最新研究をざっくりまとめてくれてるから、これから勉強するのに役立ちそう！新しいトピックがどんなのかも気になるなぁ。

**Comment:** 18 pages, 8 figures and 4 tables

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-09-24 05:58


- - -

### [Federated Large Language Models: Current Progress and Future Directions](http://arxiv.org/abs/2409.15723)

**連合大規模言語モデル: 現在の進展と将来の方向性**

Yuhang Yao, Jianyi Zhang, Junda Wu, Chengkai Huang, Yu Xia, Tong Yu, Ruiyi Zhang, Sungchul Kim, Ryan Rossi, Ang Li, Lina Yao, Julian McAuley, Yiran Chen, Carlee Joe-Wong

- 大規模言語モデル（LLMs）は人気が高まり、実世界で広く採用されている
- 連合学習（FL）は、複数のクライアントがローカルデータを共有せずにLLMsを共同で訓練する解決策である
- FLは異種データによるモデル収束問題や高い通信コストなど新たな課題を引き起こす
- 本研究は、連合LLMsの微調整とプロンプト学習に焦点を当て、既存の研究と関連する課題を議論する

連合学習で大規模な言語モデルをどう活用するかって、すごく未来に役立ちそうな研究だね！データのプライバシーを守りつつ、賢いAIを作る手法がもっと広がるといいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, **投稿日時:** 2024-09-24 04:14


- - -

### [Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIoT](http://arxiv.org/abs/2409.15711)

**データの異質性を考慮したIIoTにおける表面欠陥分類のための対抗的連合合意学習**

Jixuan Cui, Jun Li, Zhen Mei, Yiyang Ni, Wen Chen, Zengxiang Li

- 深層学習はデータ不足が原因で工業用表面欠陥分類に適用しづらい
- 個々のクライアントにおけるデータ分布の差異が連合学習の性能低下につながる
- 対抗的連合合意学習（AFedCL）はデータの異質性を克服するための新しい手法
- AFedCLはFedALAなどの最新FLメソッドと比べて精度が最大5.67%向上

これめっちゃ面白そう！データ異質性の問題を解決するなんてすごいねー。5.67%の精度向上はけっこう大きい！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, eess.SP, **投稿日時:** 2024-09-24 03:59


- - -

### [Personalized Federated Learning via Backbone Self-Distillation](http://arxiv.org/abs/2409.15636)

**バックボーン自己蒸留によるパーソナライズド連合学習**

Pengju Wang, Bochao Liu, Dan Zeng, Chenggang Yan, Shiming Ge

- 連合学習は、クライアントごとの異質なデータで個別モデルを訓練する必要がある
- 提案手法はバックボーン自己蒸留を用いて、パーソナライズド連合学習を支援
- 各クライアントはローカルモデルを訓練し、バックボーンの重みのみをサーバに送信
- 提案手法の有効性を、12の最先端手法との比較実験により示す

クライアントごとにパーソナライズドなモデルを作成できるって画期的！連合学習の効率が上がるかもね。

**Comment:** Pubished in ACM MMAsia 2023

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, cs.CV, **投稿日時:** 2024-09-24 00:43


- - -

### [Stalactite: Toolbox for Fast Prototyping of Vertical Federated Learning Systems](http://arxiv.org/abs/2409.15558)

**Stalactite: 垂直連合学習システムの迅速なプロトタイピングのためのツールボックス**

Anastasiia Zakharova, Dmitriy Alexandrov, Maria Khodorchenko, Nikolay Butakov, Alexey Vasilev, Maxim Savchenko, Alexander Grigorievskiy

- データ移転が困難なため、従来の機械学習アルゴリズムが利用できない場合が多い
- 連合学習（FL）は、分散データセットから学習しつつ元データを公開しない技術である
- 垂直連合学習（VFL）では、データが特徴ごとに異なるデータ所有者に分かれている
- StalactiteはVFLシステムのプロトタイプ構築を支援するオープンソースフレームワークである

実際の推薦データセットで試すって面白そう！研究者はアルゴリズムに集中できるし、垂直連合学習の普及が加速しそうね。



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.LG, cs.DC, cs.IR, **投稿日時:** 2024-09-23 21:29


- - -

### [FLeNS: Federated Learning with Enhanced Nesterov-Newton Sketch](http://arxiv.org/abs/2409.15216)

**FLeNS: 強化されたネステロフ・ニュートン・スケッチを用いた連合学習**

Sunny Gupta, Mohit, Pankhi Kashyap, Pranav Jeevan, Amit Sethi

- 連合学習における通信効率と高速収束のバランスが課題
- Newton型アルゴリズムは線形収束達成するがヘッセ行列の伝送が非現実的
- FLeNSはネステロフ法とヘッセスケッチの利点を活用し通信オーバーヘッドを削減
- 理論分析により、超線形収束率を達成し、通信ラウンドの駆動効率向上を証明

ネステロフ法の効率とスケッチ技術の融合がすごく面白いね！実際のパフォーマンスも期待できるし、今後の連合学習の進展が楽しみだな。

**Comment:** 10 pages, 3 figures, 2 Tables

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, cs.DC, math.OC, I.2.6; C.1.4; D.1.3; I.5.1; H.3.4, **投稿日時:** 2024-09-23 17:00


- - -

### [Robust Federated Learning Over the Air: Combating Heavy-Tailed Noise with Median Anchored Clipping](http://arxiv.org/abs/2409.15100)

**空中を介したロバストな連合学習：重尾ノイズに抵抗するためのメディアンアンカードクリッピング**

Jiaxing Li, Zihan Chen, Kai Fong Ernest Chong, Bikramjit Das, Tony Q. S. Quek, Howard H. Yang

- 空中計算を活用し、連合型エッジ学習の通信ボトルネックに対処
- 無線チャネルの電磁干渉は重尾分布を示し、強力なノイズを生じる
- 提案するメディアンアンカードクリッピング(MAC)が重尾ノイズを制御
- 実験結果はMACアルゴリズムがノイズ影響を大幅に緩和し、システムのロバスト性を向上

連合学習の通信ボトルネックを解消しつつ、電磁干渉対策も徹底しちゃうなんて、すごく技術が詰まってる感じがする！MACの効果、実際どのくらいスゴいんだろうね？



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-09-23 15:11


- - -

### [SHFL: Secure Hierarchical Federated Learning Framework for Edge Networks](http://arxiv.org/abs/2409.15067)

**SHFL：エッジネットワークのための安全な階層型連合学習フレームワーク**

Omid Tavallaie, Kanchana Thilakarathna, Suranga Seneviratne, Aruna Seneviratne, Albert Y. Zomaya

- 連合学習はプライバシーに配慮した分散機械学習のパラダイムで、非独立同分布データに対応
- 従来の連合学習フレームワークはクライアント-サーバモデルを採用し、モデル/データ毒攻撃に脆弱
- SHFLはエッジとクラウドでの二段階集約プロセスを活用し、モデル/データ毒攻撃に対抗
- 新規クライアント選択アルゴリズムと凸最適化に基づくモデル集約手法を提案、精度向上を実現

分散したIoTデバイスの環境でも精度を高めつつセキュリティを確保できるなんて、すごく実用的！未来のスマートシティがより安全になるかもね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-09-23 14:38


- - -

### [FedSlate:A Federated Deep Reinforcement Learning Recommender System](http://arxiv.org/abs/2409.14872)

**FedSlate: 連合深層強化学習レコメンデーションシステム**

Yongxin Deng, Xiaoyu Tan, Xihe Qiu, Yaochu Jin

- 強化学習でユーザーエンゲージメントを最適化、だが既存の方法は異なるプラットフォーム間でのユーザー行動の関連性を十分に活用していない
- データを中央集権化すると経済的および法的懸念（通信コスト増加とプライバシーのリスク）が発生
- 法的に共有禁止の情報を活用するために「FedSlate」を提案、これは連合強化学習に基づくアルゴリズム
- 実験結果でFedSlateが従来の方法より優れた効果を示し、従来法が使えないシナリオでも推薦戦略の学習を支援

連合学習を使うことで複数プラットフォームのデータをうまく活用しているみたい！これからはどのアプリでも自分好みのレコメンドがされるかもね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.IR, cs.AI, **投稿日時:** 2024-09-23 10:10


- - -

### [Energy-Aware Federated Learning in Satellite Constellations](http://arxiv.org/abs/2409.14832)

**衛星コンステレーションにおけるエネルギー対応型連合学習**

Nasrin Razmi, Bho Matthiesen, Armin Dekorsy, Petar Popovski

- 衛星コンステレーションの連合学習は、地上モバイルネットワークとの統合を目指す技術
- 衛星のエネルギー供給は、ソーラーパネルか内部バッテリーによって行われる
- 新たに提案されたエネルギー対応型スケジューラーは、バッテリー使用量を最小限に抑える
- エネルギー非対応のタスクスケジューリングに比べ、バッテリー寿命が3倍以上向上すると示唆

衛星ネットワークと連合学習って、まるで未来のSFじゃない？バッテリー寿命が伸びるなら、実用化が楽しみだよね！

**Comment:** This paper is accepted for the IEEE Global Communications Conference   (GLOBECOM Workshops), 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, eess.SP, **投稿日時:** 2024-09-23 09:01


- - -

### [SDBA: A Stealthy and Long-Lasting Durable Backdoor Attack in Federated Learning](http://arxiv.org/abs/2409.14805)

**連合学習におけるステルスで持続的な耐久性バックドア攻撃：SDBA**

Minyeong Choe, Cheolhee Park, Changho Seo, Hyunil Kim

- 連合学習の分散特性がバックドア攻撃を受けやすい
- NLPタスク向けに設計された新たなバックドア攻撃メカニズムSDBAを提案
- LSTMとGPT-2モデルにおける最も脆弱な層を特定し、層ごとの勾配マスキングによって持続性を実現
- 次のトークン予測及び感情分析タスクの実験で、SDBAが既存のバックドアを耐久性で上回ることを確認

連合学習の未来を考えると、バックドア攻撃への対策はもっと真剣に取り組まないとね。もっと安全なシステムが必要だよね！

**Comment:** 13 pages, 13 figures This work has been submitted to the IEEE for   possible publication. Copyright may be transferred without notice, after   which this version may no longer be accessible

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-09-23 08:30


- - -

### [FedGCA: Global Consistent Augmentation Based Single-Source Federated Domain Generalization](http://arxiv.org/abs/2409.14671)

**FedGCA: 単一ソース連合ドメイン一般化に基づくグローバル一貫性増強**

Yuan Liu, Shu Wang, Zhe Qu, Xingyu Li, Shichao Kan, Jianxin Wang

- Federated Domain Generalization（FedDG）は、見えないドメインに対して一般化するグローバルモデルを訓練
- しかし、連合学習のクライアントは単一かつIIDでないドメインに限定されることが多い
- FedGCAは多様なドメインスタイルでデータを増強するスタイル補完モジュールを導入
- 実験でFedGCAの有効性と優位性が確認された

この技術、新しいデータスタイルの生成とか超面白そうだよね！ いろんなドメインに対応する連合学習って新しい展開を期待できるかも！

**Comment:** 6 pages, 7 figures, conference

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.AI, cs.CV, I.2, **投稿日時:** 2024-09-23 02:24


- - -

### [Federated Graph Learning with Adaptive Importance-based Sampling](http://arxiv.org/abs/2409.14655)

**適応的な重要性ベースのサンプリングによる連合グラフ学習**

Anran Li, Yuanyuan Chen, Chao Ren, Wenhan Wang, Ming Hu, Tianlin Li, Han Yu, Qingyu Chen

- 連合学習ベースのGCN(FedGCN)トレーニングは、プライバシー保護のため分散グラフデータセットに必須
- 従来のFedGCNは計算と通信コストが高く、近傍ノード数の爆発的増加で困難
- 適応的な重要性ベースのサンプリング(FedAIS)で重要ノードに集中し、通信オーバーヘッドを削減
- FedAISは効率と精度の最適トレードオフを実現し、最大3.23%の精度向上と85.59%の計算コスト削減

グラフの構造と動的最適化を考慮したサンプリング方法なんて、とても賢い発想だね！性能もぐんと上がってて本当に凄い！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.CR, cs.LG, **投稿日時:** 2024-09-23 01:49


- - -

### [Accelerated Stochastic ExtraGradient: Mixing Hessian and Gradient Similarity to Reduce Communication in Distributed and Federated Learning](http://arxiv.org/abs/2409.14280)

**加速された確率的エクストラグラディエント：エッセンスと勾配の類似性を混合して分散および連合学習における通信を削減**

Dmitry Bylinkin, Kirill Degtyarev, Aleksandr Beznosikov

- モデルの汎化能力の向上により、モデルとトレーニングデータのサイズが増加
- 単一デバイスでは困難なため、分散学習や連合学習アプローチが一般化
- 地方データの類似性を利用することで通信コストを削減
- プライバシー保護のために追加ノイズを適用し、その影響を分析

分散学習と連合学習が今後ますます重要になる中で、通信とプライバシーの問題を解決する方法としてすごく未来志向っぽくて興味引かれるね！具体的な技術応用の例を探ってみたいな。

**Comment:** 25 pages, 15 figures, 4 appendices

**トピック:** [連合学習](../../fl), **カテゴリ:** math.OC, cs.LG, **投稿日時:** 2024-09-22 00:49


- - -

### [FeDETR: a Federated Approach for Stenosis Detection in Coronary Angiography](http://arxiv.org/abs/2409.14268)

**FeDETR: 冠動脈造影における狭窄検出のための連合的アプローチ**

Raffaele Mineo, Amelia Sorrenti, Federica Proietto Salanitri

- 冠動脈造影における狭窄の重篤度評価は心臓の健康に重要
- 現行の評価方法は時間、費用、侵襲性などの欠点がある
- 深層学習手法は大規模データセットが必要で連合学習がデータプライバシー保持に役立つ
- FeDETRは5つの病院から収集したデータセットで訓練され、優れた性能を示した

医療データのプライバシーを守りながら、AIで心臓病の診断が便利になるなんて超素敵！未来の医療って感じがするね。

**Comment:** 9 pages, 9 figures, Image Analysis and Processing - ICIAP 2023   Workshops. ICIAP 2023. Lecture Notes in Computer Science, vol 14366.   Springer, Cham

**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.CV, cs.LG, I.4.6; I.2.10, **投稿日時:** 2024-09-21 23:52


- - -

### [Re-Evaluating Privacy in Centralized and Decentralized Learning: An Information-Theoretical and Empirical Study](http://arxiv.org/abs/2409.14261)

**中央集権型と分散型学習におけるプライバシーの再評価：情報理論的および実証的研究**

Changlong Ji, Stephane Maag, Richard Heusdens, Qiongxiu Li

- 分散型連合学習（DFL）は中央集権型連合学習（CFL）に比べてスケーラビリティに優れる
- DFLはプライバシー優位性があると信じられてきたが、最近の研究はこれに異議を唱える
- 情報理論的分析によるプライバシーリークの評価を実施、相互情報を用いる
- セキュアアグリゲーション（SA）等のプライバシー技術の効果をCFLとDFLで比較検証

DFLがCFLに対して本当に優れているのか気になるよね。実験結果とか見るのが楽しみ！どうやってプライバシーを守るかが明確になるの、本当に重要だよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-09-21 23:05


- - -

### [Perfect Gradient Inversion in Federated Learning: A New Paradigm from the Hidden Subset Sum Problem](http://arxiv.org/abs/2409.14260)

**連合学習における完全な勾配反転: 隠れ部分和問題からの新たなパラダイム**

Qiongxiu Li, Lixia Luo, Agnese Gini, Changlong Ji, Zhanhao Hu, Xiao Li, Chengfang Fang, Jie Shi, Xiaolin Hu

- 連合学習（FL）はプライバシーに配慮した協調学習であり、ローカルデータはデバイス上に留まる
- 勾配反転攻撃は一般的な攻撃方法と見なされるが、従来の研究は小規模バッチに限定される
- この研究は、FLの共有勾配情報を用いた入力再構築問題を隠れ部分和問題（HSSP）として数学的に定式化
- 準同型暗号や秘密計算などの安全なデータ集約技術を適用することで、攻撃の時間複雑性を増加させる

隠れ部分和問題がNP完全問題に基づいているなんて、すごく理論的で興味深いね！こんな難しい問題が解決できる方向に進んでいるなんて、未来のデータプライバシーも安心だね！



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), [秘密計算](../../mpc), **カテゴリ:** cs.CR, **投稿日時:** 2024-09-21 23:01


- - -

### [Recovering Global Data Distribution Locally in Federated Learning](http://arxiv.org/abs/2409.14063)

**連合学習におけるグローバルデータ分布のローカル復元**

Ziyu Yao

- 連合学習（FL）の主な課題は、クライアント間のラベル不均衡である
- ReGLの新しいアプローチを提案、少数派や欠落クラスを補完する画像を生成
- ローカルの実データで生成プロセスを適応的に微調整、グローバル分布に近づける
- データプライバシーを保持しつつ、既存方法よりもラベル不均衡の解消に優れていると実験で示す

これはめっちゃ興味深いね！各クライアントでデータを生成することで、プライバシーを守りながら全体の精度を上げているの、すごくスマート。これからのAIの進化が楽しみ！

**Comment:** Accepted by BMVC 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, **投稿日時:** 2024-09-21 08:35


- - -

### [Data Distribution Shifts in (Industrial) Federated Learning as a Privacy Issue](http://arxiv.org/abs/2409.13875)

**（産業）連合学習におけるデータ分布の変化がプライバシー問題となるケース**

David Brunner, Alessio Montuoro

- 産業連合学習では小規模な強力な企業間の協力が第三者によって調整される
- 企業は知的財産や生産プロセスに厳しく、これに関する情報は秘密とされる
- 協力者の一部が競合企業の生産変更をデータ分布の微細な変化で推測できる
- 評価指標よりも優れた分布変化検出手法を探し、実証研究でその有効性を証明

企業間の微妙な駆け引きが連合学習にまで影響してくるの、すごく興味深い！これでより安全な方法を見つけられたら、みんなハッピーだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-09-20 20:09


- - -

### [DP-FedSAM: Enhancing Differentially Private Federated Learning Through Personalized Sharpness-Aware Minimization](http://arxiv.org/abs/2409.13645)

**DP$^2$-FedSAM: 差分プライバシーを強化する個別シャープネス認識最小化連合学習**

Zhenxiao Zhang, Yuanxiong Guo, Yanmin Gong

- 連合学習（FL）は、生データを共有せずに複数のクライアントが共同でモデルを訓練する
- 差分プライバシー連合学習（DPFL）は、モデル更新にランダムノイズを加えることで、プライバシーを保護する
- 提案手法DP$^2$-FedSAMは、ノイズやクリッピングの影響を軽減し、モデルの有用性を向上させる
- DP$^2$-FedSAMは理論的分析と評価結果により、既存のDPFLよりもプライバシーと有用性のトレードオフを改善することが確認された

クライアントごとに個別対応するってすごく柔軟でいいね！これからもっとデータのプライバシーが重要になるし、こんな技術がどんどん広まってほしいな。

**Comment:** 19 pages, 7 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-09-20 16:49


- - -

### [Boosting Federated Domain Generalization: Understanding the Role of Advanced Pre-Trained Architectures](http://arxiv.org/abs/2409.13527)

**連合ドメイン一般化の強化: 高度な事前学習アーキテクチャの役割理解**

Avi Deb Raha, Apurba Adhikary, Mrityunjoy Gain, Yu Qiao, Choong Seon Hong

- Vision Transformers、ConvNeXt、Swin Transformersなどの高度な事前学習アーキテクチャがFDG改善に有効
- 自己教師あり学習技術は画像の内在的な構造を捉え、教師あり学習よりも優れている
- 事前学習済みの高度なアーキテクチャは、Office-HomeとPACSデータセットで新たなベンチマークを樹立
- 少ないパラメータの高度なモデルが大きなResNetモデルを上回ることで、モデル効率性の重要性を示す

高度な事前学習アーキテクチャで連合学習のパフォーマンスが劇的に高まるの面白いよね。一緒に詳しく読んで、どんな可能性が開けるか考えたいな！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-09-20 14:09


- - -

### [SatFed: A Resource-Efficient LEO Satellite-Assisted Heterogeneous Federated Learning Framework](http://arxiv.org/abs/2409.13503)

**SatFed: 資源効率の高い低軌道衛星支援異種連合学習フレームワーク**

Yuxin Zhang, Zheng Lin, Zhe Chen, Zihan Fang, Wenjun Zhu, Xianhao Chen, Jin Zhao, Yue Gao

- 連合学習は地上ネットワークに依存し過ぎ、範囲制限と帯域幅混雑でモデル収束が困難
- 低軌道衛星ネットワークが新たな通信手段を提供するが、帯域幅制限とデバイスの異種性が課題
- SatFedは、重要モデルを優先するキューと、デバイス間のリアルタイム異種関係を捉えるマルチグラフを導入
- 実世界の低軌道衛星ネットワークを用いた実験で、SatFedは最先端の基準と比べ優れた性能とロバスト性を示す

低軌道衛星を活用してるのヤバくない？未来感ハンパないね。SatFedが次世代の通信手段になるかもだし強そう。

**Comment:** 11 pages, 12 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.AI, cs.LG, **投稿日時:** 2024-09-20 13:44


- - -

### [Flotta: a Secure and Flexible Spark-inspired Federated Learning Framework](http://arxiv.org/abs/2409.13473)

**Flotta: セキュアで柔軟なSpark風の連合学習フレームワーク**

Claudio Bonesana, Daniele Malpetti, Sandra Mitrović, Francesca Mangili, Laura Azzimonti

- Flottaは複数の企業が連携する生物医学分野などで、機密データを用いて機械学習モデルを訓練するための連合学習フレームワークである
- Pythonパッケージとして提供されており、Apache Sparkを元に設計され、柔軟性とセキュリティを兼ね備えている
- フレームワークの主要コンポーネントと実用的な事例を説明し、その能力を強調している
- コンソーシアム内のマシンのみを使用して研究を行うことで、セキュアかつ使いやすい環境を提供している

Flottaって、色々な会社が一緒にデータ共有しながらモデルを鍛えるのに役立つんだね！Sparkのエッセンスが加わってるから、絶対に使いやすくて面白そう！

**Comment:** Accepted for publication at FLTA 2024: The 2nd IEEE International   Conference on Federated Learning Technologies and Applications

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-20 13:04


- - -

### [Global Outlier Detection in a Federated Learning Setting with Isolation Forest](http://arxiv.org/abs/2409.13466)

**連合学習環境における孤立森林を用いたグローバル外れ値検出**

Daniele Malpetti, Laura Azzimonti

- 連合学習でクロスサイロシナリオのグローバル外れ値を検出する新しい戦略を提案
- クライアントがマスクされたローカルデータをサーバに送信し、データの秘匿を確保
- サーバはマスクされたデータで外れ値検出を行い、クライアントに結果を返送
- 方法は孤立森林アルゴリズムの中央実行と同等の結果を提供

アブスト読んだけど、これ最先端って感じ！連合学習のプライバシー保障を保ちながら外れ値を取り除くなんて、未来の技術だね！

**Comment:** Accepted for publication at FLTA 2024: The 2nd IEEE International   Conference on Federated Learning Technologies and Applications

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-09-20 12:55


- - -

### [Noise-Robust and Resource-Efficient ADMM-based Federated Learning](http://arxiv.org/abs/2409.13451)

**ノイズ耐性とリソース効率のADMMベースの連合学習**

Ehsan Lari, Reza Arablouei, Vinay Chakravarthi Gogineni, Stefan Werner

- 通信ノイズに強く、通信負荷を軽減する新しい連合学習アルゴリズムを提案
- 重み付け最小二乗法(WLS)回帰を利用し、分散凸最適化問題として定式化
- 累積通信ノイズの影響を回避する新しいローカルモデル更新を導入
- 数値結果は提案アルゴリズムの効果と理論的発見を裏付ける

新しいアルゴリズムでノイズ問題を攻略しながら効率もUPとか、まじ未来感じる！理論でばっちり証明されてるのも安心だね。

**Comment:** 13 pages, 10 figures, Submitted to IEEE Open Journal of Signal   Processing

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, eess.SP, **投稿日時:** 2024-09-20 12:32


- - -

### [Balancing Label Imbalance in Federated Environments Using Only Mixup and Artificially-Labeled Noise](http://arxiv.org/abs/2409.13235)

**フェデレーテッド環境におけるMixupと人工ラベル付きノイズを用いたラベル不均衡の解消**

Kyle Sang, Tahseen Rabbani, Furong Huang

- フェデレーテッド学習でのデータラベルの偏りがモデル性能に悪影響
- 擬似画像を用いたシンプルな拡張戦略でラベル不均衡を緩和
- DP-Instahideを用いて画像エンコーディングの解読可能性を低減
- StyleGANによる人工ラベル付きノイズでラベル分布を均一化した結果、CIFAR-10とMNISTの精度が向上

擬似画像と自然ノイズの組み合わせが面白いね！フェデレーテッド学習の課題をこんなアイディアで解決するなんて、すごく斬新なアプローチだと思う。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-20 05:44


- - -

### [Federated Learning with Label-Masking Distillation](http://arxiv.org/abs/2409.13136)

**ラベルマスキング蒸留を用いた連合学習**

Jianghu Lu, Shikun Li, Kexin Bao, Pengju Wang, Zhenxing Qian, Shiming Ge

- 連合学習はプライバシーを保ちながら、複数のローカルクライアントのデータでモデルを共同学習
- ラベル分布偏りの問題に焦点、クライアント間での異なるユーザー行動によりラベル分布に大きな違い
- FedLMDというラベルマスキング蒸留アプローチを提案、クライアントごとのラベル分布を認識し最適化
- FedLMD-Tfという教師不要の軽量バリアントも提案、計算コストを増やさず従来法を上回る性能

ラベル分布を考慮してクライアントのデータを上手に使い分けるなんて面白い発想だよね！しかも、リソース少ないクライアントへの配慮もあるとか、みんなに優しい工夫だね。

**Comment:** Accepted by ACM MM 2023

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.CV, **投稿日時:** 2024-09-20 00:46


- - -

### [CorBin-FL: A Differentially Private Federated Learning Mechanism using Common Randomness](http://arxiv.org/abs/2409.13133)

**CorBin-FL: 共通ランダム性を利用した差分プライバシー連合学習メカニズム**

Hojat Allah Salehi, Md Jueal Mia, S. Sandeep Pradhan, M. Hadi Amini, Farhad Shirani

- 連合学習は複数のクライアントの協調による分散学習を可能にするが、プライバシー、通信効率、モデル精度のバランスを取るのが課題
- CorBin-FLは相関バイナリ確率量子化を使用し、差分プライバシーを確保しつつ、全体のモデル精度を維持するメカニズム
- この方法は、個々のプライバシーを侵害せずにローカルモデルの更新を相関量子化するために秘密計算技術を使用
- AugCorBin-FLはユーザーレベルおよびサンプルレベルの中央差分プライバシーも達成し、理論的にプライバシーと精度のトレードオフを最適化

連合学習のプライバシー保護がこんなに進化してるなんてビックリ！私たちのデータがより安全に使われる世の中になるのが楽しみだな。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.IT, math.IT, **投稿日時:** 2024-09-20 00:23
