---
title: 連合学習 (2024-08-02 ~ 2024-08-08)
date: 2024-08-02
---

連合学習に関する論文まとめ (2024-08-02 ~ 2024-08-08)


- - -

### [Masked Random Noise for Communication Efficient Federaetd Learning](http://arxiv.org/abs/2408.03220)

**通信効率の高い連合学習のためのマスク付きランダムノイズ**

Shiwei Li, Yingyi Cheng, Haozhao Wang, Xing Tang, Shijie Xu, Weihong Luo, Yuhua Li, Dugang Liu, Xiuqiang He, and Ruixuan Li

- 連合学習はデータプライバシーを効果的に保護するが、通信コストが高くなる場合がある
- 分散クライアントにモデル更新をグローバルモデル相対で最適化させるためにランダムノイズを利用
- FedMRNというフレームワークを提案し、各モデルパラメータに対して1ビットのマスクを学習
- 実験結果から、FedMRNは他のベースラインと比較して優れた収束速度とテスト精度を示した

新しい視点から通信効率を上げるって面白い発想だよね！実験結果も良好みたいだから、実用化が楽しみだな。

**Comment:** Accepted by MM 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-08-06 14:26


- - -

### [FedBAT: Communication-Efficient Federated Learning via Learnable Binarization](http://arxiv.org/abs/2408.03215)

**FedBAT: 学習可能な二値化による通信効率の高い連合学習**

Shiwei Li, Wenchao Xu, Haozhao Wang, Xing Tang, Yining Qi, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li

- 連合学習は大規模データをプライバシーを守りつつ利用できるが、通信の負荷が高い課題がある
- モデル更新を二値化する従来手法は誤差が大きく、学習精度が低下することが多い
- FedBATは局所学習中に直接二値化を行い、誤差を減少させる新しい枠組みを提案
- 実験結果ではFedBATが収束を大幅に速め、従来手法より最大9%精度向上を達成

通信負荷を減らしつつ精度を高める手法を提案しているのがすごいよね！FedBATの未来が楽しみ！

**Comment:** Accepted by ICML 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-08-06 14:19


- - -

### [Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery](http://arxiv.org/abs/2408.03208)

**ロボット手術における視覚特性事前情報を用いた連合学習による手術器具セグメンテーションの個別化**

Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

- 個別化連合学習（PFL）は、複数の臨床サイトがプライバシーを保ちながら協力してモデルを訓練する手法
- 既存のPFLは多頭型自己注意の個別化や手術シーン特有の外観多様性・器具形状類似性を考慮していない
- 提案手法のPFedSISは、GPD、APE、SGEを取り入れ各サイトのSIS性能を向上
- PFedSISは既存手法よりも性能が向上し、Diceで+1.51%、IoUで+2.11%の改善を達成

新しい手法で手術器具のセグメンテーションがもっと正確になりそうでワクワクする！ロボット手術の未来がもっと進化しそうだね。

**Comment:** 9 pages, 3 figures, under review

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.AI, cs.RO, physics.med-ph, **投稿日時:** 2024-08-06 14:06


- - -

### [Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application](http://arxiv.org/abs/2408.02998)

**連合学習アーキテクチャ: 作物収量予測アプリケーションによるパフォーマンス評価**

Anwesha Mukherjee, Rajkumar Buyya

- IoTアプリ向け連合学習を使用し、LSTMネットワークで作物収量を予測
- 集中型連合学習はクライアントとサーバーでモデル更新を集約
- 分散型連合学習はデバイス間でモデル更新を行い、リングまたはメッシュトポロジーを使用
- 集中型と分散型連合学習は97%と97.5%以上の予測精度を達成し、集中型は応答時間を75%短縮

想像してみて、作物の収量予測を連合学習で実現なんて素晴らしい！未来の農業がもっと効率的になるかもね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-06 07:05


- - -

### [Mitigating Malicious Attacks in Federated Learning via Confidence-aware Defense](http://arxiv.org/abs/2408.02813)

**信頼度を活用した防衛による連合学習における悪意ある攻撃の緩和**

Qilei Li, Ahmed M. Abdelmoniem

- 連合学習はプライベートなデータを共有せずにグローバルモデルを協力して訓練する。
- 従来の防衛法は単一の攻撃タイプに焦点を当て、多様なデータ中毒攻撃に対応できない。
- モデル信頼度スコアに基づいてクライアント更新の不確実性を評価し、悪意ある更新を検出・防衛。
- 提案手法は攻撃に対するロバスト性を向上させ、様々なシナリオでモデル精度と安定性を向上。

攻撃への対応がまるでゲームのバフとデバフみたいじゃない？これ、実社会でも多用途に使われそうでワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.CV, cs.DC, **投稿日時:** 2024-08-05 20:27


- - -

### [Fair Resource Allocation For Hierarchical Federated Edge Learning in Space-Air-Ground Integrated Networks via Deep Reinforcement Learning with Hybrid Control](http://arxiv.org/abs/2408.02501)

**階層的連合エッジ学習のための公平なリソース割り当て：宇宙・空中・地上統合ネットワークにおけるハイブリッド制御を用いた深層強化学習によるアプローチ**

Chong Huang, Gaojie Chen, Pei Xiao, Jonathon A. Chambers, Wei Huang

- 宇宙・空中・地上統合ネットワーク（SAGIN）は広範なカバレッジと迅速な展開が可能で、将来の無線通信における重要な研究方向
- 階層的連合学習（HFL）とSAGINを統合し、多層集計機能を提供する新しいフレームワークを提案
- 複数の計算タスクを限られた衛星サービス時間内で公平に処理し、DSACアルゴリズムを用いてリソース割り当てを最適化
- 深層強化学習（DRL）のハイブリッド制御空間の効率性を向上させるため、新しい動的報酬関数を設計

宇宙を含むネットワークなんてSFみたいでワクワクするよね！未来の通信技術が進化して、私たちの生活ももっと便利になりそう。

**Comment:** Accepted for publication in IEEE Journal on Selected Areas in   Communications

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.IT, eess.SP, math.IT, **投稿日時:** 2024-08-05 14:22


- - -

### [Strategic Federated Learning: Application to Smart Meter Data Clustering](http://arxiv.org/abs/2408.02384)

**戦略的連合学習: スマートメーターデータのクラスタリングへの応用**

Hassan Mohamad, Chao Zhang, Samson Lasaulce, Vineeth S Varma, Mérouane Debbah, Mounir Ghogho

- 連合学習(FL)では、複数のクライアントが各自のデータで訓練したモデルを融合センター(FC)と共有
- 従来のFLは、モデル情報(MI)の最終的な利用を無視、提案手法はMIを基にしたFCの意思決定がクライアントの効用を左右
- クライアントはMIを使って効用を最大化するが、場合によっては戦略的ノイズを加えた方が有利
- 具体例として、電力消費スケジューリング問題に適用、クライアントとFCの効用の不一致が示される

戦略的にノイズを加えて効用を上げる話って面白そう！実際の電力データでの検証も興味深いなあ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.GT, **投稿日時:** 2024-08-05 11:16


- - -

### [Model Hijacking Attack in Federated Learning](http://arxiv.org/abs/2408.02131)

**連合学習におけるモデルハイジャック攻撃**

Zheng Li, Siyuan Wu, Ruichuan Chen, Paarijaat Aditya, Istemi Ekin Akkus, Manohar Vanga, Min Zhang, Hao Li, Yang Zhang

- モデルハイジャック攻撃により、MLモデルが元のタスクと異なるタスクを実行
- ハイジャックFLは連合学習における初のグローバルモデルハイジャック攻撃を提案
- 攻撃者はピクセルレベルの摂動を利用し、元のタスクとハイジャックタスクを一致させる
- 実験により、他のベースラインを上回る攻撃性能を実証し、防御方法も議論

モデルが巧妙にハイジャックされるなんて、連合学習の信頼性が問われるよね。防御策がうまく機能するかがこれからの鍵だね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-08-04 20:02


- - -

### [Personalized Federated Learning on Heterogeneous and Long-Tailed Data via Expert Collaborative Learning](http://arxiv.org/abs/2408.02019)

**異質かつロングテールデータに対する専門家協調学習による個別化連合学習**

Fengling Lv, Xinyi Shang, Yang Zhou, Yiqun Zhang, Mengke Li, Yang Lu

- 個別化連合学習（PFL）は各クライアントのデータを公開せずにカスタマイズされたモデルを取得することを目指す
- 現実のデータはしばしばロングテール分布に従い、これはPFLモデルの性能を低下させる要因になる
- クライアントごとの異質なデータ環境も連合学習の古典的な課題であり、その対応策が必要
- 専門家協調学習（ECL）を提案し、複数の専門家が異なるトレーニングサブセットを担うことで少数クラスを含む全クラスを十分に学習

ロングテールデータに対しても効果的に対応できるなんて、めちゃ興味深いね！私たちもこんな技術使ってデータ分析してみたら、びっくりするような新発見ができるかもね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-08-04 13:11


- - -

### [Joint Model Pruning and Resource Allocation for Wireless Time-triggered Federated Learning](http://arxiv.org/abs/2408.01765)

**無線時間発火連合学習のためのモデル剪定とリソース割当の同時最適化**

Xinlu Zhang, Yansha Deng, Toktam Mahmoodi

- 時間発火型連合学習は、ユーザーを固定時間間隔で階層に分ける
- デバイス増加と無線帯域幅の制約により遅延や通信オーバーヘッドが増加
- モデル剪定を適用し、剪定比率と帯域幅割当を最適化して訓練損失を最小化
- シミュレーション実験では、提案手法TT-Pruneが通信コストを40%削減しつつモデル収束を維持

時間発火型の連合学習にモデル剪定を組み合わせるなんて面白そう！これで効率的に学習できるなら、将来のIoTデバイスとかにも応用できそうだね。

**Comment:** Accepted in IEEE Global Communications Conference 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.IT, math.IT, **投稿日時:** 2024-08-03 12:19


- - -

### [TreeCSS: An Efficient Framework for Vertical Federated Learning](http://arxiv.org/abs/2408.01691)

**TreeCSS: 垂直連合学習のための効率的なフレームワーク**

Qinbo Zhang, Xiao Yan, Yukai Ding, Quanqing Xu, Chuang Hu, Xiaokai Zhou, Jiawei Jiang

- 垂直連合学習は、データサンプルの特徴が異なる参加者間で分割されている状況を対象とする
- 主要なステップは共通データサンプルの特定（アライメント）と、これを用いたモデルのトレーニングである
- 提案したTreeCSSは、ツリーベースのMPSIプロトコルとコアセット選択を用いてこの二つのステップを加速
- TreeCSSはバニラVFLと比較して最大2.93倍のトレーニング速度を実現し、同等のモデル精度を達成

データの特徴が異なる参加者同士での学習を効率化するために、ツリーベースの手法を取り入れているって面白いね！未来の垂直連合学習の可能性が広がりそう。

**Comment:** 16 pages, 7 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-08-03 07:11


- - -

### [Fed-RD: Privacy-Preserving Federated Learning for Financial Crime Detection](http://arxiv.org/abs/2408.01609)

**Fed-RD: 金融犯罪検出のためのプライバシー保護連合学習**

Md. Saikat Islam Khan, Aparna Gupta, Oshani Seneviratne, Stacy Patterson

- Fed-RDは、金融取引データセットの垂直および水平に分割されたデータに特化して開発された連合学習アルゴリズムである
- 差分プライバシーと安全なマルチパーティ計算を戦略的に使用し、トレーニングデータのプライバシーを保証する
- トレーニングアルゴリズムのエンドツーエンドのプライバシーに関する理論的分析を提供
- 実験結果は、プライバシーが増加しても高いモデル精度を維持し、ベンチマーク結果を一貫して上回ることを示している

連合学習を使って、今まで以上にプライバシーを守りながら金融犯罪を防止できるなんてすごくない？プライバシーと精度の両立が期待できて未来が楽しみ！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [秘密計算](../../mpc), **カテゴリ:** cs.CE, **投稿日時:** 2024-08-03 00:07


- - -

### [Improving Energy Efficiency in Federated Learning Through the Optimization of Communication Resources Scheduling of Wireless IoT Networks](http://arxiv.org/abs/2408.01286)

**無線IoTネットワークの通信資源スケジューリング最適化による連合学習のエネルギー効率改善**

Renan R. de Oliveira, Kleber V. Cardoso, Antonio Oliveira-Jr

- 連合学習はデータを共有せずにグローバルな機械学習モデルを訓練する技術
- 無線ネットワークでは通信チャネルの信頼性が低く、遅延や誤差がモデル更新の規則性に影響
- この研究は、エネルギーコスト削減のため通信資源をスケジュールする新しいFLアルゴリズムFL-E2WSを提案
- FL-E2WSはエネルギー消費を最大70.12%、モデルの精度を最大10.21%向上させることがシミュレーション結果で示された

この研究、ほんとに面白そう！IoTデバイスのエネルギー問題も解決できるなんてすごいね。ぜひもう少し詳しく知りたいな〜。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.NI, **投稿日時:** 2024-08-02 14:17
