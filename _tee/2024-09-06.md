---
title: TEE (2024-09-06 ~ 2024-09-12)
date: 2024-09-06
---

TEEに関する論文まとめ (2024-09-06 ~ 2024-09-12)


- - -

### [A First Look At Efficient And Secure On-Device LLM Inference Against KV Leakage](http://arxiv.org/abs/2409.04040)

**効率的で安全なデバイス上でのLLM推論におけるKVリークへの対策**

Huan Yang, Deyu Zhang, Yudong Zhao, Yuanchun Li, Yunxin Liu

- デバイス上でのLLM推論はプライバシー保護の点で注目されている
- GPU上でのLLM推論は中間情報であるKVペアをリークする可能性がある
- KV-Shieldを設計し、初期化フェーズと実行時フェーズで重み行列やアテンションベクトルをパーミュテーション
- TEE内で全てのパーミュテーション関連操作を実行し、元のKVペアを守る

KVペアの漏洩防止のためにKV-Shieldがどれだけ効果的に機能するのか楽しみだね。TEEとGPUの役割分担も興味深いし、これからの展開に注目したいところ！



**トピック:** [準同型暗号](../../he), [TEE](../../tee), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-09-06 06:16


- - -

### [Confidential Computing on nVIDIA H100 GPU: A Performance Benchmark Study](http://arxiv.org/abs/2409.03992)

**エヌビディアH100 GPUにおける機密計算：パフォーマンスベンチマーク研究**

Jianwei Zhu, Hang Yin, Shunfan Zhou

- Trusted Execution Environments（TEE）を有効にした際のパフォーマンス影響を評価する研究
- CPU-GPU間のデータ転送によるボトルネックが主な課題である
- GPU内の計算オーバーヘッドは最小限であり、全体のパフォーマンス低下はデータ転送が要因
- ほとんどの通常のLLMクエリではオーバーヘッドは5％未満で、大規模なモデルや長いシーケンスではほぼゼロのオーバーヘッド

データ転送の問題が大きいんだね。でも、パフォーマンス低下が最小限っていうのは安心だし、実際のアプリケーションにも影響少ないかもね。ついにGPUにもTEEが使われる時代ってワクワクするね。



**トピック:** [TEE](../../tee), **カテゴリ:** cs.DC, cs.AI, cs.PF, **投稿日時:** 2024-09-06 02:44
