---
title: 連合学習 (2024-11-22 ~ 2024-11-28)
date: 2024-11-22
---

連合学習に関する論文まとめ (2024-11-22 ~ 2024-11-28)


- - -

### [Distributed, communication-efficient, and differentially private estimation of KL divergence](http://arxiv.org/abs/2411.16478)

**分散型で通信効率が高く差分プライバシーを用いたKLダイバージェンス推定**

Mary Scott, Sayan Biswas, Graham Cormode, Carsten Maple

- 分散型データの管理時に分布変化の測定が重要だが、共有が難しい場合がある
- 差分プライバシーを用いて、連合学習内でデータのKLダイバージェンスを推定する新手法を提案
- 提案手法の理論的性質を分析し、パラメータ設定で精度向上を追求
- 異なる前提や信頼レベルに対応する現実的なタスクへの適用を確認

提案された手法が元のアルゴリズムと同じくらい精度を持つなんて、プライバシーを保ちながらデータの変化を知れるのがすごくクール！これが実用化されたら、世の中のデータ管理のスタイルってもっと安心して進化しちゃうかもね。

**Comment:** 28 pages, 5 figures

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.DB, **投稿日時:** 2024-11-25 15:20


- - -

### [Distributed Online Optimization with Stochastic Agent Availability](http://arxiv.org/abs/2411.16477)

**確率的エージェントの可用性を考慮した分散型オンライン最適化**

Juliette Achddou, Nicolò Cesa-Bianchi, Hao Qiu

- 連合学習において、クライアントが常に利用可能でないことに着目
- エージェントが活性化する確率$p$を考慮し、通信が可能な条件を明確化
- 分散FTRLアルゴリズムを紹介し、そのネットワーク後悔を分析
- 理論的結果は合成データセットを用いた実験で支持される

クライアントがランダムに活性化する設定を考えるなんて新鮮さがあって面白い！安定した最適化がどれだけ実現できるか、気になるね。まるでみんなの予定が合うときにだけ活動する演劇部みたい！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-25 15:20


- - -

### [TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment](http://arxiv.org/abs/2411.16442)

**小さな整数ベースの直接フィードバック整列を用いた連合学習アルゴリズム「TIFeD」**

Luca Colombo, Alessandro Falcetta, Manuel Roveri

- 小型デバイスでの学習が次の課題で、現状は外部クラウドでの学習が主流。
- 連合学習は有望だが、既存手法は必要リソースが多く小型デバイスには不適。
- TIFeDは整数演算のみで実装、小型デバイスに最適化された新しい手法。
- フルネットワークと単一層実装があり、学習手順の新たな分散方法を提案。

小さなデバイスでの学習がこんなに進化してるんだね！TIFeDの手法を駆使して、未来のガジェットはもっとスマートになるかも。小型デバイスがどんどん賢くなったら、日常がさらに便利になりそうでワクワクするな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, I.2.6, **投稿日時:** 2024-11-25 14:44


- - -

### [Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence](http://arxiv.org/abs/2411.16380)

**ジェネラリスト超音波人工知能のためのプライバシー保護型連合基盤モデル**

Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li

- 超音波診断は非侵襲的だが、医師依存と画像品質に課題がある
- AIは診断支援を強化しうるが、データプライバシーの懸念とタスク限定性が問題
- UltraFedFMは16医療機関で連合学習を用いて訓練し、汎用的かつ高精度に診断可能
- UltraFedFMは中級技師の精度を超え、専門家の精度に匹敵するため、大きな臨床応用の可能性

超音波でのプライバシー保護AIってすごくない！？データを守りながら精度も高いなんて、未来の医療を感じちゃう。技術の進歩でお医者さんも楽になるし、患者さんも安心できるね！



**トピック:** [連合学習](../../fl), **カテゴリ:** eess.IV, cs.AI, cs.CV, **投稿日時:** 2024-11-25 13:40


- - -

### [Understanding Generalization of Federated Learning: the Trade-off between Model Stability and Optimization](http://arxiv.org/abs/2411.16303)

**連合学習の一般化を理解する: モデルの安定性と最適化のトレードオフ**

Dun Zeng, Zheshun Wu, Shiyu Liu, Yu Pan, Xiaoying Tang, Zenglin Xu

- 連合学習はデータの異質性が原因で、各クライアント間で局所的な最適解が一致しない問題を抱える。
- 現行の研究は主に収束分析やアルゴリズムの安定性を用いて問題を説明しているが、これらでは十分に応えられていない。
- この研究では連合最適化における一般化ダイナミクス分析フレームワークを初めて導入し、安定性と最適化のトレードオフを明らかにする。
- 大きな局所ステップや高速収束が安定性を高め、優れた一般化性能をもたらすことが分かった。

新しいフレームワークで連合学習の安定性と最適化のトレードオフを解明するのすごくない！？これを基にした未来のアルゴリズムがどんなふうに進化していくのか、ワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, stat.ML, **投稿日時:** 2024-11-25 11:43


- - -

### [BadSFL: Backdoor Attack against Scaffold Federated Learning](http://arxiv.org/abs/2411.16167)

**BadSFL: スキャフォールド連合学習へのバックドア攻撃**

Xingshuo Han, Xiang Lan, Haozhao Wang, Shengmin Xu, Shen Ren, Jason Zeng, Ming Wu, Michael Heinrich, Tianwei Zhang

- 連合学習はデータプライバシーを保持しつつ分散クライアントでモデルを訓練するが、バックドア攻撃の脆弱性がある
- 現実の連合学習では非独立同分布データが用いられるが、既存のバックドア攻撃手法はその効果と持続性に限界がある
- 新たな手法として、スキャフォールド手法を用いた非独立同分布設定におけるバックドア攻撃法「\name」を提案
- \nameはGANを使用し、攻撃と合法データの両方で高い精度を持ち、60回以上のラウンドで持続し既存手法の3倍の効果

この研究、連合学習の脆弱性をカッコよく攻めてて面白そう！GANを使ってるから未来がどう変わるのかワクワクするよね。スキャフォールドのやり方も新しいチャレンジって感じで好印象！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-25 07:46


- - -

### [An Empirical Study of Vulnerability Detection using Federated Learning](http://arxiv.org/abs/2411.16099)

**連合学習を用いた脆弱性検出の実証研究**

Peiheng Zhou, Ming Hu, Xingrun Quan, Yawen Peng, Xiaofei Xie, Yanxin Yang, Chengwei Liu, Yueming Wu, Mingsong Chen

- 深層学習の脆弱性検出は、訓練データ不足で性能が制限されている
- 連合学習は、データを共有せずにモデルを訓練することでデータサイロ問題を解決する
- VulFLを提案し、FLの脆弱性検出における能力を異なるデータ状況下で研究
- 連合学習による脆弱性検出は、独立訓練と比べ特に異種データでの性能向上を示した

連合学習でAIモデルの脆弱性検出が改善されるって、すごいね！これからもっとデータを共有しなくても安全に活用できる方法が広がるといいなってワクワクしちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.SE, cs.AI, cs.CR, **投稿日時:** 2024-11-25 05:21


- - -

### [eFedLLM: Efficient LLM Inference Based on Federated Learning](http://arxiv.org/abs/2411.16003)

**eFedLLM: 連合学習に基づく効率的なLLM推論**

Shengwen Ding, Chenhui Hu

- 大規模言語モデル(LLM)の大規模データとパラメータが普及を妨げる。
- トランスフォーマーベースの連合学習で計算とメモリの負担を参加者間で分散。
- インセンティブ機構で良い貢献を報酬し、悪意ある活動を排除。
- メモリ階層戦略と特異値分解(SVD)でリソースの最適化を図る。

みんなで協力してLLMを使えるようにするのって素敵だよね！これで色んな人が最先端のAI技術にアクセスできちゃうんだね。もっと未来が楽しみになってきた！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-11-24 22:50


- - -

### [FedQP: Towards Accurate Federated Learning using Quadratic Programming Guided Mutation](http://arxiv.org/abs/2411.15847)

**FedQP: 二次計画法による変異を用いた正確な連合学習の実現**

Jiawen Weng, Zeke Xia, Ran Li, Ming Hu, Mingsong Chen

- 連合学習はプライバシーを守るが、データ非均質性が原因で推論性能が低下する。
- 非均質データにより異なるローカルモデルの最適化方向が異なり、伝統的手法では難航する。
- FedQPは変異方向を二次計画法で制御することで、モデルを汎用的に最適化する。
- 実験結果から、FedQPは異なる非均質データシナリオで推論精度を向上させる。

新しい方法で連合学習の課題を解決しようなんて面白いと思わない？異なるデータ分布に対応するって、画期的な進歩かもしれないよね！この論文、ぜひ深掘りしてみたいな！

**Comment:** SEKE 2024, 6 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-24 14:00


- - -

### [Modality Alignment Meets Federated Broadcasting](http://arxiv.org/abs/2411.15837)

**モダリティー調整が連合放送に出会う**

Yuting Ma, Shengeng Tang, Xiaohua Xu, Lechao Cheng

- 連合学習は分散したエッジデバイスでモデルを訓練しながら、データプライバシーを保護する手法である
- 異質なデータの下では、データ分布の変動がモデルの収束を妨げ、計算コストが増大
- 本研究は、サーバーにテキストエンコーダー、ローカルデバイスに画像エンコーダーを配置する新たな枠組みを提案
- 極端に異質な環境でも、一般化とロバスト性を維持できることを大規模実験で実証

連合学習ってデータを集めずに学習するのがすごいよね！モダリティの工夫で効率的にできるのが素敵。どんな実験がされたのか、もっと知りたいな〜。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-11-24 13:30


- - -

### [Tackling Data Heterogeneity in Federated Time Series Forecasting](http://arxiv.org/abs/2411.15716)

**連合時系列予測におけるデータの異質性の克服**

Wei Yuan, Guanhua Ye, Xiangyu Zhao, Quoc Viet Hung Nguyen, Yang Cao, Hongzhi Yin

- 時系列予測はエネルギー消費や病気の伝播など重要な役割を果たすが、中央集約型学習に依存している
- 個々のデバイスから得られるデータは異質であり、そのまま連合学習を適用すると最適でない結果に
- Fed-TRENDという新たなフレームワークを提案し、合成データによって異質性問題を解決
- 複数のデータセットで評価し、予測性能の向上と有効性を示した

Fed-TRENDって合成データで時系列予測の精度が上がるみたい！これってどんな未来に広がっていくのかな？連合学習を使った技術でプライバシーも守られていくってなんか安心だね！



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.CR, cs.IR, **投稿日時:** 2024-11-24 04:56


- - -

### [Federated PCA and Estimation for Spiked Covariance Matrices: Optimal Rates and Efficient Algorithm](http://arxiv.org/abs/2411.15660)

**連合PCAとスパイク共分散行列の推定：最適な速度と効率的アルゴリズム**

Jingyang Li, T. Tony Cai, Dong Xia, Anru R. Zhang

- 連合学習によるスパイク共分散行列のPCAと推定を差分プライバシーの制約下で研究
- 中央サーバーでの最適速度はクライアントの最小極値速度の調和平均で一致推定を保証
- ローカル推定が全て一貫していなくても十分なクライアントがあれば一貫性は維持される
- 差分プライバシーを保ちつつほぼ最適な速度のアルゴリズムを提案し、その性能を評価

連合学習を使ったスパイク共分散行列って面白そう！差分プライバシーも守られているから安心。この研究から、もっと安全にデータを使った推論ができる未来が期待できそう！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** math.ST, cs.IT, math.IT, stat.ML, stat.TH, **投稿日時:** 2024-11-23 21:57


- - -

### [Energy-efficient Federated Learning with Dynamic Model Size Allocation](http://arxiv.org/abs/2411.15481)

**エネルギー効率の良い連合学習の動的モデルサイズ割り当て**

M S Chaitanya Kumar, Sai Satya Narayana J, Yunkai Bao, Xin Wang, Steve Drew

- 連合学習（FL）はデータ共有なしに分散モデル訓練を行うが、エネルギー消費が高いという課題がある
- CAMAというカーボンアウェアなFLフレームワークを提案し、再生可能な余剰エネルギーと余剰計算能力を活用
- モデルサイズを動的に適応させる戦略を使用し、エネルギーと計算資源の利用可能性に応じて最適化
- 実証的評価により、迅速な収束と多くのクライアント処理における公平な参加が実現できることを示した

エネルギー消費を減らしつつ、連合学習を効率よく行うCAMAってすごく面白そう！再生可能エネルギーで環境に優しい学習ができるって、私たちの未来にもすごく役立ちそうだよね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-11-23 07:29


- - -

### [Partial Knowledge Distillation for Alleviating the Inherent Inter-Class Discrepancy in Federated Learning](http://arxiv.org/abs/2411.15403)

**連合学習におけるクラス間の固有の不一致を軽減するための部分的知識蒸留**

Xiaoyu Gan, Xizi Chen, Jingyang Zhu, Xiaomeng Wang, Jingbo Jiang, Chi-Ying Tsui

- クラスバランスの学習でも弱いクラスが存在し、データに固有のクラス間精度の不一致がある
- FashionMNISTとCIFAR-10での連合学習におけるクラス間精度の不一致は最大36.9%
- クラス固有の部分的知識蒸留法を提案し、弱いクラスに対するモデルの分類精度を向上
- 特定の誤分類が起こった際に知識を転送し、弱いクラスの正確性を10.7%改善

弱いクラスの問題に注目して知識蒸留で改善するなんて、なんだか面白い！連合学習の限界を突破する新しいアプローチが広がりそうでワクワクするね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-11-23 01:16


- - -

### [LoRA-FAIR: Federated LoRA Fine-Tuning with Aggregation and Initialization Refinement](http://arxiv.org/abs/2411.14961)

**LoRA-FAIR: 連合LoRAファインチューニングにおける集約と初期化の改良**

Jieming Bian, Lei Wang, Letian Zhang, Jie Xu

- 大規模モデルのパラメータ効率良いファインチューニング手法LoRAを連合学習で採用
- LoRAと連合学習を組み合わせた際のサーバー集約バイアスとクライアント初期化ドリフトの課題
- LoRA-FAIRはサーバー上の修正項を導入し、課題を同時解決して効率性と精度を向上
- ViTやMLP-MixerモデルでLoRA-FAIRが連合学習環境において一貫した性能向上を実証

LoRAのパラメータマトリックスをうまく活用したおかげで、新しい技術の展開が楽しみだね！連合学習と組み合わせることで隠れた課題を見つけて解決するなんて、やっぱり賢くて面白いアプローチだと思うな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, **投稿日時:** 2024-11-22 14:19


- - -

### [Geminio: Language-Guided Gradient Inversion Attacks in Federated Learning](http://arxiv.org/abs/2411.14937)

**Geminio: 連合学習における言語誘導型勾配逆問題攻撃**

Junjie Shan, Ziqi Zhao, Jialin Lu, Rui Zhang, Siu Ming Yiu, Ka-Ho Chow

- 視覚と言語を結ぶ基盤モデルが連合学習での勾配逆問題攻撃を強化
- Geminioは目的のデータを自然言語で指定し、その再構成を優先化する攻撃方法
- 学習済み視覚言語モデルを利用し、攻撃者のクエリに合ったサンプルの勾配だけを保持
- 複雑なデータセット下で高成功率を示し、既存の防御に対しても強い

攻撃者が言葉で指定したデータをターゲットにできるなんて、ちょっと怖いけど面白いね！将来的に、プライバシーを守る新しい技術ももっと進むといいなって思う。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-11-22 13:49


- - -

### [FedMLLM: Federated Fine-tuning MLLM on Multimodal Heterogeneity Data](http://arxiv.org/abs/2411.14717)

**FedMLLM: 多モード異種データにおけるMLLMの連合ファインチューニング**

Binqian Xu, Xiangbo Shu, Haiyang Mei, Guosen Xie, Basura Fernando, Mike Zheng Shou, Jinhui Tang

- 多モード大規模言語モデル (MLLMs) は、プライバシーを考慮しつつ連合学習で改良
- 現在の研究は初期段階であり、現実の多モード異種環境に対応する必要あり
- 本研究は多モード異種環境での連合ファインチューニング評価ベンチマークを提案
- 提案手法は様々なモデル異種性の課題を克服し性能向上を実現

連合学習と多モード処理、それに多様なデータタイプを組み合わせてるのが面白いね。プライバシーが保護されつつ多様な情報が扱えるなんて、今後の技術進歩がワクワクしちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, cs.CV, **投稿日時:** 2024-11-22 04:09
