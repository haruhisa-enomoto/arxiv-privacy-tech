---
title: 差分プライバシー (2024-09-13 ~ 2024-09-19)
date: 2024-09-13
---

差分プライバシーに関する論文まとめ (2024-09-13 ~ 2024-09-19)


- - -

### [Privacy-Preserving Student Learning with Differentially Private Data-Free Distillation](http://arxiv.org/abs/2409.12384)

**差分プライバシーを用いたデータフリー蒸留によるプライバシー保護型学生学習**

Bochao Liu, Jianghu Lu, Pengju Wang, Junjie Zhang, Dan Zeng, Zhenxing Qian, Shiming Ge

- 大規模な注釈付きデータから知識を抽出することで高い推論精度を達成する一方で、データプライバシー漏洩のリスクが存在する
- プライベートデータに基づいてよく訓練された教師モデルの能力を模倣する学生モデルを差分プライバシーとデータフリー蒸留を用いて訓練するアプローチを提案
- データフリーでの生成器訓練により、プライバシーを露出せずに合成データを生成し、教師モデルでプライベートなラベルを付与
- ラベル情報を保護するために選択的ランダム応答と呼ばれるラベル差分プライバシーアルゴリズムを提案

データプライバシーとラベルプライバシーを統一的に保護するフレームワークなんて、めちゃ賢いね！私たちが学んでいるAI倫理の授業にも役立ちそう。

**Comment:** Published by IEEE MMSP 2022

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, cs.CV, **投稿日時:** 2024-09-19 01:00


- - -

### [What to Consider When Considering Differential Privacy for Policy](http://arxiv.org/abs/2409.11680)

**プライバシーポリシー策定時に考慮すべき差分プライバシーに関する要点**

Priyanka Nanayakkara, Jessica Hullman

- 差分プライバシー（DP）はデータ公開時に広く適用できる数学的プライバシー定義
- DPは多様なプライバシー関連法規制への適合手段として認識される
- 理論から実践に移す際に生じる緊張から、DPの適用の適切さを判断するのが難しい
- プライバシー懸念に対する政策策定を支援するための3つのカテゴリーの課題と関連する質問を特定

差分プライバシーを理論から実践に移すのって、結構チャレンジングなんだね。それが政策に役立つように、具体的な質問も含めて整理されてるところが素敵だな！

**Comment:** This paper is accepted for publication in Policy Insights from the   Behavioral and Brain Sciences (2024)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CY, cs.CR, **投稿日時:** 2024-09-18 03:41


- - -

### [GReDP: A More Robust Approach for Differential Privacy Training with Gradient-Preserving Noise Reduction](http://arxiv.org/abs/2409.11663)

**GReDP: 勾配保持ノイズ低減を用いたより堅牢な差分プライバシートレーニング手法**

Haodi Wang, Tangyu Jiang, Yu Guo, Xiaohua Jia, Chengjun Cai

- 深層学習のトレーニング過程とアルゴリズム保護がプライバシー保護において重要
- 従来の差分プライバシー手法は高ノイズスケールや勾配情報の損失が課題
- GReDPは周波数領域で勾配を計算しノイズレベルを低減、元の勾配情報を保持
- GReDPは実験的に全モデルとトレーニング設定で従来手法より一貫して優れている

この新しいGReDP、かなりすごいかも！ ノイズが半分でプライバシー守れるなんて、未来のAIトレーニングがもっと安心できそうだね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-09-18 03:01


- - -

### [The Sample Complexity of Smooth Boosting and the Tightness of the Hardcore Theorem](http://arxiv.org/abs/2409.11597)

**スムースブースティングのサンプル複雑性とハードコア定理の厳密性**

Guy Blanc, Alexandre Hayderi, Caleb Koch, Li-Yang Tan

- スムースブースターは、差分プライバシーや量子学習理論に応用される技術である
- 弱学習が$m$サンプルで可能なクラスを示し、強学習には$\tilde{\Omega}(1/\gamma^2)\cdot m$サンプルが必要
- これは既存のスムースブースターのオーバーヘッドと一致し、分配独立ブースティングとの初の分離を提供
- ハードコア定理の既知の証明はスムースブースティングの枠組みで理解可能、サイズ損失が不可避であることを証明

サンプル数の話とかすごく複雑そうだけど、スムースブースティングの分野で初の発見ってすごいことだよね！ハードコア定理にも関係してるから、幅広い応用が期待できそう！

**Comment:** 46 pages, FOCS 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CC, cs.DS, cs.LG, stat.ML, **投稿日時:** 2024-09-17 23:09


- - -

### [Benchmarking Secure Sampling Protocols for Differential Privacy](http://arxiv.org/abs/2409.10667)

**差分プライバシーのための安全なサンプリングプロトコルのベンチマーク**

Yucheng Fu, Tianhao Wang

- 差分プライバシーの中央モデルとローカルモデルについて述べる
- 多者間計算 (MPC) を用いた分散モデル提案、高い有用性とプライバシーの両立
- ノイズの効率的サンプリングが課題、多様なセキュリティ仮定と理論分析
- サンプリングプロトコルの包括的評価とパフォーマンス比較を実施

ふむふむ、分散モデルでのプライバシー守りつつ効率も求めるのとか、めちゃ挑戦的！実験データが参考にできたら色んな応用が期待できるね！

**Comment:** This is the full version (18 pages) of the paper Benchmarking Secure   Sampling Protocols for Differential Privacy published at CCS'2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-09-16 19:04


- - -

### [Nebula: Efficient, Private and Accurate Histogram Estimation](http://arxiv.org/abs/2409.09676)

**Nebula: 効率的でプライベートかつ正確なヒストグラム推定**

Ali Shahin Shamsabadi, Peter Snyder, Ralph Giles, Aurélien Bellet, Hamed Haddadi

- Nebulaは、同時にプライバシー漏洩の厳格な上限を達成
- 現実的な信頼条件下でのクライアントプライバシーを保証
- 多人数計算や信頼できるハードウェアを避けながら、標準的なローカル差分プライバシーシステムよりも大幅に良い有用性を実現
- アメリカ合衆国の国勢調査データセットで88%以上の有用性向上を示し、マルチ次元データの送信も可能

Nebula、なんかすごくユニークで面白そう！特に信頼できないサーバーでも高性能を実現できるのが未来のプライバシー技術に感じるよ！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-09-15 09:55


- - -

### [A Statistical Viewpoint on Differential Privacy: Hypothesis Testing, Representation and Blackwell's Theorem](http://arxiv.org/abs/2409.09558)

**差分プライバシーの統計的視点：仮説検定、表現方法、そしてブラックウェルの定理**

Weijie J. Su

- 差分プライバシーは、プライバシー保護のあるデータ解析のための形式的なプライバシーであり、幅広い分野で採用されている
- 差分プライバシーを仮説検定の観点から捉えることで、その定義が統計的手法に基づくことを示す
- $f$-差分プライバシーを定義し、既存の差分プライバシーの定義を拡張する表現定理を提示
- この手法を用いたプライバシー境界の分析が、プライベートディープラーニングや合成データにおいて有益であることを実証

仮説検定とプライバシーが絡んでくるのが興味深いね。これで差分プライバシーがもっと理解しやすくなるといいなって思う！

**Comment:** To appear in Annual Review of Statistics and Its Application

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, math.ST, stat.ML, stat.TH, **投稿日時:** 2024-09-14 23:47


- - -

### [Ensuring System-Level Protection against Eavesdropping Adversaries in Distributed Dynamical Systems](http://arxiv.org/abs/2409.09539)

**分散動的システムにおける盗聴攻撃者に対するシステムレベルの保護の確保**

Dipankar Maity, Van Sy Mai

- 分散動的システムの状態を盗聴攻撃者から守る方法を提案
- 現行の分散アルゴリズムは、攻撃者に最終状態が推測されやすい脆弱性がある
- 通信するのはエージェントの状態ではなくイノベーション信号にすることで基本的な保護が実現可能
- 既存の研究が暗号化や差分プライバシー技術を追加するのに対し、新たに根本的な保護方針を紹介

技術的な工夫でこんなに違うんだね！新しいアプローチでより安全なシステムが作れるかも、すごく興味深い！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** eess.SY, cs.SY, **投稿日時:** 2024-09-14 21:40


- - -

### [An Efficient Privacy-aware Split Learning Framework for Satellite Communications](http://arxiv.org/abs/2409.08538)

**衛星通信のための効率的なプライバシー重視スプリットラーニングフレームワーク**

Jianfei Sun, Cong Wu, Shahid Mumtaz, Junyi Tao, Mingsheng Cao, Mei Wang, Valerio Frascolla

- 衛星ネットワークの伝統的な機械学習アプローチは、帯域幅や計算資源の制約に直面している
- DTIPという新しいフレームワークを提案し、差分プライバシーとグラフ・モデルのプルーニングを組み合わせた
- DTIPは生データに差分プライバシーを適用し、GNNsをプルーニングすることでモデルサイズと通信負荷を最適化
- Amazon2MとArXivのデータセットで精度を維持しつつ、計算効率とプライバシー保護を向上

新しいプライバシー技術で衛星通信がここまで進化するなんてすごい！これでさらに効率的な宇宙ネットワークが実現できるといいな。

**Comment:** 11 pages

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-09-13 04:59


- - -

### [Risks When Sharing LoRA Fine-Tuned Diffusion Model Weights](http://arxiv.org/abs/2409.08482)

**LoRA微調整拡散モデルの重みを共有する際のリスク**

Dixi Yao

- 生成モデルの普及により、個人の顔やアイテムを自然言語で新しいコンテキストとして生成可能
- Low Rank Adaptation（LoRA）は、メモリと計算資源を節約しながら微調整する一般的な手法
- 微調整に用いたプライベート画像が重み共有時に漏洩するリスクを検証
- モデル重みを入力としプライベート画像を再構成する変分オートエンコーダを設計し、既存の防御方法が無効であると示す

微調整中のプライベート画像が、重みの共有で再現できちゃうのは衝撃的！従来の手法で守れないなら、新しい防御策が早く必要だね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.CV, **投稿日時:** 2024-09-13 02:13
