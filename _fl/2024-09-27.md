---
title: 連合学習 (2024-09-27 ~ 2024-10-03)
date: 2024-09-27
---

連合学習に関する論文まとめ (2024-09-27 ~ 2024-10-03)


- - -

### [A Novel Framework of Horizontal-Vertical Hybrid Federated Learning for EdgeIoT](http://arxiv.org/abs/2410.01644)

**エッジIoTのための水平・垂直ハイブリッド連合学習の新しい枠組み**

Kai Li, Yilei Liang, Xin Yuan, Wei Ni, Jon Crowcroft, Chau Yuen, Ozgur B. Akan

- 新しいHoVeFLフレームワークがモバイルエッジIoT用に提案されている
- デバイスごとに同じデータ特徴を分析するもサンプルは異なる
- HoVeFLはローカルおよびグローバルモデルの訓練で全体の損失を最小化
- データセット評価でホリゾンタルデバイスが多い場合に性能向上

エッジIoTでのデバイス協調って面白そう！新しい視点で連合学習を進化させてる感じがするね。たくさんのデバイスが一緒に学ぶ未来が楽しみだな～。

**Comment:** 5 pages, 3 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, eess.SP, **投稿日時:** 2024-10-02 15:13


- - -

### [Personalized Federated Learning on Flowing Data Heterogeneity under Restricted Storage](http://arxiv.org/abs/2410.01502)

**制限されたストレージ下でデータの流動性を考慮した個別化連合学習**

Sixing Tan, Xianmin Liu

- データ異質性がFLでのクライアント要件を不一致にし、これに対応するための個別化FL（pFL）が注目されている
- 既存のpFLはデータ分布の変動を考慮せず、実際の異質データシナリオでの分布変動がモデル性能に影響を与える
- データが流れるようにクライアントを通過する状況に着目し、カテゴリ分離の考えに基づくデータ分布再構築とジェネレーターを設計
- 提案したpFedGRPフレームワークは、8つのベースライン手法と比較して優れた性能を示した

クライアントごとに流れるデータを考慮するって、FLに新しいアプローチだね。制限されたストレージ下でも効率的に学習できる工夫が詰まってて、どんどん実用的になりそう！🎵



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-10-02 12:53


- - -

### [Selective Aggregation for Low-Rank Adaptation in Federated Learning](http://arxiv.org/abs/2410.01463)

**連合学習における低ランク適応のための選択的集約**

Pengxin Guo, Shuang Zeng, Yanran Wang, Huijie Fan, Feifei Wang, Liangqiong Qu

- 連合学習でLoRAを用いた場合、A行列が一般知識、B行列がクライアント固有の知識を学習する
- FedSA-LoRAを提案、A行列のみがサーバー側で集約される仕組みを採用
- LoRAの他の変種でのAとBの関係性も解析、FedSA-rsLoRAとFedSA-VeRAに拡張
- 自然言語理解と生成タスクでの実験により提案手法の有効性を実証

この研究って、連合学習にLoRAをどう取り入れていくのかの大きな指針を作る感じだよね！クライアント固有の情報を保持しつつ、全体の知識も共有できるなんて、スマートだなーって思った！次のLoRAのバリエーションも楽しみだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-02 12:14


- - -

### [On the Convergence of FedProx with Extrapolation and Inexact Prox](http://arxiv.org/abs/2410.01410)

**FedProxの収束性に関する研究: 外挿と不正確なProxについて**

Hanmin Li, Peter Richtárik

- FedProxにサーバー側の外挿を取り入れたFedExProxを提案
- 正確なプロクシマル演算は現実的に厳しいが、その仮定を除外した研究
- 不正確さは解の近傍への収束をもたらし、適切な制御で悪影響を軽減
- 局所的最適化により各クライアントの計算複雑性の分析

FedExProxって新しいアプローチなんだね！理論だけじゃなくて、実際にどうなのかも実験してるところがいい感じ～。早くデータと友達になれそうな気がする！

**Comment:** 36 pages, 6 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** math.OC, cs.AI, 90C25, **投稿日時:** 2024-10-02 10:42


- - -

### [Overpredictive Signal Analytics in Federated Learning: Algorithms and Analysis](http://arxiv.org/abs/2410.01399)

**連合学習における過剰予測信号分析：アルゴリズムと分析**

Vijay Anavangot

- エッジ信号処理は連合学習における分散学習と推論を支援する
- IoTデバイスはデータセンターと協力し、グローバルな信号モデルを学習可能
- プライバシーと通信制約があるため、従来の生信号ではなく近似信号を使用
- 凸最適化を用いた効率的なアルゴリズムで、通信コストや誤差のトレードオフを解析

IoTデバイスが協力する未来の話って感じでワクワクするね！分散型信号分析がもっと進化すると、私たちの日常生活も便利になる予感！エネルギー消費のデータで実験してるのも、実用的でいいね～！



**トピック:** [連合学習](../../fl), **カテゴリ:** eess.SP, cs.LG, stat.ML, **投稿日時:** 2024-10-02 10:21


- - -

### [FLAME: Adaptive and Reactive Concept Drift Mitigation for Federated Learning Deployments](http://arxiv.org/abs/2410.01386)

**FLAME: 連合学習展開のための適応的かつ反応的な概念的変化軽減**

Ioannis Mavromatis, Stefano De Feo, Aftab Khan

- FLAMEは、IoT環境における概念ドリフトを検出し軽減する新たなソリューション
- 実世界のFLパイプラインを考慮しつつ、モデル性能と精度を維持しつつ帯域幅とプライバシーの制約にも対応
- 計算負荷と通信のオーバーヘッドを大幅に削減するためにさまざまな機能と拡張を導入
- 既存の軽量な軽減方法と比較して、大規模なIoT展開で高いF1スコアを維持し、リソース利用を削減する性能を発揮

FLAMEって名前がもうかっこいいし、実世界のIoT環境での役立ちそう！通信と計算の負荷を減らしつつプライバシーも守るなんて、これからの時代にぴったりな技術だよね〜。

**Comment:** Accepted for Publication at EMERGE Workshop - EWSN 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-02 09:55


- - -

### [ParallelSFL: A Novel Split Federated Learning Framework Tackling Heterogeneity Issues](http://arxiv.org/abs/2410.01256)

**ParallelSFL: 異種性問題に取り組む新しい分割連合学習フレームワーク**

Yunming Liao, Yang Xu, Hongli Xu, Zhiwei Yao, Liusheng Huang, Chunming Qiao

- スマホなどによるデータ収集は連合学習の重要な情報源である
- ParallelsFLはモデルを底部と頂部に分割し効率的に学習
- クラスタリング戦略でモデル精度と学習効率向上
- 実験で通信量21%削減、学習速度1.36倍、精度5%向上を実証

この方法ってさ、本当に色々な場面で活用できそうだよね！通信量を減らせるし、効率的で効果的な学習を実現できるっていうのがすっごく魅力的だと思うな！

**Comment:** arXiv admin note: text overlap with arXiv:2311.13348

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-10-02 06:03


- - -

### [Debiasing Federated Learning with Correlated Client Participation](http://arxiv.org/abs/2410.01209)

**相関クライアント参加による連合学習の偏り解消**

Zhenyu Sun, Ziyang Zhang, Zheng Xu, Gauri Joshi, Pranay Sharma, Ermin Wei

- 多くのモバイルクライアントがいる連合学習では、少数のクライアントのみが毎回参加する
- 既存のFedAvgの分析は独立サンプルを仮定するが、実際の状況と一致しない
- クライアント参加をマルコフ連鎖でモデル化し、最低参加間隔を考慮した理論を構築
- 提案手法は最小間隔が増加することで、バイアスを減少させることを理論的・実証的に示す

クライアント参加がどう影響するかをマルコフ連鎖で見るのが新しいね。そして、最低間隔を設けることでバイアスが減るなんて意外！将来の実用化が楽しみ～。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-10-02 03:30


- - -

### [FedPT: Federated Proxy-Tuning of Large Language Models on Resource-Constrained Edge Devices](http://arxiv.org/abs/2410.00362)

**FedPT: 資源制約のあるエッジデバイスでの大規模言語モデルの連合プロキシ調整**

Zhidong Gao, Yu Zhang, Zhenxiao Zhang, Yanmin Gong, Yuanxiong Guo

- 大規模言語モデルの微調整はデータ収集が必要でプライバシー問題が発生する
- 連合学習でデータを共有せずに共同モデル訓練が可能になる
- FedPTは出力予測のみを利用し大規模言語モデルをプロキシ調整する新手法を提案
- FedPTは計算や通信の負担を大幅に削減しながら競合性能を実現する

FedPTってすごく新しいアプローチじゃない？資源が限られているデバイスでも大規模モデルを使えるってめっちゃ便利だよね！プライバシーも守りながら効率的っていうのが最高だと思うな。

**Comment:** 29 pages, 19 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.AI, **投稿日時:** 2024-10-01 03:20


- - -

### [Quantized and Asynchronous Federated Learning](http://arxiv.org/abs/2410.00242)

**量子化および非同期型連合学習**

Tomas Ortega, Hamid Jafarkhani

- 非同期型連合学習は同期型に比べて速く拡張性が高いが、量子化を考慮していない。
- 通信ボトルネックを解消するための量子化非同期型連合学習(QAFeL)を提案。
- QAFeLは隠れ状態量子化とバッファーを用いて、スケーラビリティとセキュアな集約を実現。
- 階乗誤差の影響は高次誤差項に限定され、非凸目的の勾配降下法で最適な収束率を達成。

未来の学び方が変わりそう！非同期と量子化の最強コンボで楽しくて自由な学びが可能になるかもね！QAFeLって難しそうだけど、学びの場をもっと広げてくれそうでワクワクする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, eess.SP, math.OC, 68W10, 68W15, 68W40, 90C06, 90C35, 90C26, G.1.6; F.2.1; E.4, **投稿日時:** 2024-09-30 21:22


- - -

### [Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models](http://arxiv.org/abs/2410.00131)

**大規模言語モデルを用いたフィッシャー情報に基づく効率的カリキュラム連合学習**

Ji Liu, Jiaxiang Ren, Ruoming Jin, Zijie Zhang, Yang Zhou, Patrick Valduriez, Dejing Dou

- 連合学習は分散データでモデルを共同訓練する有望な手法である
- LLMは巨大で非IIDデータに対する訓練コストが高くなる
- 提案手法FibecFedは適応的データサンプリングと効率的なスパースパラメータ更新を行う
- 実験結果で最大45.35%の精度と98.61%の高速化を実現

フィッシャー情報を使うあたりが素敵！効率的なパラメータ更新で連合学習がもっと普及するのかもってワクワクするね。データサンプリングを工夫することで、精度と速度がこれだけ改善されるのは面白いな～。

**Comment:** 27 pages, 8 figures, 14 tables, to appear in EMNLP 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CL, cs.DC, **投稿日時:** 2024-09-30 18:12


- - -

### [Fine-Tuning Personalization in Federated Learning to Mitigate Adversarial Clients](http://arxiv.org/abs/2409.20329)

**連合学習における個別化の微調整で敵対的クライアントを軽減**

Youssef Allouah, Abdellah El Mrini, Rachid Guerraoui, Nirupam Gupta, Rafael Pinot

- クライアント間のデータ分布の異質性がモデル性能に悪影響を与える
- 個別化によって各クライアントに最適なモデルを作成しつつ、他のデータも活用
- 敵対的クライアントの存在下での連合学習の一般化性能を分析
- データの異質性と許容可能な敵対的クライアントの割合に応じた協力の調整が必要

敵対的なクライアントがいる中での連合学習のパフォーマンス向上に取り組むなんて面白そう！クライアントに合わせた細かな調整が未来の鍵になるかもね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-09-30 14:31


- - -

### [Enhancing Security Using Random Binary Weights in Privacy-Preserving Federated Learning](http://arxiv.org/abs/2409.19988)

**プライバシー保護連合学習におけるランダムバイナリ重みを用いたセキュリティ強化**

Hiroto Sawada, Shoko Imaizumi, Hitoshi Kiya

- 連合学習で生のデータを収集せずに更新情報のみで学習するが、その情報からデータが推測される問題がある
- 従来の対策にはプライバシー保護と学習効率のトレードオフがあり、モデル性能が低下する
- 提案手法はランダムバイナリ重みを用い、更新情報へのデータ推測攻撃に強く、モデル性能を低下させない
- 実験で、APRIL（Attention PRIvacy Leakage）復元攻撃に対する耐性とモデル性能の有効性を確認

新しいセキュリティ技術ってすごくわくわくするよね！データのプライバシーを守りつつ高性能を保つなんて、未来の連合学習がもっと安心して使えるようになるかも。

**Comment:** 6pages, 17figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-09-30 06:28


- - -

### [Comments on "Privacy-Enhanced Federated Learning Against Poisoning Adversaries"](http://arxiv.org/abs/2409.19964)

**「毒性攻撃者に対するプライバシー強化型連合学習」へのコメント**

Thomas Schneider, Ajith Suresh, Hossein Yalame

- PEFLは準同型暗号を用いて毒性行動を検出するフレームワークを提案
- PEFLはすべてのユーザーの勾配ベクトルを明らかにするため、プライバシーを維持しない
- 提案されたシステムに複数の欠陥があり、即時修正ではプライバシーを確保できない
- PEFLの問題点を認識せずに引用や採用する研究が後を絶たない

PEFLのフレームワーク、実際はプライバシー全然守れていないとか驚きだね！これからの研究にも影響大きそうだから、ちゃんとチェックしなきゃだね。

**Comment:** Published at IEEE Transactions on Information Forensics and   Security'23

**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-09-30 05:34


- - -

### [Leveraging Pre-trained Models for Robust Federated Learning for Kidney Stone Type Recognition](http://arxiv.org/abs/2409.19934)

**腎臓結石タイプ認識のための堅牢な連合学習のための事前学習モデルの活用**

Ivan Reyes-Amezcua, Michael Rojas-Ruiz, Gilberto Ochoa-Ruiz, Andres Mendez-Vazquez, Christian Daul

- 深層学習の進展が医療画像診断の精度を劇的に向上
- 巨大なデータセットの必要性とデータ交換の法的制限が障壁
- 事前学習モデルを用いた強力な連合学習フレームワークを提案
- 連合学習の堅牢性と診断精度の向上を示し、患者ケアの改善が期待できる

これ、プライバシーを守りながらも高精度な診断ができるなんて⤴絶対おもしろそうだよね。医療における新たな信頼の形になるかも💖🎵



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-09-30 04:23


- - -

### [HYDRA-FL: Hybrid Knowledge Distillation for Robust and Accurate Federated Learning](http://arxiv.org/abs/2409.19912)

**HYDRA-FL: ロバストかつ高精度な連合学習のためのハイブリッド知識蒸留**

Momin Ahmad Khan, Yasra Chandio, Fatima Muhammad Anwar

- 連合学習におけるデータの不均一性がグローバルモデルのパフォーマンス低下を招く
- 知識蒸留技術は高い不均一性におけるパフォーマンスを向上させるが、攻撃増幅が問題
- ハイブリッド蒸留技術HYDRA-FLを提案し、浅い層への蒸留損失の一部をオフロードすることで攻撃の影響を軽減
- FedNTDとMOONの2つのアルゴリズムに適用し、攻撃シナリオでベースラインを上回る性能を確認

連合学習の課題を解決しつつ、攻撃耐性も向上させるなんてすごいね！現実のデータに対する応用が楽しみだな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-09-30 03:29


- - -

### [Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System](http://arxiv.org/abs/2409.19756)

**プライバシー保護型連合学習の進展により実現する真の学習型医療システム**

Ravi Madduri, Zilinghan Li, Tarak Nandi, Kibaek Kim, Minseok Ryu, Alex Rodriguez

- 学習型医療システム（LHS）は、患者ケアのデータを分析して将来の医療成果を向上させる
- データ共有とプライバシー保護の大きな課題がLHS実現の妨げとなっている
- プライバシー保護型連合学習（PPFL）は、分散データの共同学習で患者プライバシーを守る
- PPFLを医療エコシステムに統合し、IOMラウンドテーブルが定義する真のLHSを目指す

医療データの共有が進むと、より良い治療が受けられるようになりそう！患者さんのプライバシーも守られるなら安心だね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, **投稿日時:** 2024-09-29 20:02


- - -

### [Tailored Federated Learning: Leveraging Direction Regulation & Knowledge Distillation](http://arxiv.org/abs/2409.19741)

**特徴的な連合学習：方向規制と知識蒸留の活用**

Huidong Tang, Chen Li, Huachong Yu, Sayaka Kamei, Yasuhiko Morimoto

- 連合学習は医療などプライバシーが重要な分野で有用だが、データや計算能力の異質性が課題
- モデルデルタ正則化、パーソナライズドモデル、連合知識蒸留、ミックスプーリングを統合したFL最適化アルゴリズムを提案
- モデルデルタ正則化は通信コストを最小限に抑えつつ、中央サーバでの効率的な更新を実現
- 実験結果では、モデルの高精度と迅速な収束を示し、多様なデータでも優れた性能を発揮

この研究めっちゃ面白そう！特に色々なデータでもうまくいくっていうのが興味深いよね。連合知識蒸留とか、次世代のプライバシー技術に期待大だね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-29 15:39


- - -

### [Federated Learning from Vision-Language Foundation Models: Theoretical Analysis and Method](http://arxiv.org/abs/2409.19610)

**視覚と言語の基盤モデルを用いた連合学習：理論的分析と手法**

Bikang Pan, Wei Huang, Ye Shi

- 事前訓練済みの視覚と言語基盤モデル（CLIPなど）を連合学習に統合することで多様なタスクの一般化を強化
- プロンプト学習を用いて通信および計算コストを削減するプロンプトベースの連合学習法の理論的分析が限られている
- プロンプトベースの連合学習の信号学習とノイズ記憶の進化をモニタリングし、タスク関連とタスク非関連の係数比で性能を評価
- グローバルおよびローカルのプロンプトを用いたプロンプトポートフォリオにより一般化と個別化のバランスを取り、最適な混合係数を導出

連合学習とポートフォリオ最適化のアナロジーが面白そう！信号学習とノイズ記憶の進化をどう捉えたのかも気になるな～



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, cs.CV, **投稿日時:** 2024-09-29 08:31


- - -

### [Infighting in the Dark: Multi-Labels Backdoor Attack in Federated Learning](http://arxiv.org/abs/2409.19601)

**暗闇で内部争い：連合学習におけるマルチラベルバックドア攻撃**

Ye Li, Yanchao Zhao, Chengcheng Zhu, Jiale Zhang

- 連合学習はバックドア攻撃に脆弱であると示されている
- ほとんどの研究が単一ラベルバックドア攻撃（SBA）に焦点を当てている
- 本研究は、既存の手法がマルチラベルバックドア攻撃（MBA）には効果がないことを示す
- 新手法M2Mは異なるトリガーパターンを適応させ、目標クラスの分布に基づいてバックドアを起動

攻撃手法がどんどん野心的になっていてびっくり。研究が進めば、連合学習の安全性がどう改善されるか楽しみだね。

**Comment:** 10 pages, 9 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, **投稿日時:** 2024-09-29 07:37


- - -

### [Fast-Convergent and Communication-Alleviated Heterogeneous Hierarchical Federated Learning in Autonomous Driving](http://arxiv.org/abs/2409.19560)

**自律走行における高速収束および通信負荷軽減の異種階層型連合学習**

Wei-Bin Kou, Qingfeng Lin, Ming Tang, Rongguang Ye, Shuai Wang, Guangxu Zhu, Yik-Chung Wu

- 自律走行のためのストリートシーンセマンティック理解は、地域ごとのデータの偏りで一般化が困難
- 提案されたFedGauアルゴリズムにより、異なる統計特性を持つ都市データの収束速度が35.5%-40.6%向上
- FedGauがRGB画像とデータセットをガウス分布としてモデル化し、統計特性に基づく集約を行う
- AdapRSポリシーが通信リソースを29.65%節約し、パフォーマンスをほぼ維持

全然新しい手法で連合学習の課題を解決するんだね！収束速度も改善するし、通信量も減らせるって、めっちゃ未来型！

**Comment:** 16 pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.RO, **投稿日時:** 2024-09-29 05:27


- - -

### [Convergence-aware Clustered Federated Graph Learning Framework for Collaborative Inter-company Labor Market Forecasting](http://arxiv.org/abs/2409.19545)

**収束意識を持つクラスタ化連合グラフ学習フレームワークによる企業間協働の労働市場予測**

Zhuoning Guo, Hao Liu, Le Zhang, Qi Zhang, Hengshu Zhu, Hui Xiong

- 人材需要と供給の変動を予測するために、企業間の需要供給シーケンスの相互連結性が重要
- 企業は競争優位性やセキュリティの懸念からプライベートな人事データを積極的に共有したがらない
- Meta-personalized Convergence-aware Clustered Federated Learning（MPCAC-FL）によりプライバシー保護をしながら精度を高める手法を提案
- 実験でMPCAC-FLは既存の最新モデルを上回り、97%以上の精度を達成しつつ、データのプライバシーも確保

これはすっごく面白そう！企業間でも協力できるなんて、これからの働き方が大きく変わりそうだね。プライバシーも守られてるのが安心できる！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-29 04:11


- - -

### [One Node Per User: Node-Level Federated Learning for Graph Neural Networks](http://arxiv.org/abs/2409.19513)

**ユーザーごとに1ノード: グラフニューラルネットワークのためのノードレベルの連合学習**

Zhidong Gao, Yuanxiong Guo, Yanmin Gong

- グラフニューラルネットワークの訓練には生データ収集が必要で、プライバシーの懸念がある
- 連合学習により、生データ共有せずに協調的なモデル訓練が可能
- 提案手法は、メッセージパッシングと特徴ベクトル変換をユーザデバイスとクラウドサーバで分離して実行する
- 特徴ベクトルの潜在表現に基づくグラフラプラシアン項を導入し、ユーザ側モデル更新の調整を行う

ユーザーのデータを守りながら精度も上がるならめっちゃ便利そう！どんな分野で使われるのか気になるよね。

**Comment:** 16 pages, 9 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-09-29 02:16


- - -

### [Heterogeneity-Aware Resource Allocation and Topology Design for Hierarchical Federated Edge Learning](http://arxiv.org/abs/2409.19509)

**異質性を考慮した階層型連合エッジ学習のためのリソース配分およびトポロジー設計**

Zhidong Gao, Yu Zhang, Yanmin Gong, Yuanxiong Guo

- 連合学習はモバイルエッジデバイス上でプライバシーを保護して機械学習モデルを訓練する手法である
- 階層型連合エッジ学習（HFEL）はエッジサーバーを中継してモデル集約を行い、通信負荷を軽減する
- HFELは効率的だが、システムとデータの異質性で収束率が低く、リソース消費が高いという課題がある
- 提案手法はリソース配分とピアツーピア接続調整でトレーニング遅延を最小化し、効率的な大規模FLを実現

異質性に対応したルート設計とか、まるで迷路をナビゲートするみたいで面白そう！しかも、従来の方法より効率が良くなるってところがワクワクするね。

**Comment:** 12 pages, 9 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, **投稿日時:** 2024-09-29 01:48


- - -

### [Subject Data Auditing via Source Inference Attack in Cross-Silo Federated Learning](http://arxiv.org/abs/2409.19417)

**クロスサイロ連合学習におけるソース推論攻撃を用いた主体データ監査**

Jiaxin Li, Marco Arazzi, Antonino Nocera, Mauro Conti

- 連合学習のソース推論攻撃（SIA）は、特定のデータポイントを使用したクライアントを特定
- クロスサイロ連合学習では複数の主体からデータ収集し、情報漏えいのリスクが高まる
- 提案するSLSIAは、既存の制約を取り除き、対象データ使用のクライアントを正確に検出
- 差分プライバシー機構を用いて、SLSIAに対する防御策を提案

クライアントのデータ使用をチェックする攻撃で、連合学習の新しい視点が広がるのめっちゃ面白そう。確かに情報漏えいは怖いから、防御策とセットで考えるのが重要だね！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-09-28 17:27


- - -

### [Efficient Federated Intrusion Detection in 5G ecosystem using optimized BERT-based model](http://arxiv.org/abs/2409.19390)

**最適化されたBERTベースモデルを用いた5Gエコシステムにおける効率的な連合侵入検知**

Frederic Adjewa, Moez Esseghir, Leila Merghem-Boulahia

- 5Gの進化に伴い、IoTを通じたアプリケーションが進化し、セキュリティ上の課題が増加
- 提案された侵入検知システムは、連合学習とBERTを組み合わせて悪意あるネットワークフローを検出
- BERTの性能をエッジデバイスでも最適化し、中央集権的・連邦学習の文脈で実験
- 線形量子化を活用してモデル圧縮を行い、0.02%の精度減少で28.74%のサイズ削減を実現

BERTをエッジデバイスでも使えるように最適化したなんてすごく面白そう！これでIoT環境でも効率的に動作するから、セキュリティレベルがもう一段上がりそうだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-09-28 15:56


- - -

### [Quantum delegated and federated learning via quantum homomorphic encryption](http://arxiv.org/abs/2409.19359)

**量子準同型暗号を用いた量子委任学習と連合学習**

Weikang Li, Dong-Ling Deng

- 量子学習モデルは古典的な領域よりも計算上の利点を持つ可能性がある
- 量子準同型暗号を用いた一般的なフレームワークを提案し、データのプライバシーを保証
- 提案されたフレームワークでは、通信の複雑さが従来の方法よりも大幅に低減
- サーバーが暗号化された量子データを操作するため、クライアント側の計算負担が軽減

量子技術でのプライバシー保護がすっごく進んでる！これからのクラウドサービスにも大きな影響がありそうね。未来の安全な学習モデルってどんな感じになるんだろう？ワクワクしちゃう！

**Comment:** 5 pages, 1 figure, 1 table

**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** quant-ph, cs.CR, cs.LG, **投稿日時:** 2024-09-28 14:13


- - -

### [Leveraging MTD to Mitigate Poisoning Attacks in Decentralized FL with Non-IID Data](http://arxiv.org/abs/2409.19302)

**非IIDデータを持つ分散型FLにおけるポイズニング攻撃を緩和するためのMTDの活用**

Chao Feng, Alberto Huertas Celdrán, Zien Zeng, Zi Ye, Jan von der Assen, Gerome Bovet, Burkhard Stiller

- 分散型連合学習（DFL）はプライバシーを保護しながら大規模データを管理できるが、ポイズニング攻撃に脆弱である
- 現行の防御方法はIIDデータを前提としており、現実での適用が難しい
- 本論文は、MTD（Moving Target Defense）を活用してDFLモデルの堅牢性を強化するフレームワークを提案
- 実験評価により、このMTDベースのメカニズムが様々なポイズニング攻撃を効果的に緩和することを示した

マジで面白そうな研究！実際のデータでの応用が、もっと安心できる連合学習の未来に繋がりそう。チェックしなきゃね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, **投稿日時:** 2024-09-28 10:09


- - -

### [Privacy Attack in Federated Learning is Not Easy: An Experimental Study](http://arxiv.org/abs/2409.19301)

**連合学習におけるプライバシー攻撃は簡単ではない: 実験的研究**

Hangyu Zhu, Liyuan Huang, Zhenping Xie

- 連合学習はデータを公開せずにモデルを共同でトレーニングし、プライバシーリスクを削減
- しかし、モデル勾配を介してプライベートデータを抽出する攻撃の可能性が示唆されている
- 既存の攻撃アルゴリズムは単一ステップの勾配からデータ再構築を試みているが、実用環境での有効性は不明
- 実験結果は、最新の攻撃アルゴリズムが現実の連合学習環境でプライバシーを効果的に侵害できないことを示唆

連合学習ってプライバシー守れると思ってたけど、やっぱり難しいんだね。でも現実の環境ではまだ安全みたいで安心！これからの研究がどう進化するか楽しみだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-09-28 10:06


- - -

### [A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs](http://arxiv.org/abs/2409.18915)

**A-FedPD: デュアルドリフトの調整が必要な連合プライマルデュアル学習**

Yan Sun, Li Shen, Dacheng Tao

- 連合学習はデータプライバシーと共同訓練を両立し、エッジクライアントの異質データセットを分散処理
- 帯域幅やセキュリティの制約で問題を並列処理可能な複数のサブ問題に分割、プライマルデュアル解を適用
- 非凸シナリオでの古典的な連合プライマルデュアル法の「デュアルドリフト」問題を指摘
- A-FedPD法を提案し、仮想デュアル更新で未参加クライアントのグローバル合意とローカルデュアル変数を調整、高効率と実用性を確認

仮想デュアル更新とか面白そう！連合学習の効率性がすごく向上するんだね。実験結果とかどうなるか見てみたいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-27 17:00


- - -

### [In-depth Analysis of Privacy Threats in Federated Learning for Medical Data](http://arxiv.org/abs/2409.18907)

**医療データの連合学習におけるプライバシー脅威の詳細分析**

Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu

- 連合学習は医療画像を扱う際に患者データを保護する有力な手法だが、プライバシー攻撃により訓練データが漏洩する危険性がある
- 提案されたMedPFLフレームワークは、連合学習環境での医療データのプライバシーリスクを分析し、対策を開発する
- 実際の分析を通じ、連合学習を用いると敵対者がプライバシー攻撃で正確な医療画像を復元可能であることを実証
- ランダムノイズの追加といった一般的な防御機構が医療画像のプライバシー保護に常に有効ではなく、これに対処する独自の研究課題が存在

医療データのプライバシーってめちゃくちゃ大事だよね！ランダムノイズが守ってくれないこともあるなんて、より安全な方法を見つけるのが重要そう😊



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-27 16:45


- - -

### [Hierarchical Federated ADMM](http://arxiv.org/abs/2409.18796)

**階層型連合ADMM**

Seyed Mohammad Azimi-Abarghouyi, Nicola Bastianello, Karl H. Johansson, Viktoria Fodor

- 従来の勾配降下法に基づく階層型連合学習（FL）アルゴリズムから離れ、ADMMに基づく新しい階層型FLフレームワークを開発
- 上層でADMMを使用する2つの新しいFLアルゴリズムを提案し、1つは下層でもADMMを使用、もう1つは従来の勾配降下法を使用
- 提案されたフレームワークはプライバシーを強化し、学習収束と精度の面で従来のアルゴリズムより優れていることを実験で証明
- 下層での勾配降下法はローカルステップ数が非常に限られている場合でも良好な性能を示し、両層でのADMM使用はそれ以外の場合に良い性能を発揮

ADMMを使って、どれだけ効率的に学習できるか実験してるのが面白そう。試してみたくなる！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, cs.IT, cs.SY, eess.SY, math.IT, **投稿日時:** 2024-09-27 14:50


- - -

### [Enhancing Spectrum Efficiency in 6G Satellite Networks: A GAIL-Powered Policy Learning via Asynchronous Federated Inverse Reinforcement Learning](http://arxiv.org/abs/2409.18718)

****

Sheikh Salman Hassan, Yu Min Park, Yan Kyaw Tun, Walid Saad, Zhu Han, Choong Seon Hong

*6G衛星ネットワークにおけるスペクトル効率の向上: 非同期連合逆強化学習によるGAIL駆動のポリシー学習*

- 手動設計の報酬関数に依存しないGAILフレームワークを導入
- 非同期連合学習を用いて、複数衛星システムが分散で最適なポリシーを協力して導出
- 鯨最適化アルゴリズムで専門家ポリシーを生成し、GAILで報酬関数を訓練
- 提案手法は従来の強化学習法よりも14.6%の改善を達成

この研究、なんだか未来のネットワーク技術をガツンと進化させそうじゃない？衛星と連合学習の組み合わせとか、すごくワクワクするよね！

**Comment:** Submitted to IEEE Transactions on Mobile Computing (16 pages, 10   figures)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.NI, cs.LG, **投稿日時:** 2024-09-27 13:05


- - -

### [An Enhanced Federated Prototype Learning Method under Domain Shift](http://arxiv.org/abs/2409.18578)

**ドメインシフト下における強化された連合プロトタイプ学習法**

Liang Kuang, Kuangpu Guo, Jian Liang, Jianguo Zhang

- 連合学習はプライベートデータを共有せずに共同で機械学習モデルをトレーニングする手法である
- データのヘテロジニアス性が連合学習モデルの性能に大きな影響を及ぼす
- FedPLCCアルゴリズムを導入し、クラス内類似性を向上させ、クラス間類似性を減少させる
- Digit-5、Office-10、DomainNetデータセットで、既存の手法よりも優れた性能を示す

連合学習って奥が深い！データのヘテロジニアス性をどう克服するかって、本当に面白そう。もっと詳しく知りたいね！

**Comment:** 8 pages, 6 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-09-27 09:28


- - -

### [HSTFL: A Heterogeneous Federated Learning Framework for Misaligned Spatiotemporal Forecasting](http://arxiv.org/abs/2409.18482)

**HSTFL：位置および時間のずれを考慮した異種連合学習フレームワークによる予測**

Shuowei Cai, Hao Liu

- スマートシティアプリにおける空間・時間予測の重要性
- 中央集権的なデータ収集が個々のプライバシーを侵害する可能性
- 垂直連合学習によって異種データの局所的依存を保持
- クロスクライアント仮想ノードの整合ブロックによりプライバシー保護を実現

複数のデータソースを連携して予測するってすごくない？将来、プライバシーを守りながらみんなでデータを活用できるようになったら楽しみ！

**Comment:** Under review

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-27 06:51


- - -

### [Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration](http://arxiv.org/abs/2409.18461)

**多様なデバイス異種連合学習へのタスク算術知識統合の道**

Mahdi Morafah, Vyacheslav Kungurtsev, Hojin Chang, Chen Chen, Bill Lin

- 連合学習はユーザーデータのプライバシーを守りながら共同機械学習を実現
- 標準的な連合学習は、IoTデバイスから大規模ワークステーションまでの多様なデバイスの異種性に対応できていない
- TAKFLは、各デバイスプロトタイプからの知識転送を独立したタスクとして扱い、個々の学習能力を保護しながら知識の希薄化を回避
- TAKFLはCVおよびNLPタスクでの評価で、既存の知識蒸留技術を大幅に上回るSOTA（最先端）結果を達成

この研究は、多種多様なデバイスの能力差を考慮して連合学習を行うように工夫しているんだね。特に個々のデバイスに応じた知識統合プロセスが興味深いな。TAKFLのコードも公開されてるし、実装しながら理解を深めていきたいよね！

**Comment:** NeurIPS 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, cs.DC, **投稿日時:** 2024-09-27 05:49


- - -

### [Hierarchical Federated Learning with Multi-Timescale Gradient Correction](http://arxiv.org/abs/2409.18448)

**マルチタイムスケール勾配補正による階層型連合学習**

Wenzhi Fang, Dong-Jun Han, Evan Chen, Shiqiang Wang, Christopher G. Brinton

- 従来の連合学習（FL）は中央サーバーとクライアントの星型拓＞ポロジーに焦点を当てるが、現実の分散システムは階層型ア＞ーキテクチャを持つことが多い
- 階層型連合学習（HFL）は、システム内の複数レベルで集約点＞を利用することでこのギャップを埋める有望な解決策である
- マルチタイムスケールモデルドリフトに取り組むため、マルチ＞タイムスケール勾配補正（MTGC）方法論を提案
- 提案手法の収束境界はデータの異質性の程度に依存せず、多レ＞ベルの非同一分布データに対しても安定であることを確認

この研究って面白そう！複雑な分散システムでも効率的に連合学習ができるとか、未来のAIがもっと賢くなりそうな予感がするよね。コードも公開されてるから、興味がある人は試してみてもいいかも。

**Comment:** Accepted to NeurIPS 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-09-27 05:10


- - -

### [FedDCL: a federated data collaboration learning as a hybrid-type privacy-preserving framework based on federated learning and data collaboration](http://arxiv.org/abs/2409.18356)

**FedDCL: 連合学習とデータコラボレーションを基にしたハイブリッド型プライバシー保護フレームワークとしての連合データコラボレーション学習**

Akira Imakura, Tetsuya Sakurai

- 連合学習は複数機関のデータを統合解析できるが、連続通信が困難な場合に課題がある
- FedDCLは連合学習とデータコラボレーション分析を組み合わせ、通信問題を解決
- 各機関は次元削減済みの中間表現を共有し、サーバーでコラボレーション表現に変換
- FedDCLは機関間の反復通信を不要とし、連続通信が困難な状況でも実装可能

新しい通信不要の学習方法に挑戦しているのが面白い！データ集約型の未来に向けた前進って感じだね。

**Comment:** 18 pages, 6 figures, 3 tables

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-09-27 00:22
