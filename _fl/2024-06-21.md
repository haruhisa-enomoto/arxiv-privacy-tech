---
title: 連合学習 (2024-06-21 ~ 2024-06-27)
date: 2024-06-21
---

連合学習に関する論文まとめ (2024-06-21 ~ 2024-06-27)


- - -

### [Personalized Federated Continual Learning via Multi-granularity Prompt](http://arxiv.org/abs/2407.00113)

**マルチ粒度プロンプトによるパーソナライズド連合継続学習**

Hao Yu, Xin Yang, Xin Gao, Yan Kang, Hao Wang, Junbo Zhang, Tianrui Li

- PFCLは知識の共有と個別化の課題を解決するシナリオである
- 既存手法は知識の多粒度表現を見落としており、STCF克服に役立つ
- 粗粒度なグローバルプロンプトと細粒度なローカルプロンプトを提案
- 粗粒度プロンプトは空間忘却防止、細粒度プロンプトは時間忘却防止に効果的

個別化された知識を効果的に共有するアイデアが面白そう！これって未来のAI学習法の基盤になるかもね。高校生の私たちでもすぐに使えるといいな。

**Comment:** Accepted by KDD 2024 Research Track

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-27 13:41


- - -

### [FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning](http://arxiv.org/abs/2406.19050)

**FedMap: 連合学習における通信効率化のための反復的な重要度ベースのプルーニング**

Alexander Herzog, Robbie Southam, Ioannis Mavromatis, Aftab Khan

- 連合学習は分散されたデータでプライバシーを保ちながら機械学習を行う手法
- FedMapは無構造なプルーニングを用いて通信効率を向上させる新しい方法
- 医療や金融などプライバシーが重要な分野での利用を想定し、モデルを一から訓練
- IID環境で90%以上、非IID環境で80%以上のプルーニングを達成しつつ精度を維持

これ、すごく未来感あるね！プライバシーを守りつつ、効率的に学習できるって必須スキルかも！

**Comment:** Submitted to IEEE Transactions on Neural Networks and Learning   Systems

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-27 09:58


- - -

### [Coded Cooperative Networks for Semi-Decentralized Federated Learning](http://arxiv.org/abs/2406.19002)

**半分分散型連合学習のための符号化協力ネットワーク**

Shudi Weng, Ming Xiao, Mikael Skoglund

- フェデレーテッドラーニング（FL）システムの遅延耐性を強化するため、半分分散型アプローチを提案
- 提案手法はネットワーク全体の事前情報を必要とせず、ワイヤレス多様性を活用
- アウトエイジと収束速度の理論解析を提供
- ベンチマーク手法に比べて優れていることを、包括的なシミュレーションで実証

ネットワーク全体の事前情報がいらないのが新しいかも！シミュレーション結果も見てみたいなって思う！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.IT, math.IT, **投稿日時:** 2024-06-27 08:42


- - -

### [FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity](http://arxiv.org/abs/2406.18995)

**FedMLP: 連合学習によるタスク異質性下でのマルチラベル医用画像分類**

Zhaobin Sun, Nannan Wu, Junjie Shi, Li Yu, Xin Yang, Kwang-Ting Cheng, Zengqiang Yan

- クロスサイロ連合学習は、データプライバシーを守りつつ分散型組織が共同でモデルを訓練する方法
- 臨床実践では、各機関が部分的なカテゴリしか診断しないため、タスク異質性が生じる
- FedMLPは、欠損ラベル補充のために擬似ラベル付けとグローバル知識学習の二段階法を提案
- 実験では、FedMLPが連合型半教師あり学習およびノイズラベル学習アプローチを上回る結果を示す

これかなり実践的な研究っぽいね！タスク異質性を考慮した医療画像の連合学習、将来もっと活躍しそう！

**Comment:** Early accepted by MICCAI 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-27 08:36


- - -

### [Towards Personalized Federated Multi-scenario Multi-task Recommendation](http://arxiv.org/abs/2406.18938)

**パーソナライズされた連合学習によるマルチシナリオ・マルチタスク推薦へのアプローチ**

Yue Ding, Yanbiao Ji, Xun Cai, Xin Xin, Xiaofeng Gao, Hongtao Lu

- 複数のターゲット（CTRやCTCVR）を予測するマルチタスク推薦システムが重要である
- 複数のビジネスシナリオを統合し、共有知識で性能を向上させる
- PF-MSMTrecフレームワークを提案し、各シナリオに専用のクライアントを割り当てる
- 実験結果が最先端の手法を上回ることを示している

複数のシナリオを同時に扱うことで、もっとカスタマイズされた推薦ができそう！こういう新しい手法がどんどん実用化されたら、私たちのネットショッピングがもっと便利になるね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.IR, **投稿日時:** 2024-06-27 07:10


- - -

### [QBI: Quantile-based Bias Initialization for Efficient Private Data Reconstruction in Federated Learning](http://arxiv.org/abs/2406.18745)

**QBI: 連邦学習における効率的なプライベートデータ再構築のための分位数ベースのバイアス初期化**

Micha V. Nowak, Tim P. Bott, David Khachaturov, Frank Puppe, Adrian Krenzer, Amar Hekalo

- 分散データ上でモデルを訓練する連合学習で、バイアス初期化がプライベートデータ再構築能力を向上
- QBIは疎な活性化パターンを生むバイアス値を直接解く新しい手法
- PAIRSアルゴリズムを提案し、データセットが利用可能な場合にデータ回復率を向上
- AGGPという防御フレームワークを提案し、勾配の疎密性攻撃を予防し、連合学習のセキュリティを向上

データがこんなに再現できちゃうなんて驚き！AGGPが未来の連合学習をもっと安全にしてくれそうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-06-26 20:19


- - -

### [Enhancing Federated Learning with Adaptive Differential Privacy and Priority-Based Aggregation](http://arxiv.org/abs/2406.18491)

**適応差分プライバシーと優先順位ベースの集約による連合学習の強化**

Mahtab Talaei, Iman Izadi

- 連合学習はローカルデータセットなしでグローバルモデルを開発
- モデル更新の取得が情報漏洩の可能性を含む、モデルインバージョン攻撃のリスク
- 差分プライバシーによりパラメータにノイズを追加しプライバシーを保護
- デバイス間の異質性を考慮し、時間的に変動する影響因子で収束性を向上

デバイスごとのリソース差を考慮したカスタマイズされたプライバシー保護、革新的ね！未来のFLはますます強力になりそう。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-06-26 16:55


- - -

### [FedAQ: Communication-Efficient Federated Edge Learning via Joint Uplink and Downlink Adaptive Quantization](http://arxiv.org/abs/2406.18156)

**FedAQ: 共同アップリンクおよびダウンリンク適応量子化による通信効率の高い連合エッジ学習**

Linping Qu, Shenghui Song, Chi-Ying Tsui

- 連合学習(FL)はクライアントのデータプライバシーを保護しつつ、データと計算資源を活用する
- モデルサイズの大きさと頻繁な集約が通信オーバーヘッドの原因となり、リソース制限のある無線ネットワークでの展開が難しい
- 本研究では量子化を用いて通信オーバーヘッドを軽減し、最適なアップリンクおよびダウンリンク量子化ビット長を決定
- 提案手法により既存のスキームと比較して最大66.7%のエネルギー節約が可能

通信効率をこんなに上げられるのはすごいね！アップリンクとダウンリンクの両方に適応できる新しい量子化手法、未来のネットワークで大活躍しそう！

**Comment:** This work has been submitted to the IEEE for possible publication.   Copyright may be transferred without notice, after which this version may no   longer be accessible

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, cs.NI, eess.SP, **投稿日時:** 2024-06-26 08:14


- - -

### [Beyond Statistical Estimation: Differentially Private Individual Computation in the Shuffle Model](http://arxiv.org/abs/2406.18145)

**統計推定を超えて：シャッフルモデルにおける差分プライバシーのための個別計算**

Shaowei Wang, Changyu Dong, Di Wang, Xiangfu Song

- シャッフルモデルは非信頼当事者間での非集中型計算で威力発揮し、匿名化とメッセージの順序入れ替えによりプライバシーと有用性を向上
- 従来の手法で計算困難または有用性損失が大きい空間クラウドソーシング、組み合わせ最適化、位置ベースのソーシャルシステム、インセンティブ付き連合学習において、シャッフルプライバシー増幅の実現可能性を探る
- メッセージ認証や結果アクセス制御などの重要なセキュリティ機能を提供しつつ、プライバシー強化効果を維持する新たなシャッフルモデルを提案
- 実験結果: 非プライベート設定に対しエラー最大90％削減、100％-300％有用性向上し、適切なプライバシー予算で実用的

シャッフルモデルって、すごく面白そう！特に連合学習でこれだけ効果が出るなら、未来の技術革新に大いに貢献しそうだよね！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-06-26 07:53


- - -

### [Navigating High-Degree Heterogeneity: Federated Learning in Aerial and Space Networks](http://arxiv.org/abs/2406.17951)

**高い異質性への対応：航空・宇宙ネットワークにおける連合学習**

Fan Dong, Henry Leung, Steve Drew

- 連合学習はドローンや衛星を通じたデータプライバシー問題の解決策として有望
- しかし、異質性とクラス不均衡がモデルの収束を阻む主要な障害
- 異質性とクラス不均衡の相関を示し、バッテリー寿命の制約が課題をさらに悪化
- 異質性の度合いが大きいと現行アルゴリズムは効果的に対処できず性能が低下

宇宙や空のデータも連合学習で使えるってすごいことだよね！だけど、クラス不均衡の問題はもっとよく考えていかないといけないみたいね。技術が進化する未来に期待しちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-25 21:57


- - -

### [Entity Augmentation for Efficient Classification of Vertically Partitioned Data with Limited Overlap](http://arxiv.org/abs/2406.17899)

**限定的な重複を持つ垂直分割データの効率的な分類のためのエンティティ拡張**

Avi Amalanshu, Viswesh Nagaswamy, G. V. S. S. Prudhvi, Yash Sirvi, Debashish Chakravarty

- 垂直連合学習（VFL）は、特徴が複数の「ゲスト」クライアント間で分散し、ラベルを所有する「ホスト」サーバと学習を行う
- 従来のVFLは、ホストが共通のエンティティを特定する「エンティティ解決」フェーズと、プライベートセットインターセクションを含む
- 提案されたエンティティ拡張技術は、明示的なエンティティ整列なしで有意義なラベルを生成し、効率的なVFLを実現
- CIFAR-10データセットで、訓練データの重複が5%の場合で48.1%から69.48%に精度向上、100%重複でもわずかに性能向上

エンティティ拡張って、新しいアイディアだね！VFLの効率が上がることで、将来もっと色々なデータを活用できそうでワクワクする！

**Comment:** GLOW @ IJCAI 2024 (12 pages + 2 page bibliography. 15 figures.)

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, cs.DC, **投稿日時:** 2024-06-25 19:20


- - -

### [Federated Dynamical Low-Rank Training with Global Loss Convergence Guarantees](http://arxiv.org/abs/2406.17887)

**グローバル損失収束保証を持つ連合動的低ランクトレーニング**

Steffen Schotthöfer, M. Paul Laiu

- 連合学習におけるクライアントの計算および通信コストを低減するためのスキームを提案
- 動的低ランク分割スキームを用いてネットワーク重みのグローバル低ランク基底を作成
- クライアントのトレーニングが小さい係数行列で可能になり、計算リソースおよび通信リソースの最適化ができる
- コンピュータビジョンベンチマークで効率を実証し、コストを約10分の1に削減しつつ精度にほとんど影響を与えない

新しいけどすっごく素敵な研究だね！次のレポートで役立つ資料見つけちゃった。試すっきゃないね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, math.OC, **投稿日時:** 2024-06-25 18:51


- - -

### [FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model](http://arxiv.org/abs/2406.17706)

**FedBiOT: 連合学習におけるフルモデルなしのLLMローカルファインチューニング**

Feijie Wu, Zitao Li, Yaliang Li, Bolin Ding, Jing Gao

- 大規模言語モデル（LLM）は適切なデータでファインチューニングするとドメイン特有のタスクで優れた性能を発揮する
- ドメイン特有のデータは複数の所有者間で分散しており、連合学習（FL）の文脈でLLMのファインチューニングを行う方法に関心が集まっている
- FLのクライアントは計算能力と通信容量が限られているため、LLMの効果的なファインチューニングが困難である
- FedBiOTでは圧縮LLMを生成し、それを用いてクライアントが軽量なアダプターをファインチューニングすることで、リソース消費を大幅に削減できる

FedBiOTめっちゃ素敵じゃない？軽量なアダプターだけで効果を維持しつつリソース削減とか、ほんとに現実的な解決策だと思う！連合学習の新しい時代が来るかもね！

**Comment:** KDD 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CL, cs.DC, **投稿日時:** 2024-06-25 16:45


- - -

### [Dynamic Scheduling for Vehicle-to-Vehicle Communications Enhanced Federated Learning](http://arxiv.org/abs/2406.17470)

**車両間通信を強化するための動的スケジューリングと連合学習**

Jintao Yan, Tan Chen, Yuxuan Sun, Zhaojun Nan, Sheng Zhou, Zhisheng Niu

- 車両の計算能力とセンサ能力を活用して、連合学習をエッジトレーニングに適用
- V2V通信を強化する動的スケジューリング（VEDS）アルゴリズムを提案
- 長期的な確率最適化問題をオンライン混合整数非線形プログラミング問題に変換
- 提案したアルゴリズムは画像分類精度と軌道予測誤差を大幅に改善

新しい車両ネットワークの連合学習、とっても面白そうだね！移動しながらでも学習が進むなんて、未来の交通システムがますます楽しみだね！

**Comment:** Submitted to IEEE for possible publication

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, cs.IT, math.IT, **投稿日時:** 2024-06-25 11:15


- - -

### [Task-Agnostic Federated Learning](http://arxiv.org/abs/2406.17235)

**タスク非依存型連合学習**

Zhengtao Yao, Hong Nguyen, Ajitesh Srivastava, Jose Luis Ambite

- 医療画像の分野では、大規模データセットの共有がプライバシーの懸念により困難
- 連合学習（FL）はプライバシーを保護しつつ協調学習を可能にするが、タスクやデータの異質性、ラベルの不足などの課題がある
- Vision Transformer（ViT）を利用して自己教師型FLフレームワークを採用し、初期ラベルなしで効果的な表現学習を実現
- 実世界の非同一分布医療画像データセットでの評価により、中央集約アプローチの5％のデータで90％のF1精度を維持し、アウトオブディストリビューションタスクへの適応も優れる

プライバシー保護しながらみんなで学べるとかすごいね！未来の医療がどんどん進む感じがしてわくわくする!



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.AI, cs.DC, **投稿日時:** 2024-06-25 02:53


- - -

### [Robust Zero Trust Architecture: Joint Blockchain based Federated learning and Anomaly Detection based Framework](http://arxiv.org/abs/2406.17172)

**堅牢なゼロトラストアーキテクチャ：ブロックチェーンベースの連合学習と異常検出に基づく枠組み**

Shiva Raj Pokhrel, Luxing Yang, Sutharshan Rajasegarar, Gang Li

- IoTネットワークにおける効率的なリモートワークと協力を目指し、分散システム用の堅牢なゼロトラストアーキテクチャを提案。
- 悪意あるクライアントからの更新を防ぐため、ブロックチェーンベースの連合学習原則を使用した堅牢な集約メカニズムを開発。
- 異常検出と信頼計算を統合し、無監視クラスタリング技術でゼロデイ攻撃のような新たな異常を検出、デバイス間の安全な協力を実現。
- スケーラビリティ向上、ディリクレ過程による先進的異常検出、量子暗号技術の統合を含む将来的な方向性を提示。

IoTでも安全にリモートワークできるなんて、すごいね！これからは量子コンピュータにも負けない時代になりそうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DC, cs.LG, **投稿日時:** 2024-06-24 23:15


- - -

### [Achieving Fairness Across Local and Global Models in Federated Learning](http://arxiv.org/abs/2406.17102)

**連合学習におけるローカルおよびグローバルモデル間の公正性の実現**

Disha Makhija, Xing Han, Joydeep Ghosh, Yejin Kim

- FL（連合学習）ではデータの異質性やクライアントのプライベートデータの機密属性へのアクセス困難が公正性の課題
- \texttt{EquiFL}は、新たな公正性の用語をローカルの最適化目標に組み込み、公正性とローカル性能のバランスを取るアプローチ
- この協調メカニズムにより、クライアント間のコラボレーションフェーズでのバイアス伝播を防止
- 実験結果から、\texttt{EquiFL}はクライアントごとの正確性と公正性のバランスを実現し、均一な性能分布を保証することが示された

わぁ、この\texttt{EquiFL}っていうの、本当に皆に優しい感じで素敵だね！医療分野でそんな風に使われてるなんて感動的、もっと調べてみたくなっちゃうね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CY, **投稿日時:** 2024-06-24 19:42


- - -

### [Personalized federated learning based on feature fusion](http://arxiv.org/abs/2406.16583)

**特徴融合に基づくパーソナライズド連合学習**

Wolong Xing, Zhenkui Shi, Hongyan Peng, Xiantao Hu, Xianxian Li

- 連合学習はデータをローカルに保存したまま、分散クライアントが協力してトレーニングできる
- データやデバイスの異質性により、最終的なグローバルモデルの性能が低下する可能性
- 特徴アップロードにより通信コストを削減し、異質なクライアントモデルを許容
- 適切なハイパーパラメータ設定で、複数のデータセットで他のFL手法を上回る性能を実現

データの異質性に着目して新しいアプローチを提案するなんて、めっちゃ面白い！通信コストの削減もできるから、もっと応用されそうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, **投稿日時:** 2024-06-24 12:16


- - -

### [Exploring Cross-Domain Few-Shot Classification via Frequency-Aware Prompting](http://arxiv.org/abs/2406.16422)

**周波数認識プロンプトによるクロスドメイン小ショット分類の探求**

Tiange Zhang, Qing Cai, Feng Gao, Lin Qi, Junyu Dong

- クロスドメインの小ショット学習において、メタ学習の進展により大きな進歩を遂げた
- 多くの既存手法は高周波成分に依存する傾向があり、そのためノイズに弱くロバスト性が低下する
- 周波数認識プロンプト法を提案し、新しい認識タスクにおいて人間の視覚をシミュレーション
- 提案手法は既存のCD-FSL手法にも適用可能で、効果的かつ性能向上を実証

新しい手法のロバスト性を向上させるところが面白そう！メタ学習の進展と組み合わせて、どんな新しい応用が見つかるかな？



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.AI, **投稿日時:** 2024-06-24 08:14


- - -

### [Semi-Variance Reduction for Fair Federated Learning](http://arxiv.org/abs/2406.16193)

**フェアな連合学習のためのセミバリアンス削減**

Saber Malekmohammadi

- フェアネスを追求する連合学習（FL）は、異なるクライアントの公平な性能を確保する点で重要
- 既存のFLアルゴリズムは、最悪の性能を持つクライアントの損失関数を重視し、全体の平均性能を犠牲にすることが多い
- 提案手法のSemiVRedは、平均損失からの最悪のクライアントの損失関数の差異を減らす
- 実験で、異質なデータ分布下でフェアネスと全体平均性能を改善することを示した

いろんなデータセットで試してバランスを取るなんて、すごい興味が湧くよね！連合学習がどんどん進化していて、未来が楽しみだなぁ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CY, **投稿日時:** 2024-06-23 19:14


- - -

### [Meta-FL: A Novel Meta-Learning Framework for Optimizing Heterogeneous Model Aggregation in Federated Learning](http://arxiv.org/abs/2406.16035)

**Meta-FL: 連合学習における異種モデル統合を最適化する新しいメタ学習フレームワーク**

Zahir Alsulaimawi

- 連合学習（FL）は、データプライバシーを保護しつつ協調的なモデル訓練を可能にする
- データの異質性とモデルの多様性はFLの主要な課題
- Meta-FLは最適化ベースのMeta-Aggregatorを使用して異種モデル更新の複雑さを解決
- 実証評価では、Meta-FLが従来のFL手法を上回る適応性、効率性、拡張性、および堅牢性を示した

新しいフレームワークがFLの課題をどう解決するかって興味深いよね！特に少ない通信回数で高精度を実現できるって、実用化につながりそうでワクワクする！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-06-23 06:57


- - -

### [Privacy Preserving Machine Learning for Electronic Health Records using Federated Learning and Differential Privacy](http://arxiv.org/abs/2406.15962)

**連合学習と差分プライバシーを用いた電子カルテのプライバシー保護機械学習**

Naif A. Ganadily, Han J. Xia

- 電子カルテは診断、治療、費用などの個人情報を含む
- 機械学習は患者データを分析し、ケアの改善に役立つ
- 社会保障番号や住所などの機密情報が含まれているため、プライバシー保護技術が必要
- 連合学習と差分プライバシーを用いて、これらの機械学習モデルのプライバシーを保護することが重要

プライバシー保護しながら医療データを活用できるってすごいよね。未来の医療がもっと効率的になる予感。

**Comment:** 5 pages, 12 figures

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.ET, **投稿日時:** 2024-06-23 00:01


- - -

### [Federated Adversarial Learning for Robust Autonomous Landing Runway Detection](http://arxiv.org/abs/2406.15925)

**ロバストな自律着陸滑走路検出のための連合敵対学習**

Yi Li, Plamen Angelov, Zhengxin Yu, Alvaro Lopez Pellicer, Neeraj Suri

- 自律着陸システムの深層学習技術発展のなかで、信頼性とセキュリティが主要な課題
- 連合敵対学習を用いたフレームワークを提案、クリーンなデータと敵対的データを組み合わせ
- 大規模な車線検出データセットで事前学習を行い、SSFによる効率的なパラメータ調整の手法を使用
- 著者の知る限り、連合学習で敵対サンプル問題に対処する初の試みであり、実験評価で高い性能を示す

自律着陸技術に連合学習を取り入れるなんてすごく面白そう！これでより安全に飛行機が降りられるようになるかもね。

**Comment:** ICANN2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, **投稿日時:** 2024-06-22 19:31


- - -

### [Split Federated Learning Empowered Vehicular Edge Intelligence: Adaptive Parellel Design and Future Directions](http://arxiv.org/abs/2406.15804)

**スプリット連合学習を活用した車載エッジインテリジェンス：適応型並列設計と将来の方向性**

Xianke Qiang, Zheng Chang, Chaoxiong Ye, Timo Hamalainen

- 車載ネットワークの知識をAIで掘り起こし、AI駆動サービスの品質を向上させる重要性
- 車載エッジインテリジェンス（VEI）は車両の計算、保存、通信資源を活用してAIモデルを訓練
- 伝統的な集中型学習はデータを中央サーバーへアップロードし、通信過負荷とプライバシーリスクが発生
- 分散機械学習方式であるスプリット連合学習（SFL）を提案し、その適応型並列設計と性能分析を実施

車とAIの融合って何か未来感がすごいよね！プライバシーも守られて安心だし、早くこの技術が普及してほしいな。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-06-22 10:15


- - -

### [Breaking Secure Aggregation: Label Leakage from Aggregated Gradients in Federated Learning](http://arxiv.org/abs/2406.15731)

**連合学習におけるラベル漏洩：集約された勾配からのプライバシー侵害**

Zhibo Wang, Zhiwei Chang, Jiahui Hu, Xiaoyi Pang, Jiacheng Du, Yongle Chen, Kui Ren

- 連合学習（FL）は勾配逆転攻撃（GIA）に対してプライバシー脆弱性を持つ
- セキュアアグリゲーション（SA）は、サーバーが個々の勾配を取得できないようにし、GIAに効果的に対抗する
- 本研究では、SAを無効化し個々のクライアントのラベルを回復するための攻撃手法（ラベル推論攻撃）を提案
- 実験により、この攻撃が様々なデータセットやモデルアーキテクチャで100%の精度でラベルを回復可能であることを示した

ラベルをこんなに簡単に抜き取るとはビックリ！連合学習の未来がちょっと心配になっちゃうけど、対策の進展も楽しみね。

**Comment:** 10 pages, conference to IEEE INFOCOM 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-06-22 04:42


- - -

### [Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach](http://arxiv.org/abs/2406.15346)

**プライバシー保護された血糖値クロス予測：非同期分散型連合学習アプローチ**

Chengzhe Piao, Taiyu Zhu, Yu Wang, Stephanie E Baldeweg, Paul Taylor, Pantelis Georgiou, Jiahao Sun, Jun Wang, Kezhi Li

- 新規T1D患者はCGMデータが不足しており、血糖値予測モデルの「コールドスタート問題」に直面
- 患者データをプライバシーに配慮し収集することが人口モデルには課題
- 「GluADFL」を提案し、分散連合学習でプライバシーを保護しつつ血糖値を予測
- 298名のデータで8つのベースライン手法と比較し、高い予測精度を確認

個人のデバイスに保存されたデータを用いる連合学習なんて、未来だよね！どんなネットワーク構造でも対応できるみたいだから、実際の社会での応用が広がりそう。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-06-21 17:57


- - -

### [Rate-Splitting Multiple Access for Overloaded Multi-group Multicast: A First Experimental Study](http://arxiv.org/abs/2406.15217)

**過負荷マルチグループマルチキャスト用レートスプリッティング複数アクセスの初実験研究**

Xinze Lyu, Sundar Aditya, Bruno Clerckx

- レートスプリッティング複数アクセス（RSMA）は多ユーザ無線通信の干渉管理技術である
- RSMAベース、空間分割多重アクセス（SDMA）ベース、非直交多重アクセス（NOMA）ベースの三者比較を実施
- 2つのアンテナ送信機と各グループ2つのアンテナユーザで構成された測定セットアップを使用
- RSMAベースMGMは、各グループのスループットでSDMAおよびNOMAを上回る公平性を実現

RSMAが理論通りの性能を実証したなんて興味深いよね！実験での公平性の高さ、本当にすごい♡

**Comment:** Submitted to IEEE Transactions on Broadcasting

**トピック:** [連合学習](../../fl), **カテゴリ:** eess.SP, cs.IT, math.IT, **投稿日時:** 2024-06-21 15:00


- - -

### [Embracing Federated Learning: Enabling Weak Client Participation via Partial Model Training](http://arxiv.org/abs/2406.15125)

**連合学習の採用：部分モデル訓練による弱いクライアント参加の実現**

Sunwoo Lee, Tuo Zhang, Saurav Prakash, Yue Niu, Salman Avestimehr

- 部分モデル訓練法により、システムリソースが不足しているクライアントも参加可能にするフレームワークを提案
- 各クライアントが使用可能なリソースに応じて連続する出力層を訓練し、効率性を向上
- 非凸で滑らかな問題に対して収束を保証し、全体として高い正確性を維持
- 大規模な評価で、既存の幅削減方法（HeteroFLやFjORD）よりも高い性能を示す

部分モデル訓練が小さなデバイスでも連合学習に貢献できるようにするってすごいね！これからもっと多様なクライアントが連合学習に参加できる未来が楽しみ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-06-21 13:19


- - -

### [Supersonic OT: Fast Unconditionally Secure Oblivious Transfer](http://arxiv.org/abs/2406.15529)

**Supersonic OT: 高速無条件安全なオブリビアストランスファー**

Aydin Abadi, Yvo Desmedt

- OTは安全なマルチパーティ計算、連合学習、プライベートセットインターセクションにおいて重要
- ポスト量子時代に向けて無条件安全なOTの開発が必要
- 既存のOTは計算仮定に依存しているが、「Supersonic OT」はこれを回避
- 単一インスタンスが0.35ミリ秒で完了し、最新技術の2000倍高速

量子コンピュータに耐えられる無条件安全な技術なんてすごくない？しかも2000倍も速いとか、とても未来が楽しみ！

**Comment:** arXiv admin note: text overlap with arXiv:2406.15063

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.DB, cs.LG, **投稿日時:** 2024-06-21 11:50


- - -

### [Tempora-Fusion: Time-Lock Puzzle with Efficient Verifiable Homomorphic Linear Combination](http://arxiv.org/abs/2406.15070)

**Tempora-Fusion: 効率的な検証可能な準同型線形結合を用いた時限ロックパズル**

Aydin Abadi

- 時限ロックパズル(TLP)は未来への機密情報の安全な送信方法である
- 準同型TLPは異なるクライアントのパズル上での計算を可能にする重要な変種
- Tempora-Fusionは計算結果の検証を可能にし、非対称鍵暗号を避けて効率的な実装を実現
- このスキームは連合学習、オンライン銀行での予定支払い、電子投票などに応用可能

既存の課題を解決し、未来の技術に光を当てるのがTempora-Fusionなんだね。これなら安心していろんなサービスが使える！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.CE, cs.LG, **投稿日時:** 2024-06-21 11:40


- - -

### [Towards Dynamic Resource Allocation and Client Scheduling in Hierarchical Federated Learning: A Two-Phase Deep Reinforcement Learning Approach](http://arxiv.org/abs/2406.14910)

**階層型連合学習における動的リソース配分とクライアントスケジューリングに向けたアプローチ: 二段階深層強化学習法**

Xiaojing Chen, Zhenyuan Li, Wei Ni, Xin Wang, Shunqing Zhang, Yanzan Sun, Shugong Xu, Qingqi Pei

- 連合学習（FL）はデータを共有せずに機械学習モデルを訓練する有望な技術である
- 階層型FL（HFL）システムでは、エネルギー、計算、通信、クライアントスケジューリングが複数層で複雑
- 二段階深層決定政策勾配（DDPG）フレームワーク「TP-DDPG」を提案し、エネルギー収集で動くHFLシステムの学習遅延とモデル精度をオンラインで調整
- TP-DDPGは迅速に有効な政策に収束し、HFLの訓練時間をベンチマークと比較して39.4%短縮可能

エネルギーを収集しながら学習するってめっちゃエコじゃん！これからのデバイスはもっと環境に優しくなるかもね。未来が楽しみだなぁ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, math.OC, **投稿日時:** 2024-06-21 07:01


- - -

### [Safely Learning with Private Data: A Federated Learning Framework for Large Language Model](http://arxiv.org/abs/2406.14898)

**プライベートデータで安全に学習する：大規模言語モデルのための連合学習フレームワーク**

JiaYing Zheng, HaiNan Zhang, LingXiang Wang, WangJie Qiu, HongWei Zheng, ZhiMing Zheng

- プライベートデータは公共データよりも質が高く、大規模言語モデルの改善が可能
- フェデレーテッドラーニング（FL）は分散したプライベートデータでもモデルを訓練可能だが、従来の方法では計算負荷が高すぎる
- スプリットラーニングはサーバーにほとんどのパラメータを任せるが、セキュリティと効率に課題がある
- 提案するFL-GLMはデータリーク防止と効率改善を実現し、実験で中央集約型モデルに匹敵する性能を示す

分散化とセキュリティの両方を見事に両立している感じが面白いよね！実験での結果もすごく期待できそう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.CL, **投稿日時:** 2024-06-21 06:43
