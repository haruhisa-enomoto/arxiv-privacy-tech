---
title: 差分プライバシー (2024-12-06 ~ 2024-12-12)
date: 2024-12-06
---

差分プライバシーに関する論文まとめ (2024-12-06 ~ 2024-12-12)


- - -

### [Numerical Estimation of Spatial Distributions under Differential Privacy](http://arxiv.org/abs/2412.06541)

**差分プライバシーを用いた空間分布の数値推定**

Leilei Du, Peng Cheng, Libin Zheng, Xiang Lian, Lei Chen, Wei Xi, Wangze Ni

- 空間分布の推定は交通予測や疫病予防に重要だが、ユーザーデータ収集はプライバシーを侵害する恐れがある
- 既存の一部の手法は一次元データに依存し、空間データの関連性を考慮せず誤差が大きい
- 提案されたDisk Area Mechanism (DAM)は空間データを一次元に射影し推定精度を向上させる
- DAMは最新手法と比べて一貫して優れた成果を見せ、データの細かさに依存せずに優位性を示す

空間データをうまく一元化して扱うアイデアが新鮮だし、実験結果が他の手法よりいいっていうのはすごいよね！これならプライバシーを守りながらも正確な予測できちゃうかもってワクワクしちゃう！

**Comment:** ICDE 2025

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.DB, **投稿日時:** 2024-12-09 14:53


- - -

### [Lightweight Federated Learning with Differential Privacy and Straggler Resilience](http://arxiv.org/abs/2412.06120)

**差分プライバシーと遅延耐性を備えた軽量な連合学習**

Shu Hong, Xiaojun Lin, Lingjie Duan

- 連合学習でモデルパラメータ交換による推論攻撃を差分プライバシーで防ぐ。
- 差分プライバシーと秘密計算の組み合わせは精度を上げるが、通信負荷が高い。
- 提案手法LightDP-FLは、低遅延、多数の騒音変異を利用してプライバシーを実現。
- CIFAR-10を用いた実験で、提案手法はより速い収束と優れた遅延耐性を示す。

これってめっちゃ便利そう！新しい手法で効率的にプライバシーを守りつつ、速く学習できるなんてすごいよね。これからのデータ時代にピッタリかも！

**Comment:** To appear at IEEE International Conference on Computer Communications   (INFOCOM) 2025

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DC, **投稿日時:** 2024-12-09 00:54


- - -

### [Privacy-Preserving Large Language Models: Mechanisms, Applications, and Future Directions](http://arxiv.org/abs/2412.06113)

**プライバシー保護型大規模言語モデル: メカニズム、応用、将来の方向性**

Guoshenghui Zhao, Eric Song

- 大規模言語モデルは様々な分野で活用される一方、データ漏洩などのプライバシー問題が懸念されている
- 差分プライバシーや連合学習などを用いたプライバシー保護メカニズムを検討し、プライバシー問題解決の効果を分析
- プライバシー重視分野での応用例と限界を紹介し、プライバシーとモデルの有用性のバランスを考慮
- 大規模言語モデルのライフサイクルにプライバシーを組み込むための新しいフレームワークの必要性を指摘

プライバシーと性能の両立ってホントに難しいよね。でも、この研究はそのバランスを上手く取りつつ、これからの方向性も示してて期待大！プライバシーの未来は明るいかもね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-12-09 00:24


- - -

### [Adversarially Robust Dense-Sparse Tradeoffs via Heavy-Hitters](http://arxiv.org/abs/2412.05807)

**敵対的状況に対する高密度-疎密トレードオフの実現**

David P. Woodruff, Samson Zhou

- 敵対的なストリーミングモデルでデータセットの統計を小さな空間で近似する手法を研究
- 既存技術を用いた高密度-疎密トレードオフ技術が敵対的耐性の$L_p$推定を実現
- 改善された敵対的耐性の$L_p$-ヘビーヒッターアルゴリズムを提案し、効率向上
- クラシカルなストリーミング設定用の新アルゴリズムで頻度モーメント推定を改善

敵対的な環境でのアルゴリズムとか重みのトレードオフが面白そう！より効率的な推定方法が実際にどう役立つか気になるね。området

**Comment:** NeurIPS 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, **投稿日時:** 2024-12-08 04:09


- - -

### [DeMem: Privacy-Enhanced Robust Adversarial Learning via De-Memorization](http://arxiv.org/abs/2412.05767)

**DeMem: 逆記憶化によるプライバシー強化型のロバスト敵対的学習**

Xiaoyu Luo, Qiongxiu Li

- 敵対的ロバスト性はモデルの信頼性に必須だが、プライバシー攻撃に弱くなる
- 差分プライバシーはプライバシー攻撃を軽減するが、サンプルのロバスト性を損なう
- DeMemを提案し、高リスクサンプルに焦点を当てロバスト性とプライバシーのバランスを向上
- DeMemは複数の訓練方法やデータセットで有効性が確認されている

DeMemって面白そうじゃない？プライバシーを守りながらモデルの強さを保てるなんていい感じ！普段使ってるアプリにも応用される日が来るかもって考えたらワクワクするよね。

**Comment:** 8 pages

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-12-08 00:22


- - -

### [Can large language models be privacy preserving and fair medical coders?](http://arxiv.org/abs/2412.05533)

**大規模言語モデルはプライバシー保護と公平な医療コード化が可能か？**

Ali Dadsetan, Dorsa Soleymani, Xijie Zeng, Frank Rudzicz

- 医療における機械学習のプライバシー保護は重要な課題
- 差分プライバシー適用でパフォーマンス低下、特にMIMIC-IIIデータで40%以上のマイクロF1スコア減少
- プライバシーと公平性のトレードオフで、男女間のリコールギャップが3%以上増加
- トレードオフの理解が現実世界での課題解決に役立つ可能性

難しいテーマだね！プライバシーを守りながら、医療分野のAIをどれだけ公平に使えるか注目だよね。もっと多くのデータで検証してみる価値がありそう～。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-12-07 04:27


- - -

### [Upcycling Noise for Federated Unlearning](http://arxiv.org/abs/2412.05529)

**連合学習におけるノイズのアップサイクリングによる忘却**

Jianan Chen, Qin Hu, Fangtian Zhong, Yan Zhuang, Minghui Xu

- 連合学習は生データを共有せずに複数のクライアントでモデルを訓練するが、差分プライバシーで保護される
- クライアントの「忘れられる権利」を満たすには、差分プライバシー連合学習が新たな課題となる
- 提案手法FUIは、差分プライバシー連合学習内で目標クライアントのデータを初めて忘却する方法
- 実験では、提案手法FUIが他の主流の忘却手法より優れた性能と効率を示すことを確認

この研究楽しいね！連合学習の新しい課題を解決する方法って、すごくわくわくするよね。難しい問題を解決するための新しい道筋が具体的に見えてきて、私も挑戦してみたいって思ったよ！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-12-07 04:07


- - -

### [Information Flows for Athletes' Health and Performance Data](http://arxiv.org/abs/2412.05055)

**アスリートの健康とパフォーマンスデータの情報フロー**

Brad Stenger, Yuanyuan Feng

- アスリートとチームがデータ技術を利用しパフォーマンス向上を目指すが、データプライバシーは低優先度
- 文脈的整合性に基づき、適切な情報フローの必要性が高まっている
- チーム中心と個人中心の2つの情報フローを提案し、アスリートの成長を支援
- 差分プライバシーを導入し、研究中心とコミュニティ中心の大規模情報共有シナリオも提示

アスリートのデータをもっと活用して、強くて優しいチームを作れる未来が見えるかも！プライバシーにもしっかり配慮しているのがかっこいい！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.HC, H.5; J.3; K.5, **投稿日時:** 2024-12-06 14:10


- - -

### [Differentially Private Random Feature Model](http://arxiv.org/abs/2412.04785)

**差分プライバシーを用いたランダムフィーチャーモデル**

Chunyang Liao, Deanna Needell, Alexander Xue

- 機械学習におけるプライバシー保護は注目され、差分プライバシーはよく用いられる。
- ランダムフィーチャーを用い、プライバシーを保つ新たなモデルを開発。
- この手法はオーバーパラメトリックな状況で理論的な保証を提供し、私的なモデルを生成。
- ランダムフィーチャーにより、差分プライバシーの偏りを軽減し公平性を改善する可能性がある。

この論文では、ランダムフィーチャーを使ってプライバシーを守りつつ学習する方法を提案しているところが面白そう。理論と実験の両方で公平性を高めるって、重要なポイントだね！

**Comment:** Submitted to an IEEE journal

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-12-06 05:31


- - -

### [Privacy-Preserving Retrieval Augmented Generation with Differential Privacy](http://arxiv.org/abs/2412.04697)

**差分プライバシーによるプライバシー保護型の検索増強生成**

Tatsuki Koga, Ruihan Wu, Kamalika Chaudhuri

- 大規模言語モデル(LLM)は、機密性の高いデータを扱う分野での利用が増加
- 検索増強生成(RAG)は、外部知識からの情報提供でLLMを補助する
- RAGの出力が機密情報を漏洩しないよう、差分プライバシー(DP)を探求
- プライバシー予算を効果的に活用するアルゴリズムで長文正確回答を実現

プライバシーを守りながらも、ちゃんとまともな文章を生成できちゃうとかすごくない!? この研究が進むともっと安心してデータを使える未来がきそうだね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.CL, **投稿日時:** 2024-12-06 01:20
