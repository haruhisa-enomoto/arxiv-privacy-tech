---
title: 差分プライバシー (2024-09-27 ~ 2024-10-03)
date: 2024-09-27
---

差分プライバシーに関する論文まとめ (2024-09-27 ~ 2024-10-03)


- - -

### [Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation](http://arxiv.org/abs/2410.02912)

**差分プライバシーを用いた自動調整型ノイズ割り当てによる言語モデルの微調整**

Xianzhi Li, Ran Zmigrod, Zhiqiang Ma, Xiaomo Liu, Xiaodan Zhu

- 言語モデルは詳細なパターンを記憶し、プライバシーリスクをもたらす
- 従来の差分プライバシーは一様なノイズ分布でプライバシーを守るが、最適ではない
- 提案手法ANADPは、モデルパラメータの重要性に基づきノイズを自動で調整する
- ANADPにより従来法とプライバシー維持の差を縮小し、性能を向上させることができる

差分プライバシーの使い方って難しそうだし、ANADPみたいに状況に応じた調整ができるのはすごく便利だね！これが普及すれば、AIのセキュリティももっと安心できそうで期待大♡

**Comment:** EMNLP 2024 findings

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.AI, cs.CL, cs.CR, cs.LG, **投稿日時:** 2024-10-03 19:02


- - -

### [Addressing Data Heterogeneity in Federated Learning with Adaptive Normalization-Free Feature Recalibration](http://arxiv.org/abs/2410.02006)

**連合学習におけるデータの不均一性を適応的な正規化不要の特徴再調整で解決**

Vasilis Siomos, Sergio Naval-Marimont, Jonathan Passerat-Palmbach, Giacomo Tarroni

- 連合学習は分散協調訓練手法でデータオーナーシップを保持しつつ性能向上を図る。
- クライアント間の統計的異質性がシステム性能を低下させる課題を解決するためにANFRを提案。
- ANFRは重み標準化とチャンネルアテンションを組み合わせ、クライアント間での不一致を抑制。
- 差分プライバシー下でも強力なプライバシー保証を維持しつつ性能を犠牲にしない。

新しい手法を提案することで、連合学習をもっと効率的にできるんだね。特に異質性っていう難しい問題を解決しつつプライバシーを守れるっていうのが魅力的。もっと色んな現場で応用されるとすごく面白そう！

**Comment:** 10 pages

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CV, **投稿日時:** 2024-10-02 20:16


- - -

### [Differentially Private Parameter-Efficient Fine-tuning for Large ASR Models](http://arxiv.org/abs/2410.01948)

**大型ASRモデルのための差分プライバシーによるパラメーター効率良好な微調整**

Hongbin Liu, Lun Wang, Om Thakkar, Abhradeep Thakurta, Arun Narayanan

- 大型ASRモデルは差分プライバシーを用いることでプライバシー漏れを軽減できる。
- 従来の差分プライバシー訓練は計算コストが高く、モデル性能に悪影響を及ぼす可能性がある。
- 差分プライバシーを考慮したパラメーター効率良好な微調整で計算と性能のコストを削減。
- 微調整で新しい性能基準を達成し、(10, 3.52e-6)-DPを維持しながら優れた結果を報告。

大規模モデルで安全性と効率性の両立ができるなんて素敵じゃない？機械学習の未来がますます楽しみだよね！プライバシーを守りつつ、高性能も実現する技術がさらに進化しそうでワクワクする。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-02 18:49


- - -

### [Efficient and Private Marginal Reconstruction with Local Non-Negativity](http://arxiv.org/abs/2410.01091)

**効率的かつプライベートな周辺再構成技術と局所的非負性**

Brett Mullins, Miguel Fuentes, Yingtai Xiao, Daniel Kifer, Cameron Musco, Daniel Sheldon

- 差分プライバシーに基づく質問応答や合成データ生成では、クエリに対する回答の再構成が重要
- ReMという効率的な後処理方法を用い、周辺クエリの回答再構成を実現
- 媒介変数を用いて効率的な擬似逆を可能にする手法が導入され、再構成に寄与
- GReM-LNN拡張により、ガウスノイズ下で一貫性と非負性を満たしエラーを軽減

プライバシー技術とデータ処理の両立を目指してるのが面白いよね！どれだけエラー減らせるか実用的にも期待できそう。研究結果が早く現場で活かされるといいな🌟

**Comment:** To appear at NeurIPS 2024

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-01 21:39


- - -

### [Convergent Privacy Loss of Noisy-SGD without Convexity and Smoothness](http://arxiv.org/abs/2410.01068)

**非凸・非スムーズな損失に対するノイジーSGDのプライバシー損失の収束**

Eli Chien, Pan Li

- ノイジーSGDでの通常のプライバシー分析は、内部状態の公開を仮定している
- 非凸・非スムーズな損失に対しても収束する差分プライバシーを証明
- H\"older連続な勾配があれば十分であり、滑らかな強凸損失よりも良いプライバシー限界を提供
- 改良されたシフトダイバージェンス分析を利用し、多方面からアプローチした

プライバシー保証が非凸で非スムーズな状況でも適用できるなんてすごいよね！もっと色んな機械学習の場面で差分プライバシーが活躍できそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-01 20:52


- - -

### [Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting](http://arxiv.org/abs/2410.00751)

**差分プライバシーにとどまらない発想：言語モデルによるテキストプライバタイズのケーススタディ**

Stephen Meisenbacher, Florian Matthes

- 大規模言語モデルの普及に伴い、プライバシー保護を施した自然言語処理が注目されている
- 差分プライバシー(DP)はNLPへの統合で支持されるが、制約と課題がある
- DP-Promptは、言語モデルを用いてテキストを再構築する新しいプライバタイズ手法
- 実験結果は、DPと非DPアプローチの利点と課題についてさらなる議論の必要性を示している

DP-Promptが、言語モデルを活用してどうやってテキストのプライバシーを守るのか気になる！実際の利用シーンにおいて、どれだけ便利に使えるのか、もっと深掘りしてみたいな。

**Comment:** 10 pages, 3 tables, Accepted to EMNLP 2024 (Main)

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CL, **投稿日時:** 2024-10-01 14:46


- - -

### [Differentially Private Active Learning: Balancing Effective Data Selection and Privacy](http://arxiv.org/abs/2410.00542)

**差分プライバシーを活用したアクティブラーニング: 効果的なデータ選択とプライバシーのバランス**

Kristian Schwethelm, Johannes Kaiser, Jonas Kuntzer, Mehmet Yigitsoy, Daniel Rueckert, Georgios Kaissis

- アクティブラーニングと差分プライバシーの組み合わせの課題を探求
- 差分プライバシーSGDを統合する際の予算配分とデータ利用困難を発見
- データ利用を最適化するステップ増幅法を提案し効果を実証
- プライバシー制約下で使用する取得関数の限界を明らかに

プライバシーを守りながらしっかりとデータを活かす方法が見つかるといいね！アクティブラーニングって言葉だけ聞くとすごく積極的なイメージだけど、プライバシーとのバランスって難しいんだね。でも、新しい提案が明日をもっと明るくしてくれるかも！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-01 09:34


- - -

### [Survey of Security and Data Attacks on Machine Unlearning In Financial and E-Commerce](http://arxiv.org/abs/2410.00055)

**金融および電子商取引における機械学習虚勢に対するセキュリティおよびデータ攻撃の調査**

Carl E. J. Brodzinski

- 機械学習虚勢に対する主要なプライバシー脅威として、メンバーシップ推論攻撃やデータ再構成攻撃を紹介
- 機械学習虚勢データ中毒、虚勢要求攻撃、虚勢ジェイルブレイク攻撃などのセキュリティ攻撃を分析
- 差分プライバシーや暗号的保証、ゼロ知識証明による防御戦略を紹介、検証可能で改ざん防止のメカニズム提供
- 金融や電子商取引でのデータ整合性とプライバシー保護のため、進化する攻撃ベクトルに対抗する防御が重要

機械学習の虚勢技術をめぐるセキュリティの世界ってすっごく面白そう！金融とかの大事なデータを守るために、新しい技術や考え方をもっとたくさん勉強してみたいって思ったよ。どんな攻撃が来ても負けないように、ますます安全な仕組みを作れたら最高だよね！



**トピック:** [差分プライバシー](../../dp), [ゼロ知識証明](../../zkp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-09-29 00:30


- - -

### [Subject Data Auditing via Source Inference Attack in Cross-Silo Federated Learning](http://arxiv.org/abs/2409.19417)

**クロスサイロ連合学習におけるソース推論攻撃を用いた主体データ監査**

Jiaxin Li, Marco Arazzi, Antonino Nocera, Mauro Conti

- 連合学習のソース推論攻撃（SIA）は、特定のデータポイントを使用したクライアントを特定
- クロスサイロ連合学習では複数の主体からデータ収集し、情報漏えいのリスクが高まる
- 提案するSLSIAは、既存の制約を取り除き、対象データ使用のクライアントを正確に検出
- 差分プライバシー機構を用いて、SLSIAに対する防御策を提案

クライアントのデータ使用をチェックする攻撃で、連合学習の新しい視点が広がるのめっちゃ面白そう。確かに情報漏えいは怖いから、防御策とセットで考えるのが重要だね！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-09-28 17:27


- - -

### [Federated Online Prediction from Experts with Differential Privacy: Separations and Regret Speed-ups](http://arxiv.org/abs/2409.19092)

**差分プライバシーによる連合型専門家のオンライン予測：分離と後悔のスピードアップ**

Fengyu Gao, Ruiquan Huang, Jing Yang

- 確率的な敵に対してFed-DP-OPE-Stochアルゴリズムを提案。クライアントごとの後悔が$\sqrt{m}$倍速で改善される。
- 通信コストは対数的に抑えつつ、純粋DPと近似DPの制約下で有効に機能。
- 一般的な無視する敵に対するクライアントの協力は後悔のスピードアップに寄与しないことを示す下限を確立。
- 低損失専門家の特殊ケースでは、Fed-SVTアルゴリズムが$m$倍の後悔スピードアップを達成し、実験による有効性も確認。

すごーく面白そう！特に、クライアント協力の限界や特殊ケースで劇的に改善できるところが斬新。発展的な研究が期待されるね。

**Comment:** Accepted to NeurIPS 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.ML, **投稿日時:** 2024-09-27 18:43


- - -

### [Differential privacy for protecting patient data in speech disorder detection using deep learning](http://arxiv.org/abs/2409.19078)

**深層学習を用いた発話障害検出における患者データ保護のための差分プライバシー**

Soroosh Tayebi Arasteh, Mahshad Lotfinia, Paula Andrea Perez-Toro, Tomas Arias-Vergara, Juan Rafael Orozco-Arroyave, Maria Schuster, Andreas Maier, Seung Hee Yang

- 発話障害の診断にはプライバシーの重要性がある
- 差分プライバシー（DP）の適用で最大3.85%の診断精度低下を観測
- 大規模データでの事前訓練によりDPでも診断精度を維持・向上可能
- 年齢による不公平が残るも、性別に対する重大なバイアスは発生しない

DPが発話障害検出でも効果的なんだね！年齢の不公平さはちょっとだけ問題だけど、この技術って本当に未来の医療を支えそうで楽しみだよね。いますぐクラスで発表したくなる内容じゃない？



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, cs.SD, eess.AS, **投稿日時:** 2024-09-27 18:25


- - -

### [CURATE: Scaling-up Differentially Private Causal Graph Discovery](http://arxiv.org/abs/2409.19060)

**CURATE：差分プライバシーをスケールアップした因果グラフ発見**

Payel Bhattacharjee, Ravi Tandon

- 因果グラフ発見（CGD）は、データセットの特徴間の結合分布を表す確率グラフモデルを推定するプロセス
- CGDアルゴリズムは2つに分類され、制約ベースアルゴリズムとスコアベースアルゴリズムが存在する
- 差分プライバシー（DP）は観測データのプライバシー保護のために採用されているが、同じ量のノイズを加えると予測性能に影響を与える
- CURATEは、適応的なプライバシー予算配分を行うことで、精度を保ちながらプライバシー漏洩を抑えた新しいDP-CGDフレームワークである

CURATEが実際にどれくらい効果があるのか気になる！これが普及したらもっと安全にデータ解析が進みそうだよね。どんな結果になるのか期待！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.IT, cs.LG, math.IT, stat.ME, **投稿日時:** 2024-09-27 18:00


- - -

### [Differentially Private Non Parametric Copulas: Generating synthetic data with non parametric copulas under privacy guarantees](http://arxiv.org/abs/2409.18611)

**差分プライバシーを用いた非パラメトリックコピュラ：プライバシー保証下での合成データ生成**

Pablo A. Osorio-Marulanda, John Esteban Castro Ramirez, Mikel Hernández Jiménez, Nicolas Moreno Reyes, Gorka Epelde Unanue

- 非パラメトリックコピュラに差分プライバシーを導入し、DPNPCモデルを強化
- DPNPCモデルは混合タブラー型データベースの合成データ生成をプライバシーを保ちながら実施
- 公開データセットを用いて他の3つのモデル（PrivBayes、DP-Copula、DP-Histogram）と比較
- DPNPCは多変量依存のモデリングで優れ、プライバシーを保ちながら学習時間を短縮

プライバシー守りながらこんなに性能良いのすごいね！未来の研究でさらに進化しそうで楽しみ〜！

**Comment:** 12 pages, 5 figures, deciding 2025 conference to which to submit

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.DB, 62H05, 62G32, I.2.6; H.2.8; G.3, **投稿日時:** 2024-09-27 10:18
