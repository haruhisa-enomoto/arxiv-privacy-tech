---
title: 差分プライバシー (2024-10-25 ~ 2024-10-31)
date: 2024-10-25
---

差分プライバシーに関する論文まとめ (2024-10-25 ~ 2024-10-31)


- - -

### [Differentially Private Learned Indexes](http://arxiv.org/abs/2410.21164)

**差分プライバシーを備えた学習インデックス**

Jianzhang Du, Tilak Mudgal, Rutvi Rahul Gadre, Yukui Luo, Chenghong Wang

- 検索効率化のためのインデックスは暗号化データベースでは漏洩リスクが高い。
- 差分プライバシーでノイズを加える方法はプライバシーを守れるが、ストレージコストが大きい。
- 学習インデックス技術を利用し、コンパクトな差分プライバシーインデックスを構築する提案。
- 提案手法は鍵空間のサイズに対するインデックスサイズを大幅に削減できる。

データベース内の検索にもプライバシーが大事だよね！そのうえで省スペースな保護方法を考えたなんて、実用化が楽しみ〜。この技術が広まれば、もっと安全なデータ処理が進みそう！



**トピック:** [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.DB, cs.CR, cs.LG, **投稿日時:** 2024-10-28 16:04


- - -

### [Privacy-Enhanced Adaptive Authentication: User Profiling with Privacy Guarantees](http://arxiv.org/abs/2410.20555)

**プライバシー強化型適応認証: プライバシー保証を伴うユーザープロファイリング**

Yaser Baseri, Abdelhakim Senhaji Hafid, Dimitrios Makrakis

- ユーザープロファイリングは適応リスク認証に不可欠だが、プライバシーの懸念が大きい。
- 新たな認証プロトコルはOPRFと差分プライバシーを用いてユーザーのプライバシーを強化。
- 暗号技術がデータの機密性や整合性を確保し、差分プライバシーでデータ点の影響を低減。
- プロトコルの計算・通信負荷は現実的で、GDPRなどの法律とも整合性がある。

ユーザーのプライバシーを守りつつ認証プロセスを強化する技術って、未来的でかっこいいよね！プライバシーの問題を配慮することで、企業の信頼性がぐっと高まりそう～。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-27 19:11


- - -

### [FL-DABE-BC: A Privacy-Enhanced, Decentralized Authentication, and Secure Communication for Federated Learning Framework with Decentralized Attribute-Based Encryption and Blockchain for IoT Scenarios](http://arxiv.org/abs/2410.20259)

**FL-DABE-BC: IoTシナリオのためのプライバシー強化、分散型認証、および安全な通信を備えた連合学習フレームワーク**

Sathwik Narkedimilli, Amballa Venkata Sriram, Satvik Raghav

- 連合学習でIoTデバイスのデータを安全に扱うために分散属性ベースの暗号化とブロックチェーンを利用
- ホモモルフィック暗号化で暗号化されたデータ上の計算を許可し、秘密計算で協力的計算のプライバシーを確保
- ローカルモデルの重みは暗号化され、フォグ層に送信して差分プライバシーで中央サーバーでの漏洩を防ぐ
- このシステムは分散IoTデバイスにおける効率的なモデル訓練とリアルタイム分析を可能にする

IoTデバイスに直接分散型認証と暗号化ができるのすごいね！この技術でデータ漏洩のリスクが減ると嬉しいな。セキュリティとプライバシーの同時実現、ワクワクしちゃう！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-10-26 19:30


- - -

### [Privacy without Noisy Gradients: Slicing Mechanism for Generative Model Training](http://arxiv.org/abs/2410.19941)

**ノイズのない勾配でプライバシーを守る：生成モデル訓練のためのスライス機構**

Kristjan Greenewald, Yuancheng Yu, Hao Wang, Kai Xu

- 差分プライバシーで生成モデルを訓練する際のノイズ注入がハイパーパラメータ調整の障害に
- スライスプライバシー機構で低次元に圧縮、ノイズを加えて強力なプライバシー保証を提供 
- スムーズスライス$f$-発散を導入、統計的一貫性を持ち、敵対的訓練が不要
- 数値実験で高品質な合成データを生成し、柔軟なモデル調整が可能に

プライバシーを守りつつも、ノイズに頼らないでデータ生成ができるのって、すっごく効率的かも！これからのデータサイエンスに革命を起こしそうで、ワクワクしちゃうね！

**Comment:** accepted to Neurips 2024

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-25 19:32


- - -

### [Noise-Aware Differentially Private Variational Inference](http://arxiv.org/abs/2410.19371)

**ノイズ認識差分プライバシー変分推論**

Talal Alrawajfeh, Joonas Jälkö, Antti Honkela

- 差分プライバシーは統計的推論のプライバシーを保護するが、結果にバイアスをもたらしやすい
- 既存のノイズ認識手法は単純な確率モデルに限られ、高次元モデルには適用困難
- 提案手法は高次元および非共役モデルにも適用可能なノイズ認識ベイズ推論法
- 高次元ベイズ線形回帰とUCI Adultデータセット上での予測確率の正確さを実証

ベイズ推論を使ったノイズ対応の手法ってすごく未来っぽい！これが実用化されれば、高次元のモデルでも信頼性のある結果が出せそうで、ワクワクするよね！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** stat.ML, cs.CR, cs.LG, **投稿日時:** 2024-10-25 08:18
