---
title: 差分プライバシー (2024-12-06 ~ 2024-12-12)
date: 2024-12-06
---

差分プライバシーに関する論文まとめ (2024-12-06 ~ 2024-12-12)


- - -

### [Private Synthetic Data Generation in Small Memory](http://arxiv.org/abs/2412.09756)

**小メモリ環境でのプライベート合成データ生成**

Rayne Holland, Seyit Camtepe, Chandra Thapa, Jason Xue

- データストリームのプライバシー保護は高メモリ消費か柔軟性制約がある。
- $\textsf{PrivHP}$は差分プライバシーを保持しつつ軽量な合成データ生成を行う。
- 階層的ドメイン分解でプライバシーを保ちながら高頻度サブドメインを保存。
- $\textsf{PrivHP}$は従来の手法よりもメモリと構築時間が小さい。

このタイトルとアブストラクトを読んでみると、小メモリでも合成データを作れるってスゴいね。データストリームのプライバシー保護における新たな解法になりそうで、ワクワクするなぁ。

**Comment:** 28 Pages, 1 Table, 3 Figures, 4 Algorithms

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DS, **投稿日時:** 2024-12-12 23:24


- - -

### [Building a Privacy Web with SPIDEr -- Secure Pipeline for Information De-Identification with End-to-End Encryption](http://arxiv.org/abs/2412.09222)

**SPIDErによるプライバシーウェブの構築 -- エンドツーエンド暗号化を用いた情報非識別化のためのセキュアパイプライン**

Novoneel Chakraborty, Anshoo Tandon, Kailash Reddy, Kaushal Kirpekar, Bryan Paul Robert, Hari Dilip Kumar, Abhilash Venkatesh, Abhay Sharma

- データの非識別化は、利用者のプライバシーを守りつつデータから洞察を得る手法
- Trusted Execution Environments（TEEs）を利用し、クラウド上で第三者を信頼せずに非識別化アプリを実行可能
- SPIDErはエンドツーエンド暗号化を実装し、多様な匿名化技術や形式的プライバシー保証を提供
- データのバッチ処理によりTEEでの差分プライバシー計算のスケーラビリティとパフォーマンス向上

この技術が普及したら、クラウドでもプライバシーをすっごくしっかり守れるようになりそうだね！データを安全に使える未来が楽しみ～。

**Comment:** 3 pages, 2 figures

**トピック:** [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.CR, cs.IT, math.IT, **投稿日時:** 2024-12-12 12:24


- - -

### [The Utility and Complexity of In- and Out-of-Distribution Machine Unlearning](http://arxiv.org/abs/2412.09119)

**イン・アウト・オブ・ディストリビューション機械学習解除の効用と複雑性**

Youssef Allouah, Joshua Kazdan, Rachid Guerraoui, Sanmi Koyejo

- 機械学習解除はプライバシーと知識ギャップへの対応に重要だが、既存手法は形式的保証が不足
- 類似データの解除では、リスク最小化と出力摂動により有効なトレードオフが可能
- 異なるデータの解除は時間複雑性が再学習を超え、既存手法が不適切
- 新しい頑健なノイズ付き勾配法で時間複雑性を低減しつつ効用を維持

機械学習モデルの記憶を取り除く「解除」って、知る人ぞ知ることだよね！既存手法の弱点を補完する新たな勾配法が登場したのかぁ、使い方広がりそう！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, math.OC, **投稿日時:** 2024-12-12 09:54


- - -

### [Deep Learning Model Security: Threats and Defenses](http://arxiv.org/abs/2412.08969)

**ディープラーニングモデルのセキュリティ：脅威と防御策**

Tianyang Wang, Ziqian Bi, Yichao Zhang, Ming Liu, Weiche Hsieh, Pohsun Feng, Lawrence K. Q. Yan, Yizhu Wen, Benji Peng, Junyu Liu, Keyu Chen, Sen Zhang, Ming Li, Chuanqi Jiang, Xinyuan Song, Junjie Yang, Bowen Jing, Jintao Ren, Junhao Song, Hong-Ming Tseng, Silin Chen, Yunze Wang, Chia Xin Liang, Jiawei Xu, Xuanhe Pan, Jinlang Wang, Qian Niu

- ディープラーニングはAIを進化させたが、攻撃やデータの毒性、モデル盗難、プライバシー漏洩などの課題に直面している
- 敵対的訓練や差分プライバシー、連合学習を使った防御策の強みと限界を調査
- 対比学習や自己教師付き学習が堅牢性向上に役立つ方法として紹介されている
- 将来の方向性として、自動化された防御やゼロトラストアーキテクチャ、AIモデルのセキュリティ課題が示されている

未来のディープラーニングって、単に賢いだけじゃなくて、安全性もしっかり考えてるのがすごいよね！ゼロトラストアーキテクチャとか、新しい概念聞くだけでワクワクしちゃう。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, cs.SE, **投稿日時:** 2024-12-12 06:04


- - -

### [Protecting Confidentiality, Privacy and Integrity in Collaborative Learning](http://arxiv.org/abs/2412.08534)

**共同学習における機密性、プライバシー、整合性の保護**

Dong Chen, Alice Dethise, Istemi Ekin Akkus, Ivica Rimac, Klaus Satzke, Antti Koskela, Marco Canini, Wei Wang, Ruichuan Chen

- データセットとモデルの所有者は、それぞれの資産の機密性とユーザープライバシーを守りたいが、現行の手法には限界がある
- Citadel++は、データセット、モデル、トレーニングコードの機密性とユーザープライバシーを同時に保護するシステムである
- 差分プライバシー技術を強化し、ユーザーデータのプライバシーを守りつつ、モデルの有用性を維持する
- 実験では、Citadel++が機密性とプライバシー要求を満たし、既存システムを大幅に凌ぐ効率と性能を示す

Citadel++の技術、すごいね！こんなに一気にパフォーマンスとプライバシーを向上させるなんて、革新的な道具になりそう。データの安全性を高めながら、モデルの実用性を維持するって、今後の技術への期待が膨らむね！



**トピック:** [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.DC, cs.CR, cs.LG, **投稿日時:** 2024-12-11 16:48


- - -

### [Mayfly: Private Aggregate Insights from Ephemeral Streams of On-Device User Data](http://arxiv.org/abs/2412.07962)

**Mayfly: デバイス上のユーザーデータの一時的なストリームからプライベートな集計インサイトを得る手法**

Christopher Bian, Albert Cheu, Stanislav Chiknavaryan, Zoe Gong, Marco Gruteser, Oliver Guinan, Yannis Guzman, Peter Kairouz, Artem Lagzdin, Ryan McKenna, Grace Ni, Edo Roth, Maya Spivak, Timon Van Overveldt, Ren Yi

- Mayflyは、端末上のデータを中央に保持せずに集計クエリを可能にする連合分析手法
- 一時的なデータ窓口とSQLプログラムでデータ量を最小化し、ストリーミング差分プライバシーで匿名化
- プライベートな集計のみを即座にメモリにてサーバーで集約し、データアナリストに開示する
- 新たな差分プライバシー機構を設計し、交通炭素排出量の推定で実用化し、他領域にも適用可能

Mayflyって未来を感じるね。データを蓄積しないで分析できるなんて画期的！これがもっと広まったら、プライバシーの心配が少なくなるんじゃないかな？

**Comment:** 22 pages, 7 figures

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DB, H.2.8; K.4.1; H.4, **投稿日時:** 2024-12-10 22:58


- - -

### [Privacy-Preserving Customer Support: A Framework for Secure and Scalable Interactions](http://arxiv.org/abs/2412.07687)

**プライバシーを保護したカスタマーサポート: 安全でスケーラブルなやり取りのためのフレームワーク**

Anant Prakash Awasthi, Chandraketu Singh, Rakshit Varma, Sanchit Sharma

- 従来の機械学習はデータプライバシーのリスクと法規制の課題がある
- PP-ZSLは事前学習済みの大規模言語モデルを使い、センシティブなデータのローカルトレーニングを回避
- フレームワークにはリアルタイムデータ匿名化と、特定ドメインのクエリ解決の手法を組み込む
- 精度を保ちながらコストと複雑性を低減し、様々な業界での活用が期待される

AIが進化すると、裏で活躍するこういうフレームワークが重要になりそうだよね！顧客情報をしっかり守りつつ効率よく対応できるなら、みんな安心して使えそうで嬉しいな。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, stat.AP, **投稿日時:** 2024-12-10 17:20


- - -

### [Game-Theoretic Joint Incentive and Cut Layer Selection Mechanism in Split Federated Learning](http://arxiv.org/abs/2412.07813)

**連合学習におけるゲーム理論的インセンティブと階層選択メカニズム**

Joohyung Lee, Jungchan Cho, Wonjun Lee, Mohamed Seif, H. Vincent Poor

- 分割連合学習は連合学習の負担軽減と収束速度向上を目指す
- 分割連合学習のモデル所有者が階層を選び、サーバとクライアント間の負担を調整
- インセンティブによりクライアント参加を促し、データ提供量やエネルギー消費を最適化
- ゲーム理論でクライアントの均衡を証明し、モデル所有者とクライアントの利益を最大化する

分割連合学習って、連合学習と特徴が組み合わさってるっぽいね！ゲーム理論的アプローチが活かされているところが、なんか新しい感じでワクワクしちゃうな。プライバシーと効率性が両立できるのか、これからも注目したいな～。

**Comment:** 10 pages, 8 figures

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.GT, cs.AI, cs.LG, **投稿日時:** 2024-12-10 06:24


- - -

### [A New Federated Learning Framework Against Gradient Inversion Attacks](http://arxiv.org/abs/2412.07187)

**新しい連合学習フレームワークでの勾配反転攻撃への対抗策**

Pengxin Guo, Shuang Zeng, Wenhao Chen, Xiaodan Zhang, Weihong Ren, Yuyin Zhou, Liangqiong Qu

- 連合学習はデータプライバシーを守るが、勾配反転攻撃に弱点がある
- 秘密計算や準同型暗号、差分プライバシーが対策として使われるが、プライバシーと有用性のトレードオフが課題
- 提案するHyperFLはハイパーネットワークを利用し、共有パラメータとプライベートデータの直接的な関係を断つ
- 理論解析と実験結果から、HyperFLのプライバシー保護能力とパフォーマンスの高さが示されている

新しい視点から問題を捉えて、ハイパーネットワークを活用したアプローチって面白そう！データの安全性を守りつつ性能も維持できるなんて、未来を考えるとワクワクするね。リンクのGitHubも覗いてみたい！

**Comment:** Accepted at AAAI 2025

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [準同型暗号](../../he), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-12-10 04:53


- - -

### [Streaming Private Continual Counting via Binning](http://arxiv.org/abs/2412.07093)

**ビニングによるストリーミングでのプライベート連続カウント**

Joel Daniel Andersson, Rasmus Pagh

- 連続的な観察はデータセットが逐次公開される状況での問題を指し、差分プライバシーを維持しつつ良好な近似を提供するのが課題である
- 継続的なカウントではバイナリ入力要素の合計を近似することを目指し、これは差分プライベート確率的勾配降下法の実装で重要
- ビニングを用いて行列乗算をサブリニア空間で維持し、低空間での因子化メカニズムの近似を実現する新手法を提案
- 動的状況に対応した因子化メカニズムと比べても非常に低空間でも高性能を維持、類似方法との比較で柔軟性に優れている

このアプローチ、新しい手法でリソース節約しつつ精度を高められるのがいいよね！連続観察って、未来のプライバシー技術にどう影響をもたらすか興味津々だなぁ。私たちの未来がもっと安全に守られるといいね！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DS, **投稿日時:** 2024-12-10 01:21


- - -

### [Numerical Estimation of Spatial Distributions under Differential Privacy](http://arxiv.org/abs/2412.06541)

**差分プライバシーを用いた空間分布の数値推定**

Leilei Du, Peng Cheng, Libin Zheng, Xiang Lian, Lei Chen, Wei Xi, Wangze Ni

- 空間分布の推定は交通予測や疫病予防に重要だが、ユーザーデータ収集はプライバシーを侵害する恐れがある
- 既存の一部の手法は一次元データに依存し、空間データの関連性を考慮せず誤差が大きい
- 提案されたDisk Area Mechanism (DAM)は空間データを一次元に射影し推定精度を向上させる
- DAMは最新手法と比べて一貫して優れた成果を見せ、データの細かさに依存せずに優位性を示す

空間データをうまく一元化して扱うアイデアが新鮮だし、実験結果が他の手法よりいいっていうのはすごいよね！これならプライバシーを守りながらも正確な予測できちゃうかもってワクワクしちゃう！

**Comment:** ICDE 2025

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.DB, **投稿日時:** 2024-12-09 14:53


- - -

### [Lightweight Federated Learning with Differential Privacy and Straggler Resilience](http://arxiv.org/abs/2412.06120)

**差分プライバシーと遅延耐性を備えた軽量な連合学習**

Shu Hong, Xiaojun Lin, Lingjie Duan

- 連合学習でモデルパラメータ交換による推論攻撃を差分プライバシーで防ぐ。
- 差分プライバシーと秘密計算の組み合わせは精度を上げるが、通信負荷が高い。
- 提案手法LightDP-FLは、低遅延、多数の騒音変異を利用してプライバシーを実現。
- CIFAR-10を用いた実験で、提案手法はより速い収束と優れた遅延耐性を示す。

これってめっちゃ便利そう！新しい手法で効率的にプライバシーを守りつつ、速く学習できるなんてすごいよね。これからのデータ時代にピッタリかも！

**Comment:** To appear at IEEE International Conference on Computer Communications   (INFOCOM) 2025

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DC, **投稿日時:** 2024-12-09 00:54


- - -

### [Privacy-Preserving Large Language Models: Mechanisms, Applications, and Future Directions](http://arxiv.org/abs/2412.06113)

**プライバシー保護型大規模言語モデル: メカニズム、応用、将来の方向性**

Guoshenghui Zhao, Eric Song

- 大規模言語モデルは様々な分野で活用される一方、データ漏洩などのプライバシー問題が懸念されている
- 差分プライバシーや連合学習などを用いたプライバシー保護メカニズムを検討し、プライバシー問題解決の効果を分析
- プライバシー重視分野での応用例と限界を紹介し、プライバシーとモデルの有用性のバランスを考慮
- 大規模言語モデルのライフサイクルにプライバシーを組み込むための新しいフレームワークの必要性を指摘

プライバシーと性能の両立ってホントに難しいよね。でも、この研究はそのバランスを上手く取りつつ、これからの方向性も示してて期待大！プライバシーの未来は明るいかもね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [TEE](../../tee), **カテゴリ:** cs.CR, cs.AI, **投稿日時:** 2024-12-09 00:24


- - -

### [Adversarially Robust Dense-Sparse Tradeoffs via Heavy-Hitters](http://arxiv.org/abs/2412.05807)

**敵対的状況に対する高密度-疎密トレードオフの実現**

David P. Woodruff, Samson Zhou

- 敵対的なストリーミングモデルでデータセットの統計を小さな空間で近似する手法を研究
- 既存技術を用いた高密度-疎密トレードオフ技術が敵対的耐性の$L_p$推定を実現
- 改善された敵対的耐性の$L_p$-ヘビーヒッターアルゴリズムを提案し、効率向上
- クラシカルなストリーミング設定用の新アルゴリズムで頻度モーメント推定を改善

敵対的な環境でのアルゴリズムとか重みのトレードオフが面白そう！より効率的な推定方法が実際にどう役立つか気になるね。området

**Comment:** NeurIPS 2024

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.DS, **投稿日時:** 2024-12-08 04:09


- - -

### [DeMem: Privacy-Enhanced Robust Adversarial Learning via De-Memorization](http://arxiv.org/abs/2412.05767)

**DeMem: 逆記憶化によるプライバシー強化型のロバスト敵対的学習**

Xiaoyu Luo, Qiongxiu Li

- 敵対的ロバスト性はモデルの信頼性に必須だが、プライバシー攻撃に弱くなる
- 差分プライバシーはプライバシー攻撃を軽減するが、サンプルのロバスト性を損なう
- DeMemを提案し、高リスクサンプルに焦点を当てロバスト性とプライバシーのバランスを向上
- DeMemは複数の訓練方法やデータセットで有効性が確認されている

DeMemって面白そうじゃない？プライバシーを守りながらモデルの強さを保てるなんていい感じ！普段使ってるアプリにも応用される日が来るかもって考えたらワクワクするよね。

**Comment:** 8 pages

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-12-08 00:22


- - -

### [Can large language models be privacy preserving and fair medical coders?](http://arxiv.org/abs/2412.05533)

**大規模言語モデルはプライバシー保護と公平な医療コード化が可能か？**

Ali Dadsetan, Dorsa Soleymani, Xijie Zeng, Frank Rudzicz

- 医療における機械学習のプライバシー保護は重要な課題
- 差分プライバシー適用でパフォーマンス低下、特にMIMIC-IIIデータで40%以上のマイクロF1スコア減少
- プライバシーと公平性のトレードオフで、男女間のリコールギャップが3%以上増加
- トレードオフの理解が現実世界での課題解決に役立つ可能性

難しいテーマだね！プライバシーを守りながら、医療分野のAIをどれだけ公平に使えるか注目だよね。もっと多くのデータで検証してみる価値がありそう～。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-12-07 04:27


- - -

### [Upcycling Noise for Federated Unlearning](http://arxiv.org/abs/2412.05529)

**連合学習におけるノイズのアップサイクリングによる忘却**

Jianan Chen, Qin Hu, Fangtian Zhong, Yan Zhuang, Minghui Xu

- 連合学習は生データを共有せずに複数のクライアントでモデルを訓練するが、差分プライバシーで保護される
- クライアントの「忘れられる権利」を満たすには、差分プライバシー連合学習が新たな課題となる
- 提案手法FUIは、差分プライバシー連合学習内で目標クライアントのデータを初めて忘却する方法
- 実験では、提案手法FUIが他の主流の忘却手法より優れた性能と効率を示すことを確認

この研究楽しいね！連合学習の新しい課題を解決する方法って、すごくわくわくするよね。難しい問題を解決するための新しい道筋が具体的に見えてきて、私も挑戦してみたいって思ったよ！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-12-07 04:07


- - -

### [Information Flows for Athletes' Health and Performance Data](http://arxiv.org/abs/2412.05055)

**アスリートの健康とパフォーマンスデータの情報フロー**

Brad Stenger, Yuanyuan Feng

- アスリートとチームがデータ技術を利用しパフォーマンス向上を目指すが、データプライバシーは低優先度
- 文脈的整合性に基づき、適切な情報フローの必要性が高まっている
- チーム中心と個人中心の2つの情報フローを提案し、アスリートの成長を支援
- 差分プライバシーを導入し、研究中心とコミュニティ中心の大規模情報共有シナリオも提示

アスリートのデータをもっと活用して、強くて優しいチームを作れる未来が見えるかも！プライバシーにもしっかり配慮しているのがかっこいい！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.HC, H.5; J.3; K.5, **投稿日時:** 2024-12-06 14:10


- - -

### [Differentially Private Random Feature Model](http://arxiv.org/abs/2412.04785)

**差分プライバシーを用いたランダムフィーチャーモデル**

Chunyang Liao, Deanna Needell, Alexander Xue

- 機械学習におけるプライバシー保護は注目され、差分プライバシーはよく用いられる。
- ランダムフィーチャーを用い、プライバシーを保つ新たなモデルを開発。
- この手法はオーバーパラメトリックな状況で理論的な保証を提供し、私的なモデルを生成。
- ランダムフィーチャーにより、差分プライバシーの偏りを軽減し公平性を改善する可能性がある。

この論文では、ランダムフィーチャーを使ってプライバシーを守りつつ学習する方法を提案しているところが面白そう。理論と実験の両方で公平性を高めるって、重要なポイントだね！

**Comment:** Submitted to an IEEE journal

**トピック:** [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-12-06 05:31


- - -

### [Privacy-Preserving Retrieval Augmented Generation with Differential Privacy](http://arxiv.org/abs/2412.04697)

**差分プライバシーによるプライバシー保護型の検索増強生成**

Tatsuki Koga, Ruihan Wu, Kamalika Chaudhuri

- 大規模言語モデル(LLM)は、機密性の高いデータを扱う分野での利用が増加
- 検索増強生成(RAG)は、外部知識からの情報提供でLLMを補助する
- RAGの出力が機密情報を漏洩しないよう、差分プライバシー(DP)を探求
- プライバシー予算を効果的に活用するアルゴリズムで長文正確回答を実現

プライバシーを守りながらも、ちゃんとまともな文章を生成できちゃうとかすごくない!? この研究が進むともっと安心してデータを使える未来がきそうだね。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.AI, cs.CL, **投稿日時:** 2024-12-06 01:20
