---
title: 連合学習 (2024-07-05 ~ 2024-07-11)
date: 2024-07-05
---

連合学習に関する論文まとめ (2024-07-05 ~ 2024-07-11)


- - -

### [Stabilized Proximal-Point Methods for Federated Optimization](http://arxiv.org/abs/2407.07084)

**連合最適化のための安定化近傍点法**

Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich

- 連合学習環境では通信制約が重要な課題
- DANEは最良の通信複雑性を達成する分散近傍点アルゴリズム
- 新しい分散アルゴリズムS-DANEを提案し、局所計算効率を向上
- S-DANEの加速法は既存手法中で最良の通信複雑性を達成

新しいS-DANE、めっちゃ気になる！これで通信量問題が解決されると、連合学習がもっと実用的になっちゃうよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, math.OC, **投稿日時:** 2024-07-09 17:56


- - -

### [A Differentially Private Blockchain-Based Approach for Vertical Federated Learning](http://arxiv.org/abs/2407.07054)

**縦型連合学習のための差分プライバシー対応ブロックチェーンアプローチ**

Linh Tran, Sanjay Chari, Md. Saikat Islam Khan, Aaron Zachariah, Stacy Patterson, Oshani Seneviratne

- DP-BBVFLアルゴリズムは、分散型アプリケーションのための検証可能性とプライバシー保証を提供
- スマートコントラクトを用いてクライアントの特徴表現（埋め込み）を透明に集約
- ブロックチェーン上に保存された埋め込みデータに対してローカル差分プライバシーを適用し、元データを保護
- 医療データでの実験は、高い精度を達成しつつ、オンチェーン集約によるトレーニング時間のトレードオフを示す

差分プライバシーとブロックチェーンの組み合わせってすごく新しい発想！これからいろんな分野で応用されそうでワクワクするね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.ET, cs.LG, **投稿日時:** 2024-07-09 17:20


- - -

### [Bayesian Federated Learning with Hamiltonian Monte Carlo: Algorithm and Theory](http://arxiv.org/abs/2407.06935)

**ハミルトニアンモンテカルロを用いたベイジアン連合学習：アルゴリズムと理論**

Jiajun Liang, Qian Zhang, Wei Deng, Qifan Song, Guang Lin

- FA-HMCアルゴリズムを提案し、パラメータ推定と不確実性の定量化を実現
- 非独立同分布データセット上での収束保証を確立
- パラメータ空間の次元、勾配のノイズ、通信頻度の影響を解析
- FA-LDアルゴリズムよりも優れた性能を実証

ハミルトニアンモンテカルロ使ってるのが面白そう！これで連合学習の精度もっと上がりそうだね、未来のアプリとかに期待しちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, stat.CO, stat.ML, **投稿日時:** 2024-07-09 15:10


- - -

### [Trust and Resilience in Federated Learning Through Smart Contracts Enabled Decentralized Systems](http://arxiv.org/abs/2407.06862)

**スマートコントラクトを活用した分散システムによる連合学習の信頼性とレジリエンス**

Lorenzo Cassano, Jacopo D'Abramo, Siraj Munir, Stefano Ferretti

- 分散型アーキテクチャを使用して、連合学習(FL)システムの信頼性と信頼性を向上
- FLのコラボレーターが暗号化されたモデルパラメータをIPFSにアップロードし、スマートコントラクトで行動を追跡
- パラメータ更新フェーズをスマートコントラクトで効率的に管理し、データセキュリティを強化
- クラシックな平均化方式と連合プロキシマル集約の2つの方法を使った重み付け集約の実験で提案の実現可能性を確認

スマートコントラクトを実際にFLに活用して、システム全体のセキュリティを強化するのってすごいね！学べば学ぶほど面白くなりそう♪

**Comment:** TRUSTCHAIN workshop

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.AI, cs.LG, **投稿日時:** 2024-07-09 13:50


- - -

### [Threats and Defenses in Federated Learning Life Cycle: A Comprehensive Survey and Challenges](http://arxiv.org/abs/2407.06754)

**連合学習ライフサイクルにおける脅威と防御: 包括的調査と課題**

Yanli Li, Jifei Hu, Zhongliang Guo, Nan Yang, Huaming Chen, Dong Yuan, Weiping Ding

- 連合学習（FL）は、分散性が理由で多様な攻撃に脆弱
- 脅威はモデルの有用性や参加者のプライバシーに直接/間接的な影響を与える
- 防御フレームワークは特定の状況で効果を発揮し、脅威と防御の関係を分析
- 現在の研究ボトルネックと今後の研究方向をまとめ、FLコミュニティに貢献

連合学習でこんなに色々なリスクがあるなんて驚き！防御方法の比較が面白そうだし、未来の課題を解決するヒントにもなりそうだよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.AI, **投稿日時:** 2024-07-09 11:05


- - -

### [DFedSat: Communication-Efficient and Robust Decentralized Federated Learning for LEO Satellite Constellations](http://arxiv.org/abs/2407.05850)

**DFedSat: LEO衛星コンステレーションのための通信効率が高く堅牢な分散連合学習**

Minghao Yang, Jingjing Zhang, Shengyun Liu

- DFLは衛星間の直接通信を可能にし、従来の集中型アプローチの問題を解決する
- DFedSatは、それぞれの衛星軌道面内外での適応モデル集約を用いて訓練プロセスを迅速化
- 自己補償メカニズムが組み込まれ、通信失敗に対する耐久性を向上させる
- DFedSatは、従来のDFLベースラインに比べ、収束速度や通信効率で優れることを実証

宇宙を駆け巡るAIって、すごく未来っぽいね！いつか自分たちもそんな研究に関わってみたいな。

**Comment:** 13 pages, 10 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-07-08 12:00


- - -

### [FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging](http://arxiv.org/abs/2407.05800)

**FedMRL: 医用画像のためのデータ不均一性対応型連合マルチエージェント深層強化学習**

Pranab Sahoo, Ashutosh Tripathi, Sriparna Saha, Samrat Mondal

- クライアント間のデータ不均一性が存在し、これが連合学習の実用化の課題
- 公正性を確保するため新しい損失関数を導入し、最終的なグローバルモデルのバイアスを防ぐ
- マルチエージェント強化学習を使用して個別ローカル目的関数の収束をグローバル最適に導く
- サーバ側で自己組織化マップを用いた適応的ウェイト調整方法を統合し、クライアントのデータ分布シフトに対応

医用画像を使った連合強化学習の可能性が広がりそうでワクワクするね！この手法が他の分野でも応用できたらすごいと思う。

**Comment:** Accepted to MICCAI 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, cs.DC, **投稿日時:** 2024-07-08 10:10


- - -

### [Gradient Diffusion: A Perturbation-Resilient Gradient Leakage Attack](http://arxiv.org/abs/2407.05285)

**勾配拡散: 摂動耐性のある勾配漏洩攻撃**

Xuan Liu, Siqi Cai, Qihua Zhou, Song Guo, Ruibin Li, Kaiwei Lin

- 連合学習における勾配漏洩攻撃の脅威に対処するため、勾配保護が重要である
- 差分プライバシーのような摂動ベースのメカニズムが一般的だが、摂動の頑強性は注入されたノイズに依存
- 本研究は摂動逆プロセス中の摂動レベルを捕捉し、摂動回復モデルを構築する
- 提案手法PGLAは既存モデルに比べて最良の勾配復元とデータ回復を実現

連合学習の安全性、もう一度考え直さないと！PGLAが広まったらどんな防御策が取られるのか、未来が楽しみだね。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-07-07 07:06


- - -

### [BFLN: A Blockchain-based Federated Learning Model for Non-IID Data](http://arxiv.org/abs/2407.05276)

**BFLN: 非IIDデータのためのブロックチェーンベースの連合学習モデル**

Yang Li, Chunhe Xia, Dongchi Huang, Lin Sun, Tianbo Wang

- 連合学習は、各クライアントに分散しているローカルデータを利用するため、プライバシーとセキュリティが向上する
- 非均衡なデータ分布は、データが独立かつ同一分布（IID）を仮定する従来の連合学習にとって課題である
- 提案モデルBFLNは、ブロックチェーン技術と新しい集約方法およびインセンティブアルゴリズムを組み合わせ、非IIDデータの精度を向上させる
- 公開データセットの実験で、BFLNは最先端モデルと比較してトレーニングの精度を向上させ、個別化された連合学習の持続可能なインセンティブメカニズムを提供する

ブロックチェーン技術を使って連合学習の課題解決なんて、まるでSFの世界みたい！この研究が実用化されたら、色んな分野でセキュリティと効率がさらにUPしそうだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, **投稿日時:** 2024-07-07 06:21


- - -

### [Federated Knowledge Transfer Fine-tuning Large Server Model with Resource-Constrained IoT Clients](http://arxiv.org/abs/2407.05268)

**連合知識転送による大規模サーバーモデルのリソース制約付きIoTクライアントでの微調整**

Shaoyuan Chen, Linlin You, Rui Liu, Shuo Yu, Ahmed M. Abdelmoniem

- 大規模モデルのトレーニングは高品質データの不足に直面している
- IoTでの学習はクライアントのプライベートかつ異種データの調整が困難
- KOALAを提案し、連合学習と知識蒸留を用いて大規模モデルを更新
- 実験結果は、従来の方法と比較してローカルストレージと計算リソースの大幅な削減を証明

分散した小規模データを使いながらも、大規模モデルのトレーニングができるようになるのはすごいね！KOALAがどれだけ効率的か、もっと知りたくなったよ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CV, **投稿日時:** 2024-07-07 05:46


- - -

### [Synthetic Data Aided Federated Learning Using Foundation Models](http://arxiv.org/abs/2407.05174)

**基盤モデルを利用した合成データ支援連合学習**

Fatima Abacha, Sin G. Teo, Lucas C. Cordeiro, Mustafa A. Mustafa

- 連合学習（FL）は、非独立同分布のデータ分布によりデータの不均一性問題に直面
- DPSDA-FLを提案、データの均一化を支援し、局所モデルのトレーニングを改善
- 差分プライバシーを適用した合成データで局所モデルを強化し、基盤モデルを活用
- CIFAR-10データセットで評価し、グローバルモデルの分類精度と再現率が最大26%および9%向上

連合学習に合成データを使う発展が面白いね！プライバシーを守りながら精度が上がる将来に期待大♪



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-07-06 20:31


- - -

### [Impact of Network Topology on Byzantine Resilience in Decentralized Federated Learning](http://arxiv.org/abs/2407.05141)

**ネットワークトポロジーが分散型連合学習におけるビザンチン耐性に与える影響**

Siddhartha Bhattacharya, Daniel Helo, Joshua Siegel

- 連合学習は、ユーザー間でトレーニングデータを共有せずに機械学習モデルを共同トレーニングする
- 分散型連合学習は、中央集約サーバ不要のピアツーピアでモデルをトレーニングする新しいパラダイム
- ビザンチンノードの影響を考慮し、複雑なネットワークトポロジーでのビザンチン耐性を評価
- 大規模で非完全に接続されたネットワークでは、最新のビザンチン耐性集約戦略は耐性が弱いことが判明

分散型連合学習って、本当にワクワクする未来が待ってる感じだよね! でも、まだ課題も多そうで、これからの研究がとても楽しみ！

**Comment:** 8 pages, 6 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, I.2.11; C.4; C.2.4, **投稿日時:** 2024-07-06 17:47


- - -

### [A Joint Approach to Local Updating and Gradient Compression for Efficient Asynchronous Federated Learning](http://arxiv.org/abs/2407.05125)

**効率的な非同期連合学習のためのローカル更新と勾配圧縮の統合アプローチ**

Jiajun Song, Jiajun Luo, Rongwei Lu, Shuzhao Xie, Bin Chen, Zhi Wang

- 非同期連合学習はデバイスの異質性や低帯域幅環境による古いモデル更新問題に直面
- 従来のアプローチはローカル更新か勾配圧縮のどちらか一方に焦点を当てるが両方は扱わない
- 新アプローチはローカル更新頻度と勾配圧縮率の相互作用が収束速度に与える影響を検討
- 提案するFedLuckフレームワークは通信消費を56%、訓練時間を平均55%削減し、競争力を実証

非同期連合学習の効率化を目指す新しい方法、すごく興味深い！多様な環境でも効果があるのが楽しみだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.DC, cs.LG, **投稿日時:** 2024-07-06 16:19


- - -

### [FedTSA: A Cluster-based Two-Stage Aggregation Method for Model-heterogeneous Federated Learning](http://arxiv.org/abs/2407.05098)

**FedTSA: モデル異種連合学習のためのクラスタベース二段階集約法**

Boyu Fan, Chenrui Wu, Xiang Su, Pan Hui

- システムの異種性がFLの大きな課題であり、既存の手法はこれを十分に考慮していない
- 実際のFLでは各クライアントのハードウェア資源が異なり、それが学習タスクに影響する
- FedTSAはクライアントの能力に基づいたクラスタリングと二段階集約、異種モデルの相互学習を提案
- 実験の結果、FedTSAは既存のベースラインを上回り、様々な要因がモデル性能に影響を与えることを示した

システム異種性の課題に対してこんなにスマートなアプローチが出てくるなんて、私も研究したくなっちゃうかも〜！将来のFLに革命をもたらすかもしれないよね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-07-06 14:59


- - -

### [Beyond the Federation: Topology-aware Federated Learning for Generalization to Unseen Clients](http://arxiv.org/abs/2407.04949)

**連合を超えて: 未見クライアントへの一般化のためのトポロジー対応連合学習**

Mengmeng Ma, Tang Li, Xi Peng

- 既存の連合学習はフェデレーション内のデータ異質性に対応するが、未見クライアントには効果が低い
- 大規模分散設定では高コストなため、新手法もスケーリングに課題
- トポロジー対応連合学習(TFL)を提案し、クライアントの関係性をグラフで表現
- クライアントトポロジー学習とトポロジー上の学習モジュールで効率的に強固なモデルを構築

新しいTFL手法がどれだけ効果的に未見クライアントへの一般化を達成するか気になるな！これが実用化されたら、もっと多様なデータを分析できそうでワクワクするね。

**Comment:** ICML 2024

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, **投稿日時:** 2024-07-06 03:57


- - -

### [Smart Sampling: Helping from Friendly Neighbors for Decentralized Federated Learning](http://arxiv.org/abs/2407.04460)

**スマートサンプリング: 分散型連合学習のためのフレンドリーネイバーズからの支援**

Lin Wang, Yang Chen, Yongxin Guo, Xiaoying Tang

- 分散型連合学習は、プライバシーを保ちながら知識を共有し通信コストを削減する
- 分散型FLは中央サーバーを必要とせず、クライアント間の直接通信が可能でリソース節約
- AFIND+アルゴリズムは有益な隣接ノードを識別し、選択するノード数を適応的に調整
- AFIND+は他のサンプリングアルゴリズムより優れた性能を示し、既存の最適化とも互換性あり

分散型の連合学習って、中央サーバーなしで済むからすごく画期的だと思う！友達のネットを通じて良いところを学ぶのってまるで勉強会みたいで、これからもっと普及しそうだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-07-05 12:10


- - -

### [A Unified Learn-to-Distort-Data Framework for Privacy-Utility Trade-off in Trustworthy Federated Learning](http://arxiv.org/abs/2407.04751)

**信頼できるフェデレーテッドラーニングにおけるプライバシーと有用性のトレードオフを実現する統一的なデータ歪曲学習フレームワーク**

Xiaojin Zhang, Mingcong Xu, Wei Chen

- フェデレーテッドラーニングにおけるプライバシーと有用性の均衡を理論的に紹介
- プライバシー保護メカニズムの歪曲を学習変数としてモデル化し、モデルパラメータと共同最適化
- データ歪曲に基づくプライバシー保護メカニズムの適用可能性を実証
- 関連領域（対抗訓練、入力の堅牢性、学習不能な事例）との繋がりを強調

プライバシーを守りつつどうやって有用性を保つかのバランスが大事なんだね！実際の応用が期待できそうでワクワクする～。未来の技術に一歩近づけそうで面白そうだなぁ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-07-05 08:15
