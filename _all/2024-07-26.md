---
title: 全て (2024-07-26 ~ 2024-08-01)
date: 2024-07-26
---

全てに関する論文まとめ (2024-07-26 ~ 2024-08-01)


- - -

### [Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation](http://arxiv.org/abs/2407.18789)

**差分プライバシーをテキストに適用する際の粒度の重要性: ニューラル機械翻訳に関する調査**

Doan Nam Long Vu, Timour Igamberdiev, Ivan Habernal

- 差分プライバシー（DP）をNLPで用いる際に粒度の選択が重要である
- 現実世界のNMTデータセットでは、対話などの文が独立していない場合が多い
- DP適用の粒度を文レベルからドキュメントレベルに変更する必要がある
- ドキュメントレベルのNMTシステムは、メンバーシップ推定攻撃に対してより耐性がある

粒度とか意外と侮れないんだね！ドキュメントレベルにするだけでこんなにプライバシーが強化されるなんて面白い！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CL, **投稿日時:** 2024-07-26 14:52


- - -

### [Learning production functions for supply chains with graph neural networks](http://arxiv.org/abs/2407.18772)

**グラフニューラルネットワークを用いたサプライチェーンの生産関数の学習**

Serina Chang, Zhiyin Lin, Benjamin Yan, Swapnil Bembde, Qi Xiu, Chi Heem Wong, Yu Qin, Frank Kloster, Alex Luo, Raj Palleti, Jure Leskovec

- 企業と取引をノードとエッジで表したサプライチェーンの生産関数を推測することが重要
- 現行のグラフニューラルネットワーク(GNN)はノード間の隠れた関係を捉えられない課題がある
- 新しい時系列GNNと在庫モジュールを組み合わせたモデルを提案、生産関数を学習
- 実データと新たなシミュレータSupplySimで評価した結果、基準より6-50%改善し、予測精度も11-62%向上

サプライチェーンの複雑な関係を解き明かす新しい方法ってすごいよね。未来の物流がもっと効率的になりそうだから、上手くいったらすごく良いことになりそう！



**トピック:** [合成データ](../../sd), **カテゴリ:** cs.LG, cs.CY, cs.SI, **投稿日時:** 2024-07-26 14:32


- - -

### [FLUE: Federated Learning with Un-Encrypted model weights](http://arxiv.org/abs/2407.18750)

**FLUE: 暗号化されていないモデル重みを用いた連合学習**

Elie Atallah

- 連合学習はデバイス間でデータをローカルに保ちながらモデルを共有し訓練する
- 差分プライバシーでも勾配の逆解析によるデータ漏洩の懸念がある
- 提案手法は暗号化なしでコード化された代理パラメータを交換し、過剰なノイズを注入
- 2つの変種アルゴリズムが提案され、コーディングとデータ特性に適応した収束率を示す

ノイズを使ってデータを守りながら学習できるのは新しいね。暗号化が不要だから計算も軽くなりそうだし、色々な連合学習への応用が期待できるかも！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-07-26 14:04


- - -

### [Towards Effective and Efficient Continual Pre-training of Large Language Models](http://arxiv.org/abs/2407.18743)

**効果的かつ効率的な継続的プレトレーニングによる大規模言語モデルの改良**

Jie Chen, Zhipeng Chen, Jiapeng Wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Yingqian Min, Wayne Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, Ji-Rong Wen

- 継続的プレトレーニング（CPT）は、言語モデルを特定のドメインやタスクに適応させる重要な方法
- CPTの過程で、中国語能力と科学的推論能力を大幅に向上させるため、特定のデータミキシングとカリキュラム戦略を設計
- 学際的な科学的質問と回答ペアを合成し、これらの合成データを組み込んでLlama-3の科学的推論能力を強化
- 広範な実験結果により、一般的な能力と科学的推論能力の両方でモデルのパフォーマンスが大幅に向上することが確認された

大規模言語モデルがどんどん進化しているって感じだよね！特に合成データで科学的推論が向上するって、面白そうだし将来も期待大かも。

**Comment:** 16 pages, 10 figures, 16 tables

**トピック:** [合成データ](../../sd), **カテゴリ:** cs.CL, 68T50, I.2.7, **投稿日時:** 2024-07-26 13:55


- - -

### [Homomorphic Encryption-Enabled Federated Learning for Privacy-Preserving Intrusion Detection in Resource-Constrained IoV Networks](http://arxiv.org/abs/2407.18503)

**プライバシー保護型侵入検知のための準同型暗号対応連合学習フレームワーク：リソース制約のあるIoVネットワークで**

Bui Duc Manh, Chi-Hieu Nguyen, Dinh Thai Hoang, Diep N. Nguyen

- データプライバシーの課題を解決する新しいフレームワークを提案
- ネットワーク車両が持つリソースの制約に対応、従来のFLの限界を克服
- 準同型暗号を用いたセキュアなデータオフロードを実現
- 暗号化されたデータに対して直接計算可能な訓練アルゴリズムを開発

これって未来の自動車ネットワークにすっごく役立ちそう！車のデータも安全に扱えるなんて、すごくクール♪



**トピック:** [連合学習](../../fl), [準同型暗号](../../he), **カテゴリ:** cs.CR, **投稿日時:** 2024-07-26 04:19


- - -

### [Revisit Event Generation Model: Self-Supervised Learning of Event-to-Video Reconstruction with Implicit Neural Representations](http://arxiv.org/abs/2407.18500)

**イベント生成モデルの再考察: 暗黙的ニューラル表現によるイベントからビデオ再構築の自己教師あり学習**

Zipeng Wang, Yunfan Lu, Lin Wang

- イベントデータから高時間分解能・動的範囲を維持して強度フレームを再構築することが重要
- 以前の方法は合成データに基づく教師あり学習であり、解釈性が乏しく過適合のリスクがある
- EvINRはラベルデータや光学フロー推定を不要にした新しい自己教師ありアプローチを提案する
- 実験結果では、EvINRがMSEで38%向上し、最先端の教師あり学習方法に匹敵または上回る性能を示す

自己教師あり学習でここまで精度が上がるなんてすごい！これがもっと広がると、イベントベースのビデオ解析ももっと身近になりそうだね。



**トピック:** [合成データ](../../sd), **カテゴリ:** cs.CV, **投稿日時:** 2024-07-26 04:18


- - -

### [FedUD: Exploiting Unaligned Data for Cross-Platform Federated Click-Through Rate Prediction](http://arxiv.org/abs/2407.18472)

**FedUD: クロスプラットフォーム連合クリック率予測のための非整合データの利用**

Wentao Ouyang, Rui Dong, Ri Tao, Xiangzheng Liu

- 広告プラットフォームでのクリック率（CTR）予測は重要であり、多くの現在の方法は自身のデータのみを使用する
- 他のプラットフォームのユーザー行動データも活用できれば、ユーザーの興味をより良くモデル化しCTR予測精度を向上できる
- プライバシーの問題から、異なるプラットフォーム間のデータを中央サーバーで集中モデル学習することはできない
- 提案手法FedUDは、非整合データを含む全てのデータを活用し、従来の縦型連合学習では使用できなかった非整合データをもCTR予測に貢献させる

この研究、めちゃくちゃ興味深い内容だね！特に、データのプライバシーを守りつつも複数のプラットフォームからデータを活用する方法って未来っぽくてすごくいい感じ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.IR, cs.LG, **投稿日時:** 2024-07-26 02:48


- - -

### [Machine Unlearning using a Multi-GAN based Model](http://arxiv.org/abs/2407.18467)

**マルチGANモデルを用いた機械学習のアンラーニング**

Amartya Hatua, Trung T. Nguyen, Andrew H. Sung

- GANモデルを用いたデータ再編成と事前学習モデルの微調整を含む2つのフェーズからなる
- GANの生成器と識別器のペアを使用し、保持と忘却データセットの合成データを生成
- 合成データと元のデータのクラスラベルを反転し、すべてのデータセットを用いて事前学習モデルを微調整
- CIFAR-10データセットを用いて実験を行い、合成データとMIAテストでモデルの優越性を証明

新しいアンラーニング方法ってすごく魅力的！GANモデルの使い方には未来の可能性を感じるね。



**トピック:** [合成データ](../../sd), **カテゴリ:** cs.LG, **投稿日時:** 2024-07-26 02:28
