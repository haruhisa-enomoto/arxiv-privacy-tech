---
title: 差分プライバシー (2024-12-20 ~ 2024-12-26)
date: 2024-12-20
---

差分プライバシーに関する論文まとめ (2024-12-20 ~ 2024-12-26)


- - -

### [When Focus Enhances Utility: Target Range LDP Frequency Estimation and Unknown Item Discovery](http://arxiv.org/abs/2412.17303)

**フォーカスが効用を高めるとき：ターゲット範囲LDP周波数推定および未知アイテム発見**

Bo Jiang, Wanrong Zhang, Donghang Lu, Jian Du, Qiang Yan

- LDPプロトコルは信頼できるデータ管理者なしでランダム化クライアントメッセージを収集する
- 提案するGCMSプロトコルは通信、プライバシー、精度のトレードオフを改善
- OCMSフレームワークはターゲット周波数の項目を収集する際に分散を最小化
- ESAフレームワークにより、元データなしで精度を維持しつつ計算コストを低減

この研究、データのプライバシーと効率を両立させようとしているのがすごく面白いね。特に、元データに触れずに精度を保てるところに未来を感じるし、もっと探究したいなって思う！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.DB, **投稿日時:** 2024-12-23 05:50


- - -

### [DR-Encoder: Encode Low-rank Gradients with Random Prior for Large Language Models Differentially Privately](http://arxiv.org/abs/2412.17053)

**DR-Encoder: 大規模言語モデルの勾配をランダムな事前分布でエンコードし差分プライバシーを保つ手法**

Huiwen Wu, Deyi Zhang, Xiaohan Li, Xiaogang Xu, Jiafei Wu, Zhe Liu

- 大規模言語モデル（LLM）の微調整で生じる情報漏えいを連合学習で検討
- 二段階の乱数導入により連合学習でのプライバシー保証を実現
- 勾配の統計情報を基にガウス分布を用いた勾配オートエンコーダを訓練
- 誤差と精度向上を複数モデルとベンチマークで示し、プライバシー分析を詳述

プライバシーをしっかりガードしつつも効率を上げてるとか素敵すぎるね！応用が進んだら、もっと安全に言語モデルを使いこなせる未来が見えてきそう。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-12-22 15:06


- - -

### [Data value estimation on private gradients](http://arxiv.org/abs/2412.17008)

**プライベート勾配におけるデータ価値推定**

Zijian Zhou, Xinyi Xu, Daniela Rus, Bryan Kian Hsiang Low

- 勾配降下法での差分プライバシー技術は、勾配をランダムなガウスノイズで摂動するものである。
- データ価値はML性能を訓練データに帰属させ、データ価格設定や連合学習で利用。
- 既存手法ではDPでノイズ摂動すると推定の不確実性が増え、ほぼランダムな推定となる。
- 提案手法では相関のあるノイズを注入し、不確実性の線形増加を防ぎ、より良い価値推定を実現。

データの価値をしっかり計算できたら、いろんなとこで使えて便利そう！ノイズをうまく扱うテクニック、なんかクールだね！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-12-22 13:15


- - -

### [On the Differential Privacy and Interactivity of Privacy Sandbox Reports](http://arxiv.org/abs/2412.16916)

**プライバシーサンドボックスレポートの差分プライバシーとインタラクティビティについて**

Badih Ghazi, Charlie Harrison, Arpana Hosabettu, Pritish Kamath, Alexander Knop, Ravi Kumar, Ethan Leeman, Pasin Manurangsi, Vikas Sahu

- プライバシーサンドボックスは、プライバシー保護を目指す広告APIを提供
- Private Aggregation APIとAttribution Reporting APIが差分プライバシーを担保
- これらのAPIのプライバシーを解析するための形式モデルを提案
- クエリとデータベースがインタラクティブに変化しても差分プライバシーを保証

プライバシーと広告の両立って、すごく難しそうなのにこの研究はそこをうまく解決しようとしてて面白そう！グーグルがそういう技術を開発しているのも興味深いし、今後の展開が楽しみだな～。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-12-22 08:22


- - -

### [SoK: Usability Studies in Differential Privacy](http://arxiv.org/abs/2412.16825)

**SoK: 差分プライバシーのユーザビリティ研究**

Onyinye Dibia, Brad Stenger, Steven Baldasty, Mako Bates, Ivoline C. Ngong, Yuanyuan Feng, Joseph P. Near

- 差分プライバシーはプライバシー保護に重要だが、実装やコミュニケーションでの使いやすさに課題がある。
- ユーザビリティ向上のため、既存の差分プライバシー研究を系統化し、実用的なツールとパラメータ伝達の戦略を整理。
- 開発者やデータ分析者、非技術者を含む多様なユーザーグループでの採用における主なチャレンジやギャップを特定。
- 分かりやすいコミュニケーションとユーザー中心設計を重視し、差分プライバシーツールの普及と実用性向上を目指した研究の方向性を示唆。

ユーザビリティとコミュニケーションを重視してるってすごくいいね！差分プライバシーがもっと身近になるかも。未来のプライバシー技術、どんどん使いやすくなってくれるといいなあ。



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.HC, cs.CR, **投稿日時:** 2024-12-22 02:21


- - -

### [Privacy in Fine-tuning Large Language Models: Attacks, Defenses, and Future Directions](http://arxiv.org/abs/2412.16504)

**大規模言語モデルの微調整におけるプライバシー: 攻撃、防御、そして将来の方向性**

Hao Du, Shang Liu, Lele Zheng, Yang Cao, Atsuyoshi Nakamura, Lei Chen

- 微調整はLLMの性能を引き出す一方で、プライバシーリスクを伴う
- メンバーシップ推論やデータ抽出攻撃など、微調整における脆弱性を調査
- 差分プライバシーなどの防御策を総括し、その利点と制限を考察
- 現行研究のギャップを指摘し、プライバシー保護の新たな道筋を提案

プライバシーを守りながら大規模モデルを微調整するなんて、なんだかスリリングだよね！何もかもがAIなのに人間らしさを求めたりして、ちょっと未来っぽい感じがするなぁ。



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.AI, **投稿日時:** 2024-12-21 06:41


- - -

### [Differentially Private Federated Learning of Diffusion Models for Synthetic Tabular Data Generation](http://arxiv.org/abs/2412.16083)

**差分プライバシーを備えた拡散モデルの連合学習による合成表データ生成**

Timur Sattarov, Marco Schreyer, Damian Borth

- 財務分野でのプライバシー保護データ分析の需要が増えている
- DP-Fed-FinDiffフレームワークは差分プライバシーと連合学習を組み合わせたもの
- 厳しいプライバシー規制を遵守しつつ高品質な合成表データを生成する
- 実証評価でプライバシーとデータ品質のバランスを最適化 

差分プライバシーと拡散モデルの組み合わせが面白そうで、しっかりデータ品質を保っているのが魅力的！金融業界でも安全にデータをシェアする未来がすぐそこに感じるね。

**Comment:** 9 pages, 9 figures, preprint version, currently under review

**トピック:** [連合学習](../../fl), [合成データ](../../sd), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, q-fin.ST, **投稿日時:** 2024-12-20 17:30


- - -

### [PoisonCatcher: Revealing and Identifying LDP Poisoning Attacks in IIoT](http://arxiv.org/abs/2412.15704)

**PoisonCatcher: IIoTにおけるLDPポイズニング攻撃の明確化と特定**

Lisha Shuai, Shaofeng Tan, Nan Zhang, Jiamin Zhang, Min Zhang, Xiaolong Yang

- LDPはIIoTで広く採用されるが、データの汚染を見分けにくくポイズニング攻撃を招く
- LDPの欠点は動的ネットワークやリアルタイムデータフローに弱く有効対策が未発達
- この研究では新たな脅威とルールポイズニング攻撃の発見、総合的な攻撃形成を示す
- PoisonCatcherで攻撃検出し特定。機械学習で微細な汚染シグネチャも識別可能に

IIoTの安全性向上に繋がりそうでわくわく！実験結果もすごく良さそうで興味津々。PoisonCatcherの精度がさらに向上したらバッチリだね。

**Comment:** 12 pages,5 figures, 3 tables

**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CR, **投稿日時:** 2024-12-20 09:26


- - -

### [SemDP: Semantic-level Differential Privacy Protection for Face Datasets](http://arxiv.org/abs/2412.15590)

**SemDP: 顔データセットのためのセマンティックレベル差分プライバシー保護**

Xiaoting Zhang, Tao Wang, Junhao Ji

- 大規模な顔データセットは深層学習を進展させる一方で、個人情報のプライバシー問題も提起
- 従来の差分プライバシー手法は画像を個別データベースとみなすが、要求を完全に満たさない
- 提案手法は、顔データセット全体にセマンティックレベルの差分プライバシーを適用する
- 提案手法は視覚的自然さを維持し、プライバシーと利用性のバランスを実現

この研究、画期的なことしてるよね！プライバシー保護しながらもデータの有用性キープとか、新しい時代の必要な解決策じゃない？どんな未来が見えるんだろうね、楽しみだね！



**トピック:** [差分プライバシー](../../dp), **カテゴリ:** cs.CV, cs.CR, **投稿日時:** 2024-12-20 06:00
