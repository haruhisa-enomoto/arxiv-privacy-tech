[
  {
    "url": "http://arxiv.org/abs/2406.12844",
    "title": "Synergizing Foundation Models and Federated Learning: A Survey",
    "japanese_title": "基盤モデルと連合学習の融合：調査",
    "authors": [
      "Shenghui Li",
      "Fanghua Ye",
      "Meng Fang",
      "Jiaxu Zhao",
      "Yun-Hin Chan",
      "Edith C. -H. Ngai",
      "Thiemo Voigt"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 基盤モデル（大型言語モデル、視覚トランスフォーマ、マルチモーダルモデル）が学術界と産業界に大きな影響を与えている\n- 小規模モデルと比較して、基盤モデルはプレトレーニングフェーズで大量のデータを必要とする\n- 一般的な基盤モデルはインターネットから収集したデータでプレトレーニング可能だが、ドメイン固有の基盤モデルは専有データが必要でプライバシーの問題が発生\n- 連合学習は、異なる参加者からのデータの可用性の壁を破り、プライバシーを保護しながら分散データセットを使用した基盤モデルのカスタマイズと適応を可能にする\n\n基盤モデルと連合学習を組み合わせることで、様々なドメインに特化した強力なモデルがプライバシーを守りながら構築できるようになるんだよね。最新技術がどのようにプライバシーとデータ利用のバランスを取るか、これからの発展が楽しみ！",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T17:58:09+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12816",
    "title": "Neural Approximate Mirror Maps for Constrained Diffusion Models",
    "japanese_title": "制約付き拡散モデルのためのニューラル近似ミラーマップ",
    "authors": [
      "Berthy T. Feng",
      "Ricardo Baptista",
      "Katherine L. Bouman"
    ],
    "categories": [
      "cs.LG",
      "cs.CV",
      "eess.IV"
    ],
    "comment": "",
    "summary": "- 拡散モデルは視覚的に説得力のある画像を生成するが、データの微妙な制約を満たすのは困難\n- 制約には物理ベース、幾何学的、意味的なものがあり、制約を満たすことでモデルの精度が向上する\n- 現行手法は制約の柔軟性に欠けるが、ニューラル近似ミラーマップ（NAMMs）を提案\n- NAMMsは学習したミラー空間と逆マップを使い、制約を満たした状態でデータを生成できる\n\n物理ベースから意味的な制約まで柔軟に対応できるNAMMsのアプローチ、期待値高いかも！制約問題のソルバーも簡単に応用できるって、すごく使えそうだよね！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-18T17:36:09+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12815",
    "title": "Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation",
    "japanese_title": "医療画像における不確実性推定を伴うプライバシー保護型連合学習",
    "authors": [
      "Nikolas Koutsoubis",
      "Yasin Yilmaz",
      "Ravi P. Ramachandran",
      "Matthew Schabath",
      "Ghulam Rasool"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "eess.IV",
      "stat.ML"
    ],
    "comment": "31 pages, 5 figures, 3 tables, Journal preprint",
    "summary": "- 連合学習（FL）はプライバシー保護の下で機械学習モデルの訓練を可能にする\n- 患者データのプライバシー問題が大規模な訓練データセットの構築を妨げている\n- 不確実性推定がFLにおいて重要であり、データの異質性が課題となる\n- 現行研究の調査とともに、プライバシー向上とノイズの多い医療画像データの課題解決の方向性を提案\n\n医療分野での連合学習の重要性が分かるね！これからの研究がどのようにプライバシーを守りつつ精度を上げていけるのかに注目したい。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T17:35:52+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12785",
    "title": "In-Context Learning of Energy Functions",
    "japanese_title": "エネルギー関数のインコンテキスト学習",
    "authors": [
      "Rylan Schaeffer",
      "Mikail Khona",
      "Sanmi Koyejo"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "Proceedings of the 1st Workshop on In-Context Learning at the 41st   International Conference on Machine Learning, Vienna, Austria. 2024. arXiv   admin note: text overlap with arXiv:2402.10202",
    "summary": "- インコンテキスト学習は、最先端のAIモデルの成功を支える強力な能力\n- 今回の研究で、モデルの制約なしにエネルギー関数を学習する新しい方法を提案\n- 我々の手法は、合成データでの実験で実証されている\n- 入力空間と出力空間が異なる場合でも機能する初の例として示唆\n\n新しい視点でインコンテキスト学習の可能性を広げているところが面白い！これからのAIの応用範囲がますます広がりそうだね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-18T16:54:43+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12725",
    "title": "Can Large Language Models Code Like a Linguist?: A Case Study in Low Resource Sound Law Induction",
    "japanese_title": "大規模言語モデルは言語学者のようにコードできるか？低リソース音声法則の導入に関するケーススタディ",
    "authors": [
      "Atharva Naik",
      "Kexun Zhang",
      "Nathaniel Robinson",
      "Aravind Mysore",
      "Clayton Marr",
      "Hong Sng Rebecca Byrnes",
      "Anna Cai",
      "Kalvin Chang",
      "David Mortensen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- 歴史言語学者は、親言語の再構築された単語を子孫言語に変換するプログラムを書く\n- プログラム作成はエラーが多く時間がかかるため、方法の改善が求められている\n- 大規模言語モデル（LLM）を使い、音声変化例からPythonの音声法則プログラムを生成する方法を提案\n- LLMの効果を評価し、既存の自動音声法則導入方法と比較すると、LLMがそれらの弱点を補うことができる\n\n音の変化をPythonでプログラムにするなんて面白い！これから言語学もAIがどんどん手伝ってくれるようになりそうでワクワクするね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-18T15:46:04+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12671",
    "title": "GeoBench: Benchmarking and Analyzing Monocular Geometry Estimation Models",
    "japanese_title": "GeoBench: 単眼幾何推定モデルのベンチマークと分析",
    "authors": [
      "Yongtao Ge",
      "Guangkai Xu",
      "Zhiyue Zhao",
      "Libo Sun",
      "Zheng Huang",
      "Yanlong Sun",
      "Hao Chen",
      "Chunhua Shen"
    ],
    "categories": [
      "cs.CV"
    ],
    "comment": "https://github.com/aim-uofa/GeoBench",
    "summary": "- 判別的な単眼幾何推定モデルは、大規模な微調整データに依存してゼロショット一般化を実現\n- 生成ベースのパラダイムでは、事前学習された拡散モデルと合成トレーニングデータの微調整で見事な一般化性能を発揮\n- 既存の幾何評価ベンチマークにはシーンの多様性やラベル品質の欠如などの欠点がある\n- 微調整データの品質が、データスケールやモデルアーキテクチャよりも重要であることが判明\n\nシンプルなDINOv2だけで最先端を達成できるなら、複雑な生成モデルいらないかもね？この研究、将来の幾何推定の進展に貢献しそう！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-18T14:44:12+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12658",
    "title": "Federated Learning with a Single Shared Image",
    "japanese_title": "連合学習における単一の共有画像の利用",
    "authors": [
      "Sunny Soni",
      "Aaqib Saeed",
      "Yuki M. Asano"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "comment": "8 Pages, 3 Figures, Appendix 4 Pages, CVPRW 2024",
    "summary": "- 連合学習はプライベートなトレーニングデータ共有を避け、モデルを協同で訓練する技術\n- 既存のFedDFは共通の共有データセットを使用するが、これはプライバシーやストレージの問題で困難\n- 本研究では、クライアント間とサーバー間で単一の共有画像のみを使用する新たな知識蒸留法を提案\n- 新しい適応型データセットプルーニングアルゴリズムにより、単一画像から最も情報価値の高い切り取り範囲を選択\n\n一枚の画像で全体の連合学習がより効果的に行えるなんて革新的だね！異なるクライアントアーキテクチャも対応できるのはすごい未来な感じ。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T14:26:09+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12588",
    "title": "UIFV: Data Reconstruction Attack in Vertical Federated Learning",
    "japanese_title": "UIFV: 垂直連合学習におけるデータ再構築攻撃",
    "authors": [
      "Jirui Yang",
      "Peng Chen",
      "Zhihui Lu",
      "Qiang Duan",
      "Yubing Bao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ],
    "comment": "",
    "summary": "- 垂直連合学習（VFL）は、生データを共有せずに協調機械学習を行う手法である\n- 既存のデータ再構築方法はモデルや勾配情報に依存し、VFL適用には限界がある\n- 本研究では、UIFVという新しい方法を提案し、中間特徴データを用いて元データを再構築する\n- 実験では、提案手法が最先端技術よりも高い攻撃精度を示し、VFLのプライバシーの脆弱性を明らかにした\n\nデータ共有なしで協力するのに、まだこんな抜け道があるなんてビックリ！UIFVのような新しい方法で、もっとプライバシーを守れる方法が必要だね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T13:18:52+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12564",
    "title": "Low-Resource Machine Translation through the Lens of Personalized Federated Learning",
    "japanese_title": "パーソナライズド連合学習による低リソース機械翻訳へのアプローチ",
    "authors": [
      "Viktor Moskvoretskii",
      "Nazarii Tupitsa",
      "Chris Biemann",
      "Samuel Horváth",
      "Eduard Gorbunov",
      "Irina Nikishina"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "comment": "18 pages, 7 figures",
    "summary": "- MeritFedアルゴリズムに基づく新しいアプローチを提案\n- 低リソース機械翻訳のタスクに適用し、その有効性を検証\n- 訓練に使用する各言語の影響を追跡できるため、MeritFedは非常に解釈可能\n- ターゲットデータセットのサイズ、関連性のない言語の影響、および補助最適化パラメータの効果を分析\n\nMeritFedって、低リソース言語の機械翻訳にも使えるんだね！異なる言語の影響を追跡できるって、かなり役立ちそう💡",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T12:50:00+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12516",
    "title": "Update Selective Parameters: Federated Machine Unlearning Based on Model Explanation",
    "japanese_title": "更新選択パラメータ: モデル説明に基づく連合機械学習のアンラーニング",
    "authors": [
      "Heng Xu",
      "Tianqing Zhu",
      "Lefeng Zhang",
      "Wanlei Zhou",
      "Philip S. Yu"
    ],
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "comment": "Accepted by IEEE Transactions on Big Data",
    "summary": "- 機械アンラーニングが必要な理由は、特定のトレーニングデータの影響をモデルから除去するため\n- 現行の中央集権的なアンラーニング手法では連合学習に不向きであり、全データへのアクセスが前提となる\n- 新たな手法はモデル説明に基づき、重要なチャネルのみを調整してデータの影響を削減\n- 提案手法は計算コストと通信コストを削減しつつ、モデルの性能を維持することを実験で実証\n\nこの論文は連合学習の新しいアプローチだね！モデル説明を活用するアイデア、とってもクールじゃない？",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T11:43:20+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12480",
    "title": "The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions",
    "japanese_title": "オンライン政治討論における立場検出のためのLLM生成の合成データの力",
    "authors": [
      "Stefan Sylvius Wagner",
      "Maike Behrendt",
      "Marc Ziegele",
      "Stefan Harmeling"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 立場検出は議論の要約、誤情報の検出、意見分布の評価に有用\n- トランスフォーマーモデルは多くのデータを必要とするが、オンライン討論の多様性がデータ収集を難しくする\n- Mistral-7Bモデルで生成した合成データで立場検出エージェントのパフォーマンスを向上\n- 合成データと未ラベルデータの最も情報量豊富なサンプルを組み合わせることで、ラベリング労力を軽減しベースラインモデルを超える成果を達成\n\nLLMによる合成データでラベリングの手間が減ってパフォーマンスも向上するなんて、すごく画期的じゃない？特に多様な議論の場では大きな助けになるね！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-18T10:36:21+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12435",
    "title": "Federated Learning with Limited Node Labels",
    "japanese_title": "ラベルの限定されたノードを持つ連合学習",
    "authors": [
      "Bisheng Tang",
      "Xiaojun Chen",
      "Shaopu Wang",
      "Yuexin Xuan",
      "Zhendong Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "comment": "",
    "summary": "- 分散グラフ構造データを扱うための手法として、サブグラフ連合学習（SFL）が注目を集めている\n- SFLの一部モデルは、サブグラフ間の欠落エッジの重要性を見落とし、ローカルGNNがグローバル表現を他のパーティのGNNに渡せなくなる\n- 既存のSFLモデルは多くのラベル付きデータを必要とし、実用性を制限している\n- 提案する新たなSFLフレームワークFedMpaは、少量のデータでMLPモデルを訓練し、連合特徴をローカル構造に伝播\n\n新しいSFLフレームワークが実用性を高める方法についての研究なんて面白そうだね！将来的にもっと現実の応用が増えるかもって感じだよね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T09:30:10+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12423",
    "title": "Deep Temporal Deaggregation: Large-Scale Spatio-Temporal Generative Models",
    "japanese_title": "深層時系列デアグリゲーション: 大規模時空間生成モデル",
    "authors": [
      "David Bergström",
      "Mattias Tiger",
      "Fredrik Heintz"
    ],
    "categories": [
      "cs.LG"
    ],
    "comment": "",
    "summary": "- 時系列データはセンサーや取引システムから生成され、プライバシーとビジネス感受性が課題\n- 従来の方法は短いシーケンスと小規模なデータに限られ、大規模データには不向き\n- 本研究では、TDDPMというトランスフォーマーベースの拡散モデルを提案し、性能とスケーラビリティを向上\n- 新たな包括的ベンチマークで評価し、事前の空間占有周波数情報に基づくモビリティデータ生成を実現\n\n大規模な時系列データを活用して、都市の動きがシミュレートされるの楽しそう！特に、未知の環境でも適応できるなんてすごいね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-18T09:16:11+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12397",
    "title": "Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models",
    "japanese_title": "欠点の解明：合成データの不完全性と大規模言語モデルの緩和戦略の探求",
    "authors": [
      "Jie Chen",
      "Yupeng Zhang",
      "Bingning Wang",
      "Wayne Xin Zhao",
      "Ji-Rong Wen",
      "Weipeng Chen"
    ],
    "categories": [
      "cs.CL"
    ],
    "comment": "15 pages",
    "summary": "- 高品質データの不足を補うため、合成データが提案されている\n- 合成データはモデルの性能を改善するが、パターンオーバーフィッティングの課題あり\n- Q-Aペアに関連する特定の欠点を解析し、アンラーニング技術を提案\n- 提案手法は、低コストで性能を維持しつつ、指示追従問題を緩和\n\n合成データを使うとこういう困ったがあるんだね。でも新しい手法で改善できるなら、試してみる価値ありそう！未来のAIがもっと賢くなりそう～。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-18T08:38:59+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12330",
    "title": "Security and Privacy of 6G Federated Learning-enabled Dynamic Spectrum Sharing",
    "japanese_title": "6G連合学習対応動的スペクトル共有のセキュリティとプライバシー",
    "authors": [
      "Viet Vo",
      "Thusitha Dayaratne",
      "Blake Haydon",
      "Xingliang Yuan",
      "Shangqi Lai",
      "Sharif Abuadbba",
      "Hajime Suzuki",
      "Carsten Rudolph"
    ],
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.ET",
      "cs.LG",
      "cs.NI"
    ],
    "comment": "7 pages, 5 figures. The paper is submitted to IEEE Networks for   review",
    "summary": "- 6G無線通信における動的スペクトル共有が重要\n- 連合学習によるスペクトルセンシング技術が注目を集める\n- 協調トレーニングの整合性とローカルユーザのスペクトル情報のプライバシーが未解決\n- 実践的な攻撃ベクトルと防御の指針を提示\n\n連合学習でプライバシーを保ちながら6Gの通信をより効率的にするなんて、未来のネットワークがもっと便利になりそうでワクワクする！新しいテクノロジーでどんな日常が来るのか、楽しみだね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T06:54:15+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12222",
    "title": "BadSampler: Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning",
    "japanese_title": "BadSampler: カタストロフィックフォゲッティングの力を利用したビザンチン耐性連合学習の毒殺攻撃",
    "authors": [
      "Yi Liu",
      "Cong Wang",
      "Xingliang Yuan"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "comment": "In Proceedings of the 30th ACM SIGKDD Conference on Knowledge   Discovery and Data Mining (KDD' 24), August 25-29, 2024, Barcelona, Spain",
    "summary": "- ビザンチン耐性の連合学習における毒殺攻撃の研究がほとんど行われていない\n- 本論文では、カタストロフィックフォゲッティングを利用した新たな攻撃BadSamplerを提案\n- Clean-labelデータのみを使用し、モデルの一般化誤差を最大化するように訓練データを選択\n- 提案手法の有効性と性能を二つの実データセットで評価し、効率的な攻撃が可能であることを示した\n\nこれ、めっちゃ興味深いね！毒殺攻撃とか、まるでスパイ映画みたいだし、連合学習がもっと強くなるかもってワクワクするね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T02:43:56+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12200",
    "title": "SFedCA: Credit Assignment-Based Active Client Selection Strategy for Spiking Federated Learning",
    "japanese_title": "SFedCA: スパイキング連合学習のための信用配分に基づくアクティブクライアント選択戦略",
    "authors": [
      "Qiugang Zhan",
      "Jinbo Cao",
      "Xiurui Xie",
      "Malu Zhang",
      "Huajin Tang",
      "Guisong Liu"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.ET",
      "cs.MM",
      "cs.NE"
    ],
    "comment": "9 pages",
    "summary": "- スパイキング連合学習は、デバイスが局所データを交換せず低消費電力で協力して学習する\n- プライバシー保護機能とエネルギー効率を兼ね備え、マルチメディアデータ処理に革命をもたらす可能性\n- 既存手法はクライアントの無作為選択に依存し、統計的異質性がグローバルモデルの収束や精度に影響\n- SFedCAは閾値に基づきクライアントを選定し、データ分布のバランスを維持。また、通信ラウンド数を減らすことに成功\n\nこの技術で低消費電力で効率的に学習できるとか、未来のガジェットがすごくスマートになりそう！早く実用化されるといいね。",
    "topics": [
      "連合学習"
    ],
    "published": "2024-06-18T01:56:22+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12158",
    "title": "LLMs Are Prone to Fallacies in Causal Inference",
    "japanese_title": "LLMは因果推論において誤謬を犯しやすい",
    "authors": [
      "Nitish Joshi",
      "Abulhair Saparov",
      "Yixin Wang",
      "He He"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "comment": "",
    "summary": "- LLMは事前学習データから因果関係を抽出できるが、記憶に依存する可能性がある\n- 合成データを用いて因果関係の推論能力を検証した結果、LLMはテキスト中の順序から因果関係を推論しがち\n- 時系列関係（XがYの前に発生）でも同様の誤謬を示すことが多い\n- 反事実的な関係から因果関係を推論するのが困難であり、因果性の理解に疑問が残る\n\nLLMって便利だけど、因果関係の推論はまだまだ課題が多いみたい。テンプレから外れた状況でも柔軟に対応できるようになるといいな！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-18T00:14:07+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12123",
    "title": "ChatEMG: Synthetic Data Generation to Control a Robotic Hand Orthosis for Stroke",
    "japanese_title": "ChatEMG：脳卒中の手の装具を制御するための合成データ生成",
    "authors": [
      "Jingxi Xu",
      "Runsheng Wang",
      "Siqi Shang",
      "Ava Chen",
      "Lauren Winterbottom",
      "To-Liang Hsu",
      "Wenxi Chen",
      "Khondoker Ahmed",
      "Pedro Leandro La Rotta",
      "Xinyue Zhu",
      "Dawn M. Nilsen",
      "Joel Stein",
      "Matei Ciocarlie"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "comment": "8 pages",
    "summary": "- 障害を持つ被験者からのデータ収集の困難さにより、手の装具での意図推定が困難\n- EMG信号は条件、セッション、被験者ごとに大きな変動があり、分類器の一般化が難しい\n- ChatEMGはプロンプトに基づいて合成EMG信号を生成し、少量のデータを拡張\n- 合成データは分類器に依存せず、意図推定精度を向上させ、機能的な装具支援作業に利用可能\n\n合成データで意図推定をサポートするのってすごくない？新しい被験者でもすぐに活用できちゃうとか、未来のリハビリは明るい感じがするなぁ！",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-17T22:04:44+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12103",
    "title": "Centering Policy and Practice: Research Gaps around Usable Differential Privacy",
    "japanese_title": "政策と実践の中心化：使いやすい差分プライバシーに関する研究のギャップ",
    "authors": [
      "Rachel Cummings",
      "Jayshree Sarathy"
    ],
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "comment": "",
    "summary": "- 差分プライバシーは理論的に非常に強力だが、実践には大きな課題がある\n- 実世界での利用可能性を向上させるためには、研究者と実務家の協力が必要\n- ユーザーのニーズに合わせたリスクフレームワークの開発が提案されている\n- ユーザーインターフェースの投資やアルゴリズム監査が重要な改善点である\n\n理論だけじゃなくて実践も大事って視点が新鮮！みんなのための差分プライバシーが早く実現するといいな。",
    "topics": [
      "差分プライバシー"
    ],
    "published": "2024-06-17T21:32:30+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12034",
    "title": "Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts",
    "japanese_title": "Self-MoE: 自己特化型専門家を備えた構成可能な大規模言語モデルに向けて",
    "authors": [
      "Junmo Kang",
      "Leonid Karlinsky",
      "Hongyin Luo",
      "Zhen Wang",
      "Jacob Hansen",
      "James Glass",
      "David Cox",
      "Rameswar Panda",
      "Rogerio Feris",
      "Alan Ritter"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "comment": "",
    "summary": "- モノリシックなLLMを自己特化型専門家によるモジュールシステムに変換するアプローチであるSelf-MoEを提案\n- 自己生成の合成データを用いて専門家モジュールを構築し、自己最適化ルーティングを組み込む\n- 人間のラベル付けデータや追加パラメータなしで、動的かつ能力特化型のタスク処理が可能\n- 多様なベンチマークで基盤LLMを上回る性能を示し、モジュール性と自己改善の重要性を示す\n\n自己改善のアイデアがすごくおもしろそう！もっと効率的で柔軟なAIシステムが実現できる可能性、大きいよね。",
    "topics": [
      "合成データ"
    ],
    "published": "2024-06-17T19:06:54+00:00"
  },
  {
    "url": "http://arxiv.org/abs/2406.12003",
    "title": "P3GNN: A Privacy-Preserving Provenance Graph-Based Model for APT Detection in Software Defined Networking",
    "japanese_title": "P3GNN: ソフトウェア定義ネットワーキングにおけるAPT検出のためのプライバシー保護型プロベナンスグラフベースモデル",
    "authors": [
      "Hedyeh Nazari",
      "Abbas Yazdinejad",
      "Ali Dehghantanha",
      "Fattane Zarrinkalam",
      "Gautam Srivastava"
    ],
    "categories": [
      "cs.CR"
    ],
    "comment": "",
    "summary": "- SDNはネットワーク管理に進展をもたらしたが、APTやゼロデイ攻撃の脅威も増加\n- 既存の対策は新しい脅威の検出や共同学習中のデータプライバシーの問題に不十分\n- P3GNNは連合学習と準同型暗号を組み合わせ、データ機密性と勾配の整合性を強化\n- 無監督学習で攻撃を検知し、DARPA TCE3データセットで高い精度と低い誤検知率を実現\n\n連合学習と準同型暗号の組み合わせってすごいね！これなら新しい脅威にも対応できるから安心じゃん？",
    "topics": [
      "連合学習",
      "準同型暗号"
    ],
    "published": "2024-06-17T18:14:03+00:00"
  }
]