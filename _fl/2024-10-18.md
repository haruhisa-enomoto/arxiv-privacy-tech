---
title: 連合学習 (2024-10-18 ~ 2024-10-24)
date: 2024-10-18
---

連合学習に関する論文まとめ (2024-10-18 ~ 2024-10-24)


- - -

### [FedSPD: A Soft-clustering Approach for Personalized Decentralized Federated Learning](http://arxiv.org/abs/2410.18862)

**FedSPD: ソフトクラスタリングによる個人化分散連合学習アプローチ**

I-Cheng Lin, Osman Yagan, Carlee Joe-Wong

- 従来の連合学習は集中型サーバーを使用するが、FedSPDは分散型で単一故障点を排除
- 個々のクライアントが異なるデータに最適化されたパーソナライズモデルを生成
- クラスターベースの手法でモデルの統一と個別化を両立し、低接続環境でも有効
- 通信コストが従来手法より大幅に削減され、同時に精度も向上することを実証

FedSPDってすごく面白そう！低接続ネットワークとかでのチームワークがどんどん進化しちゃうってことだよね。みんなでデータを共有しなくても、情報をうまく集めて強くなれるって感じがするよ！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-24 15:48


- - -

### [Adapting MLOps for Diverse In-Network Intelligence in 6G Era: Challenges and Solutions](http://arxiv.org/abs/2410.18793)

**6G時代におけるネットワーク内インテリジェンスの多様性に適応したMLOpsの課題と解決策**

Peizheng Li, Ioannis Mavromatis, Tim Farnham, Adnan Aijaz, Aftab Khan

- AIとMLを無線システムに統合することが6Gの発展に不可欠
- 現行のMLOpsアプローチは多様な学習パラダイムやネットワークの異質性に対応できていない
- 新たなアプローチとしてRLOps、FedOps、GenOpsの3つのオペレーションパイプラインを導入
- 各オペレーションに特化した課題と解決策を示し、AIネイティブな6Gネットワークの大規模展開を可能にする

6Gがますます現実味を帯びてくる中、AIとMLがどんな風にネットワークと関連付けられるのか興味津々だね！新しいMLOpsのアイデアがこれからの技術の進化を加速させるのかも。

**Comment:** 7 pages, 5 figures. This paper has been submitted to IEEE for   possible publication

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.NI, cs.LG, **投稿日時:** 2024-10-24 14:47


- - -

### [Classifier Clustering and Feature Alignment for Federated Learning under Distributed Concept Drift](http://arxiv.org/abs/2410.18478)

**連合学習における分散概念ドリフトへの分類器クラスタリングと特徴整合**

Junbao Chen, Jingfeng Xue, Yong Wang, Zhenyan Liu, Lu Huang

- 分散概念ドリフトは、クライアントごとに異なるドリフトを経験するため、連合学習において大きな課題である
- 条件付き分布$P(Y|X)$とデータ不均一性の度合いの2つが特徴整合において重要な要素である
- 提案されたFedCCFAフレームワークは、分類器クラスタリングと特徴整合を採用し、ドリフト下での協調を強化する
- FedCCFAは、ラベル分布$P(Y)$のエントロピーに基づいて特徴空間を適応的に整合し、既存の手法を凌駕する結果を示す

クライアントのデータが異なっても、連合学習をうまく適用できるように工夫されてておもしろい！違うデータセットでも一緒に活用できる未来の技術なんだね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-24 07:04


- - -

### [FedBaF: Federated Learning Aggregation Biased by a Foundation Model](http://arxiv.org/abs/2410.18352)

**FedBaF: 基盤モデルによる連合学習の偏りを抑える手法**

Jong-Ik Park, Srinivasa Pranav, José M. F. Moura, Carlee Joe-Wong

- 基盤モデルは多様なタスクに汎化する能力で注目され、連合学習に利用されている
- 既存手法はモデル重みをクライアントに開示しプライバシーを守るが、情報セキュリティにリスク
- FedBaFは重みの秘密を保持しつつ、連合学習の統合過程で基盤モデルを活用する新手法
- 実験で既存手法を最大15.8%上回る精度を示し、言語モデルの困惑度を最大39.2%削減

FedBaFって、すごくおもしろいアイディアだよね！基盤モデルを使ってるのに秘密を守りつつ精度も向上できるなんて。これから連合学習がもっと広まっていきそう♪



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.DC, **投稿日時:** 2024-10-24 01:14


- - -

### [LEGO: Language Model Building Blocks](http://arxiv.org/abs/2410.18287)

**LEGO: 言語モデル構築ブロック**

Shrenik Bhansali, Alwin Jin, Tyler Lizzo, Larry Heck

- 大規模言語モデル(LLM)は重要だが、データ収集や学習が高コストである
- タスク特化型小規模言語モデル(SLM)は安価だが、頑健性と一般化に欠ける
- LEGO技術はLLMからSLMsを抽出して再結合し、効率的なモデル微調整を可能にする
- LEGOは連合学習と新しい集約スキームを使用し、データの多様性に対応しつつ頑健性を維持

LEGOって、なんか組み合わせて新しいものを作る感じが楽しそうだよね！ユーザーのデータも守りつつ、効率よくモデル化できるなんて高校のプロジェクトとかにも応用できそうじゃない？



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CL, cs.LG, **投稿日時:** 2024-10-23 21:31


- - -

### [ProFL: Performative Robust Optimal Federated Learning](http://arxiv.org/abs/2410.18075)

**ProFL: パフォーマティブなロバスト最適連合学習**

Xue Zheng, Tian Xie, Xuwei Tan, Aylin Yener, Xueru Zhang, Ali Payani, Myungjin Lee

- パフォーマティブ予測は、モデルの配備による学習中のデータ分布の変化を捉える枠組み
- 連合学習におけるモデル誘発型の分布シフトの影響はまだ未解明
- 提案手法ProFLは、ノイズがあり汚染されたデータから最適点を見つける
- 非凸目的関数下での収束解析と広範な実験により効率性を実証

これすごく必要そう！どんなに複雑でノイズだらけのデータでも、最適な解を見つけるなんて魔法みたい。未来のAIがもっと賢くなるために、こういう技術がどんどん進化していくといいな。それに、どんなシフトがあっても対応できるって頼もしいよね。

**Comment:** 27 pages with Appendix, 18 figures. The paper has been submitted and   is currently under review

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.IT, math.IT, **投稿日時:** 2024-10-23 17:57


- - -

### [Federated Transformer: Multi-Party Vertical Federated Learning on Practical Fuzzily Linked Data](http://arxiv.org/abs/2410.17986)

**連合トランスフォーマー: 実用的に曖昧にリンクされたデータにおけるマルチパーティ縦連合学習**

Zhaomin Wu, Junyi Hou, Yiqun Diao, Bingsheng He

- 縦連合学習は異なる組織が異なる特徴を提供し協力してモデルを訓練する方式
- プラグマティックマルチパーティフジー VFL では性能低下とプライバシー維持費用が課題
- 新たにフェデレーテッドトランスフォーマー（FeT）を開発し、改良技術で性能向上を図る
- 作成したプライバシーフレームワークで、差分プライバシーと秘密計算を融合し、性能とプライバシーを向上

多くの組織で協力しながらプライバシーも守れるってすごいよね！FeTがどんなふうに幅広く活用されていくのか、とっても楽しみ♪



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-23 16:00


- - -

### [Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning](http://arxiv.org/abs/2410.17933)

**ブロックチェーン対応連合学習を用いた多大陸健康モデル**

Rui Sun, Zhipeng Wang, Hengrui Zhang, Ming Jiang, Yizhe Wen, Jiqun Zhang, Jiahao Sun, Shuoying Zhang, Erwu Liu, Kezhi Li

- 医療データの共有は難しく、従来のモデル構築が非常に困難
- 提案フレームワークは多大陸のデータを使い、データを共有せずにモデル構築
- ブロックチェーン対応連合学習により、データのプライバシーと安全性を確保
- 提案手法は精度も高く、国際的な医療プロジェクト連携を支援

これって、データを共有しないでこんなにいい結果が出るってすごくない？世界中のデータを使って、もっとかっこいいことができそうだよね。まさに未来の医療って感じ！

**Comment:** Accepted by IEEE Global Blockchain Conference

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-23 14:55


- - -

### [Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection](http://arxiv.org/abs/2410.17792)

**動的データキューとデータエントロピー駆動の参加者選択による連合学習の収束性向上**

Charuka Herath, Xiaolan Liu, Sangarapillai Lambotharan, Yogachandran Rahulamathavan

- 連合学習は非中央集権的でプライバシー保護や規制遵守に優れたモデル訓練方法
- デバイス間でデータが不均一に分布する場合の統計複雑性に焦点を当てる
- 動的データキューを用いてデバイスにデータを配布し収束性を改善する方法を提案
- 提案手法はSOTAアルゴリズムより高精度で、MNISTやCIFARデータセットで最大20%の精度向上を実現

へー！連合学習ってそんなにデータの分布がばらつくと難しいんだね。でもこの方法なら、ちゃんと収束しやすくなって精度もアップしちゃうなんてスゴイじゃん！みんなもこうやって連携してどんどん良くなるっていいねー！

**Comment:** The Journal is submitted to IEEE Transactions in the Internet of   Things

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, 14J60 (Primary), I.2.11; I.5.1; I.5.4, **投稿日時:** 2024-10-23 11:47


- - -

### [Towards Active Participant-Centric Vertical Federated Learning: Some Representations May Be All You Need](http://arxiv.org/abs/2410.17648)

**能動的参加者中心の垂直連合学習に向けて: 一部の表現が全ての鍵かもしれない**

Jon Irureta, Jon Imaz, Aizea Lojo, Marco González, Iñigo Perona

- 垂直連合学習は異なる参加者間での共同モデル学習を可能にするが、高通信コストなどで課題がある
- 新しい方法「能動的参加者中心の垂直連合学習（APC-VFL）」を提案し、参加者間の通信を1ラウンドに削減した
- 無監督表現学習と知識蒸留を組み合わせ、古典的な方法と同等の精度を実現し通信ラウンドを最大4200倍削減
- 提案手法は非連合的なローカルモデルや他の連合学習提案とも比較し効率的かつ柔軟であることを示した

参加者同士の通信ラウンドが1回で済むの、めっちゃ効率的じゃない！？しかも精度を維持しつつ柔軟性があるなんて、今後の連合学習のプラットフォームのありかたがガラリと変わっちゃうかも！🌟



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-23 08:07


- - -

### [Securing Federated Learning Against Novel and Classic Backdoor Threats During Foundation Model Integration](http://arxiv.org/abs/2410.17573)

**基盤モデル統合中の新しいおよび古典的なバックドア脅威に対抗する連合学習のセキュリティ確保**

Xiaohuan Bi, Xi Li

- 基盤モデルを連合学習に統合することで、新たなバックドア攻撃のメカニズムが生じている。
- 攻撃者は、合成データを利用してバックドアを埋め込むことで、クライアントモデルを感染させる。
- 提案された防御策はデータなしで隠れた特徴空間の異常活動を制約し、モデル性能への影響を最小限に抑える。
- 提案手法は、新旧のバックドア攻撃に対して効果的で、既存の防御よりも優れることを実証。

連合学習と基盤モデルの統合で、新たな問題も生まれちゃったんだね。でも、この論文はその対策をうまく考えてるみたい！未来のプライバシー技術がもっと進化しそう🌟



**トピック:** [連合学習](../../fl), [合成データ](../../sd), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-23 05:54


- - -

### [Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering](http://arxiv.org/abs/2410.17484)

**どのクライアントが信頼できるか？：医療画像質問応答のための信頼性の高いパーソナライズされたプロンプトベースの連合学習**

He Zhu, Ren Togo, Takahiro Ogawa, Miki Haseyama

- 通常の医療AIモデルは、プライバシーの敏感な特徴を扱えず倫理的問題を引き起こす
- パーソナライズされた連合学習(pFL)で医療分野のプライバシー信頼性を改善
- transformerに学習可能なプロンプトを加え、多様な医療データ上で効率的なトレーニングを実現
- デンプスター・シェーファーの証拠理論を用いて予測の不確実性を定量化、モデルの信頼性を向上

医療画像を扱う連合学習で信頼性を重点的に改善するってすごいね！プライバシーを守りながらより正確な医療AIモデルが生まれると、より多くの分野で役立つかも！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CV, cs.CL, cs.LG, **投稿日時:** 2024-10-23 00:31


- - -

### [Data Obfuscation through Latent Space Projection (LSP) for Privacy-Preserving AI Governance: Case Studies in Medical Diagnosis and Finance Fraud Detection](http://arxiv.org/abs/2410.17459)

**プライバシー保護AIガバナンスのための潜在空間投影によるデータ難読化：医療診断と金融詐欺検出のケーススタディ**

Mahesh Vaijainthymala Krishnamoorthy

- LSPは機械学習を使ってデータを潜在空間に投影し、データの本質を保ちながら効果的に難読化する技術
- 差分プライバシーや準同型暗号などの従来技術とは異なり、抽象化された低次元形式でデータ処理を実現
- 自動エンコーダーと敵対的訓練を用いてプライバシーとデータ有用性のトレードオフを精密に制御
- LSPは既存のプライバシー方法を上回る性能を示し、AIガバナンスの枠組みとの整合性も強調

新しいプライバシー技術が、医療や金融の分野でめちゃ役立ちそうな予感！それがAIガバナンスにもフィットしてるの、本当に未来感あるよね。これからのAIシステム、ますます楽しみになっちゃう！

**Comment:** 19 pages, 6 figures, submitted to Conference ICADCML2025

**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), [準同型暗号](../../he), **カテゴリ:** cs.LG, cs.AI, cs.CR, cs.CY, F.2.1; E.3, **投稿日時:** 2024-10-22 22:31


- - -

### [Meta Stackelberg Game: Robust Federated Learning against Adaptive and Mixed Poisoning Attacks](http://arxiv.org/abs/2410.17431)

**メタ・スタッケルベルクゲーム: 適応的および混合的なポイズニング攻撃に対する頑強な連合学習**

Tao Li, Henger Li, Yunian Pan, Tianyi Xu, Zizhan Zheng, Quanyan Zhu

- 連合学習は多様なセキュリティ脅威に脆弱
- 提案手法は、ベイズ・スタッケルベルク・マルコフゲームとして敵対的連合学習を定式化
- 強力な攻撃行動をシミュレートし、適応的攻撃に対抗するメタRLベースの防御を設計
- 理論的に提案手法は決まった点に集まり、多様な攻撃に対して優れた性能を示す

この論文、ポイズニング攻撃への対策としてすごく革新的！ゲーム理論を使って強力な防御ができるとか、実際に試してみたくなるよね。きっとサイバーセキュリティの世界がもっとクールになるはず！

**Comment:** This work has been submitted to the IEEE for possible publication

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, cs.GT, **投稿日時:** 2024-10-22 21:08


- - -

### [Beyond Yao's Millionaires: Secure Multi-Party Computation of Non-Polynomial Functions](http://arxiv.org/abs/2410.17000)

**ヤオの百万長者問題を超えて：非多項式関数の安全なマルチパーティ計算**

Seyed Reza Hoseini Najarkolaei, Mohammad Mahdi Mojahedian, Mohammad Reza Aref

- シャミア秘密分散を用いて、秘密の入力を明かさずに$N$個のプライベートな数の最大値を決定するスキームを提案
- 提案スキームは、計算複雑性が低く、既存の二つの数を比較する方法より効率的である
- 提案スキームは情報理論的に安全で、最小値、中央値、順位などの非多項式関数の計算も可能
- フェデレーテッドラーニングを含む様々な応用が考えられ、各パーティが結果の一部を保持する

この論文は、連合学習に使えそうな秘密計算の進化を感じる！シャミア秘密分散を駆使するところとか、ちょっとワクワクしない？私たちのデータをしっかり守りながら、みんなで賢く学んでいける未来が楽しみだなぁ。

**Comment:** 11 pages, 4 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.CR, cs.IT, math.IT, **投稿日時:** 2024-10-22 13:22


- - -

### [Federated Causal Inference: Multi-Centric ATE Estimation beyond Meta-Analysis](http://arxiv.org/abs/2410.16870)

**連合因果推論: メタアナリシスを超えた多中心ATE推定**

Rémi Khellaf, Aurélien Bellet, Julie Josse

- 連合因果推論が分散データから治療効果を推定する方法として研究
- ATE推定器を3種比較：メタ分析、単回連合学習、多回連合学習
- 線形モデルにおけるこれらの推定器の漸近分散をRCTに基づいて導出
- シナリオに応じた適切な推定器選択のための実践的ガイダンスを提供

これ、すごいよね！連合学習を使って因果推論を進化させちゃうなんて。RCTの結果を効率的にまとめる方法が増えたら、きっと医療とかでも大活躍だよね。🔍💡✨



**トピック:** [連合学習](../../fl), **カテゴリ:** stat.ML, cs.LG, math.ST, stat.TH, **投稿日時:** 2024-10-22 10:19


- - -

### [Subword Embedding from Bytes Gains Privacy without Sacrificing Accuracy and Complexity](http://arxiv.org/abs/2410.16410)

**バイトからのサブワード埋め込みは精度と複雑性を犠牲にせずプライバシーを向上させる**

Mengjiao Zhang, Jia Xu

- NLPモデルのプライバシー侵害が懸念され、特に埋め込み攻撃の防護が課題である
- 提案手法であるSEBは、サブワードをバイト列にエンコードし、テキスト回復を困難にする
- SEBは小さなメモリで効率を維持し、埋め込み攻撃からの保護を強化する
- 機械翻訳や言語モデリングで標準手法よりも優れた精度と効率を証明

攻撃からのプライバシー保護をしつつ、効率もアップするなんて夢みたい！データを守りつつ進化する技術の可能性がいっぱいで、未来の私たちの生活を考えるとワクワクしちゃうね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.AI, **投稿日時:** 2024-10-21 18:25


- - -

### [DMM: Distributed Matrix Mechanism for Differentially-Private Federated Learning using Packed Secret Sharing](http://arxiv.org/abs/2410.16161)

**差分プライベート連合学習のための分散行列機構：パック秘密共有を用いて**

Alexander Bienstock, Ujjwal Kumar, Antigoni Polychroniadou

- 連合学習では、異なるユーザーのデータを用いてプライバシーを守ることが課題
- 中央DPとローカルDPの違いは、データのノイズ処理のタイミングと場所にある
- 分散行列機構を提案し、ローカルDPにおいてもプライバシーとユーティリティのバランスを改善
- 提案手法により、ユーザーの動的な参加に対応しつつプライバシーを向上

新しい仕組みで課題を解決できるのってすごいね！プライバシーを守りつつパフォーマンスを高めるって、これからもっといろんな分野に広がりそう！



**トピック:** [連合学習](../../fl), [差分プライバシー](../../dp), **カテゴリ:** cs.CR, cs.LG, **投稿日時:** 2024-10-21 16:25


- - -

### [Extracting Spatiotemporal Data from Gradients with Large Language Models](http://arxiv.org/abs/2410.16121)

**大規模言語モデルを用いた勾配からの時空間データ抽出**

Lele Zheng, Yang Cao, Renhe Jiang, Kenjiro Taura, Yulong Shen, Sheng Li, Masatoshi Yoshikawa

- 連合学習では勾配更新からユーザーデータが再構築され、プライバシーが脅かされている
- 画像データでの成功事例はあるが、時空間データには直接適用できない
- ST-GIAとST-GIA+を提案、勾配からの位置再構築を成功させる
- 動的に摂動を調整した防御戦略により、プライバシーと有用性のトレードオフを改善

連合学習ってデータのプライバシーを守る技術なのに、逆に情報が漏れちゃうなんてびっくり！やっぱり、防御もちょっとした工夫でプライバシーも守りつつ学習もできるようになるんだね。そんな技術の進歩のスピード感にワクワクしちゃう！

**Comment:** arXiv admin note: substantial text overlap with arXiv:2407.08529

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-21 15:48


- - -

### [Distributed Learning for UAV Swarms](http://arxiv.org/abs/2410.15882)

**UAV群のための分散学習**

Chen Hu, Hanchi Ren, Jingjing Deng, Xianghua Xie

- 環境モニタリングや監視にUAV群を活用する場面で、連合学習がプライバシーとセキュリティの課題に対する有望な解決策となる
- UAVが収集するデータは非IIDであるため、FedAvg, FedProx, FedOpt, MOONなどの多様な集約方法を検討
- FedProxは、非IID環境下で最も安定した性能を示し、ローカル更新を正規化する重要性を確認
- ベースラインのMNISTから監視向けのCelebAまで、データセットごとに異なるアルゴリズム性能を比較

UAVが協力して学習する世界なんて、未来を感じちゃうよね。みんなで情報を交換しながら、それぞれのお仕事をきちんとこなしていけるなんてすごいかっこいい！FedProxの安定した性能がどんな風に活かされていくのか、これからが楽しみだね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CV, cs.RO, **投稿日時:** 2024-10-21 11:01


- - -

### [Geographical Node Clustering and Grouping to Guarantee Data IIDness in Federated Learning](http://arxiv.org/abs/2410.15693)

**連合学習におけるデータIID性を保証する地理的ノードクラスタリングとグルーピング**

Minkwon Lee, Hyoil Kim, Changhee Joo

- 連合学習では非IIDデータセット問題が大きな課題で、多くの試みが行われている
- 本論文は、地理的特徴を用いたIoTノードのクラスタリングとグルーピングを提案
- Dynamic ClusteringとPartial-Steady GroupingアルゴリズムでデータセットのIID性を改善
- 提案手法は、離脱デバイス数と各グループの均一性におけるコストを既存手法より110倍以上改善

IoTデバイスの地理情報を使ってデータの特性を改善するアイデアが新しいよね！これでたくさんのデバイスが集まっても効率的に学習できちゃうのがすごいかも。これからもっとスマートに連携していけそうだね。

**Comment:** 10 pages, 7 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.AI, cs.NI, **投稿日時:** 2024-10-21 07:03


- - -

### [Federated Learning with MMD-based Early Stopping for Adaptive GNSS Interference Classification](http://arxiv.org/abs/2410.15681)

**適応的GNSS干渉分類のためのMMDベース早期停止を用いた連合学習**

Nishant S. Gaikwad, Lucas Heublein, Nisha L. Raichur, Tobias Feigl, Christopher Mutschler, Felix Ott

- 連合学習は複数デバイスでグローバルモデルを共同訓練するが、データの偏りが課題
- 提案手法は少数ショット学習とモデル重みのグローバルサーバーでの集約を組み合わせる
- ローカルとグローバルモデル間の特徴埋め込みの最大平均差異を利用し動的早期停止を導入
- 提案手法は最新技術を上回り、新規の干渉クラスやマルチパスシナリオに適応可能と判明

連合学習が新しいデータに対してどう適応するのかを工夫していて面白そう！親しみやすい具体例もあって、実際の応用がイメージできるね。個々のデバイスでの偏りを解決するアイデアが魅力的だと思うなあ。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, 62P30, 68T30, 68T05, 68T37, G.3; I.2.4; I.2.6, **投稿日時:** 2024-10-21 06:43


- - -

### [Bayesian data fusion for distributed learning](http://arxiv.org/abs/2410.15473)

**分散学習のためのベイジアンデータ融合**

Peng Wu, Tales Imbiriba, Pau Closas

- 連合学習の課題は、クライアント間のデータ分布の不均等性による非独立かつ非同一分布データの処理
- 知識共有とモデルの個別化が重要で、クライアントを同様のデータ分布でクラスタ化する方法を提案
- 本研究では、クライアントをクラスタに関連付けるベイジアンフレームワークを提案し、実際のアルゴリズムを提供
- 提案フレームワークは一意のクライアント-クラスタ関連付けを不要にし、モデルの性能が向上

この論文、クライアントごとに異なるデータをうまく扱おうとしていて、すごくおもしろそう！クラスターごとにモデルを改善していく方法は、他の分野にも応用できそうだね。未来にわくわくしちゃう！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.DC, stat.ML, **投稿日時:** 2024-10-20 19:11


- - -

### [Tighter Performance Theory of FedExProx](http://arxiv.org/abs/2410.15368)

**FedExProxの強化パフォーマンス理論**

Wojciech Anyszka, Kaja Gruntkowska, Alexander Tyurin, Peter Richtárik

- FedExProxの理論的保証が従来の勾配降下法と同水準なのが発覚
- 新たな解析で非強凸二次問題に対する収束率を改善
- 計算・通信コストを考慮し、部分参加シナリオでもFedExProxが優位
- 一般関数での適用性を拡大し、従来の強凸解析を超える成果を発揮

FedExProxが最初の評価を覆してかなり役立ちそうな技法に変貌したのが面白い！これを使った連合学習の新たな可能性がどんどん広がりそうでワクワクするね。

**Comment:** 43 pages, 4 figures

**トピック:** [連合学習](../../fl), **カテゴリ:** math.OC, cs.LG, stat.ML, **投稿日時:** 2024-10-20 11:53


- - -

### [DPVS-Shapley:Faster and Universal Contribution Evaluation Component in Federated Learning](http://arxiv.org/abs/2410.15093)

**DPVS-Shapley:連合学習における高速かつ汎用的な貢献評価コンポーネント**

Ketin Yin, Zonghao Guo, ZhengHan Qin

- 連合学習はデータプライバシーとシステムの拡張性を向上させる新しい学習方法。
- 公平な貢献評価は連合学習における参加者の動機づけに不可欠な要素。
- 動的プルーニングにより評価プロセスを高速化し、精度を損なわない解法を提案。
- DPVS-Shapleyは難易度の高い例を識別できる参加者により高い貢献スコアを付与可能。

参加者の貢献度に対して公平で早い評価を提供する技術って、すごく大切だよね！DPVS-Shapleyのアプローチが色々な領域で役立ちそうで楽しみ！どんな結果をもたらすか気になるね。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, cs.GT, **投稿日時:** 2024-10-19 13:01


- - -

### [Personalized Federated Learning with Adaptive Feature Aggregation and Knowledge Transfer](http://arxiv.org/abs/2410.15073)

**適応的特徴集約と知識伝達による個別化連合学習**

Keting Yin, Jiayi Mao

- 非独立同分布（Non-IID）データでのパーソナライズモデル向けに提案された新手法
- Global modelの知識を活用し、パーソナライゼーションと汎化のバランスを向上
- 三つのデータセットで多数のベンチマークを超える優れた性能を実証
- 適応的特徴集約と知識伝達を駆使し、統計的異質性問題に対処

この研究は、個別対応の機械学習の未来を変える可能性があるね！自分だけのモデルを持つなんて、ちょっと特別な感じで素敵！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.CR, **投稿日時:** 2024-10-19 11:32


- - -

### [FedSpaLLM: Federated Pruning of Large Language Models](http://arxiv.org/abs/2410.14852)

**FedSpaLLM: 大規模言語モデルの連合プルーニング**

Guangji Bai, Yijiang Li, Zilinghan Li, Liang Zhao, Kibaek Kim

- 大規模言語モデルは高性能だが計算負荷やストレージ需要が課題
- プライバシーに配慮し、FedSpaLLMがモデルをローカルでプルーニング
- 独自の$\ell_0$-ノルム集約関数で重要なモデルパラメータ保持を実現
- レイヤーサンプリングにより通信オーバーヘッド削減とプライニングのカスタマイズを推進

連合学習を使ってプライバシーを守りながら、効率よくモデルを軽量化する技術を提案してるみたい。データのプライバシーを守りつつ計算コストも減らせるなんて、すごく実用的で面白そう！これが広まると、もっと便利になりそうだね。

**Comment:** Preprint

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.CR, **投稿日時:** 2024-10-18 20:33


- - -

### [Personalizing Low-Rank Bayesian Neural Networks Via Federated Learning](http://arxiv.org/abs/2410.14390)

**連合学習による低ランクベイズニューラルネットワークの個別化**

Boning Zhang, Dongzhu Liu, Osvaldo Simeone, Guanchu Wang, Dimitrios Pezaros, Guangxu Zhu

- モデルが現実世界での意思決定に不可欠であり、予測に信頼性のある信頼度を持たせる必要がある
- 個別化連合学習では不確実性の定量化が重要だが、ローカルデータが少なく最適なモデルパラメータを決定しにくい
- 提案手法LR-BPFLは、グローバルな決定論的モデルと低ランクなベイズ補正を学習し、クライアントごとの不確実性に適応
- LR-BPFLは様々なデータセットで評価され、キャリブレーションや精度、計算とメモリの要件で利点を示す

この論文は、パーソナライズされたモデルをよりスマートに作る方法を提案しているね！クライアントごとに適応するから、多様なデータに対応できてなんかワクワクするよね。いつか私たちも使って自分専用のモデルを作ってみたいな～。



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, **投稿日時:** 2024-10-18 11:50


- - -

### [Comparative Evaluation of Clustered Federated Learning Method](http://arxiv.org/abs/2410.14212)

**クラスタ化連合学習法の比較評価**

Michael Ben Ali, Omar El-Rifai, Imen Megdiche, André Peninou, Olivier Teste

- 連合学習は分散学習の一手法であり、データプライバシーを保護する
- 非IIDデータ分布がFLプロトコルの参加者間で生じるのが課題
- クラスター化連合学習（CFL）は参加者を均質な分布に分ける手法
- 提案するデータ異質性の分類に基づき、2つのCFLアルゴリズムの性能を評価

クラスター化連合学習って、学習グループを使い分ける工夫で効率が上がるみたい！データがバラバラでもやり方次第でいい結果を出せるんだね。将来もっと使いやすくなると良いなぁ。



**トピック:** [連合学習](../../fl), **カテゴリ:** stat.ML, cs.LG, **投稿日時:** 2024-10-18 07:01


- - -

### [FedMSE: Federated learning for IoT network intrusion detection](http://arxiv.org/abs/2410.14121)

**FedMSE: IoTネットワーク侵入検知のための連合学習**

Van Tuan Nguyen, Razvan Beuran

- IoTの拡大でサイバー攻撃のリスク増加、従来の集中型学習ではプライバシーが課題
- 半教師あり連合学習により、異常検知を強化するSAE-CENモデルを提案
- MSEAvgアルゴリズムで、正確なローカルモデルを重視しグローバル性能を向上
- 実験では、異なるIoTネットワークでの検出精度と学習コストを改善し、堅牢性を示す

連合学習を使ってIoTの侵入検知を効率化するって、すごく未来的だよね！半教師ありってことはちょっとギリギリ知らないデータでもいけちゃうのかな？ワクワクするね！



**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, **投稿日時:** 2024-10-18 02:23


- - -

### [A Communication and Computation Efficient Fully First-order Method for Decentralized Bilevel Optimization](http://arxiv.org/abs/2410.14115)

**通信と計算が効率的な分散双レベル最適化のための完全一階手法**

Min Wen, Chengchang Liu, Ahmed Abdelmoniem, Yipeng Zhou, Yuedong Xu

- 双レベル最適化は分散学習であまり探求されていない
- 従来の手法は計算と通信の負荷が高い二階情報を利用
- この研究は一階情報のみを使用し効率的な方法を提案
- 提案手法は様々なデータ分布で優れた性能を実証

この論文、分散環境でも双レベル最適化を一階情報で進めるなんてすごいね！特に通信の効率化が注目ポイントだし、どんな場面で応用されるのか気になるよ。

**Comment:** 19 Pages

**トピック:** [連合学習](../../fl), **カテゴリ:** cs.LG, cs.AI, cs.DC, math.OC, **投稿日時:** 2024-10-18 02:00
